{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Generative Models of Graphs\n\n**Author**: [Mufei Li](https://github.com/mufeili),\n[Lingfan Yu](https://github.com/ylfdq1118), Zheng Zhang\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The tutorial aims at gaining insights into the paper, with code as a mean\n    of explanation. The implementation thus is NOT optimized for running\n    efficiency. For recommended implementation, please refer to the [official\n    examples](https://github.com/dmlc/dgl/tree/master/examples).</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, you learn how to train and generate one graph at\na time. You also explore parallelism within the graph embedding operation, which is an\nessential building block. The tutorial ends with a simple optimization that\ndelivers double the speed by batching across graphs.\n\nEarlier tutorials showed how embedding a graph or\na node enables you to work on tasks such as [semi-supervised classification for nodes](http://docs.dgl.ai/tutorials/models/1_gcn.html#sphx-glr-tutorials-models-1-gcn-py)_\nor [sentiment analysis](http://docs.dgl.ai/tutorials/models/3_tree-lstm.html#sphx-glr-tutorials-models-3-tree-lstm-py)_.\nWouldn't it be interesting to predict the future evolution of the graph and\nperform the analysis iteratively?\n\nTo address the evolution of the graphs, you generate a variety of graph samples. In other words, you need\n**generative models** of graphs. In-addition to learning\nnode and edge features, you would need to model the distribution of arbitrary graphs.\nWhile general generative models can model the density function explicitly and\nimplicitly and generate samples at once or sequentially, you only focus\non explicit generative models for sequential generation here. Typical applications\ninclude drug or materials discovery, chemical processes, or proteomics.\n\n## Introduction\nThe primitive actions of mutating a graph in Deep Graph Library (DGL) are nothing more than ``add_nodes``\nand ``add_edges``. That is, if you were to draw a circle of three nodes,\n\n.. figure:: https://user-images.githubusercontent.com/19576924/48313438-78baf000-e5f7-11e8-931e-cd00ab34fa50.gif\n   :alt:\n\nyou can write the code as follows.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nos.environ[\"DGLBACKEND\"] = \"pytorch\"\nimport dgl\n\ng = dgl.DGLGraph()\ng.add_nodes(1)  # Add node 0\ng.add_nodes(1)  # Add node 1\n\n# Edges in DGLGraph are directed by default.\n# For undirected edges, add edges for both directions.\ng.add_edges([1, 0], [0, 1])  # Add edges (1, 0), (0, 1)\ng.add_nodes(1)  # Add node 2\ng.add_edges([2, 1], [1, 2])  # Add edges (2, 1), (1, 2)\ng.add_edges([2, 0], [0, 2])  # Add edges (2, 0), (0, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Real-world graphs are much more complex. There are many families of graphs,\nwith different sizes, topologies, node types, edge types, and the possibility\nof multigraphs. Besides, a same graph can be generated in many different\norders. Regardless, the generative process entails a few steps.\n\n- Encode a changing graph.\n- Perform actions stochastically.\n- If you are training, collect error signals and optimize the model parameters.\n\nWhen it comes to implementation, another important aspect is speed. How do you\nparallelize the computation, given that generating a graph is fundamentally a\nsequential process?\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>To be sure, this is not necessarily a hard constraint. Subgraphs can be\n   built in parallel and then get assembled. But we\n   will restrict ourselves to the sequential processes for this tutorial.</p></div>\n\n\n## DGMG: The main flow\nFor this tutorial, you use\n[Deep Generative Models of Graphs](https://arxiv.org/abs/1803.03324)_\n) (DGMG) to implement a graph generative model using DGL. Its algorithmic\nframework is general but also challenging to parallelize.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>While it's possible for DGMG to handle complex graphs with typed nodes,\n   typed edges, and multigraphs, here you use a simplified version of it\n   for generating graph topologies.</p></div>\n\nDGMG generates a graph by following a state machine, which is basically a\ntwo-level loop. Generate one node at a time and connect it to a subset of\nthe existing nodes, one at a time. This is similar to language modeling. The\ngenerative process is an iterative one that emits one word or character or sentence\nat a time, conditioned on the sequence generated so far.\n\nAt each time step, you either:\n     - Add a new node to the graph\n     - Select two existing nodes and add an edge between them\n\n.. figure:: https://user-images.githubusercontent.com/19576924/48605003-7f11e900-e9b6-11e8-8880-87362348e154.png\n   :alt:\n\nThe Python code will look as follows. In fact, this is *exactly* how inference\nwith DGMG is implemented in DGL.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward_inference(self):\n    stop = self.add_node_and_update()\n    while (not stop) and (self.g.num_nodes() < self.v_max + 1):\n        num_trials = 0\n        to_add_edge = self.add_edge_or_not()\n        while to_add_edge and (num_trials < self.g.num_nodes() - 1):\n            self.choose_dest_and_update()\n            num_trials += 1\n            to_add_edge = self.add_edge_or_not()\n        stop = self.add_node_and_update()\n    return self.g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assume you have a pre-trained model for generating cycles of nodes 10-20.\nHow does it generate a cycle on-the-fly during inference? Use the code below\nto create an animation with your own model.\n\n::\n\n    import torch\n    import matplotlib.animation as animation\n    import matplotlib.pyplot as plt\n    import networkx as nx\n    from copy import deepcopy\n\n    if __name__ == '__main__':\n        # pre-trained model saved with path ./model.pth\n        model = torch.load('./model.pth')\n        model.eval()\n        g = model()\n\n        src_list = g.edges()[1]\n        dest_list = g.edges()[0]\n\n        evolution = []\n\n        nx_g = nx.Graph()\n        evolution.append(deepcopy(nx_g))\n\n        for i in range(0, len(src_list), 2):\n            src = src_list[i].item()\n            dest = dest_list[i].item()\n            if src not in nx_g.nodes():\n                nx_g.add_node(src)\n                evolution.append(deepcopy(nx_g))\n            if dest not in nx_g.nodes():\n                nx_g.add_node(dest)\n                evolution.append(deepcopy(nx_g))\n            nx_g.add_edges_from([(src, dest), (dest, src)])\n            evolution.append(deepcopy(nx_g))\n\n        def animate(i):\n            ax.cla()\n            g_t = evolution[i]\n            nx.draw_circular(g_t, with_labels=True, ax=ax,\n                             node_color=['#FEBD69'] * g_t.num_nodes())\n\n        fig, ax = plt.subplots()\n        ani = animation.FuncAnimation(fig, animate,\n                                      frames=len(evolution),\n                                      interval=600)\n\n.. figure:: https://user-images.githubusercontent.com/19576924/48928548-2644d200-ef1b-11e8-8591-da93345382ad.gif\n   :alt:\n\n## DGMG: Optimization objective\nSimilar to language modeling, DGMG trains the model with *behavior cloning*,\nor *teacher forcing*. Assume for each graph there exists a sequence of\n*oracle actions* $a_{1},\\cdots,a_{T}$ that generates it. What the model\ndoes is to follow these actions, compute the joint probabilities of such\naction sequences, and maximize them.\n\nBy chain rule, the probability of taking $a_{1},\\cdots,a_{T}$ is:\n\n\\begin{align}p(a_{1},\\cdots, a_{T}) = p(a_{1})p(a_{2}|a_{1})\\cdots p(a_{T}|a_{1},\\cdots,a_{T-1}).\\\\\\end{align}\n\nThe optimization objective is then simply the typical MLE loss:\n\n\\begin{align}-\\log p(a_{1},\\cdots,a_{T})=-\\sum_{t=1}^{T}\\log p(a_{t}|a_{1},\\cdots, a_{t-1}).\\\\\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward_train(self, actions):\n    \"\"\"\n    - actions: list\n        - Contains a_1, ..., a_T described above\n    - self.prepare_for_train()\n        - Initializes self.action_step to be 0, which will get\n          incremented by 1 every time it is called.\n        - Initializes objects recording log p(a_t|a_1,...a_{t-1})\n\n    Returns\n    -------\n    - self.get_log_prob(): log p(a_1, ..., a_T)\n    \"\"\"\n    self.prepare_for_train()\n\n    stop = self.add_node_and_update(a=actions[self.action_step])\n    while not stop:\n        to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n        while to_add_edge:\n            self.choose_dest_and_update(a=actions[self.action_step])\n            to_add_edge = self.add_edge_or_not(a=actions[self.action_step])\n        stop = self.add_node_and_update(a=actions[self.action_step])\n    return self.get_log_prob()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The key difference between ``forward_train`` and ``forward_inference`` is\nthat the training process takes oracle actions as input and returns log\nprobabilities for evaluating the loss.\n\n## DGMG: The implementation\nThe ``DGMG`` class\n``````````````````````````\nBelow you can find the skeleton code for the model. You gradually\nfill in the details for each function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\n\nclass DGMGSkeleton(nn.Module):\n    def __init__(self, v_max):\n        \"\"\"\n        Parameters\n        ----------\n        v_max: int\n            Max number of nodes considered\n        \"\"\"\n        super(DGMGSkeleton, self).__init__()\n\n        # Graph configuration\n        self.v_max = v_max\n\n    def add_node_and_update(self, a=None):\n        \"\"\"Decide if to add a new node.\n        If a new node should be added, update the graph.\"\"\"\n        return NotImplementedError\n\n    def add_edge_or_not(self, a=None):\n        \"\"\"Decide if a new edge should be added.\"\"\"\n        return NotImplementedError\n\n    def choose_dest_and_update(self, a=None):\n        \"\"\"Choose destination and connect it to the latest node.\n        Add edges for both directions and update the graph.\"\"\"\n        return NotImplementedError\n\n    def forward_train(self, actions):\n        \"\"\"Forward at training time. It records the probability\n        of generating a ground truth graph following the actions.\"\"\"\n        return NotImplementedError\n\n    def forward_inference(self):\n        \"\"\"Forward at inference time.\n        It generates graphs on the fly.\"\"\"\n        return NotImplementedError\n\n    def forward(self, actions=None):\n        # The graph you will work on\n        self.g = dgl.DGLGraph()\n\n        # If there are some features for nodes and edges,\n        # zero tensors will be set for those of new nodes and edges.\n        self.g.set_n_initializer(dgl.frame.zero_initializer)\n        self.g.set_e_initializer(dgl.frame.zero_initializer)\n\n        if self.training:\n            return self.forward_train(actions=actions)\n        else:\n            return self.forward_inference()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding a dynamic graph\nAll the actions generating a graph are sampled from probability\ndistributions. In order to do that, you project the structured data,\nnamely the graph, onto an Euclidean space. The challenge is that such\nprocess, called *embedding*, needs to be repeated as the graphs mutate.\n\n#### Graph embedding\nLet $G=(V,E)$ be an arbitrary graph. Each node $v$ has an\nembedding vector $\\textbf{h}_{v} \\in \\mathbb{R}^{n}$. Similarly,\nthe graph has an embedding vector $\\textbf{h}_{G} \\in \\mathbb{R}^{k}$.\nTypically, $k > n$ since a graph contains more information than\nan individual node.\n\nThe graph embedding is a weighted sum of node embeddings under a linear\ntransformation:\n\n\\begin{align}\\textbf{h}_{G} =\\sum_{v\\in V}\\text{Sigmoid}(g_m(\\textbf{h}_{v}))f_{m}(\\textbf{h}_{v}),\\\\\\end{align}\n\nThe first term, $\\text{Sigmoid}(g_m(\\textbf{h}_{v}))$, computes a\ngating function and can be thought of as how much the overall graph embedding\nattends on each node. The second term $f_{m}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{k}$\nmaps the node embeddings to the space of graph embeddings.\n\nImplement graph embedding as a ``GraphEmbed`` class.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\n\nclass GraphEmbed(nn.Module):\n    def __init__(self, node_hidden_size):\n        super(GraphEmbed, self).__init__()\n\n        # Setting from the paper\n        self.graph_hidden_size = 2 * node_hidden_size\n\n        # Embed graphs\n        self.node_gating = nn.Sequential(\n            nn.Linear(node_hidden_size, 1), nn.Sigmoid()\n        )\n        self.node_to_graph = nn.Linear(node_hidden_size, self.graph_hidden_size)\n\n    def forward(self, g):\n        if g.num_nodes() == 0:\n            return torch.zeros(1, self.graph_hidden_size)\n        else:\n            # Node features are stored as hv in ndata.\n            hvs = g.ndata[\"hv\"]\n            return (self.node_gating(hvs) * self.node_to_graph(hvs)).sum(\n                0, keepdim=True\n            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Update node embeddings via graph propagation\n\nThe mechanism of updating node embeddings in DGMG is similar to that for\ngraph convolutional networks. For a node $v$ in the graph, its\nneighbor $u$ sends a message to it with\n\n\\begin{align}\\textbf{m}_{u\\rightarrow v}=\\textbf{W}_{m}\\text{concat}([\\textbf{h}_{v}, \\textbf{h}_{u}, \\textbf{x}_{u, v}]) + \\textbf{b}_{m},\\\\\\end{align}\n\nwhere $\\textbf{x}_{u,v}$ is the embedding of the edge between\n$u$ and $v$.\n\nAfter receiving messages from all its neighbors, $v$ summarizes them\nwith a node activation vector\n\n\\begin{align}\\textbf{a}_{v} = \\sum_{u: (u, v)\\in E}\\textbf{m}_{u\\rightarrow v}\\\\\\end{align}\n\nand use this information to update its own feature:\n\n\\begin{align}\\textbf{h}'_{v} = \\textbf{GRU}(\\textbf{h}_{v}, \\textbf{a}_{v}).\\\\\\end{align}\n\nPerforming all the operations above once for all nodes synchronously is\ncalled one round of graph propagation. The more rounds of graph propagation\nyou perform, the longer distance messages travel throughout the graph.\n\nWith DGL, you implement graph propagation with ``g.update_all``.\nThe message notation here can be a bit confusing. Researchers can refer\nto $\\textbf{m}_{u\\rightarrow v}$ as messages, however the message function\nbelow only passes $\\text{concat}([\\textbf{h}_{u}, \\textbf{x}_{u, v}])$.\nThe operation $\\textbf{W}_{m}\\text{concat}([\\textbf{h}_{v}, \\textbf{h}_{u}, \\textbf{x}_{u, v}]) + \\textbf{b}_{m}$\nis then performed across all edges at once for efficiency consideration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import partial\n\n\nclass GraphProp(nn.Module):\n    def __init__(self, num_prop_rounds, node_hidden_size):\n        super(GraphProp, self).__init__()\n\n        self.num_prop_rounds = num_prop_rounds\n\n        # Setting from the paper\n        self.node_activation_hidden_size = 2 * node_hidden_size\n\n        message_funcs = []\n        node_update_funcs = []\n        self.reduce_funcs = []\n\n        for t in range(num_prop_rounds):\n            # input being [hv, hu, xuv]\n            message_funcs.append(\n                nn.Linear(\n                    2 * node_hidden_size + 1, self.node_activation_hidden_size\n                )\n            )\n\n            self.reduce_funcs.append(partial(self.dgmg_reduce, round=t))\n            node_update_funcs.append(\n                nn.GRUCell(self.node_activation_hidden_size, node_hidden_size)\n            )\n        self.message_funcs = nn.ModuleList(message_funcs)\n        self.node_update_funcs = nn.ModuleList(node_update_funcs)\n\n    def dgmg_msg(self, edges):\n        \"\"\"For an edge u->v, return concat([h_u, x_uv])\"\"\"\n        return {\"m\": torch.cat([edges.src[\"hv\"], edges.data[\"he\"]], dim=1)}\n\n    def dgmg_reduce(self, nodes, round):\n        hv_old = nodes.data[\"hv\"]\n        m = nodes.mailbox[\"m\"]\n        message = torch.cat(\n            [hv_old.unsqueeze(1).expand(-1, m.size(1), -1), m], dim=2\n        )\n        node_activation = (self.message_funcs[round](message)).sum(1)\n\n        return {\"a\": node_activation}\n\n    def forward(self, g):\n        if g.num_edges() > 0:\n            for t in range(self.num_prop_rounds):\n                g.update_all(\n                    message_func=self.dgmg_msg, reduce_func=self.reduce_funcs[t]\n                )\n                g.ndata[\"hv\"] = self.node_update_funcs[t](\n                    g.ndata[\"a\"], g.ndata[\"hv\"]\n                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Actions\nAll actions are sampled from distributions parameterized using neural networks\nand here they are in turn.\n\n#### Action 1: Add nodes\n\nGiven the graph embedding vector $\\textbf{h}_{G}$, evaluate\n\n\\begin{align}\\text{Sigmoid}(\\textbf{W}_{\\text{add node}}\\textbf{h}_{G}+b_{\\text{add node}}),\\\\\\end{align}\n\nwhich is then used to parametrize a Bernoulli distribution for deciding whether\nto add a new node.\n\nIf a new node is to be added, initialize its feature with\n\n\\begin{align}\\textbf{W}_{\\text{init}}\\text{concat}([\\textbf{h}_{\\text{init}} , \\textbf{h}_{G}])+\\textbf{b}_{\\text{init}},\\\\\\end{align}\n\nwhere $\\textbf{h}_{\\text{init}}$ is a learnable embedding module for\nuntyped nodes.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\nfrom torch.distributions import Bernoulli\n\n\ndef bernoulli_action_log_prob(logit, action):\n    \"\"\"Calculate the log p of an action with respect to a Bernoulli\n    distribution. Use logit rather than prob for numerical stability.\"\"\"\n    if action == 0:\n        return F.logsigmoid(-logit)\n    else:\n        return F.logsigmoid(logit)\n\n\nclass AddNode(nn.Module):\n    def __init__(self, graph_embed_func, node_hidden_size):\n        super(AddNode, self).__init__()\n\n        self.graph_op = {\"embed\": graph_embed_func}\n\n        self.stop = 1\n        self.add_node = nn.Linear(graph_embed_func.graph_hidden_size, 1)\n\n        # If to add a node, initialize its hv\n        self.node_type_embed = nn.Embedding(1, node_hidden_size)\n        self.initialize_hv = nn.Linear(\n            node_hidden_size + graph_embed_func.graph_hidden_size,\n            node_hidden_size,\n        )\n\n        self.init_node_activation = torch.zeros(1, 2 * node_hidden_size)\n\n    def _initialize_node_repr(self, g, node_type, graph_embed):\n        \"\"\"Whenver a node is added, initialize its representation.\"\"\"\n        num_nodes = g.num_nodes()\n        hv_init = self.initialize_hv(\n            torch.cat(\n                [\n                    self.node_type_embed(torch.LongTensor([node_type])),\n                    graph_embed,\n                ],\n                dim=1,\n            )\n        )\n        g.nodes[num_nodes - 1].data[\"hv\"] = hv_init\n        g.nodes[num_nodes - 1].data[\"a\"] = self.init_node_activation\n\n    def prepare_training(self):\n        self.log_prob = []\n\n    def forward(self, g, action=None):\n        graph_embed = self.graph_op[\"embed\"](g)\n\n        logit = self.add_node(graph_embed)\n        prob = torch.sigmoid(logit)\n\n        if not self.training:\n            action = Bernoulli(prob).sample().item()\n        stop = bool(action == self.stop)\n\n        if not stop:\n            g.add_nodes(1)\n            self._initialize_node_repr(g, action, graph_embed)\n        if self.training:\n            sample_log_prob = bernoulli_action_log_prob(logit, action)\n\n            self.log_prob.append(sample_log_prob)\n        return stop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Action 2: Add edges\n\nGiven the graph embedding vector $\\textbf{h}_{G}$ and the node\nembedding vector $\\textbf{h}_{v}$ for the latest node $v$,\nyou evaluate\n\n\\begin{align}\\text{Sigmoid}(\\textbf{W}_{\\text{add edge}}\\text{concat}([\\textbf{h}_{G}, \\textbf{h}_{v}])+b_{\\text{add edge}}),\\\\\\end{align}\n\nwhich is then used to parametrize a Bernoulli distribution for deciding\nwhether to add a new edge starting from $v$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class AddEdge(nn.Module):\n    def __init__(self, graph_embed_func, node_hidden_size):\n        super(AddEdge, self).__init__()\n\n        self.graph_op = {\"embed\": graph_embed_func}\n        self.add_edge = nn.Linear(\n            graph_embed_func.graph_hidden_size + node_hidden_size, 1\n        )\n\n    def prepare_training(self):\n        self.log_prob = []\n\n    def forward(self, g, action=None):\n        graph_embed = self.graph_op[\"embed\"](g)\n        src_embed = g.nodes[g.num_nodes() - 1].data[\"hv\"]\n\n        logit = self.add_edge(torch.cat([graph_embed, src_embed], dim=1))\n        prob = torch.sigmoid(logit)\n\n        if self.training:\n            sample_log_prob = bernoulli_action_log_prob(logit, action)\n            self.log_prob.append(sample_log_prob)\n        else:\n            action = Bernoulli(prob).sample().item()\n        to_add_edge = bool(action == 0)\n        return to_add_edge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Action 3: Choose a destination\n\nWhen action 2 returns `True`, choose a destination for the\nlatest node $v$.\n\nFor each possible destination $u\\in\\{0, \\cdots, v-1\\}$, the\nprobability of choosing it is given by\n\n\\begin{align}\\frac{\\text{exp}(\\textbf{W}_{\\text{dest}}\\text{concat}([\\textbf{h}_{u}, \\textbf{h}_{v}])+\\textbf{b}_{\\text{dest}})}{\\sum_{i=0}^{v-1}\\text{exp}(\\textbf{W}_{\\text{dest}}\\text{concat}([\\textbf{h}_{i}, \\textbf{h}_{v}])+\\textbf{b}_{\\text{dest}})}\\\\\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.distributions import Categorical\n\n\nclass ChooseDestAndUpdate(nn.Module):\n    def __init__(self, graph_prop_func, node_hidden_size):\n        super(ChooseDestAndUpdate, self).__init__()\n\n        self.graph_op = {\"prop\": graph_prop_func}\n        self.choose_dest = nn.Linear(2 * node_hidden_size, 1)\n\n    def _initialize_edge_repr(self, g, src_list, dest_list):\n        # For untyped edges, only add 1 to indicate its existence.\n        # For multiple edge types, use a one-hot representation\n        # or an embedding module.\n        edge_repr = torch.ones(len(src_list), 1)\n        g.edges[src_list, dest_list].data[\"he\"] = edge_repr\n\n    def prepare_training(self):\n        self.log_prob = []\n\n    def forward(self, g, dest):\n        src = g.num_nodes() - 1\n        possible_dests = range(src)\n\n        src_embed_expand = g.nodes[src].data[\"hv\"].expand(src, -1)\n        possible_dests_embed = g.nodes[possible_dests].data[\"hv\"]\n\n        dests_scores = self.choose_dest(\n            torch.cat([possible_dests_embed, src_embed_expand], dim=1)\n        ).view(1, -1)\n        dests_probs = F.softmax(dests_scores, dim=1)\n\n        if not self.training:\n            dest = Categorical(dests_probs).sample().item()\n        if not g.has_edges_between(src, dest):\n            # For undirected graphs, add edges for both directions\n            # so that you can perform graph propagation.\n            src_list = [src, dest]\n            dest_list = [dest, src]\n\n            g.add_edges(src_list, dest_list)\n            self._initialize_edge_repr(g, src_list, dest_list)\n\n            self.graph_op[\"prop\"](g)\n        if self.training:\n            if dests_probs.nelement() > 1:\n                self.log_prob.append(\n                    F.log_softmax(dests_scores, dim=1)[:, dest : dest + 1]\n                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Putting it together\n\nYou are now ready to have a complete implementation of the model class.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DGMG(DGMGSkeleton):\n    def __init__(self, v_max, node_hidden_size, num_prop_rounds):\n        super(DGMG, self).__init__(v_max)\n\n        # Graph embedding module\n        self.graph_embed = GraphEmbed(node_hidden_size)\n\n        # Graph propagation module\n        self.graph_prop = GraphProp(num_prop_rounds, node_hidden_size)\n\n        # Actions\n        self.add_node_agent = AddNode(self.graph_embed, node_hidden_size)\n        self.add_edge_agent = AddEdge(self.graph_embed, node_hidden_size)\n        self.choose_dest_agent = ChooseDestAndUpdate(\n            self.graph_prop, node_hidden_size\n        )\n\n        # Forward functions\n        self.forward_train = partial(forward_train, self=self)\n        self.forward_inference = partial(forward_inference, self=self)\n\n    @property\n    def action_step(self):\n        old_step_count = self.step_count\n        self.step_count += 1\n\n        return old_step_count\n\n    def prepare_for_train(self):\n        self.step_count = 0\n\n        self.add_node_agent.prepare_training()\n        self.add_edge_agent.prepare_training()\n        self.choose_dest_agent.prepare_training()\n\n    def add_node_and_update(self, a=None):\n        \"\"\"Decide if to add a new node.\n        If a new node should be added, update the graph.\"\"\"\n\n        return self.add_node_agent(self.g, a)\n\n    def add_edge_or_not(self, a=None):\n        \"\"\"Decide if a new edge should be added.\"\"\"\n\n        return self.add_edge_agent(self.g, a)\n\n    def choose_dest_and_update(self, a=None):\n        \"\"\"Choose destination and connect it to the latest node.\n        Add edges for both directions and update the graph.\"\"\"\n\n        self.choose_dest_agent(self.g, a)\n\n    def get_log_prob(self):\n        add_node_log_p = torch.cat(self.add_node_agent.log_prob).sum()\n        add_edge_log_p = torch.cat(self.add_edge_agent.log_prob).sum()\n        choose_dest_log_p = torch.cat(self.choose_dest_agent.log_prob).sum()\n        return add_node_log_p + add_edge_log_p + choose_dest_log_p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is an animation where a graph is generated on the fly\nafter every 10 batches of training for the first 400 batches. You\ncan see how the model improves over time and begins generating cycles.\n\n.. figure:: https://user-images.githubusercontent.com/19576924/48929291-60fe3880-ef22-11e8-832a-fbe56656559a.gif\n   :alt:\n\nFor generative models, you can evaluate performance by checking the percentage\nof valid graphs among the graphs it generates on the fly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.utils.model_zoo as model_zoo\n\n# Download a pre-trained model state dict for generating cycles with 10-20 nodes.\nstate_dict = model_zoo.load_url(\n    \"https://data.dgl.ai/model/dgmg_cycles-5a0c40be.pth\"\n)\nmodel = DGMG(v_max=20, node_hidden_size=16, num_prop_rounds=2)\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\n\ndef is_valid(g):\n    # Check if g is a cycle having 10-20 nodes.\n    def _get_previous(i, v_max):\n        if i == 0:\n            return v_max\n        else:\n            return i - 1\n\n    def _get_next(i, v_max):\n        if i == v_max:\n            return 0\n        else:\n            return i + 1\n\n    size = g.num_nodes()\n\n    if size < 10 or size > 20:\n        return False\n    for node in range(size):\n        neighbors = g.successors(node)\n\n        if len(neighbors) != 2:\n            return False\n        if _get_previous(node, size - 1) not in neighbors:\n            return False\n        if _get_next(node, size - 1) not in neighbors:\n            return False\n    return True\n\n\nnum_valid = 0\nfor i in range(100):\n    g = model()\n    num_valid += is_valid(g)\ndel model\nprint(\"Among 100 graphs generated, {}% are valid.\".format(num_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the complete implementation, see the [DGL DGMG example](https://github.com/dmlc/dgl/tree/master/examples/pytorch/dgmg)_.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}