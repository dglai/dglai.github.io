<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>EdgeConv &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SAGEConv" href="dgl.nn.pytorch.conv.SAGEConv.html" />
    <link rel="prev" title="EdgeGATConv" href="dgl.nn.pytorch.conv.EdgeGATConv.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../stochastic_training/index.html">üÜï Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_cn/index.html">Áî®Êà∑ÊåáÂçó„ÄêÂåÖÂê´ËøáÊó∂‰ø°ÊÅØ„Äë</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_ko/index.html">ÏÇ¨Ïö©Ïûê Í∞ÄÏù¥Îìú[ÏãúÎåÄÏóê Îí§Ï≥êÏßÑ]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtransformer/index.html">üÜï Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.graphbolt.html">üÜï dgl.graphbolt</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../api/python/nn-pytorch.html#conv-layers">Conv Layers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GraphConv.html">GraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeWeightNorm.html">EdgeWeightNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.RelGraphConv.html">RelGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TAGConv.html">TAGConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GATConv.html">GATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GATv2Conv.html">GATv2Conv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EGATConv.html">EGATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeGATConv.html">EdgeGATConv</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">EdgeConv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dgl.nn.pytorch.conv.EdgeConv"><code class="docutils literal notranslate"><span class="pre">EdgeConv</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.SAGEConv.html">SAGEConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.SGConv.html">SGConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.APPNPConv.html">APPNPConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GINConv.html">GINConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GINEConv.html">GINEConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GatedGraphConv.html">GatedGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GatedGCNConv.html">GatedGCNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GMMConv.html">GMMConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.ChebConv.html">ChebConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.AGNNConv.html">AGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.NNConv.html">NNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.AtomicConv.html">AtomicConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.CFConv.html">CFConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.DotGatConv.html">DotGatConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TWIRLSConv.html">TWIRLSConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TWIRLSUnfoldingAndAttention.html">TWIRLSUnfoldingAndAttention</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GCN2Conv.html">GCN2Conv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.HGTConv.html">HGTConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GroupRevRes.html">GroupRevRes</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EGNNConv.html">EGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.PNAConv.html">PNAConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.DGNConv.html">DGNConv</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#cugraph-conv-layers">CuGraph Conv Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#dense-conv-layers">Dense Conv Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#global-pooling-layers">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#score-modules-for-link-prediction-and-knowledge-graph-completion">Score Modules for Link Prediction and Knowledge Graph Completion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#heterogeneous-learning-modules">Heterogeneous Learning Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#utility-modules">Utility Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#network-embedding-modules">Network Embedding Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#utility-modules-for-graph-transformer">Utility Modules for Graph Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
      <li class="breadcrumb-item active">EdgeConv</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/generated/dgl.nn.pytorch.conv.EdgeConv.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="edgeconv">
<h1>EdgeConv<a class="headerlink" href="#edgeconv" title="Link to this heading">ÔÉÅ</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.EdgeConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dgl.nn.pytorch.conv.</span></span><span class="sig-name descname"><span class="pre">EdgeConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_zero_in_degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/edgeconv.html#EdgeConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.EdgeConv" title="Link to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>EdgeConv layer from <a class="reference external" href="https://arxiv.org/pdf/1801.07829">Dynamic Graph CNN for Learning on Point Clouds</a></p>
<p>It can be described as follows:</p>
<div class="math notranslate nohighlight">
\[h_i^{(l+1)} = \max_{j \in \mathcal{N}(i)} (
\Theta \cdot (h_j^{(l)} - h_i^{(l)}) + \Phi \cdot h_i^{(l)})\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}(i)\)</span> is the neighbor of <span class="math notranslate nohighlight">\(i\)</span>.
<span class="math notranslate nohighlight">\(\Theta\)</span> and <span class="math notranslate nohighlight">\(\Phi\)</span> are linear layers.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The original formulation includes a ReLU inside the maximum operator.
This is equivalent to first applying a maximum operator then applying
the ReLU.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_feat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) ‚Äì Input feature size; i.e, the number of dimensions of <span class="math notranslate nohighlight">\(h_j^{(l)}\)</span>.</p></li>
<li><p><strong>out_feat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) ‚Äì Output feature size; i.e., the number of dimensions of <span class="math notranslate nohighlight">\(h_i^{(l+1)}\)</span>.</p></li>
<li><p><strong>batch_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) ‚Äì Whether to include batch normalization on messages. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>allow_zero_in_degree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) ‚Äì If there are 0-in-degree nodes in the graph, output for those nodes will be invalid
since no message will be passed to those nodes. This is harmful for some applications
causing silent performance regression. This module will raise a DGLError if it detects
0-in-degree nodes in input graph. By setting <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will suppress the check
and let the users handle it by themselves. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero in-degree nodes will lead to invalid output value. This is because no message
will be passed to those nodes, the aggregation function will be appied on empty input.
A common practice to avoid this is to add a self-loop for each node in the graph if
it is homogeneous, which can be achieved by:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># a DGLGraph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
<p>Calling <code class="docutils literal notranslate"><span class="pre">add_self_loop</span></code> will not work for some graphs, for example, heterogeneous graph
since the edge type can not be decided for self_loop edges. Set <code class="docutils literal notranslate"><span class="pre">allow_zero_in_degree</span></code>
to <code class="docutils literal notranslate"><span class="pre">True</span></code> for those cases to unblock the code and handle zero-in-degree nodes manually.
A common practise to handle this is to filter out the nodes with zero-in-degree when use
after conv.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">dgl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dgl.nn</span> <span class="kn">import</span> <span class="n">EdgeConv</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Case 1: Homogeneous graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">graph</span><span class="p">(([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">EdgeConv</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">tensor([[-0.2347,  0.5849],</span>
<span class="go">        [-0.2347,  0.5849],</span>
<span class="go">        [-0.2347,  0.5849],</span>
<span class="go">        [-0.2347,  0.5849],</span>
<span class="go">        [-0.2347,  0.5849],</span>
<span class="go">        [-0.2347,  0.5849]], grad_fn=&lt;CopyReduceBackward&gt;)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Case 2: Unidirectional bipartite graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">heterograph</span><span class="p">({(</span><span class="s1">&#39;_N&#39;</span><span class="p">,</span> <span class="s1">&#39;_E&#39;</span><span class="p">,</span> <span class="s1">&#39;_N&#39;</span><span class="p">):(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u_fea</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_fea</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">EdgeConv</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="p">(</span><span class="n">u_fea</span><span class="p">,</span> <span class="n">v_fea</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">tensor([[ 1.6375,  0.2085],</span>
<span class="go">        [-1.1925, -1.2852],</span>
<span class="go">        [ 0.2101,  1.3466],</span>
<span class="go">        [ 0.2342, -0.9868]], grad_fn=&lt;CopyReduceBackward&gt;)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.EdgeConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">g</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/edgeconv.html#EdgeConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.EdgeConv.forward" title="Link to this definition">ÔÉÅ</a></dt>
<dd><section id="description">
<h2>Description<a class="headerlink" href="#description" title="Link to this heading">ÔÉÅ</a></h2>
<p>Forward computation</p>
<dl class="field-list">
<dt class="field-odd">param g<span class="colon">:</span></dt>
<dd class="field-odd"><p>The graph.</p>
</dd>
<dt class="field-even">type g<span class="colon">:</span></dt>
<dd class="field-even"><p>DGLGraph</p>
</dd>
<dt class="field-odd">param feat<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="math notranslate nohighlight">\((N, D)\)</span> where <span class="math notranslate nohighlight">\(N\)</span> is the number of nodes and
<span class="math notranslate nohighlight">\(D\)</span> is the number of feature dimensions.</p>
<p>If a pair of tensors is given, the graph must be a uni-bipartite graph
with only one edge type, and the two tensors must have the same
dimensionality on all except the first axis.</p>
</dd>
<dt class="field-even">type feat<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor or pair of tensors</p>
</dd>
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>New node features.</p>
</dd>
<dt class="field-even">rtype<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">raises DGLError<span class="colon">:</span></dt>
<dd class="field-odd"><p>If there are 0-in-degree nodes in the input graph, it will raise DGLError
    since no message will be passed to those nodes. This will cause invalid output.
    The error can be ignored by setting <code class="docutils literal notranslate"><span class="pre">allow_zero_in_degree</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</section>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dgl.nn.pytorch.conv.EdgeGATConv.html" class="btn btn-neutral float-left" title="EdgeGATConv" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dgl.nn.pytorch.conv.SAGEConv.html" class="btn btn-neutral float-right" title="SAGEConv" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>