<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GCN2Conv &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="HGTConv" href="dgl.nn.pytorch.conv.HGTConv.html" />
    <link rel="prev" title="TWIRLSUnfoldingAndAttention" href="dgl.nn.pytorch.conv.TWIRLSUnfoldingAndAttention.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../api/python/nn-pytorch.html#conv-layers">Conv Layers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GraphConv.html">GraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeWeightNorm.html">EdgeWeightNorm</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.RelGraphConv.html">RelGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TAGConv.html">TAGConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GATConv.html">GATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GATv2Conv.html">GATv2Conv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EGATConv.html">EGATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeGATConv.html">EdgeGATConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EdgeConv.html">EdgeConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.SAGEConv.html">SAGEConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.SGConv.html">SGConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.APPNPConv.html">APPNPConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GINConv.html">GINConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GINEConv.html">GINEConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GatedGraphConv.html">GatedGraphConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GatedGCNConv.html">GatedGCNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GMMConv.html">GMMConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.ChebConv.html">ChebConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.AGNNConv.html">AGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.NNConv.html">NNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.AtomicConv.html">AtomicConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.CFConv.html">CFConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.DotGatConv.html">DotGatConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TWIRLSConv.html">TWIRLSConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.TWIRLSUnfoldingAndAttention.html">TWIRLSUnfoldingAndAttention</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">GCN2Conv</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dgl.nn.pytorch.conv.GCN2Conv"><code class="docutils literal notranslate"><span class="pre">GCN2Conv</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.HGTConv.html">HGTConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.GroupRevRes.html">GroupRevRes</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.EGNNConv.html">EGNNConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.PNAConv.html">PNAConv</a></li>
<li class="toctree-l3"><a class="reference internal" href="dgl.nn.pytorch.conv.DGNConv.html">DGNConv</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#cugraph-conv-layers">CuGraph Conv Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#dense-conv-layers">Dense Conv Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#global-pooling-layers">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#score-modules-for-link-prediction-and-knowledge-graph-completion">Score Modules for Link Prediction and Knowledge Graph Completion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#heterogeneous-learning-modules">Heterogeneous Learning Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#utility-modules">Utility Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#network-embedding-modules">Network Embedding Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/python/nn-pytorch.html#utility-modules-for-graph-transformer">Utility Modules for Graph Transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
      <li class="breadcrumb-item active">GCN2Conv</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/generated/dgl.nn.pytorch.conv.GCN2Conv.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="gcn2conv">
<h1>GCN2Conv<a class="headerlink" href="#gcn2conv" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GCN2Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dgl.nn.pytorch.conv.</span></span><span class="sig-name descname"><span class="pre">GCN2Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_feats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">project_initial_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_zero_in_degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/gcn2conv.html#GCN2Conv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.GCN2Conv" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Graph Convolutional Network via Initial residual
and Identity mapping (GCNII) from <a class="reference external" href="https://arxiv.org/abs/2007.02133">Simple and Deep Graph Convolutional
Networks</a></p>
<p>It is mathematically is defined as follows:</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}^{(l+1)} =\left( (1 - \alpha)(\mathbf{D}^{-1/2} \mathbf{\hat{A}}
\mathbf{D}^{-1/2})\mathbf{h}^{(l)} + \alpha {\mathbf{h}^{(0)}} \right)
\left( (1 - \beta_l) \mathbf{I} + \beta_l \mathbf{W} \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\hat{A}}\)</span> is the adjacency matrix with self-loops,
<span class="math notranslate nohighlight">\(\mathbf{D}_{ii} = \sum_{j=0} \mathbf{A}_{ij}\)</span> is its diagonal degree matrix,
<span class="math notranslate nohighlight">\(\mathbf{h}^{(0)}\)</span> is the initial node features,
<span class="math notranslate nohighlight">\(\mathbf{h}^{(l)}\)</span> is the feature of layer <span class="math notranslate nohighlight">\(l\)</span>,
<span class="math notranslate nohighlight">\(\alpha\)</span> is the fraction of initial node features, and
<span class="math notranslate nohighlight">\(\beta_l\)</span> is the hyperparameter to tune the strength of identity mapping.
It is defined by <span class="math notranslate nohighlight">\(\beta_l = \log(\frac{\lambda}{l}+1)\approx\frac{\lambda}{l}\)</span>,
where <span class="math notranslate nohighlight">\(\lambda\)</span> is a hyperparameter. <span class="math notranslate nohighlight">\(\beta\)</span> ensures that the decay of
the weight matrix adaptively increases as we stack more layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_feats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Input feature size; i.e, the number of dimensions of <span class="math notranslate nohighlight">\(h_j^{(l)}\)</span>.</p></li>
<li><p><strong>layer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – the index of current layer.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – The fraction of the initial input features. Default: <code class="docutils literal notranslate"><span class="pre">0.1</span></code></p></li>
<li><p><strong>lambda</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – The hyperparameter to ensure the decay of the weight matrix
adaptively increases. Default: <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
<li><p><strong>project_initial_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – Whether to share a weight matrix between initial features and
smoothed features. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>activation</strong> (<em>callable activation function/layer</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – If not None, applies an activation function to the updated node features.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>allow_zero_in_degree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>, </em><em>optional</em>) – If there are 0-in-degree nodes in the graph, output for those nodes will be invalid
since no message will be passed to those nodes. This is harmful for some applications
causing silent performance regression. This module will raise a DGLError if it detects
0-in-degree nodes in input graph. By setting <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will suppress the check
and let the users handle it by themselves. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zero in-degree nodes will lead to invalid output value. This is because no message
will be passed to those nodes, the aggregation function will be appied on empty input.
A common practice to avoid this is to add a self-loop for each node in the graph if
it is homogeneous, which can be achieved by:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># a DGLGraph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
<p>Calling <code class="docutils literal notranslate"><span class="pre">add_self_loop</span></code> will not work for some graphs, for example, heterogeneous graph
since the edge type can not be decided for self_loop edges. Set <code class="docutils literal notranslate"><span class="pre">allow_zero_in_degree</span></code>
to <code class="docutils literal notranslate"><span class="pre">True</span></code> for those cases to unblock the code and handle zero-in-degree nodes manually.
A common practise to handle this is to filter out the nodes with zero-in-degree when use
after conv.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">dgl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dgl.nn</span> <span class="kn">import</span> <span class="n">GCN2Conv</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Homogeneous graph</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">graph</span><span class="p">(([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feat</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g</span> <span class="o">=</span> <span class="n">dgl</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv1</span> <span class="o">=</span> <span class="n">GCN2Conv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> \
<span class="gp">... </span>        <span class="n">project_initial_features</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_zero_in_degree</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv2</span> <span class="o">=</span> <span class="n">GCN2Conv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> \
<span class="gp">... </span>        <span class="n">project_initial_features</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_zero_in_degree</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">feat</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv1</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">conv2</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">feat</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="go">tensor([[1.3803, 3.3191, 2.9572],</span>
<span class="go">        [1.3803, 3.3191, 2.9572],</span>
<span class="go">        [1.3803, 3.3191, 2.9572],</span>
<span class="go">        [1.4770, 3.8326, 3.2451],</span>
<span class="go">        [1.3623, 3.2102, 2.8679],</span>
<span class="go">        [1.3803, 3.3191, 2.9572]], grad_fn=&lt;AddBackward0&gt;)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GCN2Conv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/gcn2conv.html#GCN2Conv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.GCN2Conv.forward" title="Link to this definition"></a></dt>
<dd><section id="description">
<h2>Description<a class="headerlink" href="#description" title="Link to this heading"></a></h2>
<p>Compute graph convolution.</p>
<dl class="field-list simple">
<dt class="field-odd">param graph<span class="colon">:</span></dt>
<dd class="field-odd"><p>The graph.</p>
</dd>
<dt class="field-even">type graph<span class="colon">:</span></dt>
<dd class="field-even"><p>DGLGraph</p>
</dd>
<dt class="field-odd">param feat<span class="colon">:</span></dt>
<dd class="field-odd"><p>The input feature of shape
<span class="math notranslate nohighlight">\((N, D_{in})\)</span>
where <span class="math notranslate nohighlight">\(D_{in}\)</span> is the size of input feature and <span class="math notranslate nohighlight">\(N\)</span> is the number of nodes.</p>
</dd>
<dt class="field-even">type feat<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">param feat_0<span class="colon">:</span></dt>
<dd class="field-odd"><p>The initial feature of shape <span class="math notranslate nohighlight">\((N, D_{in})\)</span></p>
</dd>
<dt class="field-even">type feat_0<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">param edge_weight<span class="colon">:</span></dt>
<dd class="field-odd"><p>edge_weight to use in the message passing process. This is equivalent to
using weighted adjacency matrix in the equation above, and
<span class="math notranslate nohighlight">\(\tilde{D}^{-1/2}\tilde{A} \tilde{D}^{-1/2}\)</span>
is based on <a class="reference internal" href="dgl.nn.pytorch.conv.EdgeWeightNorm.html#dgl.nn.pytorch.conv.EdgeWeightNorm" title="dgl.nn.pytorch.conv.graphconv.EdgeWeightNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">dgl.nn.pytorch.conv.graphconv.EdgeWeightNorm</span></code></a>.</p>
</dd>
<dt class="field-even">type edge_weight<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor, optional</p>
</dd>
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The output feature</p>
</dd>
<dt class="field-even">rtype<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">raises DGLError<span class="colon">:</span></dt>
<dd class="field-odd"><p>If there are 0-in-degree nodes in the input graph, it will raise DGLError
    since no message will be passed to those nodes. This will cause invalid output.
    The error can be ignored by setting <code class="docutils literal notranslate"><span class="pre">allow_zero_in_degree</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Input shape: <span class="math notranslate nohighlight">\((N, *, \text{in_feats})\)</span> where * means any number of additional
dimensions, <span class="math notranslate nohighlight">\(N\)</span> is the number of nodes.</p></li>
<li><p>Output shape: <span class="math notranslate nohighlight">\((N, *, \text{out_feats})\)</span> where all but the last dimension are
the same shape as the input.</p></li>
<li><p>Weight shape: <span class="math notranslate nohighlight">\((\text{in_feats}, \text{out_feats})\)</span>.</p></li>
</ul>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dgl.nn.pytorch.conv.GCN2Conv.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dgl/nn/pytorch/conv/gcn2conv.html#GCN2Conv.reset_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dgl.nn.pytorch.conv.GCN2Conv.reset_parameters" title="Link to this definition"></a></dt>
<dd><section id="id1">
<h2>Description<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<p>Reinitialize learnable parameters.</p>
</section>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dgl.nn.pytorch.conv.TWIRLSUnfoldingAndAttention.html" class="btn btn-neutral float-left" title="TWIRLSUnfoldingAndAttention" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dgl.nn.pytorch.conv.HGTConv.html" class="btn btn-neutral float-right" title="HGTConv" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>