<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dgl.convert &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../stochastic_training/index.html">üÜï Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_cn/index.html">Áî®Êà∑ÊåáÂçó„ÄêÂåÖÂê´ËøáÊó∂‰ø°ÊÅØ„Äë</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_ko/index.html">ÏÇ¨Ïö©Ïûê Í∞ÄÏù¥Îìú[ÏãúÎåÄÏóê Îí§Ï≥êÏßÑ]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../graphtransformer/index.html">üÜï Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.graphbolt.html">üÜï dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dgl.convert</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dgl.convert</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Module for converting graph from/to other object.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Mapping</span>

<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">spmatrix</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">graph_index</span><span class="p">,</span> <span class="n">heterograph_index</span><span class="p">,</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">DGLError</span><span class="p">,</span> <span class="n">EID</span><span class="p">,</span> <span class="n">ETYPE</span><span class="p">,</span> <span class="n">NID</span><span class="p">,</span> <span class="n">NTYPE</span>
<span class="kn">from</span> <span class="nn">.heterograph</span> <span class="kn">import</span> <span class="n">combine_frames</span><span class="p">,</span> <span class="n">DGLBlock</span><span class="p">,</span> <span class="n">DGLGraph</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;hetero_from_shared_memory&quot;</span><span class="p">,</span>
    <span class="s2">&quot;heterograph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;create_block&quot;</span><span class="p">,</span>
    <span class="s2">&quot;block_to_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_heterogeneous&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_homogeneous&quot;</span><span class="p">,</span>
    <span class="s2">&quot;from_scipy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;bipartite_from_scipy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;from_networkx&quot;</span><span class="p">,</span>
    <span class="s2">&quot;bipartite_from_networkx&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_networkx&quot;</span><span class="p">,</span>
    <span class="s2">&quot;from_cugraph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_cugraph&quot;</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="graph">
<a class="viewcode-back" href="../../generated/dgl.graph.html#dgl.graph">[docs]</a>
<span class="k">def</span> <span class="nf">graph</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">num_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">row_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">col_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a graph and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : graph data</span>
<span class="sd">        The data for constructing a graph, which takes the form of :math:`(U, V)`.</span>
<span class="sd">        :math:`(U[i], V[i])` forms the edge with ID :math:`i` in the graph.</span>
<span class="sd">        The allowed data formats are:</span>

<span class="sd">        - ``(Tensor, Tensor)``: Each tensor must be a 1D tensor containing node IDs.</span>
<span class="sd">          DGL calls this format &quot;tuple of node-tensors&quot;. The tensors should have the same</span>
<span class="sd">          data type of int32/int64 and device context (see below the descriptions of</span>
<span class="sd">          :attr:`idtype` and :attr:`device`).</span>
<span class="sd">        - ``(&#39;coo&#39;, (Tensor, Tensor))``: Same as ``(Tensor, Tensor)``.</span>
<span class="sd">        - ``(&#39;csr&#39;, (Tensor, Tensor, Tensor))``: The three tensors form the CSR representation</span>
<span class="sd">          of the graph&#39;s adjacency matrix.  The first one is the row index pointer.  The</span>
<span class="sd">          second one is the column indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>
<span class="sd">        - ``(&#39;csc&#39;, (Tensor, Tensor, Tensor))``: The three tensors form the CSC representation</span>
<span class="sd">          of the graph&#39;s adjacency matrix.  The first one is the column index pointer.  The</span>
<span class="sd">          second one is the row indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>

<span class="sd">        The tensors can be replaced with any iterable of integers (e.g. list, tuple,</span>
<span class="sd">        numpy.ndarray).</span>
<span class="sd">    num_nodes : int, optional</span>
<span class="sd">        The number of nodes in the graph. If not given, this will be the largest node ID</span>
<span class="sd">        plus 1 from the :attr:`data` argument. If given and the value is no greater than</span>
<span class="sd">        the largest node ID from the :attr:`data` argument, DGL will raise an error.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        If ``None`` (default), DGL infers the ID type from the :attr:`data` argument.</span>
<span class="sd">        See &quot;Notes&quot; for more details.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the returned graph, which should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). If ``None`` (default), DGL uses the device of the tensors of</span>
<span class="sd">        the :attr:`data` argument. If :attr:`data` is not a tuple of node-tensors, the</span>
<span class="sd">        returned graph is on CPU.  If the specified :attr:`device` differs from that of the</span>
<span class="sd">        provided tensors, it casts the given tensors to the specified device first.</span>
<span class="sd">    row_sorted : bool, optional</span>
<span class="sd">        Whether or not the rows of the COO are in ascending order.</span>
<span class="sd">    col_sorted : bool, optional</span>
<span class="sd">        Whether or not the columns of the COO are in ascending order within</span>
<span class="sd">        each row. This only has an effect when ``row_sorted`` is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. If the :attr:`idtype` argument is not given then:</span>

<span class="sd">       - in the case of the tuple of node-tensor format, DGL uses the</span>
<span class="sd">         data type of the given ID tensors.</span>
<span class="sd">       - in the case of the tuple of sequence format, DGL uses int64.</span>

<span class="sd">       Once the graph has been created, you can change the data type by using</span>
<span class="sd">       :func:`dgl.DGLGraph.long` or :func:`dgl.DGLGraph.int`.</span>

<span class="sd">       If the specified :attr:`idtype` argument differs from the data type of the provided</span>
<span class="sd">       tensors, it casts the given tensors to the specified data type first.</span>
<span class="sd">    2. The most efficient construction approach is to provide a tuple of node tensors without</span>
<span class="sd">       specifying :attr:`idtype` and :attr:`device`. This is because the returned graph shares</span>
<span class="sd">       the storage with the input node-tensors in this case.</span>
<span class="sd">    3. DGL internally maintains multiple copies of the graph structure in different</span>
<span class="sd">       `sparse formats &lt;https://en.wikipedia.org/wiki/Sparse_matrix&gt;`_ and chooses the most</span>
<span class="sd">       efficient one depending on the computation invoked. If memory usage becomes an issue</span>
<span class="sd">       in the case of large graphs, use :func:`dgl.DGLGraph.formats` to restrict the allowed</span>
<span class="sd">       formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a small three-edge graph.</span>

<span class="sd">    &gt;&gt;&gt; # Source nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; src_ids = torch.tensor([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; # Destination nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; dst_ids = torch.tensor([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids))</span>

<span class="sd">    Explicitly specify the number of nodes in the graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids), num_nodes=100)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids), idtype=torch.int32, device=&#39;cuda:0&#39;)</span>

<span class="sd">    Creating a graph with CSR representation:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((&#39;csr&#39;, ([0, 0, 0, 1, 2, 3], [1, 2, 3], [])))</span>

<span class="sd">    Create the same graph with CSR representation and edge IDs.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((&#39;csr&#39;, ([0, 0, 0, 1, 2, 3], [1, 2, 3], [0, 1, 2])))</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    from_scipy</span>
<span class="sd">    from_networkx</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">spmatrix</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;dgl.graph no longer supports graph construction from a SciPy &quot;</span>
            <span class="s2">&quot;sparse matrix, use dgl.from_scipy instead.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;dgl.graph no longer supports graph construction from a NetworkX &quot;</span>
            <span class="s2">&quot;graph, use dgl.from_networkx instead.&quot;</span>
        <span class="p">)</span>

    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">idtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_nodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># override the number of nodes</span>
        <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&lt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;The num_nodes argument must be larger than the max ID in the data,&quot;</span>
                <span class="s2">&quot; but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_nodes</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
        <span class="n">sparse_fmt</span><span class="p">,</span>
        <span class="n">arrays</span><span class="p">,</span>
        <span class="s2">&quot;_N&quot;</span><span class="p">,</span>
        <span class="s2">&quot;_E&quot;</span><span class="p">,</span>
        <span class="s2">&quot;_N&quot;</span><span class="p">,</span>
        <span class="n">urange</span><span class="p">,</span>
        <span class="n">vrange</span><span class="p">,</span>
        <span class="n">row_sorted</span><span class="o">=</span><span class="n">row_sorted</span><span class="p">,</span>
        <span class="n">col_sorted</span><span class="o">=</span><span class="n">col_sorted</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">hetero_from_shared_memory</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a heterograph from shared memory with the given name.</span>

<span class="sd">    The newly created graph will have the same node types and edge types as the original graph.</span>
<span class="sd">    But it does not have node features or edges features.</span>

<span class="sd">    Paramaters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        The name of the share memory</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    HeteroGraph (in shared memory)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_shared_memory</span><span class="p">(</span>
        <span class="n">name</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">)</span>


<div class="viewcode-block" id="heterograph">
<a class="viewcode-back" href="../../generated/dgl.heterograph.html#dgl.heterograph">[docs]</a>
<span class="k">def</span> <span class="nf">heterograph</span><span class="p">(</span><span class="n">data_dict</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a heterogeneous graph and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data_dict : graph data</span>
<span class="sd">        The dictionary data for constructing a heterogeneous graph. The keys are in the form of</span>
<span class="sd">        string triplets (src_type, edge_type, dst_type), specifying the source node,</span>
<span class="sd">        edge, and destination node types. The values are graph data in the form of</span>
<span class="sd">        :math:`(U, V)`, where :math:`(U[i], V[i])` forms the edge with ID :math:`i`.</span>
<span class="sd">        The allowed graph data formats are:</span>

<span class="sd">        - ``(Tensor, Tensor)``: Each tensor must be a 1D tensor containing node IDs. DGL calls</span>
<span class="sd">          this format &quot;tuple of node-tensors&quot;. The tensors should have the same data type,</span>
<span class="sd">          which must be either int32 or int64. They should also have the same device context</span>
<span class="sd">          (see below the descriptions of :attr:`idtype` and :attr:`device`).</span>
<span class="sd">        - ``(&#39;coo&#39;, (Tensor, Tensor))``: Same as ``(Tensor, Tensor)``.</span>
<span class="sd">        - ``(&#39;csr&#39;, (Tensor, Tensor, Tensor))``: The three tensors form the CSR representation</span>
<span class="sd">          of the graph&#39;s adjacency matrix.  The first one is the row index pointer.  The</span>
<span class="sd">          second one is the column indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          (i.e. with 0 elements) to represent consecutive integer IDs starting from 0.</span>
<span class="sd">        - ``(&#39;csc&#39;, (Tensor, Tensor, Tensor))``: The three tensors form the CSC representation</span>
<span class="sd">          of the graph&#39;s adjacency matrix.  The first one is the column index pointer.  The</span>
<span class="sd">          second one is the row indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>

<span class="sd">        The tensors can be replaced with any iterable of integers (e.g. list, tuple,</span>
<span class="sd">        numpy.ndarray).</span>
<span class="sd">    num_nodes_dict : dict[str, int], optional</span>
<span class="sd">        The number of nodes for some node types, which is a dictionary mapping a node type</span>
<span class="sd">        :math:`T` to the number of :math:`T`-typed nodes. If not given for a node type</span>
<span class="sd">        :math:`T`, DGL finds the largest ID appearing in *every* graph data whose source</span>
<span class="sd">        or destination node type is :math:`T`, and sets the number of nodes to be that ID</span>
<span class="sd">        plus one. If given and the value is no greater than the largest ID for some node type,</span>
<span class="sd">        DGL will raise an error. By default, DGL infers the number of nodes for all node types.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        If ``None`` (default), DGL infers the ID type from the :attr:`data_dict` argument.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the returned graph, which should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). If ``None`` (default), DGL uses the device of the tensors of</span>
<span class="sd">        the :attr:`data` argument. If :attr:`data` is not a tuple of node-tensors, the</span>
<span class="sd">        returned graph is on CPU.  If the specified :attr:`device` differs from that of the</span>
<span class="sd">        provided tensors, it casts the given tensors to the specified device first.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. If the :attr:`idtype` argument is not given then:</span>

<span class="sd">       - in the case of the tuple of node-tensor format, DGL uses</span>
<span class="sd">         the data type of the given ID tensors.</span>
<span class="sd">       - in the case of the tuple of sequence format, DGL uses int64.</span>

<span class="sd">       Once the graph has been created, you can change the data type by using</span>
<span class="sd">       :func:`dgl.DGLGraph.long` or :func:`dgl.DGLGraph.int`.</span>

<span class="sd">       If the specified :attr:`idtype` argument differs from the data type of the provided</span>
<span class="sd">       tensors, it casts the given tensors to the specified data type first.</span>
<span class="sd">    2. The most efficient construction approach is to provide a tuple of node tensors without</span>
<span class="sd">       specifying :attr:`idtype` and :attr:`device`. This is because the returned graph shares</span>
<span class="sd">       the storage with the input node-tensors in this case.</span>
<span class="sd">    3. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>
<span class="sd">    4. DGL internally decides a deterministic order for the same set of node types and canonical</span>
<span class="sd">       edge types, which does not necessarily follow the order in :attr:`data_dict`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a heterograph with three canonical edge types.</span>

<span class="sd">    &gt;&gt;&gt; data_dict = {</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;topic&#39;): (torch.tensor([1, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 3]), torch.tensor([3, 4]))</span>
<span class="sd">    ... }</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph(data_dict)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes={&#39;game&#39;: 5, &#39;topic&#39;: 3, &#39;user&#39;: 4},</span>
<span class="sd">          num_edges={(&#39;user&#39;, &#39;follows&#39;, &#39;topic&#39;): 2, (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): 2,</span>
<span class="sd">                     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): 2},</span>
<span class="sd">          metagraph=[(&#39;user&#39;, &#39;topic&#39;, &#39;follows&#39;), (&#39;user&#39;, &#39;user&#39;, &#39;follows&#39;),</span>
<span class="sd">                     (&#39;user&#39;, &#39;game&#39;, &#39;plays&#39;)])</span>

<span class="sd">    Explicitly specify the number of nodes for each node type in the graph.</span>

<span class="sd">    &gt;&gt;&gt; num_nodes_dict = {&#39;user&#39;: 4, &#39;topic&#39;: 4, &#39;game&#39;: 6}</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph(data_dict, num_nodes_dict=num_nodes_dict)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph(data_dict, idtype=torch.int32, device=&#39;cuda:0&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Convert all data to node tensors first</span>
    <span class="n">node_tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">need_infer</span> <span class="o">=</span> <span class="n">num_nodes_dict</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">num_nodes_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_nodes_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">),</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">spmatrix</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;dgl.heterograph no longer supports graph construction from a SciPy &quot;</span>
                <span class="s2">&quot;sparse matrix, use dgl.from_scipy instead.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;dgl.heterograph no longer supports graph construction from a NetworkX &quot;</span>
                <span class="s2">&quot;graph, use dgl.from_networkx instead.&quot;</span>
            <span class="p">)</span>
        <span class="n">is_bipartite</span> <span class="o">=</span> <span class="n">sty</span> <span class="o">!=</span> <span class="n">dty</span>
        <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">bipartite</span><span class="o">=</span><span class="n">is_bipartite</span>
        <span class="p">)</span>
        <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span><span class="p">)</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># sanity check</span>
            <span class="k">if</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">urange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;The given number of nodes of node type </span><span class="si">{}</span><span class="s2"> must be larger than&quot;</span>
                    <span class="s2">&quot; the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">sty</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">vrange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;The given number of nodes of node type </span><span class="si">{}</span><span class="s2"> must be larger than&quot;</span>
                    <span class="s2">&quot; the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">dty</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
    <span class="c1"># Create the graph</span>
    <span class="p">(</span>
        <span class="n">metagraph</span><span class="p">,</span>
        <span class="n">ntypes</span><span class="p">,</span>
        <span class="n">etypes</span><span class="p">,</span>
        <span class="n">relations</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_metagraph_index</span><span class="p">(</span>
        <span class="n">num_nodes_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">node_tensor_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span>
        <span class="p">[</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span><span class="p">],</span> <span class="s2">&quot;int64&quot;</span>
    <span class="p">)</span>
    <span class="n">rel_graphs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">relations</span><span class="p">:</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span> <span class="o">=</span> <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">)]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
            <span class="n">sparse_fmt</span><span class="p">,</span>
            <span class="n">arrays</span><span class="p">,</span>
            <span class="n">srctype</span><span class="p">,</span>
            <span class="n">etype</span><span class="p">,</span>
            <span class="n">dsttype</span><span class="p">,</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">srctype</span><span class="p">],</span>
            <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">dsttype</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">rel_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

    <span class="c1"># create graph index</span>
    <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
        <span class="n">metagraph</span><span class="p">,</span> <span class="p">[</span><span class="n">rgrh</span><span class="o">.</span><span class="n">_graph</span> <span class="k">for</span> <span class="n">rgrh</span> <span class="ow">in</span> <span class="n">rel_graphs</span><span class="p">],</span> <span class="n">num_nodes_per_type</span>
    <span class="p">)</span>
    <span class="n">retg</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">retg</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="create_block">
<a class="viewcode-back" href="../../generated/dgl.create_block.html#dgl.create_block">[docs]</a>
<span class="k">def</span> <span class="nf">create_block</span><span class="p">(</span>
    <span class="n">data_dict</span><span class="p">,</span>
    <span class="n">num_src_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_dst_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">node_count_check</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a message flow graph (MFG) as a :class:`DGLBlock` object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data_dict : graph data</span>
<span class="sd">        The dictionary data for constructing a MFG. The keys are in the form of</span>
<span class="sd">        string triplets (src_type, edge_type, dst_type), specifying the source node type,</span>
<span class="sd">        edge type, and destination node type. The values are graph data in the form of</span>
<span class="sd">        :math:`(U, V)`, where :math:`(U[i], V[i])` forms the edge with ID :math:`i`.</span>
<span class="sd">        The allowed graph data formats are:</span>

<span class="sd">        - ``(Tensor, Tensor)``: Each tensor must be a 1D tensor containing node IDs. DGL calls</span>
<span class="sd">          this format &quot;tuple of node-tensors&quot;. The tensors should have the same data type,</span>
<span class="sd">          which must be either int32 or int64. They should also have the same device context</span>
<span class="sd">          (see below the descriptions of :attr:`idtype` and :attr:`device`).</span>
<span class="sd">        - ``(&#39;coo&#39;, (Tensor, Tensor))``: Same as ``(Tensor, Tensor)``.</span>
<span class="sd">        - ``(&#39;csr&#39;, (Tensor, Tensor, Tensor))``: The three tensors form the CSR representation</span>
<span class="sd">          of the graph&#39;s adjacency matrix.  The first one is the row index pointer.  The</span>
<span class="sd">          second one is the column indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>
<span class="sd">        - ``(&#39;csc&#39;, (Tensor, Tensor, Tensor))``: The three tensors form the CSC representation</span>
<span class="sd">          of the graph&#39;s adjacency matrix.  The first one is the column index pointer.  The</span>
<span class="sd">          second one is the row indices.  The third one is the edge IDs, which can be empty</span>
<span class="sd">          to represent consecutive integer IDs starting from 0.</span>

<span class="sd">        The tensors can be replaced with any iterable of integers (e.g. list, tuple,</span>
<span class="sd">        numpy.ndarray).</span>

<span class="sd">        If you would like to create a MFG with a single source node type, a single destination</span>
<span class="sd">        node type, and a single edge type, then you can pass in the graph data directly</span>
<span class="sd">        without wrapping it as a dictionary.</span>
<span class="sd">    num_src_nodes : dict[str, int] or int, optional</span>
<span class="sd">        The number of nodes for each source node type, which is a dictionary mapping a node type</span>
<span class="sd">        :math:`T` to the number of :math:`T`-typed source nodes.</span>

<span class="sd">        If not given for a node type :math:`T`, DGL finds the largest ID appearing in *every*</span>
<span class="sd">        graph data whose source node type is :math:`T`, and sets the number of nodes to</span>
<span class="sd">        be that ID plus one. If given and the value is no greater than the largest ID for some</span>
<span class="sd">        source node type, DGL will raise an error. By default, DGL infers the number of nodes for</span>
<span class="sd">        all source node types.</span>

<span class="sd">        If you would like to create a MFG with a single source node type, a single destination</span>
<span class="sd">        node type, and a single edge type, then you can pass in an integer to directly</span>
<span class="sd">        represent the number of source nodes.</span>
<span class="sd">    num_dst_nodes : dict[str, int] or int, optional</span>
<span class="sd">        The number of nodes for each destination node type, which is a dictionary mapping a node</span>
<span class="sd">        type :math:`T` to the number of :math:`T`-typed destination nodes.</span>

<span class="sd">        If not given for a node type :math:`T`, DGL finds the largest ID appearing in *every*</span>
<span class="sd">        graph data whose destination node type is :math:`T`, and sets the number of nodes to</span>
<span class="sd">        be that ID plus one. If given and the value is no greater than the largest ID for some</span>
<span class="sd">        destination node type, DGL will raise an error. By default, DGL infers the number of nodes</span>
<span class="sd">        for all destination node types.</span>

<span class="sd">        If you would like to create a MFG with a single destination node type, a single</span>
<span class="sd">        destination node type, and a single edge type, then you can pass in an integer to directly</span>
<span class="sd">        represent the number of destination nodes.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        If ``None`` (default), DGL infers the ID type from the :attr:`data_dict` argument.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the returned graph, which should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). If ``None`` (default), DGL uses the device of the tensors of</span>
<span class="sd">        the :attr:`data` argument. If :attr:`data` is not a tuple of node-tensors, the</span>
<span class="sd">        returned graph is on CPU.  If the specified :attr:`device` differs from that of the</span>
<span class="sd">        provided tensors, it casts the given tensors to the specified device first.</span>
<span class="sd">    node_count_check : bool, optional</span>
<span class="sd">        When num_src_nodes and num_dst_nodes are passed, whether we should perform</span>
<span class="sd">        sanity checks to ensure they are valid.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLBlock</span>
<span class="sd">        The created MFG.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. If the :attr:`idtype` argument is not given then:</span>

<span class="sd">       - in the case of the tuple of node-tensor format, DGL uses</span>
<span class="sd">         the data type of the given ID tensors.</span>
<span class="sd">       - in the case of the tuple of sequence format, DGL uses int64.</span>

<span class="sd">       Once the graph has been created, you can change the data type by using</span>
<span class="sd">       :func:`dgl.DGLGraph.long` or :func:`dgl.DGLGraph.int`.</span>

<span class="sd">       If the specified :attr:`idtype` argument differs from the data type of the provided</span>
<span class="sd">       tensors, it casts the given tensors to the specified data type first.</span>
<span class="sd">    2. The most efficient construction approach is to provide a tuple of node tensors without</span>
<span class="sd">       specifying :attr:`idtype` and :attr:`device`. This is because the returned graph shares</span>
<span class="sd">       the storage with the input node-tensors in this case.</span>
<span class="sd">    3. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>
<span class="sd">    4. DGL internally decides a deterministic order for the same set of node types and canonical</span>
<span class="sd">       edge types, which does not necessarily follow the order in :attr:`data_dict`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; block = dgl.create_block(([0, 1, 2], [1, 2, 3]), num_src_nodes=3, num_dst_nodes=4)</span>
<span class="sd">    &gt;&gt;&gt; block</span>
<span class="sd">    Block(num_src_nodes=3, num_dst_nodes=4, num_edges=3)</span>

<span class="sd">    &gt;&gt;&gt; block = dgl.create_block({</span>
<span class="sd">    ...     (&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([1, 2, 3], [2, 1, 0]),</span>
<span class="sd">    ...     (&#39;B&#39;, &#39;BA&#39;, &#39;A&#39;): ([2, 1], [2, 3])},</span>
<span class="sd">    ...     num_src_nodes={&#39;A&#39;: 6, &#39;B&#39;: 5},</span>
<span class="sd">    ...     num_dst_nodes={&#39;A&#39;: 4, &#39;B&#39;: 3})</span>
<span class="sd">    &gt;&gt;&gt; block</span>
<span class="sd">    Block(num_src_nodes={&#39;A&#39;: 6, &#39;B&#39;: 5},</span>
<span class="sd">          num_dst_nodes={&#39;A&#39;: 4, &#39;B&#39;: 3},</span>
<span class="sd">          num_edges={(&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): 3, (&#39;B&#39;, &#39;BA&#39;, &#39;A&#39;): 2},</span>
<span class="sd">          metagraph=[(&#39;A&#39;, &#39;B&#39;, &#39;AB&#39;), (&#39;B&#39;, &#39;A&#39;, &#39;BA&#39;)])</span>

<span class="sd">    See also</span>
<span class="sd">    --------</span>
<span class="sd">    to_block</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">need_infer</span> <span class="o">=</span> <span class="n">num_src_nodes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_dst_nodes</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{(</span><span class="s2">&quot;_N&quot;</span><span class="p">,</span> <span class="s2">&quot;_E&quot;</span><span class="p">,</span> <span class="s2">&quot;_N&quot;</span><span class="p">):</span> <span class="n">data_dict</span><span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_src_nodes</span><span class="p">,</span> <span class="nb">int</span>
            <span class="p">),</span> <span class="s2">&quot;num_src_nodes must be a pair of integers if data_dict is not a dict&quot;</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_dst_nodes</span><span class="p">,</span> <span class="nb">int</span>
            <span class="p">),</span> <span class="s2">&quot;num_dst_nodes must be a pair of integers if data_dict is not a dict&quot;</span>
            <span class="n">num_src_nodes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;_N&quot;</span><span class="p">:</span> <span class="n">num_src_nodes</span><span class="p">}</span>
            <span class="n">num_dst_nodes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;_N&quot;</span><span class="p">:</span> <span class="n">num_dst_nodes</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_src_nodes</span><span class="p">,</span> <span class="n">Mapping</span>
            <span class="p">),</span> <span class="s2">&quot;num_src_nodes must be a dict if data_dict is a dict&quot;</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">num_dst_nodes</span><span class="p">,</span> <span class="n">Mapping</span>
            <span class="p">),</span> <span class="s2">&quot;num_dst_nodes must be a dict if data_dict is a dict&quot;</span>

    <span class="k">if</span> <span class="n">need_infer</span><span class="p">:</span>
        <span class="n">num_src_nodes</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">num_dst_nodes</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Convert all data to node tensors first</span>
    <span class="n">node_tensor_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">),</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span>
            <span class="n">idtype</span><span class="p">,</span>
            <span class="n">bipartite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">infer_node_count</span><span class="o">=</span><span class="n">need_infer</span> <span class="ow">or</span> <span class="n">node_count_check</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">sty</span><span class="p">,</span> <span class="n">ety</span><span class="p">,</span> <span class="n">dty</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">need_infer</span><span class="p">:</span>
            <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span><span class="p">)</span>
            <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">node_count_check</span><span class="p">:</span>  <span class="c1"># sanity check</span>
            <span class="k">if</span> <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">urange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;The given number of nodes of source node type </span><span class="si">{}</span><span class="s2"> must be larger&quot;</span>
                    <span class="s2">&quot; than the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">sty</span><span class="p">,</span> <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">sty</span><span class="p">],</span> <span class="n">urange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">vrange</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;The given number of nodes of destination node type </span><span class="si">{}</span><span class="s2"> must be&quot;</span>
                    <span class="s2">&quot; larger than the max ID in the data, but got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">dty</span><span class="p">,</span> <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dty</span><span class="p">],</span> <span class="n">vrange</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                <span class="p">)</span>
    <span class="c1"># Create the graph</span>

    <span class="c1"># Sort the ntypes and relation tuples to have a deterministic order for the same set</span>
    <span class="c1"># of type names.</span>
    <span class="n">srctypes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">num_src_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">dsttypes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">num_dst_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">relations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">node_tensor_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span>
        <span class="p">[</span><span class="n">num_src_nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">srctypes</span><span class="p">]</span>
        <span class="o">+</span> <span class="p">[</span><span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">dsttypes</span><span class="p">],</span>
        <span class="s2">&quot;int64&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">srctype_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">srctypes</span><span class="p">)}</span>
    <span class="n">dsttype_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ntype</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">srctypes</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dsttypes</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">meta_edges_src</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">meta_edges_dst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">etypes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">rel_graphs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">relations</span><span class="p">:</span>
        <span class="n">meta_edges_src</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">srctype_dict</span><span class="p">[</span><span class="n">srctype</span><span class="p">])</span>
        <span class="n">meta_edges_dst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dsttype_dict</span><span class="p">[</span><span class="n">dsttype</span><span class="p">])</span>
        <span class="n">etypes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span> <span class="o">=</span> <span class="n">node_tensor_dict</span><span class="p">[(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">)]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
            <span class="n">sparse_fmt</span><span class="p">,</span>
            <span class="n">arrays</span><span class="p">,</span>
            <span class="s2">&quot;SRC/&quot;</span> <span class="o">+</span> <span class="n">srctype</span><span class="p">,</span>
            <span class="n">etype</span><span class="p">,</span>
            <span class="s2">&quot;DST/&quot;</span> <span class="o">+</span> <span class="n">dsttype</span><span class="p">,</span>
            <span class="n">num_src_nodes</span><span class="p">[</span><span class="n">srctype</span><span class="p">],</span>
            <span class="n">num_dst_nodes</span><span class="p">[</span><span class="n">dsttype</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">rel_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

    <span class="c1"># metagraph is DGLGraph, currently still using int64 as index dtype</span>
    <span class="n">metagraph</span> <span class="o">=</span> <span class="n">graph_index</span><span class="o">.</span><span class="n">from_coo</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">srctypes</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">dsttypes</span><span class="p">),</span> <span class="n">meta_edges_src</span><span class="p">,</span> <span class="n">meta_edges_dst</span><span class="p">,</span> <span class="kc">True</span>
    <span class="p">)</span>
    <span class="c1"># create graph index</span>
    <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
        <span class="n">metagraph</span><span class="p">,</span> <span class="p">[</span><span class="n">rgrh</span><span class="o">.</span><span class="n">_graph</span> <span class="k">for</span> <span class="n">rgrh</span> <span class="ow">in</span> <span class="n">rel_graphs</span><span class="p">],</span> <span class="n">num_nodes_per_type</span>
    <span class="p">)</span>
    <span class="n">retg</span> <span class="o">=</span> <span class="n">DGLBlock</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="p">(</span><span class="n">srctypes</span><span class="p">,</span> <span class="n">dsttypes</span><span class="p">),</span> <span class="n">etypes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">retg</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="block_to_graph">
<a class="viewcode-back" href="../../generated/dgl.block_to_graph.html#dgl.block_to_graph">[docs]</a>
<span class="k">def</span> <span class="nf">block_to_graph</span><span class="p">(</span><span class="n">block</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a message flow graph (MFG) as a :class:`DGLBlock` object to a :class:`DGLGraph`.</span>

<span class="sd">    DGL will rename all the source node types by suffixing with ``_src``, and</span>
<span class="sd">    all the destination node types by suffixing with ``_dst``.</span>

<span class="sd">    Features on the returned graph will be preserved.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    block : DGLBlock</span>
<span class="sd">        The MFG.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; block = dgl.create_block({</span>
<span class="sd">    ...     (&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([1, 2, 3], [2, 1, 0]),</span>
<span class="sd">    ...     (&#39;B&#39;, &#39;BA&#39;, &#39;A&#39;): ([2, 1], [2, 3])})</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.block_to_graph(block)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes={&#39;A_src&#39;: 4, &#39;B_src&#39;: 3, &#39;A_dst&#39;: 4, &#39;B_dst&#39;: 3},</span>
<span class="sd">          num_edges={(&#39;A_src&#39;, &#39;AB&#39;, &#39;B_dst&#39;): 3, (&#39;B_src&#39;, &#39;BA&#39;, &#39;A_dst&#39;): 2},</span>
<span class="sd">          metagraph=[(&#39;A_src&#39;, &#39;B_dst&#39;, &#39;AB&#39;), (&#39;B_src&#39;, &#39;A_dst&#39;, &#39;BA&#39;)])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">ntype</span> <span class="o">+</span> <span class="s2">&quot;_src&quot;</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">srctypes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">ntype</span> <span class="o">+</span> <span class="s2">&quot;_dst&quot;</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">dsttypes</span>
    <span class="p">]</span>
    <span class="n">retg</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">new_types</span><span class="p">,</span> <span class="n">block</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">srctype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">srctypes</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">srctype</span> <span class="o">+</span> <span class="s2">&quot;_src&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">srcnodes</span><span class="p">[</span><span class="n">srctype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">dsttypes</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">dsttype</span> <span class="o">+</span> <span class="s2">&quot;_dst&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">dstnodes</span><span class="p">[</span><span class="n">dsttype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">block</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">srctype</span> <span class="o">+</span> <span class="s2">&quot;_src&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">+</span> <span class="s2">&quot;_dst&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">block</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">retg</span></div>



<div class="viewcode-block" id="to_heterogeneous">
<a class="viewcode-back" href="../../generated/dgl.to_heterogeneous.html#dgl.to_heterogeneous">[docs]</a>
<span class="k">def</span> <span class="nf">to_heterogeneous</span><span class="p">(</span>
    <span class="n">G</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">,</span> <span class="n">ntype_field</span><span class="o">=</span><span class="n">NTYPE</span><span class="p">,</span> <span class="n">etype_field</span><span class="o">=</span><span class="n">ETYPE</span><span class="p">,</span> <span class="n">metagraph</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a homogeneous graph to a heterogeneous graph and return.</span>

<span class="sd">    The input graph should have only one type of nodes and edges. Each node and edge</span>
<span class="sd">    stores an integer feature as its type ID</span>
<span class="sd">    (specified by :attr:`ntype_field` and :attr:`etype_field`).</span>
<span class="sd">    DGL uses it to retrieve the type names stored in the given</span>
<span class="sd">    :attr:`ntypes` and :attr:`etypes` arguments.</span>

<span class="sd">    The function will automatically distinguish edge types that have the same given</span>
<span class="sd">    type IDs but different src and dst type IDs. For example, it allows both edges A and B</span>
<span class="sd">    to have the same type ID 0, but one has (0, 1) and the other as (2, 3) as the</span>
<span class="sd">    (src, dst) type IDs. In this case, the function will &quot;split&quot; edge type 0 into two types:</span>
<span class="sd">    (0, ty_A, 1) and (2, ty_B, 3). In another word, these two edges share the same edge</span>
<span class="sd">    type name, but can be distinguished by an edge type triplet.</span>

<span class="sd">    The function stores the node and edge IDs in the input graph using the ``dgl.NID``</span>
<span class="sd">    and ``dgl.EID`` names in the ``ndata`` and ``edata`` of the resulting graph.</span>
<span class="sd">    It also copies any node/edge features from :attr:`G` to the returned heterogeneous</span>
<span class="sd">    graph, except for reserved fields for storing type IDs (``dgl.NTYPE`` and ``dgl.ETYPE``)</span>
<span class="sd">    and node/edge IDs (``dgl.NID`` and ``dgl.EID``).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    G : DGLGraph</span>
<span class="sd">        The homogeneous graph.</span>
<span class="sd">    ntypes : list[str]</span>
<span class="sd">        The node type names.</span>
<span class="sd">    etypes : list[str]</span>
<span class="sd">        The edge type names.</span>
<span class="sd">    ntype_field : str, optional</span>
<span class="sd">        The feature field used to store node type. (Default: ``dgl.NTYPE``)</span>
<span class="sd">    etype_field : str, optional</span>
<span class="sd">        The feature field used to store edge type. (Default: ``dgl.ETYPE``)</span>
<span class="sd">    metagraph : networkx MultiDiGraph, optional</span>
<span class="sd">        Metagraph of the returned heterograph.</span>
<span class="sd">        If provided, DGL assumes that G can indeed be described with the given metagraph.</span>
<span class="sd">        If None, DGL will infer the metagraph from the given inputs, which could be</span>
<span class="sd">        costly for large graphs.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A heterogeneous graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    * The returned node and edge types may not necessarily be in the same order as</span>
<span class="sd">      ``ntypes`` and ``etypes``.</span>
<span class="sd">    * Calling :func:`~dgl.to_homogeneous` then calling :func:`~dgl.to_heterogeneous` again</span>
<span class="sd">      yields the same result.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;develops&#39;, &#39;activity&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]), torch.tensor([0, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; print(hg)</span>
<span class="sd">    Graph(num_nodes={&#39;activity&#39;: 3, &#39;developer&#39;: 2, &#39;game&#39;: 2, &#39;user&#39;: 2},</span>
<span class="sd">          num_edges={(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;develops&#39;, &#39;activity&#39;): 2},</span>
<span class="sd">          metagraph=[(&#39;developer&#39;, &#39;game&#39;, &#39;develops&#39;), (&#39;user&#39;, &#39;activity&#39;, &#39;develops&#39;)])</span>

<span class="sd">    We first convert the heterogeneous graph to a homogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.to_homogeneous(hg)</span>
<span class="sd">    &gt;&gt;&gt; print(g)</span>
<span class="sd">    Graph(num_nodes=9, num_edges=4,</span>
<span class="sd">          ndata_schemes={&#39;_TYPE&#39;: Scheme(shape=(), dtype=torch.int64),</span>
<span class="sd">                         &#39;_ID&#39;: Scheme(shape=(), dtype=torch.int64)}</span>
<span class="sd">          edata_schemes={&#39;_TYPE&#39;: Scheme(shape=(), dtype=torch.int64),</span>
<span class="sd">                         &#39;_ID&#39;: Scheme(shape=(), dtype=torch.int64)})</span>
<span class="sd">    &gt;&gt;&gt; g.ndata</span>
<span class="sd">    {&#39;_TYPE&#39;: tensor([0, 0, 0, 1, 1, 2, 2, 3, 3]), &#39;_ID&#39;: tensor([0, 1, 2, 0, 1, 0, 1, 0, 1])}</span>
<span class="sd">    Nodes 0, 1, 2 for &#39;activity&#39;, 3, 4 for &#39;developer&#39;, 5, 6 for &#39;game&#39;, 7, 8 for &#39;user&#39;</span>
<span class="sd">    &gt;&gt;&gt; g.edata</span>
<span class="sd">    {&#39;_TYPE&#39;: tensor([0, 0, 1, 1]), &#39;_ID&#39;: tensor([0, 1, 0, 1])}</span>
<span class="sd">    Edges 0, 1 for (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;), 2, 3 for (&#39;user&#39;, &#39;develops&#39;, &#39;activity&#39;)</span>

<span class="sd">    Now convert the homogeneous graph back to a heterogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; hg_2 = dgl.to_heterogeneous(g, hg.ntypes, hg.etypes)</span>
<span class="sd">    &gt;&gt;&gt; print(hg_2)</span>
<span class="sd">    Graph(num_nodes={&#39;activity&#39;: 3, &#39;developer&#39;: 2, &#39;game&#39;: 2, &#39;user&#39;: 2},</span>
<span class="sd">          num_edges={(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;develops&#39;, &#39;activity&#39;): 2},</span>
<span class="sd">          metagraph=[(&#39;developer&#39;, &#39;game&#39;, &#39;develops&#39;), (&#39;user&#39;, &#39;activity&#39;, &#39;develops&#39;)])</span>

<span class="sd">    Retrieve the original node/edge IDs.</span>

<span class="sd">    &gt;&gt;&gt; hg_2.ndata[dgl.NID]</span>
<span class="sd">    {&#39;activity&#39;: tensor([0, 1, 2]),</span>
<span class="sd">     &#39;developer&#39;: tensor([3, 4]),</span>
<span class="sd">     &#39;game&#39;: tensor([5, 6]),</span>
<span class="sd">     &#39;user&#39;: tensor([7, 8])}</span>
<span class="sd">    &gt;&gt;&gt; hg_2.edata[dgl.EID]</span>
<span class="sd">    {(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): tensor([0, 1]),</span>
<span class="sd">     (&#39;user&#39;, &#39;develops&#39;, &#39;activity&#39;): tensor([2, 3])}</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_homogeneous</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">hasattr</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s2">&quot;ntypes&quot;</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s2">&quot;etypes&quot;</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;The input graph should be homogeneous and have only one &quot;</span>
            <span class="s2">&quot; type of nodes and edges.&quot;</span>
        <span class="p">)</span>

    <span class="n">num_ntypes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span>
    <span class="n">idtype</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">idtype</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span>

    <span class="n">ntype_ids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">ntype_field</span><span class="p">])</span>
    <span class="n">etype_ids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">etype_field</span><span class="p">])</span>

    <span class="c1"># relabel nodes to per-type local IDs</span>
    <span class="n">ntype_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="n">num_ntypes</span><span class="p">)</span>
    <span class="n">ntype_offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ntype_count</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ntype_ids_sortidx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;stable&quot;</span><span class="p">)</span>
    <span class="n">ntype_local_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">)</span>
    <span class="n">node_groups</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_ntypes</span><span class="p">):</span>
        <span class="n">node_group</span> <span class="o">=</span> <span class="n">ntype_ids_sortidx</span><span class="p">[</span><span class="n">ntype_offset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="p">:</span> <span class="n">ntype_offset</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
        <span class="n">node_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_group</span><span class="p">)</span>
        <span class="n">ntype_local_ids</span><span class="p">[</span><span class="n">node_group</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">ntype_count</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">all_edges</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">)</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">dst</span><span class="p">)</span>
    <span class="n">src_local</span> <span class="o">=</span> <span class="n">ntype_local_ids</span><span class="p">[</span><span class="n">src</span><span class="p">]</span>
    <span class="n">dst_local</span> <span class="o">=</span> <span class="n">ntype_local_ids</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span>
    <span class="c1"># a 2D tensor of shape (E, 3). Each row represents the (stid, etid, dtid) tuple.</span>
    <span class="n">edge_ctids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ntype_ids</span><span class="p">[</span><span class="n">src</span><span class="p">],</span> <span class="n">etype_ids</span><span class="p">,</span> <span class="n">ntype_ids</span><span class="p">[</span><span class="n">dst</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># infer metagraph and canonical edge types</span>
    <span class="c1"># No matter which branch it takes, the code will generate a 2D tensor of shape (E_m, 3),</span>
    <span class="c1"># E_m is the set of all possible canonical edge tuples. Each row represents the</span>
    <span class="c1"># (stid, dtid, dtid) tuple. We then compute a 2D tensor of shape (E, E_m) using the</span>
    <span class="c1"># above ``edge_ctids`` matrix. Each element i,j indicates whether the edge i is of the</span>
    <span class="c1"># canonical edge type j. We can then group the edges of the same type together.</span>
    <span class="k">if</span> <span class="n">metagraph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">canonical_etids</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">etype_remapped</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">make_invmap</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">edge_ctids</span><span class="p">),</span> <span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">etype_mask</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">etype_remapped</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ntypes_invmap</span> <span class="o">=</span> <span class="p">{</span><span class="n">nt</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">nt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)}</span>
        <span class="n">etypes_invmap</span> <span class="o">=</span> <span class="p">{</span><span class="n">et</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">et</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">etypes</span><span class="p">)}</span>
        <span class="n">canonical_etids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">,</span> <span class="n">etype</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
            <span class="n">metagraph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">srctype_id</span> <span class="o">=</span> <span class="n">ntypes_invmap</span><span class="p">[</span><span class="n">srctype</span><span class="p">]</span>
            <span class="n">etype_id</span> <span class="o">=</span> <span class="n">etypes_invmap</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
            <span class="n">dsttype_id</span> <span class="o">=</span> <span class="n">ntypes_invmap</span><span class="p">[</span><span class="n">dsttype</span><span class="p">]</span>
            <span class="n">canonical_etids</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">srctype_id</span><span class="p">,</span> <span class="n">etype_id</span><span class="p">,</span> <span class="n">dsttype_id</span><span class="p">))</span>
        <span class="n">canonical_etids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">)</span>
        <span class="n">etype_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">edge_ctids</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">==</span> <span class="n">canonical_etids</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">edge_groups</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">etype_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">))</span>
    <span class="p">]</span>

    <span class="n">data_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">canonical_etypes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">stid</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="n">dtid</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">canonical_etids</span><span class="p">):</span>
        <span class="n">src_of_etype</span> <span class="o">=</span> <span class="n">src_local</span><span class="p">[</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">dst_of_etype</span> <span class="o">=</span> <span class="n">dst_local</span><span class="p">[</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
        <span class="n">canonical_etypes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">ntypes</span><span class="p">[</span><span class="n">stid</span><span class="p">],</span> <span class="n">etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">],</span> <span class="n">ntypes</span><span class="p">[</span><span class="n">dtid</span><span class="p">]))</span>
        <span class="n">data_dict</span><span class="p">[</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">src_of_etype</span><span class="p">,</span> <span class="n">dst_of_etype</span><span class="p">)</span>
    <span class="n">hg</span> <span class="o">=</span> <span class="n">heterograph</span><span class="p">(</span>
        <span class="n">data_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">ntype_count</span><span class="p">)),</span> <span class="n">idtype</span><span class="o">=</span><span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
    <span class="p">)</span>

    <span class="n">ntype2ngrp</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype</span><span class="p">:</span> <span class="n">node_groups</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)}</span>

    <span class="c1"># features</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">ndata</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="n">ntype_field</span><span class="p">,</span> <span class="n">NID</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">ntypes</span><span class="p">):</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ntype2ngrp</span><span class="p">[</span><span class="n">ntype</span><span class="p">]),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
            <span class="n">hg</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rows</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="n">etype_field</span><span class="p">,</span> <span class="n">EID</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">etid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)):</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">etid</span><span class="p">]),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
            <span class="n">hg</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">hg</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">])][</span>
                <span class="n">key</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rows</span><span class="p">)</span>

    <span class="c1"># Record the original IDs of the nodes/edges</span>
    <span class="k">for</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">ntypes</span><span class="p">):</span>
        <span class="n">hg</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">][</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ntype2ngrp</span><span class="p">[</span><span class="n">ntype</span><span class="p">]),</span> <span class="n">device</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">etid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hg</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)):</span>
        <span class="n">hg</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">hg</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">])][</span>
            <span class="n">EID</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edge_groups</span><span class="p">[</span><span class="n">etid</span><span class="p">]),</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hg</span></div>



<div class="viewcode-block" id="to_homogeneous">
<a class="viewcode-back" href="../../generated/dgl.to_homogeneous.html#dgl.to_homogeneous">[docs]</a>
<span class="k">def</span> <span class="nf">to_homogeneous</span><span class="p">(</span>
    <span class="n">G</span><span class="p">,</span> <span class="n">ndata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">store_type</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_count</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a heterogeneous graph to a homogeneous graph and return.</span>

<span class="sd">    By default, the function stores the node and edge types of the input graph as</span>
<span class="sd">    the ``dgl.NTYPE`` and ``dgl.ETYPE`` features in the returned graph.</span>
<span class="sd">    Each feature is an integer representing the type id, determined by the</span>
<span class="sd">    :meth:`DGLGraph.get_ntype_id` and :meth:`DGLGraph.get_etype_id` methods.</span>
<span class="sd">    One can omit it by specifying ``store_type=False``.</span>

<span class="sd">    The result graph assigns nodes and edges of the same type with IDs in continuous range</span>
<span class="sd">    (i.e., nodes of the first type have IDs 0 ~ ``G.num_nodes(G.ntypes[0])``; nodes</span>
<span class="sd">    of the second type come after; so on and so forth). Therefore, a more memory-efficient</span>
<span class="sd">    format for type information is an integer list; the i^th corresponds to</span>
<span class="sd">    the number of nodes/edges of the i^th type. One can choose this format by</span>
<span class="sd">    specifying ``return_count=True``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    G : DGLGraph</span>
<span class="sd">        The heterogeneous graph.</span>
<span class="sd">    ndata : list[str], optional</span>
<span class="sd">        The node features to combine across all node types. For each feature ``feat`` in</span>
<span class="sd">        :attr:`ndata`, it concatenates ``G.nodes[T].data[feat]`` across all node types ``T``.</span>
<span class="sd">        As a result, the feature ``feat`` of all node types should have the same shape and</span>
<span class="sd">        data type. By default, the returned graph will not have any node features.</span>
<span class="sd">    edata : list[str], optional</span>
<span class="sd">        The edge features to combine across all edge types. For each feature ``feat`` in</span>
<span class="sd">        :attr:`edata`, it concatenates ``G.edges[T].data[feat]`` across all edge types ``T``.</span>
<span class="sd">        As a result, the feature ``feat`` of all edge types should have the same shape and</span>
<span class="sd">        data type. By default, the returned graph will not have any edge features.</span>
<span class="sd">    store_type : bool, optional</span>
<span class="sd">        If True, store type information as the ``dgl.NTYPE`` and ``dgl.ETYPE`` features</span>
<span class="sd">        in the returned graph.</span>
<span class="sd">    return_count : bool, optional</span>
<span class="sd">        If True, return type information as an integer list; the i^th element corresponds to</span>
<span class="sd">        the number of nodes/edges of the i^th type.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A homogeneous graph.</span>
<span class="sd">    ntype_count : list[int], optional</span>
<span class="sd">        Number of nodes of each type. Return when ``return_count`` is True.</span>
<span class="sd">    etype_count : list[int], optional</span>
<span class="sd">        Number of edges of each type. Return when ``return_count`` is True.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    * Calculating type information may introduce noticeable cost. Setting both ``store_type``</span>
<span class="sd">      and ``return_count`` to False can avoid such cost if type information is not needed.</span>
<span class="sd">      Otherwise, DGL recommends to use ``store_type=False`` and ``return_count=True`` due</span>
<span class="sd">      to its memory efficiency.</span>
<span class="sd">    * The ``ntype_count`` and ``etype_count`` lists can help speed up some operations.</span>
<span class="sd">      See :class:`~dgl.nn.pytorch.conv.RelGraphConv` for such an example.</span>
<span class="sd">    * Calling :func:`~dgl.to_homogeneous` then calling :func:`~dgl.to_heterogeneous` again</span>
<span class="sd">      yields the same result.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 2]),</span>
<span class="sd">    ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): ([0, 1], [0, 1])</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; hg.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.ones(3, 1)</span>
<span class="sd">    &gt;&gt;&gt; hg.nodes[&#39;developer&#39;].data[&#39;h&#39;] = torch.zeros(2, 1)</span>
<span class="sd">    &gt;&gt;&gt; hg.nodes[&#39;game&#39;].data[&#39;h&#39;] = torch.ones(2, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.to_homogeneous(hg)</span>
<span class="sd">    &gt;&gt;&gt; # The first three nodes are for &#39;user&#39;, the next two are for &#39;developer&#39;,</span>
<span class="sd">    &gt;&gt;&gt; # and the last two are for &#39;game&#39;</span>
<span class="sd">    &gt;&gt;&gt; g.ndata</span>
<span class="sd">    {&#39;_TYPE&#39;: tensor([0, 0, 0, 1, 1, 2, 2]), &#39;_ID&#39;: tensor([0, 1, 2, 0, 1, 0, 1])}</span>
<span class="sd">    &gt;&gt;&gt; # The first two edges are for &#39;follows&#39;, and the next two are for &#39;develops&#39; edges.</span>
<span class="sd">    &gt;&gt;&gt; g.edata</span>
<span class="sd">    {&#39;_TYPE&#39;: tensor([0, 0, 1, 1]), &#39;_ID&#39;: tensor([0, 1, 0, 1])}</span>

<span class="sd">    Combine feature &#39;h&#39; across all node types in the conversion.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.to_homogeneous(hg, ndata=[&#39;h&#39;])</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">    tensor([[1.], [1.], [1.], [0.], [0.], [1.], [1.]])</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    to_heterogeneous</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_nodes_per_ntype</span> <span class="o">=</span> <span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">]</span>
    <span class="n">offset_per_ntype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">num_nodes_per_ntype</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">srcs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dsts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">eids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
        <span class="n">ntype_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">etype_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
        <span class="n">ntype_count</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">etype_count</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">total_num_nodes</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">ntype_id</span><span class="p">,</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">):</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="n">total_num_nodes</span> <span class="o">+=</span> <span class="n">num_nodes</span>
        <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
            <span class="c1"># Type ID is always in int64</span>
            <span class="n">ntype_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">ntype_id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
            <span class="n">ntype_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
        <span class="n">nids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">etype_id</span><span class="p">,</span> <span class="n">etype</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">):</span>
        <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="n">etype</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">all_edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">)</span>
        <span class="n">num_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
        <span class="n">srcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">src</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset_per_ntype</span><span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">srctype</span><span class="p">)]))</span>
        <span class="n">dsts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dst</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset_per_ntype</span><span class="p">[</span><span class="n">G</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">dsttype</span><span class="p">)]))</span>
        <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
            <span class="c1"># Type ID is always in int64</span>
            <span class="n">etype_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">etype_id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
            <span class="n">etype_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_edges</span><span class="p">)</span>
        <span class="n">eids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_edges</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>

    <span class="n">retg</span> <span class="o">=</span> <span class="n">graph</span><span class="p">(</span>
        <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">srcs</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">dsts</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span>
        <span class="n">num_nodes</span><span class="o">=</span><span class="n">total_num_nodes</span><span class="p">,</span>
        <span class="n">idtype</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">G</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># copy features</span>
    <span class="k">if</span> <span class="n">ndata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ndata</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">edata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edata</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">comb_nf</span> <span class="o">=</span> <span class="n">combine_frames</span><span class="p">(</span>
        <span class="n">G</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)),</span> <span class="n">col_names</span><span class="o">=</span><span class="n">ndata</span>
    <span class="p">)</span>
    <span class="n">comb_ef</span> <span class="o">=</span> <span class="n">combine_frames</span><span class="p">(</span>
        <span class="n">G</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">etypes</span><span class="p">)),</span> <span class="n">col_names</span><span class="o">=</span><span class="n">edata</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">comb_nf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">ndata</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">comb_nf</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">comb_ef</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">comb_ef</span><span class="p">)</span>

    <span class="n">retg</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">retg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">store_type</span><span class="p">:</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NTYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ntype_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">retg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">ETYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">etype_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_count</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">retg</span><span class="p">,</span> <span class="n">ntype_count</span><span class="p">,</span> <span class="n">etype_count</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">retg</span></div>



<div class="viewcode-block" id="from_scipy">
<a class="viewcode-back" href="../../generated/dgl.from_scipy.html#dgl.from_scipy">[docs]</a>
<span class="k">def</span> <span class="nf">from_scipy</span><span class="p">(</span><span class="n">sp_mat</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a graph from a SciPy sparse matrix and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sp_mat : scipy.sparse.spmatrix</span>
<span class="sd">        The graph adjacency matrix. Each nonzero entry ``sp_mat[i, j]`` represents an edge from</span>
<span class="sd">        node ``i`` to ``j``. The matrix must have square shape ``(N, N)``, where ``N`` is the</span>
<span class="sd">        number of nodes in the graph.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        The edata name for storing the nonzero values of :attr:`sp_mat`. If given, DGL will</span>
<span class="sd">        store the nonzero values of :attr:`sp_mat` in ``edata[eweight_name]`` of the returned</span>
<span class="sd">        graph.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. The function supports all kinds of SciPy sparse matrix classes (e.g.,</span>
<span class="sd">       :class:`scipy.sparse.csr.csr_matrix`). It converts the input matrix to the COOrdinate</span>
<span class="sd">       format using :func:`scipy.sparse.spmatrix.tocoo` before creates a :class:`DGLGraph`.</span>
<span class="sd">       Creating from a :class:`scipy.sparse.coo.coo_matrix` is hence the most efficient way.</span>
<span class="sd">    2. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from scipy.sparse import coo_matrix</span>

<span class="sd">    Create a small three-edge graph.</span>

<span class="sd">    &gt;&gt;&gt; # Source nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; src_ids = np.array([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; # Destination nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; dst_ids = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; # Weight for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; eweight = np.array([0.2, 0.3, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; sp_mat = coo_matrix((eweight, (src_ids, dst_ids)), shape=(5, 5))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.from_scipy(sp_mat)</span>

<span class="sd">    Retrieve the edge weights.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_scipy(sp_mat, eweight_name=&#39;w&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;]</span>
<span class="sd">    tensor([0.2000, 0.3000, 0.5000], dtype=torch.float64)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_scipy(sp_mat, idtype=torch.int32, device=&#39;cuda:0&#39;)</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    graph</span>
<span class="sd">    from_networkx</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Sanity check</span>
    <span class="n">num_rows</span> <span class="o">=</span> <span class="n">sp_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_cols</span> <span class="o">=</span> <span class="n">sp_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">num_rows</span> <span class="o">!=</span> <span class="n">num_cols</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Expect the number of rows to be the same as the number of columns for &quot;</span>
            <span class="s2">&quot;sp_mat, got </span><span class="si">{:d}</span><span class="s2"> and </span><span class="si">{:d}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">sp_mat</span><span class="p">,</span> <span class="n">idtype</span>
    <span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="s2">&quot;_N&quot;</span><span class="p">,</span> <span class="s2">&quot;_E&quot;</span><span class="p">,</span> <span class="s2">&quot;_N&quot;</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sp_mat</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="bipartite_from_scipy">
<a class="viewcode-back" href="../../generated/dgl.bipartite_from_scipy.html#dgl.bipartite_from_scipy">[docs]</a>
<span class="k">def</span> <span class="nf">bipartite_from_scipy</span><span class="p">(</span>
    <span class="n">sp_mat</span><span class="p">,</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a uni-directional bipartite graph from a SciPy sparse matrix and return.</span>

<span class="sd">    The created graph will have two types of nodes ``utype`` and ``vtype`` as well as one</span>
<span class="sd">    edge type ``etype`` whose edges are from ``utype`` to ``vtype``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sp_mat : scipy.sparse.spmatrix</span>
<span class="sd">        The graph adjacency matrix. Each nonzero entry ``sp_mat[i, j]``</span>
<span class="sd">        represents an edge from node ``i`` of type :attr:`utype` to ``j`` of type :attr:`vtype`.</span>
<span class="sd">        Let the matrix shape be ``(N, M)``. There will be ``N`` nodes of type :attr:`utype`</span>
<span class="sd">        and ``M`` nodes of type ``vtype`` in the resulting graph.</span>
<span class="sd">    utype : str, optional</span>
<span class="sd">        The name of the source node type.</span>
<span class="sd">    etype : str, optional</span>
<span class="sd">        The name of the edge type.</span>
<span class="sd">    vtype : str, optional</span>
<span class="sd">        The name of the destination node type.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        The edata name for storing the nonzero values of :attr:`sp_mat`.</span>
<span class="sd">        If given, DGL will store the nonzero values of :attr:`sp_mat` in ``edata[eweight_name]``</span>
<span class="sd">        of the returned graph.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    1. The function supports all kinds of SciPy sparse matrix classes (e.g.,</span>
<span class="sd">       :class:`scipy.sparse.csr.csr_matrix`). It converts the input matrix to the COOrdinate</span>
<span class="sd">       format using :func:`scipy.sparse.spmatrix.tocoo` before creates a :class:`DGLGraph`.</span>
<span class="sd">       Creating from a :class:`scipy.sparse.coo.coo_matrix` is hence the most efficient way.</span>
<span class="sd">    2. DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">       formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">       If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">       :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from scipy.sparse import coo_matrix</span>

<span class="sd">    Create a small three-edge graph.</span>

<span class="sd">    &gt;&gt;&gt; # Source nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; src_ids = np.array([2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; # Destination nodes for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; dst_ids = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; # Weight for edges (2, 1), (3, 2), (4, 3)</span>
<span class="sd">    &gt;&gt;&gt; eweight = np.array([0.2, 0.3, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; sp_mat = coo_matrix((eweight, (src_ids, dst_ids)))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_scipy(sp_mat, utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;)</span>

<span class="sd">    Retrieve the edge weights.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_scipy(sp_mat, utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;, eweight_name=&#39;w&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;]</span>
<span class="sd">    tensor([0.2000, 0.3000, 0.5000], dtype=torch.float64)</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_scipy(sp_mat, utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;,</span>
<span class="sd">    ...                              idtype=torch.int32, device=&#39;cuda:0&#39;)</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    heterograph</span>
<span class="sd">    bipartite_from_networkx</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">sp_mat</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">bipartite</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sp_mat</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_batcher</span><span class="p">(</span><span class="n">lst</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">lst</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">F</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lst</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lst</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>


<div class="viewcode-block" id="from_networkx">
<a class="viewcode-back" href="../../generated/dgl.from_networkx.html#dgl.from_networkx">[docs]</a>
<span class="k">def</span> <span class="nf">from_networkx</span><span class="p">(</span>
    <span class="n">nx_graph</span><span class="p">,</span>
    <span class="n">node_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a graph from a NetworkX graph and return.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Creating a DGLGraph from a NetworkX graph is not fast especially for large scales.</span>
<span class="sd">        It is recommended to first convert a NetworkX graph into a tuple of node-tensors</span>
<span class="sd">        and then construct a DGLGraph with :func:`dgl.graph`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nx_graph : networkx.Graph</span>
<span class="sd">        The NetworkX graph holding the graph structure and the node/edge attributes.</span>
<span class="sd">        DGL will relabel the nodes using consecutive integers starting from zero if it is</span>
<span class="sd">        not the case. If the input graph is undirected, DGL converts it to a directed graph</span>
<span class="sd">        by :func:`networkx.Graph.to_directed`.</span>
<span class="sd">    node_attrs : list[str], optional</span>
<span class="sd">        The names of the node attributes to retrieve from the NetworkX graph. If given, DGL</span>
<span class="sd">        stores the retrieved node attributes in ``ndata`` of the returned graph using their</span>
<span class="sd">        original names. The attribute data must be convertible to Tensor type (e.g., scalar,</span>
<span class="sd">        numpy.ndarray, list, etc.).</span>
<span class="sd">    edge_attrs : list[str], optional</span>
<span class="sd">        The names of the edge attributes to retrieve from the NetworkX graph. If given, DGL</span>
<span class="sd">        stores the retrieved edge attributes in ``edata`` of the returned graph using their</span>
<span class="sd">        original names. The attribute data must be convertible to Tensor type (e.g., scalar,</span>
<span class="sd">        ``numpy.ndarray``, list, etc.). It must be None if :attr:`nx_graph` is undirected.</span>
<span class="sd">    edge_id_attr_name : str, optional</span>
<span class="sd">        The name of the edge attribute that stores the edge IDs. If given, DGL will assign edge</span>
<span class="sd">        IDs accordingly when creating the graph, so the attribute must be valid IDs, i.e.</span>
<span class="sd">        consecutive integers starting from zero. By default, the edge IDs of the returned graph</span>
<span class="sd">        can be arbitrary. It must be None if :attr:`nx_graph` is undirected.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., ``torch.int32``).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., ``torch.device``). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    DGL internally maintains multiple copies of the graph structure in different sparse</span>
<span class="sd">    formats and chooses the most efficient one depending on the computation invoked.</span>
<span class="sd">    If memory usage becomes an issue in the case of large graphs, use</span>
<span class="sd">    :func:`dgl.DGLGraph.formats` to restrict the allowed formats.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import networkx as nx</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a 2-edge NetworkX graph.</span>

<span class="sd">    &gt;&gt;&gt; nx_g = nx.DiGraph()</span>
<span class="sd">    &gt;&gt;&gt; # Add 3 nodes and two features for them</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_nodes_from([0, 1, 2], feat1=np.zeros((3, 1)), feat2=np.ones((3, 1)))</span>
<span class="sd">    &gt;&gt;&gt; # Add 2 edges (1, 2) and (2, 1) with two features, one being edge IDs</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(1, 2, weight=np.ones((1, 1)), eid=np.array([1]))</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(2, 1, weight=np.ones((1, 1)), eid=np.array([0]))</span>

<span class="sd">    Convert it into a DGLGraph with structure only.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g)</span>

<span class="sd">    Retrieve the node/edge features of the graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g, node_attrs=[&#39;feat1&#39;, &#39;feat2&#39;], edge_attrs=[&#39;weight&#39;])</span>

<span class="sd">    Use a pre-specified ordering of the edges.</span>

<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([1, 2]), tensor([2, 1]))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g, edge_id_attr_name=&#39;eid&#39;)</span>
<span class="sd">    (tensor([2, 1]), tensor([1, 2]))</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.from_networkx(nx_g, idtype=torch.int32, device=&#39;cuda:0&#39;)</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    graph</span>
<span class="sd">    from_scipy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Sanity check</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="ow">and</span> <span class="n">edge_id_attr_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)))[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Failed to find the pre-specified edge IDs in the edge features of &quot;</span>
            <span class="s2">&quot;the NetworkX graph with name </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">edge_id_attr_name</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Expect edge_id_attr_name and edge_attrs to be None when nx_graph is &quot;</span>
            <span class="s2">&quot;undirected, got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">edge_id_attr_name</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Relabel nodes using consecutive integers starting from 0</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">convert_node_labels_to_integers</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">,</span> <span class="n">ordering</span><span class="o">=</span><span class="s2">&quot;sorted&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">():</span>
        <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span>

    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">nx_graph</span><span class="p">,</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="n">edge_id_attr_name</span>
    <span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="s2">&quot;_N&quot;</span><span class="p">,</span> <span class="s2">&quot;_E&quot;</span><span class="p">,</span> <span class="s2">&quot;_N&quot;</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span><span class="p">)</span>

    <span class="c1"># nx_graph.edges(data=True) returns src, dst, attr_dict</span>
    <span class="n">has_edge_id</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="c1"># handle features</span>
    <span class="c1"># copy attributes</span>
    <span class="k">if</span> <span class="n">node_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()):</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">:</span>
                <span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nid</span><span class="p">][</span><span class="n">attr</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">())</span>
        <span class="c1"># each defaultdict value is initialized to be a list of None</span>
        <span class="c1"># None here serves as placeholder to be replaced by feature with</span>
        <span class="c1"># corresponding edge id</span>
        <span class="k">if</span> <span class="n">has_edge_id</span><span class="p">:</span>
            <span class="n">num_edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">attrs</span><span class="p">[</span><span class="n">edge_id_attr_name</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">num_edges</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">&quot;Expect the pre-specified edge ids to be&quot;</span>
                        <span class="s2">&quot; smaller than the number of edges --&quot;</span>
                        <span class="s2">&quot; </span><span class="si">{}</span><span class="s2">, got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">attrs</span><span class="p">[</span><span class="n">edge_id_attr_name</span><span class="p">]]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># XXX: assuming networkx iteration order is deterministic</span>
            <span class="c1">#      so the order is the same as graph_index.from_networkx</span>
            <span class="k">for</span> <span class="n">eid</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">eid</span><span class="p">]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">&quot;Not all edges have attribute </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<div class="viewcode-block" id="bipartite_from_networkx">
<a class="viewcode-back" href="../../generated/dgl.bipartite_from_networkx.html#dgl.bipartite_from_networkx">[docs]</a>
<span class="k">def</span> <span class="nf">bipartite_from_networkx</span><span class="p">(</span>
    <span class="n">nx_graph</span><span class="p">,</span>
    <span class="n">utype</span><span class="p">,</span>
    <span class="n">etype</span><span class="p">,</span>
    <span class="n">vtype</span><span class="p">,</span>
    <span class="n">u_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">e_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">v_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">idtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a unidirectional bipartite graph from a NetworkX graph and return.</span>

<span class="sd">    The created graph will have two types of nodes ``utype`` and ``vtype`` as well as one</span>
<span class="sd">    edge type ``etype`` whose edges are from ``utype`` to ``vtype``.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Creating a DGLGraph from a NetworkX graph is not fast especially for large scales.</span>
<span class="sd">        It is recommended to first convert a NetworkX graph into a tuple of node-tensors</span>
<span class="sd">        and then construct a DGLGraph with :func:`dgl.heterograph`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nx_graph : networkx.DiGraph</span>
<span class="sd">        The NetworkX graph holding the graph structure and the node/edge attributes.</span>
<span class="sd">        DGL will relabel the nodes using consecutive integers starting from zero if it is</span>
<span class="sd">        not the case. The graph must follow `NetworkX&#39;s bipartite graph convention</span>
<span class="sd">        &lt;https://networkx.github.io/documentation/stable/reference/algorithms/bipartite.html&gt;`_,</span>
<span class="sd">        and furthermore the edges must be from nodes with attribute ``bipartite=0`` to nodes</span>
<span class="sd">        with attribute ``bipartite=1``.</span>
<span class="sd">    utype : str, optional</span>
<span class="sd">        The name of the source node type.</span>
<span class="sd">    etype : str, optional</span>
<span class="sd">        The name of the edge type.</span>
<span class="sd">    vtype : str, optional</span>
<span class="sd">        The name of the destination node type.</span>
<span class="sd">    u_attrs : list[str], optional</span>
<span class="sd">        The names of the node attributes for node type :attr:`utype` to retrieve from the</span>
<span class="sd">        NetworkX graph. If given, DGL stores the retrieved node attributes in</span>
<span class="sd">        ``nodes[utype].data`` of the returned graph using their original names. The attribute</span>
<span class="sd">        data must be convertible to Tensor type (e.g., scalar, ``numpy.ndarray``, list, etc.).</span>
<span class="sd">    e_attrs : list[str], optional</span>
<span class="sd">        The names of the edge attributes to retrieve from the NetworkX graph. If given, DGL</span>
<span class="sd">        stores the retrieved edge attributes in ``edata`` of the returned graph using their</span>
<span class="sd">        original names. The attribute data must be convertible to Tensor type (e.g., scalar,</span>
<span class="sd">        numpy.ndarray, list, etc.).</span>
<span class="sd">    v_attrs : list[str], optional</span>
<span class="sd">        The names of the node attributes for node type :attr:`vtype` to retrieve from the</span>
<span class="sd">        NetworkX graph.  If given, DGL stores the retrieved node attributes in</span>
<span class="sd">        ``nodes[vtype].data`` of the returned graph using their original names. The attribute</span>
<span class="sd">        data must be convertible to Tensor type (e.g., scalar, numpy.array, list, etc.).</span>
<span class="sd">    edge_id_attr_name : str, optional</span>
<span class="sd">        The name of the edge attribute that stores the edge IDs. If given, DGL will assign edge</span>
<span class="sd">        IDs accordingly when creating the graph, so the attribute must be valid IDs, i.e.</span>
<span class="sd">        consecutive integers starting from zero. By default, the edge IDs of the returned graph</span>
<span class="sd">        can be arbitrary.</span>
<span class="sd">    idtype : int32 or int64, optional</span>
<span class="sd">        The data type for storing the structure-related graph information such as node and</span>
<span class="sd">        edge IDs. It should be a framework-specific data type object (e.g., torch.int32).</span>
<span class="sd">        By default, DGL uses int64.</span>
<span class="sd">    device : device context, optional</span>
<span class="sd">        The device of the resulting graph. It should be a framework-specific device object</span>
<span class="sd">        (e.g., torch.device). By default, DGL stores the graph on CPU.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import networkx as nx</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    Create a 2-edge unidirectional bipartite graph.</span>

<span class="sd">    &gt;&gt;&gt; nx_g = nx.DiGraph()</span>
<span class="sd">    &gt;&gt;&gt; # Add nodes for the source type</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_nodes_from([1, 3], bipartite=0, feat1=np.zeros((2, 1)), feat2=np.ones((2, 1)))</span>
<span class="sd">    &gt;&gt;&gt; # Add nodes for the destination type</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_nodes_from([2, 4, 5], bipartite=1, feat3=np.zeros((3, 1)))</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(1, 4, weight=np.ones((1, 1)), eid=np.array([1]))</span>
<span class="sd">    &gt;&gt;&gt; nx_g.add_edge(3, 5, weight=np.ones((1, 1)), eid=np.array([0]))</span>

<span class="sd">    Convert it into a DGLGraph with structure only.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g, utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;)</span>

<span class="sd">    Retrieve the node/edge features of the graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g, utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;,</span>
<span class="sd">    ...                                 u_attrs=[&#39;feat1&#39;, &#39;feat2&#39;],</span>
<span class="sd">    ...                                 e_attrs=[&#39;weight&#39;],</span>
<span class="sd">    ...                                 v_attrs=[&#39;feat3&#39;])</span>

<span class="sd">    Use a pre-specified ordering of the edges.</span>

<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g,</span>
<span class="sd">    ...                                 utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;,</span>
<span class="sd">    ...                                 edge_id_attr_name=&#39;eid&#39;)</span>
<span class="sd">    (tensor([1, 0]), tensor([2, 1]))</span>

<span class="sd">    Create a graph on the first GPU with data type int32.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.bipartite_from_networkx(nx_g, utype=&#39;_U&#39;, etype=&#39;_E&#39;, vtype=&#39;_V&#39;,</span>
<span class="sd">    ...                                 idtype=torch.int32, device=&#39;cuda:0&#39;)</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    heterograph</span>
<span class="sd">    bipartite_from_scipy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Expect nx_graph to be a directed NetworkX graph.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="ow">and</span> <span class="ow">not</span> <span class="n">edge_id_attr_name</span> <span class="ow">in</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)))[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Failed to find the pre-specified edge IDs in the edge features &quot;</span>
            <span class="s2">&quot;of the NetworkX graph with name </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">edge_id_attr_name</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Get the source and destination node sets</span>
    <span class="n">top_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">bottom_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">ndata</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;bipartite&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ndata</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Expect the node </span><span class="si">{}</span><span class="s2"> to have attribute bipartite&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;bipartite&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">top_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;bipartite&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">bottom_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expect the bipartite attribute of the node </span><span class="si">{}</span><span class="s2"> to be 0 or 1, &quot;</span>
                <span class="s2">&quot;got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;bipartite&quot;</span><span class="p">])</span>
            <span class="p">)</span>

    <span class="c1"># Separately relabel the source and destination nodes.</span>
    <span class="n">top_nodes</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">top_nodes</span><span class="p">)</span>
    <span class="n">bottom_nodes</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">bottom_nodes</span><span class="p">)</span>
    <span class="n">top_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">top_nodes</span><span class="p">)}</span>
    <span class="n">bottom_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bottom_nodes</span><span class="p">)}</span>

    <span class="c1"># Get the node tensors and the number of nodes</span>
    <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
        <span class="n">nx_graph</span><span class="p">,</span>
        <span class="n">idtype</span><span class="p">,</span>
        <span class="n">bipartite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">edge_id_attr_name</span><span class="o">=</span><span class="n">edge_id_attr_name</span><span class="p">,</span>
        <span class="n">top_map</span><span class="o">=</span><span class="n">top_map</span><span class="p">,</span>
        <span class="n">bottom_map</span><span class="o">=</span><span class="n">bottom_map</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">create_from_edges</span><span class="p">(</span>
        <span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">,</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">,</span> <span class="n">urange</span><span class="p">,</span> <span class="n">vrange</span>
    <span class="p">)</span>

    <span class="c1"># nx_graph.edges(data=True) returns src, dst, attr_dict</span>
    <span class="n">has_edge_id</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">edge_id_attr_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="c1"># handle features</span>
    <span class="c1"># copy attributes</span>
    <span class="k">if</span> <span class="n">u_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">src_attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nid</span> <span class="ow">in</span> <span class="n">top_map</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">u_attrs</span><span class="p">:</span>
                <span class="n">src_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nid</span><span class="p">][</span><span class="n">attr</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">u_attrs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">srcdata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">src_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">v_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">dst_attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nid</span> <span class="ow">in</span> <span class="n">bottom_map</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">v_attrs</span><span class="p">:</span>
                <span class="n">dst_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nid</span><span class="p">][</span><span class="n">attr</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">v_attrs</span><span class="p">:</span>
            <span class="n">g</span><span class="o">.</span><span class="n">dstdata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">dst_attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">e_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># mapping from feature name to a list of tensors to be concatenated</span>
        <span class="n">attr_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">())</span>
        <span class="c1"># each defaultdict value is initialized to be a list of None</span>
        <span class="c1"># None here serves as placeholder to be replaced by feature with</span>
        <span class="c1"># corresponding edge id</span>
        <span class="k">if</span> <span class="n">has_edge_id</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">e_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">attrs</span><span class="p">[</span><span class="n">edge_id_attr_name</span><span class="p">]]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># XXX: assuming networkx iteration order is deterministic</span>
            <span class="c1">#      so the order is the same as graph_index.from_networkx</span>
            <span class="k">for</span> <span class="n">eid</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">e_attrs</span><span class="p">:</span>
                    <span class="n">attr_dict</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">eid</span><span class="p">]</span> <span class="o">=</span> <span class="n">attrs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">e_attrs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">&quot;Not all edges have attribute </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">_batcher</span><span class="p">(</span><span class="n">attr_dict</span><span class="p">[</span><span class="n">attr</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_to_networkx_homogeneous</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">):</span>
    <span class="c1"># TODO: consider adding an eid_attr parameter as in</span>
    <span class="c1">#  `_to_networkx_heterogeneous` when this function is properly tested</span>
    <span class="c1"># (see GitHub issue #5735)</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">dst</span><span class="p">)</span>
    <span class="c1"># xiangsx: Always treat graph as multigraph</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>
    <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()))</span>
    <span class="k">for</span> <span class="n">eid</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)):</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="n">eid</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">node_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">nid</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_n_repr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nid</span><span class="p">)</span>
            <span class="n">attr</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">}</span>
            <span class="p">)</span>
    <span class="k">if</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="n">attr</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span>
            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_e_repr</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">eid</span><span class="p">)</span>
            <span class="n">attr</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">}</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">nx_graph</span>


<span class="k">def</span> <span class="nf">_to_networkx_heterogeneous</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="n">ntype_attr</span><span class="p">,</span> <span class="n">etype_attr</span><span class="p">,</span> <span class="n">eid_attr</span>
<span class="p">):</span>
    <span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>

    <span class="c1"># This implementation does not use `ndata` and `edata` in the call to</span>
    <span class="c1"># `to_homogeneous` because the function expects node and edge attributes</span>
    <span class="c1"># both to be defined for every type and to have the same shape.</span>
    <span class="c1"># If the `to_homogeneous` function is updated to support non-uniform node</span>
    <span class="c1"># and edge attributes, the implementation can be simplified.</span>
    <span class="n">hom_g</span> <span class="o">=</span> <span class="n">to_homogeneous</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">store_type</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_count</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ntypes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span>
    <span class="n">etypes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span>

    <span class="k">for</span> <span class="n">hom_nid</span><span class="p">,</span> <span class="n">ndata</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">hom_g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NID</span><span class="p">],</span> <span class="n">hom_g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NTYPE</span><span class="p">])):</span>
        <span class="n">orig_nid</span><span class="p">,</span> <span class="n">ntype</span> <span class="o">=</span> <span class="n">ndata</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype_attr</span><span class="p">:</span> <span class="n">ntypes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]}</span>

        <span class="k">if</span> <span class="n">node_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">ntype_attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">ntype_attr</span><span class="si">}</span><span class="s2">&#39; already used as node type attribute, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;please provide a different value for ntype_attr&quot;</span>
            <span class="p">)</span>

            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_n_repr</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="n">orig_nid</span><span class="p">)</span>
            <span class="n">attrs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">node_attrs</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">feat_dict</span>
                <span class="p">}</span>
            <span class="p">)</span>

        <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">hom_nid</span><span class="p">,</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">hom_eid</span><span class="p">,</span> <span class="n">edata</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">hom_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">],</span> <span class="n">hom_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">ETYPE</span><span class="p">])):</span>
        <span class="n">orig_eid</span><span class="p">,</span> <span class="n">etype</span> <span class="o">=</span> <span class="n">edata</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="p">{</span><span class="n">eid_attr</span><span class="p">:</span> <span class="n">hom_eid</span><span class="p">,</span> <span class="n">etype_attr</span><span class="p">:</span> <span class="n">etypes</span><span class="p">[</span><span class="n">etype</span><span class="p">]}</span>

        <span class="k">if</span> <span class="n">edge_attrs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">etype_attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">etype_attr</span><span class="si">}</span><span class="s2">&#39; already used as edge type attribute, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;please provide a different value for etype_attr&quot;</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="n">eid_attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">eid_attr</span><span class="si">}</span><span class="s2">&#39; already used as edge ID attribute, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;please provide a different value for eid_attr&quot;</span>
            <span class="p">)</span>

            <span class="n">feat_dict</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_get_e_repr</span><span class="p">(</span><span class="n">etype</span><span class="p">,</span> <span class="n">orig_eid</span><span class="p">)</span>
            <span class="n">attrs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">feat_dict</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_attrs</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">feat_dict</span>
                <span class="p">}</span>
            <span class="p">)</span>

        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">hom_g</span><span class="o">.</span><span class="n">find_edges</span><span class="p">(</span><span class="n">hom_eid</span><span class="p">)</span>
        <span class="n">nx_graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">src</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">dst</span><span class="p">),</span> <span class="o">**</span><span class="n">attrs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">nx_graph</span>


<div class="viewcode-block" id="to_networkx">
<a class="viewcode-back" href="../../generated/dgl.to_networkx.html#dgl.to_networkx">[docs]</a>
<span class="k">def</span> <span class="nf">to_networkx</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">node_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ntype_attr</span><span class="o">=</span><span class="s2">&quot;ntype&quot;</span><span class="p">,</span>
    <span class="n">etype_attr</span><span class="o">=</span><span class="s2">&quot;etype&quot;</span><span class="p">,</span>
    <span class="n">eid_attr</span><span class="o">=</span><span class="s2">&quot;id&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a graph to a NetworkX graph and return.</span>

<span class="sd">    The resulting NetworkX graph also contains the node/edge features of the input graph.</span>
<span class="sd">    Additionally, DGL saves the edge IDs as the ``&#39;id&#39;`` edge attribute in the</span>
<span class="sd">    returned NetworkX graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        A homogeneous or heterogeneous graph.</span>
<span class="sd">    node_attrs : iterable of str, optional</span>
<span class="sd">        The node attributes to copy from ``g.ndata``. (Default: None)</span>
<span class="sd">    edge_attrs : iterable of str, optional</span>
<span class="sd">        The edge attributes to copy from ``g.edata``.</span>
<span class="sd">        (Default: None)</span>
<span class="sd">    ntype_attr : str, optional</span>
<span class="sd">        The name of the node attribute to store the node types in the NetworkX object.</span>
<span class="sd">        (Default: &quot;ntype&quot;)</span>
<span class="sd">    etype_attr : str, optional</span>
<span class="sd">        The name of the edge attribute to store the edge canonical types in the NetworkX object.</span>
<span class="sd">        (Default: &quot;etype&quot;)</span>
<span class="sd">    eid_attr : str, optional</span>
<span class="sd">        The name of the edge attribute to store the original edge ID in the NetworkX object.</span>
<span class="sd">        (Default: &quot;id&quot;)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    networkx.DiGraph</span>
<span class="sd">        The converted NetworkX graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The function only supports CPU graph input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following examples use the PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    With a homogeneous graph:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.zeros(4, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h1&#39;] = torch.ones(2, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h2&#39;] = torch.zeros(2, 2)</span>
<span class="sd">    &gt;&gt;&gt; nx_g = dgl.to_networkx(g, node_attrs=[&#39;h&#39;], edge_attrs=[&#39;h1&#39;, &#39;h2&#39;])</span>
<span class="sd">    &gt;&gt;&gt; nx_g.nodes(data=True)</span>
<span class="sd">    NodeDataView({</span>
<span class="sd">        0: {&#39;h&#39;: tensor([0.])},</span>
<span class="sd">        1: {&#39;h&#39;: tensor([0.])},</span>
<span class="sd">        2: {&#39;h&#39;: tensor([0.])},</span>
<span class="sd">        3: {&#39;h&#39;: tensor([0.])}</span>
<span class="sd">    })</span>
<span class="sd">    &gt;&gt;&gt; nx_g.edges(data=True)</span>
<span class="sd">    OutMultiEdgeDataView([</span>
<span class="sd">        (1, 1, {&#39;id&#39;: 0, &#39;h1&#39;: tensor([1.]), &#39;h2&#39;: tensor([0., 0.])}),</span>
<span class="sd">        (2, 3, {&#39;id&#39;: 1, &#39;h1&#39;: tensor([1.]), &#39;h2&#39;: tensor([0., 0.])})</span>
<span class="sd">    ])</span>

<span class="sd">    With a heterogeneous graph:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;topic&#39;): (torch.tensor([1, 1]), torch.tensor([1, 2])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 3]), torch.tensor([3, 4]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;n&#39;] = {</span>
<span class="sd">    ...     &#39;game&#39;: torch.zeros(5, 1),</span>
<span class="sd">    ...     &#39;user&#39;: torch.ones(4, 1)</span>
<span class="sd">    ... }</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;e&#39;] = {</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.zeros(2, 1),</span>
<span class="sd">    ...     &#39;plays&#39;: torch.ones(2, 1)</span>
<span class="sd">    ... }</span>
<span class="sd">    &gt;&gt;&gt; nx_g = dgl.to_networkx(g, node_attrs=[&#39;n&#39;], edge_attrs=[&#39;e&#39;])</span>
<span class="sd">    &gt;&gt;&gt; nx_g.nodes(data=True)</span>
<span class="sd">    NodeDataView({</span>
<span class="sd">        0: {&#39;ntype&#39;: &#39;game&#39;, &#39;n&#39;: tensor([0.])},</span>
<span class="sd">        1: {&#39;ntype&#39;: &#39;game&#39;, &#39;n&#39;: tensor([0.])},</span>
<span class="sd">        2: {&#39;ntype&#39;: &#39;game&#39;, &#39;n&#39;: tensor([0.])},</span>
<span class="sd">        3: {&#39;ntype&#39;: &#39;game&#39;, &#39;n&#39;: tensor([0.])},</span>
<span class="sd">        4: {&#39;ntype&#39;: &#39;game&#39;, &#39;n&#39;: tensor([0.])},</span>
<span class="sd">        5: {&#39;ntype&#39;: &#39;topic&#39;},</span>
<span class="sd">        6: {&#39;ntype&#39;: &#39;topic&#39;},</span>
<span class="sd">        7: {&#39;ntype&#39;: &#39;topic&#39;},</span>
<span class="sd">        8: {&#39;ntype&#39;: &#39;user&#39;, &#39;n&#39;: tensor([1.])},</span>
<span class="sd">        9: {&#39;ntype&#39;: &#39;user&#39;, &#39;n&#39;: tensor([1.])},</span>
<span class="sd">        10: {&#39;ntype&#39;: &#39;user&#39;, &#39;n&#39;: tensor([1.])},</span>
<span class="sd">        11: {&#39;ntype&#39;: &#39;user&#39;, &#39;n&#39;: tensor([1.])}</span>
<span class="sd">    })</span>
<span class="sd">    &gt;&gt;&gt; nx_g.edges(data=True)</span>
<span class="sd">    OutMultiEdgeDataView([</span>
<span class="sd">        (8, 9, {&#39;id&#39;: 2, &#39;etype&#39;: (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;), &#39;e&#39;: tensor([0.])}),</span>
<span class="sd">        (8, 3, {&#39;id&#39;: 4, &#39;etype&#39;: (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;), &#39;e&#39;: tensor([1.])}),</span>
<span class="sd">        (9, 6, {&#39;id&#39;: 0, &#39;etype&#39;: (&#39;user&#39;, &#39;follows&#39;, &#39;topic&#39;)}),</span>
<span class="sd">        (9, 7, {&#39;id&#39;: 1, &#39;etype&#39;: (&#39;user&#39;, &#39;follows&#39;, &#39;topic&#39;)}),</span>
<span class="sd">        (9, 10, {&#39;id&#39;: 3, &#39;etype&#39;: (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;), &#39;e&#39;: tensor([0.])}),</span>
<span class="sd">        (11, 4, {&#39;id&#39;: 5, &#39;etype&#39;: (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;), &#39;e&#39;: tensor([1.])})</span>
<span class="sd">    ])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Cannot convert a CUDA graph to networkx. Call g.cpu() first.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_to_networkx_homogeneous</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_to_networkx_heterogeneous</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">node_attrs</span><span class="p">,</span> <span class="n">edge_attrs</span><span class="p">,</span> <span class="n">ntype_attr</span><span class="p">,</span> <span class="n">etype_attr</span><span class="p">,</span> <span class="n">eid_attr</span>
        <span class="p">)</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">to_networkx</span> <span class="o">=</span> <span class="n">to_networkx</span>


<div class="viewcode-block" id="to_cugraph">
<a class="viewcode-back" href="../../generated/dgl.to_cugraph.html#dgl.to_cugraph">[docs]</a>
<span class="k">def</span> <span class="nf">to_cugraph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a DGL graph to a :class:`cugraph.Graph` and return.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        A homogeneous graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cugraph.Graph</span>
<span class="sd">        The converted cugraph graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The function only supports GPU graph input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import cugraph</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 2]), torch.tensor([1, 3]))).to(&#39;cuda&#39;)</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g = g.to_cugraph()</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g.edges()</span>
<span class="sd">        src  dst</span>
<span class="sd">    0    2    3</span>
<span class="sd">    1    1    1</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Cannot convert a </span><span class="si">{</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2"> graph to cugraph.&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;Call g.to(&#39;cuda&#39;) first.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;dgl.to_cugraph only supports homogeneous graphs.&quot;</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">cudf</span>
        <span class="kn">import</span> <span class="nn">cugraph</span>
    <span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ModuleNotFoundError</span><span class="p">(</span>
            <span class="s2">&quot;to_cugraph requires cugraph which could not be imported&quot;</span>
        <span class="p">)</span>

    <span class="n">edgelist</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">src_ser</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dlpack</span><span class="p">(</span><span class="n">edgelist</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">dst_ser</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dlpack</span><span class="p">(</span><span class="n">edgelist</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">cudf_data</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="n">src_ser</span><span class="p">,</span> <span class="s2">&quot;destination&quot;</span><span class="p">:</span> <span class="n">dst_ser</span><span class="p">})</span>
    <span class="n">g_cugraph</span> <span class="o">=</span> <span class="n">cugraph</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">g_cugraph</span><span class="o">.</span><span class="n">from_cudf_edgelist</span><span class="p">(</span>
        <span class="n">cudf_data</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">&quot;source&quot;</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="s2">&quot;destination&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">g_cugraph</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">to_cugraph</span> <span class="o">=</span> <span class="n">to_cugraph</span>


<div class="viewcode-block" id="from_cugraph">
<a class="viewcode-back" href="../../generated/dgl.from_cugraph.html#dgl.from_cugraph">[docs]</a>
<span class="k">def</span> <span class="nf">from_cugraph</span><span class="p">(</span><span class="n">cugraph_graph</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a graph from a :class:`cugraph.Graph` object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cugraph_graph : cugraph.Graph</span>
<span class="sd">        The cugraph graph object holding the graph structure. Node and edge attributes are</span>
<span class="sd">        dropped.</span>

<span class="sd">        If the input graph is undirected, DGL converts it to a directed graph</span>
<span class="sd">        by :func:`cugraph.Graph.to_directed`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The created graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import cugraph</span>
<span class="sd">    &gt;&gt;&gt; import cudf</span>

<span class="sd">    Create a cugraph graph.</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g = cugraph.Graph(directed=True)</span>
<span class="sd">    &gt;&gt;&gt; df = cudf.DataFrame({&quot;source&quot;:[0, 1, 2, 3],</span>
<span class="sd">                     &quot;destination&quot;:[1, 2, 3, 0]})</span>
<span class="sd">    &gt;&gt;&gt; cugraph_g.from_cudf_edgelist(df)</span>

<span class="sd">    Convert it into a DGLGraph</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.from_cugraph(cugraph_g)</span>
<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([1, 2, 3, 0], device=&#39;cuda:0&#39;), tensor([2, 3, 0, 1], device=&#39;cuda:0&#39;))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">cugraph_graph</span><span class="o">.</span><span class="n">is_directed</span><span class="p">():</span>
        <span class="n">cugraph_graph</span> <span class="o">=</span> <span class="n">cugraph_graph</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span>

    <span class="n">edges</span> <span class="o">=</span> <span class="n">cugraph_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">src_t</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dlpack</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_dlpack</span><span class="p">())</span>
    <span class="n">dst_t</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dlpack</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="s2">&quot;dst&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_dlpack</span><span class="p">())</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">graph</span><span class="p">((</span><span class="n">src_t</span><span class="p">,</span> <span class="n">dst_t</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">g</span></div>



<span class="c1">############################################################</span>
<span class="c1"># Internal APIs</span>
<span class="c1">############################################################</span>


<span class="k">def</span> <span class="nf">create_from_edges</span><span class="p">(</span>
    <span class="n">sparse_fmt</span><span class="p">,</span>
    <span class="n">arrays</span><span class="p">,</span>
    <span class="n">utype</span><span class="p">,</span>
    <span class="n">etype</span><span class="p">,</span>
    <span class="n">vtype</span><span class="p">,</span>
    <span class="n">urange</span><span class="p">,</span>
    <span class="n">vrange</span><span class="p">,</span>
    <span class="n">row_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">col_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Internal function to create a graph from incident nodes with types.</span>

<span class="sd">    utype could be equal to vtype</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sparse_fmt : str</span>
<span class="sd">        The sparse adjacency matrix format.</span>
<span class="sd">    arrays : tuple[Tensor]</span>
<span class="sd">        The sparse adjacency matrix arrays.</span>
<span class="sd">    utype : str</span>
<span class="sd">        Source node type name.</span>
<span class="sd">    etype : str</span>
<span class="sd">        Edge type name.</span>
<span class="sd">    vtype : str</span>
<span class="sd">        Destination node type name.</span>
<span class="sd">    urange : int, optional</span>
<span class="sd">        The source node ID range. If None, the value is the maximum</span>
<span class="sd">        of the source node IDs in the edge list plus 1. (Default: None)</span>
<span class="sd">    vrange : int, optional</span>
<span class="sd">        The destination node ID range. If None, the value is the</span>
<span class="sd">        maximum of the destination node IDs in the edge list plus 1. (Default: None)</span>
<span class="sd">    row_sorted : bool, optional</span>
<span class="sd">        Whether or not the rows of the COO are in ascending order.</span>
<span class="sd">    col_sorted : bool, optional</span>
<span class="sd">        Whether or not the columns of the COO are in ascending order within</span>
<span class="sd">        each row. This only has an effect when ``row_sorted`` is True.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
        <span class="n">num_ntypes</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_ntypes</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="n">sparse_fmt</span> <span class="o">==</span> <span class="s2">&quot;coo&quot;</span><span class="p">:</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">arrays</span>
        <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_coo</span><span class="p">(</span>
            <span class="n">num_ntypes</span><span class="p">,</span>
            <span class="n">urange</span><span class="p">,</span>
            <span class="n">vrange</span><span class="p">,</span>
            <span class="n">u</span><span class="p">,</span>
            <span class="n">v</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span>
            <span class="n">row_sorted</span><span class="p">,</span>
            <span class="n">col_sorted</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;csr&#39; or &#39;csc&#39;</span>
        <span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">eids</span> <span class="o">=</span> <span class="n">arrays</span>
        <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_csr</span><span class="p">(</span>
            <span class="n">num_ntypes</span><span class="p">,</span>
            <span class="n">urange</span><span class="p">,</span>
            <span class="n">vrange</span><span class="p">,</span>
            <span class="n">indptr</span><span class="p">,</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">eids</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span>
            <span class="n">sparse_fmt</span> <span class="o">==</span> <span class="s2">&quot;csc&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="p">[</span><span class="n">utype</span><span class="p">],</span> <span class="p">[</span><span class="n">etype</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">hgidx</span><span class="p">,</span> <span class="p">[</span><span class="n">utype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">],</span> <span class="p">[</span><span class="n">etype</span><span class="p">])</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>