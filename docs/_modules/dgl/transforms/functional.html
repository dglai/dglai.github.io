<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dgl.transforms.functional &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dgl.transforms.functional</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dgl.transforms.functional</h1><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">#   Copyright 2019-2021 Contributors</span>
<span class="c1">#</span>
<span class="c1">#   Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1">#   you may not use this file except in compliance with the License.</span>
<span class="c1">#   You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#       http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1">#   Unless required by applicable law or agreed to in writing, software</span>
<span class="c1">#   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1">#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1">#   See the License for the specific language governing permissions and</span>
<span class="c1">#   limitations under the License.</span>
<span class="c1">#</span>
<span class="sd">&quot;&quot;&quot;Functional interface for transform&quot;&quot;&quot;</span>
<span class="c1"># pylint: disable= too-many-lines</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Mapping</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sparse</span>
<span class="kn">import</span> <span class="nn">scipy.sparse.linalg</span>

<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">version</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">backend</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">,</span>
    <span class="n">convert</span><span class="p">,</span>
    <span class="n">function</span><span class="p">,</span>
    <span class="n">ndarray</span> <span class="k">as</span> <span class="n">nd</span><span class="p">,</span>
    <span class="n">subgraph</span><span class="p">,</span>
    <span class="n">utils</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.._ffi.function</span> <span class="kn">import</span> <span class="n">_init_api</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">dgl_warning</span><span class="p">,</span> <span class="n">DGLError</span><span class="p">,</span> <span class="n">EID</span><span class="p">,</span> <span class="n">NID</span>
<span class="kn">from</span> <span class="nn">..frame</span> <span class="kn">import</span> <span class="n">Frame</span>
<span class="kn">from</span> <span class="nn">..heterograph</span> <span class="kn">import</span> <span class="n">DGLGraph</span>
<span class="kn">from</span> <span class="nn">..heterograph_index</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">create_heterograph_from_relations</span><span class="p">,</span>
    <span class="n">create_metagraph_index</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..partition</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">metis_partition</span><span class="p">,</span>
    <span class="n">metis_partition_assignment</span><span class="p">,</span>
    <span class="n">partition_graph_with_halo</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">..sampling.neighbor</span> <span class="kn">import</span> <span class="n">sample_neighbors</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;line_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;khop_adj&quot;</span><span class="p">,</span>
    <span class="s2">&quot;khop_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_bidirected&quot;</span><span class="p">,</span>
    <span class="s2">&quot;add_reverse_edges&quot;</span><span class="p">,</span>
    <span class="s2">&quot;laplacian_lambda_max&quot;</span><span class="p">,</span>
    <span class="s2">&quot;knn_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;segmented_knn_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;add_edges&quot;</span><span class="p">,</span>
    <span class="s2">&quot;add_nodes&quot;</span><span class="p">,</span>
    <span class="s2">&quot;remove_edges&quot;</span><span class="p">,</span>
    <span class="s2">&quot;remove_nodes&quot;</span><span class="p">,</span>
    <span class="s2">&quot;add_self_loop&quot;</span><span class="p">,</span>
    <span class="s2">&quot;remove_self_loop&quot;</span><span class="p">,</span>
    <span class="s2">&quot;metapath_reachable_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;compact_graphs&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_simple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_simple_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;sort_csr_by_tag&quot;</span><span class="p">,</span>
    <span class="s2">&quot;sort_csc_by_tag&quot;</span><span class="p">,</span>
    <span class="s2">&quot;metis_partition_assignment&quot;</span><span class="p">,</span>
    <span class="s2">&quot;partition_graph_with_halo&quot;</span><span class="p">,</span>
    <span class="s2">&quot;metis_partition&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adj_product_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adj_sum_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;reorder_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;norm_by_dst&quot;</span><span class="p">,</span>
    <span class="s2">&quot;radius_graph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;random_walk_pe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;laplacian_pe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;lap_pe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_bfloat16&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_half&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_float&quot;</span><span class="p">,</span>
    <span class="s2">&quot;to_double&quot;</span><span class="p">,</span>
    <span class="s2">&quot;double_radius_node_labeling&quot;</span><span class="p">,</span>
    <span class="s2">&quot;shortest_dist&quot;</span><span class="p">,</span>
    <span class="s2">&quot;svd_pe&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">pairwise_squared_distance</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    x : (n_samples, n_points, dims)</span>
<span class="sd">    return : (n_samples, n_points, n_points)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x2s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="c1"># assuming that __matmul__ is always implemented (true for PyTorch, MXNet and Chainer)</span>
    <span class="k">return</span> <span class="n">x2s</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">x2s</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">@</span> <span class="n">F</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>


<span class="c1"># pylint: disable=invalid-name</span>
<div class="viewcode-block" id="knn_graph">
<a class="viewcode-back" href="../../../generated/dgl.knn_graph.html#dgl.knn_graph">[docs]</a>
<span class="k">def</span> <span class="nf">knn_graph</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;bruteforce-blas&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span> <span class="n">exclude_self</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct a graph from a set of points according to k-nearest-neighbor (KNN)</span>
<span class="sd">    and return.</span>

<span class="sd">    The function transforms the coordinates/features of a point set</span>
<span class="sd">    into a directed homogeneous graph. The coordinates of the point</span>
<span class="sd">    set is specified as a matrix whose rows correspond to points and</span>
<span class="sd">    columns correspond to coordinate/feature dimensions.</span>

<span class="sd">    The nodes of the returned graph correspond to the points, where the predecessors</span>
<span class="sd">    of each point are its k-nearest neighbors measured by the chosen distance.</span>

<span class="sd">    If :attr:`x` is a 3D tensor, then each submatrix will be transformed</span>
<span class="sd">    into a separate graph. DGL then composes the graphs into a large batched</span>
<span class="sd">    graph of multiple (:math:`shape(x)[0]`) connected components.</span>

<span class="sd">    See :doc:`the benchmark &lt;../api/python/knn_benchmark&gt;` for a complete benchmark result.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        The point coordinates. It can be either on CPU or GPU.</span>

<span class="sd">        * If is 2D, ``x[i]`` corresponds to the i-th node in the KNN graph.</span>

<span class="sd">        * If is 3D, ``x[i]`` corresponds to the i-th KNN graph and</span>
<span class="sd">          ``x[i][j]`` corresponds to the j-th node in the i-th KNN graph.</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of nearest neighbors per node.</span>
<span class="sd">    algorithm : str, optional</span>
<span class="sd">        Algorithm used to compute the k-nearest neighbors.</span>

<span class="sd">        * &#39;bruteforce-blas&#39; will first compute the distance matrix</span>
<span class="sd">          using BLAS matrix multiplication operation provided by</span>
<span class="sd">          backend frameworks. Then use topk algorithm to get</span>
<span class="sd">          k-nearest neighbors. This method is fast when the point</span>
<span class="sd">          set is small but has :math:`O(N^2)` memory complexity where</span>
<span class="sd">          :math:`N` is the number of points.</span>

<span class="sd">        * &#39;bruteforce&#39; will compute distances pair by pair and</span>
<span class="sd">          directly select the k-nearest neighbors during distance</span>
<span class="sd">          computation. This method is slower than &#39;bruteforce-blas&#39;</span>
<span class="sd">          but has less memory overhead (i.e., :math:`O(Nk)` where :math:`N`</span>
<span class="sd">          is the number of points, :math:`k` is the number of nearest</span>
<span class="sd">          neighbors per node) since we do not need to store all distances.</span>

<span class="sd">        * &#39;bruteforce-sharemem&#39; (CUDA only) is similar to &#39;bruteforce&#39;</span>
<span class="sd">          but use shared memory in CUDA devices for buffer. This method is</span>
<span class="sd">          faster than &#39;bruteforce&#39; when the dimension of input points</span>
<span class="sd">          is not large. This method is only available on CUDA device.</span>

<span class="sd">        * &#39;kd-tree&#39; will use the kd-tree algorithm (CPU only).</span>
<span class="sd">          This method is suitable for low-dimensional data (e.g. 3D</span>
<span class="sd">          point clouds)</span>

<span class="sd">        * &#39;nn-descent&#39; is an approximate approach from paper</span>
<span class="sd">          `Efficient k-nearest neighbor graph construction for generic similarity</span>
<span class="sd">          measures &lt;https://www.cs.princeton.edu/cass/papers/www11.pdf&gt;`_. This method</span>
<span class="sd">          will search for nearest neighbor candidates in &quot;neighbors&#39; neighbors&quot;.</span>

<span class="sd">        (default: &#39;bruteforce-blas&#39;)</span>
<span class="sd">    dist : str, optional</span>
<span class="sd">        The distance metric used to compute distance between points. It can be the following</span>
<span class="sd">        metrics:</span>
<span class="sd">        * &#39;euclidean&#39;: Use Euclidean distance (L2 norm) :math:`\sqrt{\sum_{i} (x_{i} - y_{i})^{2}}`.</span>
<span class="sd">        * &#39;cosine&#39;: Use cosine distance.</span>
<span class="sd">        (default: &#39;euclidean&#39;)</span>
<span class="sd">    exclude_self : bool, optional</span>
<span class="sd">        If True, the output graph will not contain self loop edges, and each node will not</span>
<span class="sd">        be counted as one of its own k neighbors.  If False, the output graph will contain</span>
<span class="sd">        self loop edges, and a node will be counted as one of its own k neighbors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The constructed graph. The node IDs are in the same order as :attr:`x`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following examples use PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    When :attr:`x` is a 2D tensor, a single KNN graph is constructed.</span>

<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[0.0, 0.0, 1.0],</span>
<span class="sd">    ...                   [1.0, 0.5, 0.5],</span>
<span class="sd">    ...                   [0.5, 0.2, 0.2],</span>
<span class="sd">    ...                   [0.3, 0.2, 0.4]])</span>
<span class="sd">    &gt;&gt;&gt; knn_g = dgl.knn_graph(x, 2)  # Each node has two predecessors</span>
<span class="sd">    &gt;&gt;&gt; knn_g.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 2, 2, 3, 3, 3]), tensor([0, 1, 1, 2, 3, 0, 2, 3]))</span>

<span class="sd">    When :attr:`x` is a 3D tensor, DGL constructs multiple KNN graphs and</span>
<span class="sd">    and then composes them into a graph of multiple connected components.</span>

<span class="sd">    &gt;&gt;&gt; x1 = torch.tensor([[0.0, 0.0, 1.0],</span>
<span class="sd">    ...                    [1.0, 0.5, 0.5],</span>
<span class="sd">    ...                    [0.5, 0.2, 0.2],</span>
<span class="sd">    ...                    [0.3, 0.2, 0.4]])</span>
<span class="sd">    &gt;&gt;&gt; x2 = torch.tensor([[0.0, 1.0, 1.0],</span>
<span class="sd">    ...                    [0.3, 0.3, 0.3],</span>
<span class="sd">    ...                    [0.4, 0.4, 1.0],</span>
<span class="sd">    ...                    [0.3, 0.8, 0.2]])</span>
<span class="sd">    &gt;&gt;&gt; x = torch.stack([x1, x2], dim=0)</span>
<span class="sd">    &gt;&gt;&gt; knn_g = dgl.knn_graph(x, 2)  # Each node has two predecessors</span>
<span class="sd">    &gt;&gt;&gt; knn_g.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 2, 2, 3, 3, 3, 4, 5, 5, 5, 6, 6, 7, 7]),</span>
<span class="sd">     tensor([0, 1, 1, 2, 3, 0, 2, 3, 4, 5, 6, 7, 4, 6, 5, 7]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">exclude_self</span><span class="p">:</span>
        <span class="c1"># add 1 to k, for the self edge, since it will be removed</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># check invalid k</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid k value. expect k &gt; 0, got k = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

    <span class="c1"># check empty point set</span>
    <span class="n">x_size</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">x_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Find empty point set&quot;</span><span class="p">)</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x_seg</span> <span class="o">=</span> <span class="n">x_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">[</span><span class="n">x_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">3</span> <span class="k">else</span> <span class="p">[</span><span class="n">x_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s2">&quot;bruteforce-blas&quot;</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_knn_graph_blas</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">x_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_size</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">knn</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_seg</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">graph</span><span class="p">((</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="c1"># set batch information if x is 3D</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_seg</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set_batch_num_nodes</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
        <span class="c1"># if any segment is too small for k, all algorithms reduce k for all segments</span>
        <span class="n">clamped_k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x_seg</span><span class="p">))</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set_batch_num_edges</span><span class="p">(</span><span class="n">clamped_k</span> <span class="o">*</span> <span class="n">num_nodes</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">exclude_self</span><span class="p">:</span>
        <span class="c1"># remove_self_loop will update batch_num_edges as needed</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">remove_self_loop</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="c1"># If there were more than k(+1) coincident points, there may not have been self loops on</span>
        <span class="c1"># all nodes, in which case there would still be one too many out edges on some nodes.</span>
        <span class="c1"># However, if every node had a self edge, the common case, every node would still have the</span>
        <span class="c1"># same degree as each other, so we can check that condition easily.</span>
        <span class="c1"># The -1 is for the self edge removal.</span>
        <span class="n">clamped_k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x_seg</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span> <span class="o">!=</span> <span class="n">clamped_k</span> <span class="o">*</span> <span class="n">result</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">():</span>
            <span class="c1"># edges on any nodes with too high degree should all be length zero,</span>
            <span class="c1"># so pick an arbitrary one to remove from each such node</span>
            <span class="n">degrees</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">()</span>
            <span class="n">node_indices</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">degrees</span> <span class="o">&gt;</span> <span class="n">clamped_k</span><span class="p">)</span>
            <span class="n">edges_to_remove_graph</span> <span class="o">=</span> <span class="n">sample_neighbors</span><span class="p">(</span>
                <span class="n">result</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">edge_dir</span><span class="o">=</span><span class="s2">&quot;in&quot;</span>
            <span class="p">)</span>
            <span class="n">edge_ids</span> <span class="o">=</span> <span class="n">edges_to_remove_graph</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">remove_edges</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">edge_ids</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>



<span class="k">def</span> <span class="nf">_knn_graph_blas</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct a graph from a set of points according to k-nearest-neighbor (KNN).</span>

<span class="sd">    This function first compute the distance matrix using BLAS matrix multiplication</span>
<span class="sd">    operation provided by backend frameworks. Then use topk algorithm to get</span>
<span class="sd">    k-nearest neighbors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        The point coordinates. It can be either on CPU or GPU.</span>

<span class="sd">        * If is 2D, ``x[i]`` corresponds to the i-th node in the KNN graph.</span>

<span class="sd">        * If is 3D, ``x[i]`` corresponds to the i-th KNN graph and</span>
<span class="sd">          ``x[i][j]`` corresponds to the j-th node in the i-th KNN graph.</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of nearest neighbors per node.</span>
<span class="sd">    dist : str, optional</span>
<span class="sd">        The distance metric used to compute distance between points. It can be the following</span>
<span class="sd">        metrics:</span>
<span class="sd">        * &#39;euclidean&#39;: Use Euclidean distance (L2 norm) :math:`\sqrt{\sum_{i} (x_{i} - y_{i})^{2}}`.</span>
<span class="sd">        * &#39;cosine&#39;: Use cosine distance.</span>
<span class="sd">        (default: &#39;euclidean&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_points</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">n_points</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span>
            <span class="s2">&quot;&#39;k&#39; should be less than or equal to the number of points in &#39;x&#39;&quot;</span>
            <span class="s2">&quot;expect k &lt;= </span><span class="si">{0}</span><span class="s2">, got k = </span><span class="si">{1}</span><span class="s2">, use k = </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">n_points</span>

    <span class="c1"># if use cosine distance, normalize input points first</span>
    <span class="c1"># thus we can use euclidean distance to find knn equivalently.</span>
    <span class="k">if</span> <span class="n">dist</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
        <span class="n">l2_norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">ctx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">pairwise_squared_distance</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">k_indices</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">argtopk</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="c1"># index offset for each sample</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_points</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">k_indices</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_points</span> <span class="o">*</span> <span class="n">k</span><span class="p">))</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">offset</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_points</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">),</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">offset</span>
    <span class="k">return</span> <span class="n">convert</span><span class="o">.</span><span class="n">graph</span><span class="p">((</span><span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))))</span>


<span class="c1"># pylint: disable=invalid-name</span>
<div class="viewcode-block" id="segmented_knn_graph">
<a class="viewcode-back" href="../../../generated/dgl.segmented_knn_graph.html#dgl.segmented_knn_graph">[docs]</a>
<span class="k">def</span> <span class="nf">segmented_knn_graph</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">k</span><span class="p">,</span>
    <span class="n">segs</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;bruteforce-blas&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span>
    <span class="n">exclude_self</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct multiple graphs from multiple sets of points according to</span>
<span class="sd">    k-nearest-neighbor (KNN) and return.</span>

<span class="sd">    Compared with :func:`dgl.knn_graph`, this allows multiple point sets with</span>
<span class="sd">    different capacity. The points from different sets are stored contiguously</span>
<span class="sd">    in the :attr:`x` tensor.</span>
<span class="sd">    :attr:`segs` specifies the number of points in each point set. The</span>
<span class="sd">    function constructs a KNN graph for each point set, where the predecessors</span>
<span class="sd">    of each point are its k-nearest neighbors measured by the Euclidean distance.</span>
<span class="sd">    DGL then composes all KNN graphs</span>
<span class="sd">    into a batched graph with multiple (:math:`len(segs)`) connected components.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        Coordinates/features of points. Must be 2D. It can be either on CPU or GPU.</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of nearest neighbors per node.</span>
<span class="sd">    segs : list[int]</span>
<span class="sd">        Number of points in each point set. The numbers in :attr:`segs`</span>
<span class="sd">        must sum up to the number of rows in :attr:`x`.</span>
<span class="sd">    algorithm : str, optional</span>
<span class="sd">        Algorithm used to compute the k-nearest neighbors.</span>

<span class="sd">        * &#39;bruteforce-blas&#39; will first compute the distance matrix</span>
<span class="sd">          using BLAS matrix multiplication operation provided by</span>
<span class="sd">          backend frameworks. Then use topk algorithm to get</span>
<span class="sd">          k-nearest neighbors. This method is fast when the point</span>
<span class="sd">          set is small but has :math:`O(N^2)` memory complexity where</span>
<span class="sd">          :math:`N` is the number of points.</span>

<span class="sd">        * &#39;bruteforce&#39; will compute distances pair by pair and</span>
<span class="sd">          directly select the k-nearest neighbors during distance</span>
<span class="sd">          computation. This method is slower than &#39;bruteforce-blas&#39;</span>
<span class="sd">          but has less memory overhead (i.e., :math:`O(Nk)` where :math:`N`</span>
<span class="sd">          is the number of points, :math:`k` is the number of nearest</span>
<span class="sd">          neighbors per node) since we do not need to store all distances.</span>

<span class="sd">        * &#39;bruteforce-sharemem&#39; (CUDA only) is similar to &#39;bruteforce&#39;</span>
<span class="sd">          but use shared memory in CUDA devices for buffer. This method is</span>
<span class="sd">          faster than &#39;bruteforce&#39; when the dimension of input points</span>
<span class="sd">          is not large. This method is only available on CUDA device.</span>

<span class="sd">        * &#39;kd-tree&#39; will use the kd-tree algorithm (CPU only).</span>
<span class="sd">          This method is suitable for low-dimensional data (e.g. 3D</span>
<span class="sd">          point clouds)</span>

<span class="sd">        * &#39;nn-descent&#39; is an approximate approach from paper</span>
<span class="sd">          `Efficient k-nearest neighbor graph construction for generic similarity</span>
<span class="sd">          measures &lt;https://www.cs.princeton.edu/cass/papers/www11.pdf&gt;`_. This method</span>
<span class="sd">          will search for nearest neighbor candidates in &quot;neighbors&#39; neighbors&quot;.</span>

<span class="sd">        (default: &#39;bruteforce-blas&#39;)</span>
<span class="sd">    dist : str, optional</span>
<span class="sd">        The distance metric used to compute distance between points. It can be the following</span>
<span class="sd">        metrics:</span>
<span class="sd">        * &#39;euclidean&#39;: Use Euclidean distance (L2 norm) :math:`\sqrt{\sum_{i} (x_{i} - y_{i})^{2}}`.</span>
<span class="sd">        * &#39;cosine&#39;: Use cosine distance.</span>
<span class="sd">        (default: &#39;euclidean&#39;)</span>
<span class="sd">    exclude_self : bool, optional</span>
<span class="sd">        If True, the output graph will not contain self loop edges, and each node will not</span>
<span class="sd">        be counted as one of its own k neighbors.  If False, the output graph will contain</span>
<span class="sd">        self loop edges, and a node will be counted as one of its own k neighbors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The batched graph. The node IDs are in the same order as :attr:`x`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following examples use PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    In the example below, the first point set has three points</span>
<span class="sd">    and the second point set has four points.</span>

<span class="sd">    &gt;&gt;&gt; # Features/coordinates of the first point set</span>
<span class="sd">    &gt;&gt;&gt; x1 = torch.tensor([[0.0, 0.5, 0.2],</span>
<span class="sd">    ...                    [0.1, 0.3, 0.2],</span>
<span class="sd">    ...                    [0.4, 0.2, 0.2]])</span>
<span class="sd">    &gt;&gt;&gt; # Features/coordinates of the second point set</span>
<span class="sd">    &gt;&gt;&gt; x2 = torch.tensor([[0.3, 0.2, 0.1],</span>
<span class="sd">    ...                    [0.5, 0.2, 0.3],</span>
<span class="sd">    ...                    [0.1, 0.1, 0.2],</span>
<span class="sd">    ...                    [0.6, 0.3, 0.3]])</span>
<span class="sd">    &gt;&gt;&gt; x = torch.cat([x1, x2], dim=0)</span>
<span class="sd">    &gt;&gt;&gt; segs = [x1.shape[0], x2.shape[0]]</span>
<span class="sd">    &gt;&gt;&gt; knn_g = dgl.segmented_knn_graph(x, 2, segs)</span>
<span class="sd">    &gt;&gt;&gt; knn_g.edges()</span>
<span class="sd">    (tensor([0, 0, 1, 1, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6]),</span>
<span class="sd">     tensor([0, 1, 0, 1, 2, 2, 3, 5, 4, 6, 3, 5, 4, 6]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">exclude_self</span><span class="p">:</span>
        <span class="c1"># add 1 to k, for the self edge, since it will be removed</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># check invalid k</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid k value. expect k &gt; 0, got k = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

    <span class="c1"># check empty point set</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Find empty point set&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s2">&quot;bruteforce-blas&quot;</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_segmented_knn_graph_blas</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">segs</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">knn</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">segs</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">graph</span><span class="p">((</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">))</span>

    <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">segs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">result</span><span class="o">.</span><span class="n">set_batch_num_nodes</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)</span>
    <span class="c1"># if any segment is too small for k, all algorithms reduce k for all segments</span>
    <span class="n">clamped_k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">segs</span><span class="p">))</span>
    <span class="n">result</span><span class="o">.</span><span class="n">set_batch_num_edges</span><span class="p">(</span><span class="n">clamped_k</span> <span class="o">*</span> <span class="n">num_nodes</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">exclude_self</span><span class="p">:</span>
        <span class="c1"># remove_self_loop will update batch_num_edges as needed</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">remove_self_loop</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="c1"># If there were more than k(+1) coincident points, there may not have been self loops on</span>
        <span class="c1"># all nodes, in which case there would still be one too many out edges on some nodes.</span>
        <span class="c1"># However, if every node had a self edge, the common case, every node would still have the</span>
        <span class="c1"># same degree as each other, so we can check that condition easily.</span>
        <span class="c1"># The -1 is for the self edge removal.</span>
        <span class="n">clamped_k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">segs</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span> <span class="o">!=</span> <span class="n">clamped_k</span> <span class="o">*</span> <span class="n">result</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">():</span>
            <span class="c1"># edges on any nodes with too high degree should all be length zero,</span>
            <span class="c1"># so pick an arbitrary one to remove from each such node</span>
            <span class="n">degrees</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">()</span>
            <span class="n">node_indices</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">degrees</span> <span class="o">&gt;</span> <span class="n">clamped_k</span><span class="p">)</span>
            <span class="n">edges_to_remove_graph</span> <span class="o">=</span> <span class="n">sample_neighbors</span><span class="p">(</span>
                <span class="n">result</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">edge_dir</span><span class="o">=</span><span class="s2">&quot;in&quot;</span>
            <span class="p">)</span>
            <span class="n">edge_ids</span> <span class="o">=</span> <span class="n">edges_to_remove_graph</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">remove_edges</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">edge_ids</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>



<span class="k">def</span> <span class="nf">_segmented_knn_graph_blas</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">segs</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct multiple graphs from multiple sets of points according to</span>
<span class="sd">    k-nearest-neighbor (KNN).</span>

<span class="sd">    This function first compute the distance matrix using BLAS matrix multiplication</span>
<span class="sd">    operation provided by backend frameworks. Then use topk algorithm to get</span>
<span class="sd">    k-nearest neighbors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        Coordinates/features of points. Must be 2D. It can be either on CPU or GPU.</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of nearest neighbors per node.</span>
<span class="sd">    segs : list[int]</span>
<span class="sd">        Number of points in each point set. The numbers in :attr:`segs`</span>
<span class="sd">        must sum up to the number of rows in :attr:`x`.</span>
<span class="sd">    dist : str, optional</span>
<span class="sd">        The distance metric used to compute distance between points. It can be the following</span>
<span class="sd">        metrics:</span>
<span class="sd">        * &#39;euclidean&#39;: Use Euclidean distance (L2 norm) :math:`\sqrt{\sum_{i} (x_{i} - y_{i})^{2}}`.</span>
<span class="sd">        * &#39;cosine&#39;: Use cosine distance.</span>
<span class="sd">        (default: &#39;euclidean&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># if use cosine distance, normalize input points first</span>
    <span class="c1"># thus we can use euclidean distance to find knn equivalently.</span>
    <span class="k">if</span> <span class="n">dist</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
        <span class="n">l2_norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">n_total_points</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">segs</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">min_seg_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">segs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">min_seg_size</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span>
            <span class="s2">&quot;&#39;k&#39; should be less than or equal to the number of points in &#39;x&#39;&quot;</span>
            <span class="s2">&quot;expect k &lt;= </span><span class="si">{0}</span><span class="s2">, got k = </span><span class="si">{1}</span><span class="s2">, use k = </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">min_seg_size</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">min_seg_size</span>

    <span class="n">h_list</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">segs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">src</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">F</span><span class="o">.</span><span class="n">argtopk</span><span class="p">(</span><span class="n">pairwise_squared_distance</span><span class="p">(</span><span class="n">h_g</span><span class="p">),</span> <span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">h_g</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">h_list</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_total_points</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">),</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">convert</span><span class="o">.</span><span class="n">graph</span><span class="p">((</span><span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))))</span>


<span class="k">def</span> <span class="nf">_nndescent_knn_graph</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">k</span><span class="p">,</span>
    <span class="n">segs</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_candidates</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">delta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct multiple graphs from multiple sets of points according to</span>
<span class="sd">    **approximate** k-nearest-neighbor using NN-descent algorithm from paper</span>
<span class="sd">    `Efficient k-nearest neighbor graph construction for generic similarity</span>
<span class="sd">    measures &lt;https://www.cs.princeton.edu/cass/papers/www11.pdf&gt;`_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        Coordinates/features of points. Must be 2D. It can be either on CPU or GPU.</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of nearest neighbors per node.</span>
<span class="sd">    segs : list[int]</span>
<span class="sd">        Number of points in each point set. The numbers in :attr:`segs`</span>
<span class="sd">        must sum up to the number of rows in :attr:`x`.</span>
<span class="sd">    num_iters : int, optional</span>
<span class="sd">        The maximum number of NN-descent iterations to perform. A value will be</span>
<span class="sd">        chosen based on the size of input by default.</span>
<span class="sd">        (Default: None)</span>
<span class="sd">    max_candidates : int, optional</span>
<span class="sd">        The maximum number of candidates to be considered during one iteration.</span>
<span class="sd">        Larger values will provide more accurate search results later, but</span>
<span class="sd">        potentially at non-negligible computation cost. A value will be chosen</span>
<span class="sd">        based on the number of neighbors by default.</span>
<span class="sd">        (Default: None)</span>
<span class="sd">    delta : float, optional</span>
<span class="sd">        A value controls the early abort. This function will abort if</span>
<span class="sd">        :math:`k * N * delta &gt; c`, where :math:`N` is the number of points,</span>
<span class="sd">        :math:`c` is the number of updates during last iteration.</span>
<span class="sd">        (Default: 0.001)</span>
<span class="sd">    sample_rate : float, optional</span>
<span class="sd">        A value controls how many candidates sampled. It should be a float value</span>
<span class="sd">        between 0 and 1. Larger values will provide higher accuracy and converge</span>
<span class="sd">        speed but with higher time cost.</span>
<span class="sd">        (Default: 0.5)</span>
<span class="sd">    dist : str, optional</span>
<span class="sd">        The distance metric used to compute distance between points. It can be the following</span>
<span class="sd">        metrics:</span>
<span class="sd">        * &#39;euclidean&#39;: Use Euclidean distance (L2 norm) :math:`\sqrt{\sum_{i} (x_{i} - y_{i})^{2}}`.</span>
<span class="sd">        * &#39;cosine&#39;: Use cosine distance.</span>
<span class="sd">        (default: &#39;euclidean&#39;)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph. The node IDs are in the same order as :attr:`x`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_points</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">segs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">segs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">segs</span><span class="p">)</span>
    <span class="n">segs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">segs</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">max_candidates</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_candidates</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_iters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_iters</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">num_points</span><span class="p">))))</span>
    <span class="n">max_candidates</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sample_rate</span> <span class="o">*</span> <span class="n">max_candidates</span><span class="p">)</span>

    <span class="c1"># if use cosine distance, normalize input points first</span>
    <span class="c1"># thus we can use euclidean distance to find knn equivalently.</span>
    <span class="k">if</span> <span class="n">dist</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
        <span class="n">l2_norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="c1"># k must less than or equal to min(segs)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">segs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;&#39;k&#39; must be less than or equal to the number of points in &#39;x&#39;&quot;</span>
            <span class="s2">&quot;expect &#39;k&#39; &lt;= </span><span class="si">{}</span><span class="s2">, got &#39;k&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">segs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">delta</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">delta</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;&#39;delta&#39; must in [0, 1], got &#39;delta&#39; = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">delta</span><span class="p">))</span>

    <span class="n">offset</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">segs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,),</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">segs</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">segs</span><span class="p">))</span>
    <span class="n">offset</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">segs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_points</span> <span class="o">*</span> <span class="n">k</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">segs</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">segs</span><span class="p">))</span>

    <span class="c1"># points, offsets, out, k, num_iters, max_candidates, delta</span>
    <span class="n">_CAPI_DGLNNDescent</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">offset</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dgl_ndarray_for_write</span><span class="p">(</span><span class="n">out</span><span class="p">),</span>
        <span class="n">k</span><span class="p">,</span>
        <span class="n">num_iters</span><span class="p">,</span>
        <span class="n">max_candidates</span><span class="p">,</span>
        <span class="n">delta</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">knn</span><span class="p">(</span>
    <span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_segs</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_segs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;bruteforce&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;For each element in each segment in :attr:`y`, find :attr:`k` nearest</span>
<span class="sd">    points in the same segment in :attr:`x`. If :attr:`y` is None, perform a self-query</span>
<span class="sd">    over :attr:`x`.</span>

<span class="sd">    This function allows multiple point sets with different capacity. The points</span>
<span class="sd">    from different sets are stored contiguously in the :attr:`x` and :attr:`y` tensor.</span>
<span class="sd">    :attr:`x_segs` and :attr:`y_segs` specifies the number of points in each point set.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of nearest neighbors per node.</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        The point coordinates in x. It can be either on CPU or GPU (must be the</span>
<span class="sd">        same as :attr:`y`). Must be 2D.</span>
<span class="sd">    x_segs : Union[List[int], Tensor]</span>
<span class="sd">        Number of points in each point set in :attr:`x`. The numbers in :attr:`x_segs`</span>
<span class="sd">        must sum up to the number of rows in :attr:`x`.</span>
<span class="sd">    y : Tensor, optional</span>
<span class="sd">        The point coordinates in y. It can be either on CPU or GPU (must be the</span>
<span class="sd">        same as :attr:`x`). Must be 2D.</span>
<span class="sd">        (default: None)</span>
<span class="sd">    y_segs : Union[List[int], Tensor], optional</span>
<span class="sd">        Number of points in each point set in :attr:`y`. The numbers in :attr:`y_segs`</span>
<span class="sd">        must sum up to the number of rows in :attr:`y`.</span>
<span class="sd">        (default: None)</span>
<span class="sd">    algorithm : str, optional</span>
<span class="sd">        Algorithm used to compute the k-nearest neighbors.</span>

<span class="sd">        * &#39;bruteforce&#39; will compute distances pair by pair and</span>
<span class="sd">          directly select the k-nearest neighbors during distance</span>
<span class="sd">          computation. This method is slower than &#39;bruteforce-blas&#39;</span>
<span class="sd">          but has less memory overhead (i.e., :math:`O(Nk)` where :math:`N`</span>
<span class="sd">          is the number of points, :math:`k` is the number of nearest</span>
<span class="sd">          neighbors per node) since we do not need to store all distances.</span>

<span class="sd">        * &#39;bruteforce-sharemem&#39; (CUDA only) is similar to &#39;bruteforce&#39;</span>
<span class="sd">          but use shared memory in CUDA devices for buffer. This method is</span>
<span class="sd">          faster than &#39;bruteforce&#39; when the dimension of input points</span>
<span class="sd">          is not large. This method is only available on CUDA device.</span>

<span class="sd">        * &#39;kd-tree&#39; will use the kd-tree algorithm (CPU only).</span>
<span class="sd">          This method is suitable for low-dimensional data (e.g. 3D</span>
<span class="sd">          point clouds)</span>

<span class="sd">        * &#39;nn-descent&#39; is an approximate approach from paper</span>
<span class="sd">          `Efficient k-nearest neighbor graph construction for generic similarity</span>
<span class="sd">          measures &lt;https://www.cs.princeton.edu/cass/papers/www11.pdf&gt;`_. This method</span>
<span class="sd">          will search for nearest neighbor candidates in &quot;neighbors&#39; neighbors&quot;.</span>

<span class="sd">        Note: Currently, &#39;nn-descent&#39; only supports self-query cases, i.e. :attr:`y` is None.</span>
<span class="sd">        (default: &#39;bruteforce&#39;)</span>
<span class="sd">    dist : str, optional</span>
<span class="sd">        The distance metric used to compute distance between points. It can be the following</span>
<span class="sd">        metrics:</span>
<span class="sd">        * &#39;euclidean&#39;: Use Euclidean distance (L2 norm) :math:`\sqrt{\sum_{i} (x_{i} - y_{i})^{2}}`.</span>
<span class="sd">        * &#39;cosine&#39;: Use cosine distance.</span>
<span class="sd">        (default: &#39;euclidean&#39;)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        Tensor with size `(2, k * num_points(y))`</span>
<span class="sd">        The first subtensor contains point indexs in :attr:`y`. The second subtensor contains</span>
<span class="sd">        point indexs in :attr:`x`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO(lygztq) add support for querying different point sets using nn-descent.</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="s2">&quot;nn-descent&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">y_segs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Currently &#39;nn-descent&#39; only supports self-query cases.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">_nndescent_knn_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">x_segs</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="c1"># self query</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">y_segs</span> <span class="o">=</span> <span class="n">x_segs</span>

    <span class="k">assert</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_segs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">x_segs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_segs</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_segs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">y_segs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_segs</span><span class="p">)</span>
    <span class="n">x_segs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">x_segs</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">y_segs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">y_segs</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

    <span class="c1"># k shoule be less than or equal to min(x_segs)</span>
    <span class="n">min_num_points</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x_segs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">min_num_points</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span>
            <span class="s2">&quot;&#39;k&#39; should be less than or equal to the number of points in &#39;x&#39;&quot;</span>
            <span class="s2">&quot;expect k &lt;= </span><span class="si">{0}</span><span class="s2">, got k = </span><span class="si">{1}</span><span class="s2">, use k = </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">min_num_points</span><span class="p">,</span> <span class="n">k</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">min_num_points</span><span class="p">)</span>

    <span class="c1"># invalid k</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid k value. expect k &gt; 0, got k = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

    <span class="c1"># empty point set</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Find empty point set&quot;</span><span class="p">)</span>

    <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">dist_metric_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;euclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;cosine&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">dist</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dist_metric_list</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Only </span><span class="si">{}</span><span class="s2"> are supported for distance&quot;</span>
            <span class="s2">&quot;computation, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dist_metric_list</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">x_offset</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x_segs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,),</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">x_segs</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x_segs</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">x_offset</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">x_segs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">y_offset</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y_segs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,),</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">y_segs</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">y_segs</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">y_offset</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">y_segs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">k</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">x_segs</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">x_segs</span><span class="p">))</span>

    <span class="c1"># if use cosine distance, normalize input points first</span>
    <span class="c1"># thus we can use euclidean distance to find knn equivalently.</span>
    <span class="k">if</span> <span class="n">dist</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
        <span class="n">l2_norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="p">(</span><span class="n">l2_norm</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">_CAPI_DGLKNN</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">x_offset</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">y_offset</span><span class="p">),</span>
        <span class="n">k</span><span class="p">,</span>
        <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dgl_ndarray_for_write</span><span class="p">(</span><span class="n">out</span><span class="p">),</span>
        <span class="n">algorithm</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>


<div class="viewcode-block" id="to_bidirected">
<a class="viewcode-back" href="../../../generated/dgl.to_bidirected.html#dgl.to_bidirected">[docs]</a>
<span class="k">def</span> <span class="nf">to_bidirected</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">copy_ndata</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">readonly</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert the graph to a bi-directional simple graph and return.</span>

<span class="sd">    For an input graph :math:`G`, return a new graph :math:`G&#39;` such that an edge</span>
<span class="sd">    :math:`(u, v)\in G&#39;` exists if and only if there exists an edge</span>
<span class="sd">    :math:`(v, u)\in G`. The resulting graph :math:`G&#39;` is a simple graph,</span>
<span class="sd">    meaning there is no parallel edge.</span>

<span class="sd">    The operation only works for edges whose two endpoints belong to the same node type.</span>
<span class="sd">    DGL will raise error if the input graph is heterogeneous and contains edges</span>
<span class="sd">    with different types of endpoints.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    copy_ndata: bool, optional</span>
<span class="sd">        If True, the node features of the bidirected graph are copied from the</span>
<span class="sd">        original graph. If False, the bidirected graph will not have any node features.</span>
<span class="sd">        (Default: False)</span>
<span class="sd">    readonly : bool</span>
<span class="sd">        **DEPRECATED**.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The bidirected graph</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If :attr:`copy_ndata` is True, the resulting graph will share the node feature</span>
<span class="sd">    tensors with the input graph. Hence, users should try to avoid in-place operations</span>
<span class="sd">    which will be visible to both graphs.</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following examples use PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch as th</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph((th.tensor([0, 1, 2]), th.tensor([1, 2, 0])))</span>
<span class="sd">    &gt;&gt;&gt; bg1 = dgl.to_bidirected(g)</span>
<span class="sd">    &gt;&gt;&gt; bg1.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 1, 2, 0]), tensor([1, 2, 0, 0, 1, 2]))</span>

<span class="sd">    The graph already have i-&gt;j and j-&gt;i</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((th.tensor([0, 1, 2, 0]), th.tensor([1, 2, 0, 2])))</span>
<span class="sd">    &gt;&gt;&gt; bg1 = dgl.to_bidirected(g)</span>
<span class="sd">    &gt;&gt;&gt; bg1.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 1, 2, 0]), tensor([1, 2, 0, 0, 1, 2]))</span>

<span class="sd">    **Heterogeneous graphs with Multiple Edge Types**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;): (th.tensor([0, 2, 0, 2]), th.tensor([1, 1, 2, 0])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (th.tensor([1, 2, 1]), th.tensor([2, 1, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; bg1 = dgl.to_bidirected(g)</span>
<span class="sd">    &gt;&gt;&gt; bg1.edges(etype=&#39;wins&#39;)</span>
<span class="sd">    (tensor([0, 0, 1, 1, 2, 2]), tensor([1, 2, 0, 2, 0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; bg1.edges(etype=&#39;follows&#39;)</span>
<span class="sd">    (tensor([1, 1, 2]), tensor([1, 2, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">readonly</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span>
            <span class="s2">&quot;Parameter readonly is deprecated&quot;</span>
            <span class="s2">&quot;There will be no difference between readonly and non-readonly DGLGraph&quot;</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="p">(</span>
                <span class="s2">&quot;to_bidirected is not well defined for &quot;</span>
                <span class="s2">&quot;unidirectional bipartite graphs&quot;</span>
                <span class="s2">&quot;, but </span><span class="si">{}</span><span class="s2"> is unidirectional bipartite&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">add_reverse_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">copy_ndata</span><span class="o">=</span><span class="n">copy_ndata</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">to_simple</span><span class="p">(</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy_ndata</span><span class="o">=</span><span class="n">copy_ndata</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="add_reverse_edges">
<a class="viewcode-back" href="../../../generated/dgl.add_reverse_edges.html#dgl.add_reverse_edges">[docs]</a>
<span class="k">def</span> <span class="nf">add_reverse_edges</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">readonly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">copy_ndata</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ignore_bipartite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_self</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add a reversed edge for each edge in the input graph and return a new graph.</span>

<span class="sd">    For a graph with edges :math:`(i_1, j_1), \cdots, (i_n, j_n)`, this</span>
<span class="sd">    function creates a new graph with edges</span>
<span class="sd">    :math:`(i_1, j_1), \cdots, (i_n, j_n), (j_1, i_1), \cdots, (j_n, i_n)`.</span>

<span class="sd">    The returned graph may have duplicate edges. To create a bidirected graph without</span>
<span class="sd">    duplicate edges, use :func:`to_bidirected`.</span>

<span class="sd">    The operation only works for edges whose two endpoints belong to the same node type.</span>
<span class="sd">    DGL will raise error if the input graph is heterogeneous and contains edges</span>
<span class="sd">    with different types of endpoints. If :attr:`ignore_bipartite` is true, DGL will</span>
<span class="sd">    ignore those edges instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    readonly : bool, default to be True</span>
<span class="sd">        Deprecated. There will be no difference between readonly and non-readonly</span>
<span class="sd">    copy_ndata: bool, optional</span>
<span class="sd">        If True, the node features of the new graph are copied from</span>
<span class="sd">        the original graph. If False, the new graph will not have any</span>
<span class="sd">        node features.</span>

<span class="sd">        (Default: True)</span>
<span class="sd">    copy_edata: bool, optional</span>
<span class="sd">        If True, the features of the reversed edges will be identical to</span>
<span class="sd">        the original ones.</span>

<span class="sd">        If False, the new graph will not have any edge features.</span>

<span class="sd">        (Default: False)</span>
<span class="sd">    ignore_bipartite: bool, optional</span>
<span class="sd">        If True, unidirectional bipartite graphs are ignored and</span>
<span class="sd">        no error is raised. If False, an error will be raised if</span>
<span class="sd">        an edge type of the input heterogeneous graph is for a unidirectional</span>
<span class="sd">        bipartite graph.</span>
<span class="sd">    exclude_self: bool, optional</span>
<span class="sd">        If True, it does not add reverse edges for self-loops, which is likely</span>
<span class="sd">        meaningless in most cases.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph with reversed edges added.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If :attr:`copy_ndata` is True, the resulting graph will share the node feature</span>
<span class="sd">    tensors with the input graph. Hence, users should try to avoid in-place operations</span>
<span class="sd">    which will be visible to both graphs. On the contrary, the two graphs do not share</span>
<span class="sd">    the same edge feature storage.</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    **Homogeneous graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((th.tensor([0, 0]), th.tensor([0, 1])))</span>
<span class="sd">    &gt;&gt;&gt; bg1 = dgl.add_reverse_edges(g)</span>
<span class="sd">    &gt;&gt;&gt; bg1.edges()</span>
<span class="sd">    (tensor([0, 0, 0, 1]), tensor([0, 1, 0, 0]))</span>

<span class="sd">    **Heterogeneous graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    &gt;&gt;&gt;     (&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;): (th.tensor([0, 2, 0, 2, 2]), th.tensor([1, 1, 2, 1, 0])),</span>
<span class="sd">    &gt;&gt;&gt;     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (th.tensor([1, 2, 1]), th.tensor([2, 1, 1])),</span>
<span class="sd">    &gt;&gt;&gt;     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (th.tensor([1, 2, 1), th.tensor([0, 0, 0]))</span>
<span class="sd">    &gt;&gt;&gt; })</span>
<span class="sd">    &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;hv&#39;] = th.ones(3, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edges[&#39;wins&#39;].data[&#39;h&#39;] = th.tensor([0, 1, 2, 3, 4])</span>

<span class="sd">    The :func:`add_reverse_edges` operation is applied to the edge type</span>
<span class="sd">    ``(&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;)`` and the edge type ``(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;)``.</span>
<span class="sd">    The edge type ``(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)`` is ignored.  Both the node features and</span>
<span class="sd">    edge features are shared.</span>

<span class="sd">    &gt;&gt;&gt; bg = dgl.add_reverse_edges(g, copy_ndata=True,</span>
<span class="sd">                               copy_edata=True, ignore_bipartite=True)</span>
<span class="sd">    &gt;&gt;&gt; bg.edges((&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;))</span>
<span class="sd">    (tensor([0, 2, 0, 2, 2, 1, 1, 2, 1, 0]), tensor([1, 1, 2, 1, 0, 0, 2, 0, 2, 2]))</span>
<span class="sd">    &gt;&gt;&gt; bg.edges((&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;))</span>
<span class="sd">    (tensor([1, 2, 1, 0, 0, 0]), tensor([0, 0, 0, 1, 2, 1]))</span>
<span class="sd">    &gt;&gt;&gt; bg.edges((&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;))</span>
<span class="sd">    (th.tensor([1, 2, 1]), th.tensor([2, 1, 1]))</span>
<span class="sd">    &gt;&gt;&gt; bg.nodes[&#39;game&#39;].data[&#39;hv&#39;]</span>
<span class="sd">    tensor([0, 0, 0])</span>
<span class="sd">    &gt;&gt;&gt; bg.edges[(&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;)].data[&#39;h&#39;]</span>
<span class="sd">    th.tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">readonly</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span>
            <span class="s2">&quot;Parameter readonly is deprecated&quot;</span>
            <span class="s2">&quot;There will be no difference between readonly and non-readonly DGLGraph&quot;</span>
        <span class="p">)</span>

    <span class="c1"># get node cnt for each ntype</span>
    <span class="n">num_nodes_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
        <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>

    <span class="n">canonical_etypes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span>
    <span class="n">num_nodes_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntype</span><span class="p">:</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">}</span>
    <span class="n">subgs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">rev_eids</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">add_for_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">):</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">rev_u</span><span class="p">,</span> <span class="n">rev_v</span> <span class="o">=</span> <span class="n">v</span><span class="p">,</span> <span class="n">u</span>
        <span class="n">eid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">)),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">exclude_self</span><span class="p">:</span>
            <span class="n">self_loop_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">rev_u</span><span class="p">,</span> <span class="n">rev_v</span><span class="p">)</span>
            <span class="n">non_self_loop_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">self_loop_mask</span><span class="p">)</span>
            <span class="n">rev_u</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">rev_u</span><span class="p">,</span> <span class="n">non_self_loop_mask</span><span class="p">)</span>
            <span class="n">rev_v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">rev_v</span><span class="p">,</span> <span class="n">non_self_loop_mask</span><span class="p">)</span>
            <span class="n">non_self_loop_eid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="n">non_self_loop_mask</span><span class="p">)</span>
            <span class="n">rev_eids</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">eid</span><span class="p">,</span> <span class="n">non_self_loop_eid</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rev_eids</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">eid</span><span class="p">,</span> <span class="n">eid</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">subgs</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">u</span><span class="p">,</span> <span class="n">rev_u</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">rev_v</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

    <span class="c1"># fast path</span>
    <span class="k">if</span> <span class="n">ignore_bipartite</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="p">(</span>
                    <span class="s2">&quot;add_reverse_edges is not well defined for &quot;</span>
                    <span class="s2">&quot;unidirectional bipartite graphs&quot;</span>
                    <span class="s2">&quot;, but </span><span class="si">{}</span><span class="s2"> is unidirectional bipartite&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">add_for_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)</span>

        <span class="n">new_g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">heterograph</span><span class="p">(</span><span class="n">subgs</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="o">=</span><span class="n">num_nodes_dict</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
                <span class="n">subgs</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">add_for_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)</span>

        <span class="n">new_g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">heterograph</span><span class="p">(</span><span class="n">subgs</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="o">=</span><span class="n">num_nodes_dict</span><span class="p">)</span>

    <span class="c1"># handle features</span>
    <span class="k">if</span> <span class="n">copy_ndata</span><span class="p">:</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_node_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">new_g</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="n">node_frames</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">copy_edata</span><span class="p">:</span>
        <span class="c1"># find indices</span>
        <span class="n">eids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                <span class="n">eids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)),</span> <span class="n">new_g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rev_eids</span><span class="p">[</span><span class="n">c_etype</span><span class="p">])</span>

        <span class="n">edge_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_edge_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">new_g</span><span class="p">,</span> <span class="n">edge_frames</span><span class="o">=</span><span class="n">edge_frames</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="line_graph">
<a class="viewcode-back" href="../../../generated/dgl.line_graph.html#dgl.line_graph">[docs]</a>
<span class="k">def</span> <span class="nf">line_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">backtracking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shared</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the line graph of this graph.</span>

<span class="sd">    The line graph ``L(G)`` of a given graph ``G`` is defined as another graph where</span>
<span class="sd">    the nodes in ``L(G)`` correspond to the edges in ``G``.  For any pair of edges ``(u, v)``</span>
<span class="sd">    and ``(v, w)`` in ``G``, the corresponding node of edge ``(u, v)`` in ``L(G)`` will</span>
<span class="sd">    have an edge connecting to the corresponding node of edge ``(v, w)``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        Input graph.  Must be homogeneous.</span>
<span class="sd">    backtracking : bool, optional</span>
<span class="sd">        If False, the line graph node corresponding to edge ``(u, v)`` will not have</span>
<span class="sd">        an edge connecting to the line graph node corresponding to edge ``(v, u)``.</span>

<span class="sd">        Default: True.</span>
<span class="sd">    shared : bool, optional</span>
<span class="sd">        Whether to copy the edge features of the original graph as the node features</span>
<span class="sd">        of the result line graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    G : DGLGraph</span>
<span class="sd">        The line graph of this graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    * If :attr:`shared` is True, the node features of the resulting graph share the same</span>
<span class="sd">      storage with the edge features of the input graph. Hence, users should try to</span>
<span class="sd">      avoid in-place operations which will be visible to both graphs.</span>
<span class="sd">    * The function supports input graph on GPU but copies it to CPU during computation.</span>
<span class="sd">    * This function discards the batch information. Please use</span>
<span class="sd">      :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">      and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">      to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Assume that the graph has the following adjacency matrix: ::</span>

<span class="sd">       A = [[0, 0, 1],</span>
<span class="sd">            [1, 0, 1],</span>
<span class="sd">            [1, 1, 0]]</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 1, 2, 2],[2, 0, 2, 0, 1]), &#39;user&#39;, &#39;follows&#39;)</span>
<span class="sd">    &gt;&gt;&gt; lg = g.line_graph()</span>
<span class="sd">    &gt;&gt;&gt; lg</span>
<span class="sd">    Graph(num_nodes=5, num_edges=8,</span>
<span class="sd">    ndata_schemes={}</span>
<span class="sd">    edata_schemes={})</span>
<span class="sd">    &gt;&gt;&gt; lg.edges()</span>
<span class="sd">    (tensor([0, 0, 1, 2, 2, 3, 4, 4]), tensor([3, 4, 0, 3, 4, 0, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; lg = g.line_graph(backtracking=False)</span>
<span class="sd">    &gt;&gt;&gt; lg</span>
<span class="sd">    Graph(num_nodes=5, num_edges=4,</span>
<span class="sd">    ndata_schemes={}</span>
<span class="sd">    edata_schemes={})</span>
<span class="sd">    &gt;&gt;&gt; lg.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 4]), tensor([4, 0, 3, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">,</span> <span class="s2">&quot;only homogeneous graph is supported&quot;</span>

    <span class="n">dev</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
    <span class="n">lg</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span>
        <span class="n">_CAPI_DGLHeteroLineGraph</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">nd</span><span class="o">.</span><span class="n">cpu</span><span class="p">()),</span> <span class="n">backtracking</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">lg</span> <span class="o">=</span> <span class="n">lg</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shared</span><span class="p">:</span>
        <span class="n">new_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_edge_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">lg</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="n">new_frames</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">lg</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">line_graph</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">alias_func</span><span class="p">(</span><span class="n">line_graph</span><span class="p">)</span>


<div class="viewcode-block" id="khop_adj">
<a class="viewcode-back" href="../../../generated/dgl.khop_adj.html#dgl.khop_adj">[docs]</a>
<span class="k">def</span> <span class="nf">khop_adj</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the matrix of :math:`A^k` where :math:`A` is the adjacency matrix of the graph</span>
<span class="sd">    :math:`g`.</span>

<span class="sd">    The returned matrix is a 32-bit float dense matrix on CPU. The graph must be homogeneous.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    k : int</span>
<span class="sd">        The :math:`k` in :math:`A^k`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        The returned tensor.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,0,1,2,3,4], [0,1,2,3,4,1,2,3,4,0]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.khop_adj(g, 1)</span>
<span class="sd">    tensor([[1., 1., 0., 0., 0.],</span>
<span class="sd">            [0., 1., 1., 0., 0.],</span>
<span class="sd">            [0., 0., 1., 1., 0.],</span>
<span class="sd">            [0., 0., 0., 1., 1.],</span>
<span class="sd">            [1., 0., 0., 0., 1.]])</span>
<span class="sd">    &gt;&gt;&gt; dgl.khop_adj(g, 3)</span>
<span class="sd">    tensor([[1., 3., 3., 1., 0.],</span>
<span class="sd">            [0., 1., 3., 3., 1.],</span>
<span class="sd">            [1., 0., 1., 3., 3.],</span>
<span class="sd">            [3., 1., 0., 1., 3.],</span>
<span class="sd">            [3., 3., 1., 0., 1.]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">,</span> <span class="s2">&quot;only homogeneous graph is supported&quot;</span>
    <span class="n">adj_k</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scipy_fmt</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">formats</span><span class="p">()[</span><span class="s2">&quot;created&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="o">**</span> <span class="n">k</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">adj_k</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span></div>



<div class="viewcode-block" id="khop_graph">
<a class="viewcode-back" href="../../../generated/dgl.khop_graph.html#dgl.khop_graph">[docs]</a>
<span class="k">def</span> <span class="nf">khop_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">copy_ndata</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the graph whose edges connect the :attr:`k`-hop neighbors of the original graph.</span>

<span class="sd">    More specifically, an edge from node ``u`` and node ``v`` exists in the new graph if</span>
<span class="sd">    and only if a path with length :attr:`k` exists from node ``u`` to node ``v`` in the</span>
<span class="sd">    original graph.</span>

<span class="sd">    The adjacency matrix of the returned graph is :math:`A^k`</span>
<span class="sd">    (where :math:`A` is the adjacency matrix of :math:`g`).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    k : int</span>
<span class="sd">        The :math:`k` in `k`-hop graph.</span>
<span class="sd">    copy_ndata: bool, optional</span>
<span class="sd">        If True, the node features of the new graph are copied from the</span>
<span class="sd">        original graph.</span>

<span class="sd">        If False, the new graph will not have any node features.</span>

<span class="sd">        (Default: True)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The returned graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If :attr:`copy_ndata` is True, the resulting graph will share the node feature</span>
<span class="sd">    tensors with the input graph. Hence, users should try to avoid in-place operations</span>
<span class="sd">    which will be visible to both graphs.</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    Below gives an easy example:</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1], [1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; g_2 = dgl.transforms.khop_graph(g, 2)</span>
<span class="sd">    &gt;&gt;&gt; print(g_2.edges())</span>
<span class="sd">    (tensor([0]), tensor([2]))</span>

<span class="sd">    A more complicated example:</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,0,1,2,3,4], [0,1,2,3,4,1,2,3,4,0]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.khop_graph(g, 1)</span>
<span class="sd">    DGLGraph(num_nodes=5, num_edges=10,</span>
<span class="sd">             ndata_schemes={}</span>
<span class="sd">             edata_schemes={})</span>
<span class="sd">    &gt;&gt;&gt; dgl.khop_graph(g, 3)</span>
<span class="sd">    DGLGraph(num_nodes=5, num_edges=40,</span>
<span class="sd">             ndata_schemes={}</span>
<span class="sd">             edata_schemes={})</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">,</span> <span class="s2">&quot;only homogeneous graph is supported&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
    <span class="n">adj_k</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scipy_fmt</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">formats</span><span class="p">()[</span><span class="s2">&quot;created&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="o">**</span> <span class="n">k</span>
    <span class="p">)</span>
    <span class="n">adj_k</span> <span class="o">=</span> <span class="n">adj_k</span><span class="o">.</span><span class="n">tocoo</span><span class="p">()</span>
    <span class="n">multiplicity</span> <span class="o">=</span> <span class="n">adj_k</span><span class="o">.</span><span class="n">data</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">adj_k</span><span class="o">.</span><span class="n">row</span><span class="p">,</span> <span class="n">multiplicity</span><span class="p">)</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">adj_k</span><span class="o">.</span><span class="n">col</span><span class="p">,</span> <span class="n">multiplicity</span><span class="p">)</span>
    <span class="c1"># TODO(zihao): we should support creating multi-graph from scipy sparse matrix</span>
    <span class="c1"># in the future.</span>
    <span class="n">new_g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">graph</span><span class="p">(</span>
        <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">),</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span>

    <span class="c1"># handle ndata</span>
    <span class="k">if</span> <span class="n">copy_ndata</span><span class="p">:</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_node_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">new_g</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="n">node_frames</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="reverse">
<a class="viewcode-back" href="../../../generated/dgl.reverse.html#dgl.reverse">[docs]</a>
<span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">copy_ndata</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">share_ndata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">share_edata</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a new graph with every edges being the reverse ones in the input graph.</span>

<span class="sd">    The reverse (also called converse, transpose) of a graph with edges</span>
<span class="sd">    :math:`(i_1, j_1), (i_2, j_2), \cdots` of type ``(U, E, V)`` is a new graph with edges</span>
<span class="sd">    :math:`(j_1, i_1), (j_2, i_2), \cdots` of type ``(V, E, U)``.</span>

<span class="sd">    The returned graph shares the data structure with the original graph, i.e. dgl.reverse</span>
<span class="sd">    will not create extra storage for the reversed graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    copy_ndata: bool, optional</span>
<span class="sd">        If True, the node features of the reversed graph are copied from the</span>
<span class="sd">        original graph. If False, the reversed graph will not have any node features.</span>
<span class="sd">        (Default: True)</span>
<span class="sd">    copy_edata: bool, optional</span>
<span class="sd">        If True, the edge features of the reversed graph are copied from the</span>
<span class="sd">        original graph. If False, the reversed graph will not have any edge features.</span>
<span class="sd">        (Default: False)</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The reversed graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If :attr:`copy_ndata` or :attr:`copy_edata` is True,</span>
<span class="sd">    the resulting graph will share the node or edge feature</span>
<span class="sd">    tensors with the input graph. Hence, users should try to avoid in-place operations</span>
<span class="sd">    which will be visible to both graphs.</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    **Homogeneous graphs**</span>

<span class="sd">    Create a graph to reverse.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch as th</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph((th.tensor([0, 1, 2]), th.tensor([1, 2, 0])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = th.tensor([[0.], [1.], [2.]])</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;] = th.tensor([[3.], [4.], [5.]])</span>

<span class="sd">    Reverse the graph.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reverse(g, copy_edata=True)</span>
<span class="sd">    &gt;&gt;&gt; rg.ndata[&#39;h&#39;]</span>
<span class="sd">    tensor([[0.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [2.]])</span>

<span class="sd">    The i-th edge in the reversed graph corresponds to the i-th edge in the</span>
<span class="sd">    original graph. When :attr:`copy_edata` is True, they have the same features.</span>

<span class="sd">    &gt;&gt;&gt; rg.edges()</span>
<span class="sd">    (tensor([1, 2, 0]), tensor([0, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; rg.edata[&#39;h&#39;]</span>
<span class="sd">    tensor([[3.],</span>
<span class="sd">            [4.],</span>
<span class="sd">            [5.]])</span>

<span class="sd">    **Heterogenenous graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (th.tensor([0, 2]), th.tensor([1, 2])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (th.tensor([1, 2, 1]), th.tensor([2, 1, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;hv&#39;] = th.ones(3, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;he&#39;] = th.zeros(3, 1)</span>

<span class="sd">    The resulting graph will have edge types</span>
<span class="sd">    ``(&#39;user&#39;, &#39;follows&#39;, &#39;user)`` and ``(&#39;game&#39;, &#39;plays&#39;, &#39;user&#39;)``.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reverse(g, copy_ndata=True)</span>
<span class="sd">    &gt;&gt;&gt; rg</span>
<span class="sd">    Graph(num_nodes={&#39;game&#39;: 3, &#39;user&#39;: 3},</span>
<span class="sd">          num_edges={(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): 2, (&#39;game&#39;, &#39;plays&#39;, &#39;user&#39;): 3},</span>
<span class="sd">          metagraph=[(&#39;user&#39;, &#39;user&#39;), (&#39;game&#39;, &#39;user&#39;)])</span>
<span class="sd">    &gt;&gt;&gt; rg.edges(etype=&#39;follows&#39;)</span>
<span class="sd">    (tensor([1, 2]), tensor([0, 2]))</span>
<span class="sd">    &gt;&gt;&gt; rg.edges(etype=&#39;plays&#39;)</span>
<span class="sd">    (tensor([2, 1, 1]), tensor([1, 2, 1]))</span>
<span class="sd">    &gt;&gt;&gt; rg.nodes[&#39;game&#39;].data[&#39;hv&#39;]</span>
<span class="sd">    tensor([[1.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [1.]])</span>
<span class="sd">    &gt;&gt;&gt; rg.edges[&#39;plays&#39;].data</span>
<span class="sd">    {}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">share_ndata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span><span class="s2">&quot;share_ndata argument has been renamed to copy_ndata.&quot;</span><span class="p">)</span>
        <span class="n">copy_ndata</span> <span class="o">=</span> <span class="n">share_ndata</span>
    <span class="k">if</span> <span class="n">share_edata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dgl_warning</span><span class="p">(</span><span class="s2">&quot;share_edata argument has been renamed to copy_edata.&quot;</span><span class="p">)</span>
        <span class="n">copy_edata</span> <span class="o">=</span> <span class="n">share_edata</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">is_block</span><span class="p">:</span>
        <span class="c1"># TODO(0.5 release, xiangsx) need to handle BLOCK</span>
        <span class="c1"># currently reversing a block results in undefined behavior</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Reversing a block graph is not supported.&quot;</span><span class="p">)</span>
    <span class="n">gidx</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
    <span class="n">new_g</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">gidx</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>

    <span class="c1"># handle ndata</span>
    <span class="k">if</span> <span class="n">copy_ndata</span><span class="p">:</span>
        <span class="c1"># for each ntype</span>
        <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="n">new_g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># handle edata</span>
    <span class="k">if</span> <span class="n">copy_edata</span><span class="p">:</span>
        <span class="c1"># for each etype</span>
        <span class="k">for</span> <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">new_g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">vtype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">utype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">new_g</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">reverse</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">alias_func</span><span class="p">(</span><span class="n">reverse</span><span class="p">)</span>


<div class="viewcode-block" id="to_simple_graph">
<a class="viewcode-back" href="../../../generated/dgl.to_simple_graph.html#dgl.to_simple_graph">[docs]</a>
<span class="k">def</span> <span class="nf">to_simple_graph</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert the graph to a simple graph with no multi-edge.</span>

<span class="sd">    DEPRECATED: renamed to dgl.to_simple</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A simple graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dgl_warning</span><span class="p">(</span><span class="s2">&quot;dgl.to_simple_graph is renamed to dgl.to_simple in v0.5.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">to_simple</span><span class="p">(</span><span class="n">g</span><span class="p">)</span></div>



<div class="viewcode-block" id="laplacian_lambda_max">
<a class="viewcode-back" href="../../../generated/dgl.laplacian_lambda_max.html#dgl.laplacian_lambda_max">[docs]</a>
<span class="k">def</span> <span class="nf">laplacian_lambda_max</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the largest eigenvalue of the normalized symmetric Laplacian of a graph.</span>

<span class="sd">    If the graph is batched from multiple graphs, return the list of the largest eigenvalue</span>
<span class="sd">    for each graph instead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph, it must be a bi-directed homogeneous graph, i.e., every edge</span>
<span class="sd">        should have an accompanied reverse edge in the graph.</span>
<span class="sd">        The graph can be batched from multiple graphs.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[float]</span>
<span class="sd">        A list where the i-th item indicates the largest eigenvalue</span>
<span class="sd">        of i-th graph in :attr:`g`.</span>

<span class="sd">        In the case where the function takes a single graph, it will return a list</span>
<span class="sd">        consisting of a single element.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3, 4, 0, 1, 2, 3, 4], [1, 2, 3, 4, 0, 4, 0, 1, 2, 3]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.laplacian_lambda_max(g)</span>
<span class="sd">    [1.809016994374948]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">g_arr</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">unbatch</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">g_i</span> <span class="ow">in</span> <span class="n">g_arr</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">g_i</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">adj</span> <span class="o">=</span> <span class="n">g_i</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span>
            <span class="n">transpose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scipy_fmt</span><span class="o">=</span><span class="n">g_i</span><span class="o">.</span><span class="n">formats</span><span class="p">()[</span><span class="s2">&quot;created&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">g_i</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">())</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span>
        <span class="p">)</span>
        <span class="n">laplacian</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="n">norm</span> <span class="o">*</span> <span class="n">adj</span> <span class="o">*</span> <span class="n">norm</span>
        <span class="n">rst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigs</span><span class="p">(</span>
                <span class="n">laplacian</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;LM&quot;</span><span class="p">,</span> <span class="n">return_eigenvectors</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">rst</span></div>



<div class="viewcode-block" id="metapath_reachable_graph">
<a class="viewcode-back" href="../../../generated/dgl.metapath_reachable_graph.html#dgl.metapath_reachable_graph">[docs]</a>
<span class="k">def</span> <span class="nf">metapath_reachable_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">metapath</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return a graph where the successors of any node ``u`` are nodes reachable from ``u`` by</span>
<span class="sd">    the given metapath.</span>

<span class="sd">    If the beginning node type ``s`` and ending node type ``t`` are the same, it will return</span>
<span class="sd">    a homogeneous graph with node type ``s = t``.  Otherwise, a unidirectional bipartite graph</span>
<span class="sd">    with source node type ``s`` and destination node type ``t`` is returned.</span>

<span class="sd">    In both cases, two nodes ``u`` and ``v`` will be connected with an edge ``(u, v)`` if</span>
<span class="sd">    there exists one path matching the metapath from ``u`` to ``v``.</span>

<span class="sd">    The result graph keeps the node set of type ``s`` and ``t`` in the original graph even if</span>
<span class="sd">    they might have no neighbor.</span>

<span class="sd">    The features of the source/destination node type in the original graph would be copied to</span>
<span class="sd">    the new graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph</span>
<span class="sd">    metapath : list[str or tuple of str]</span>
<span class="sd">        Metapath in the form of a list of edge types</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A homogeneous or unidirectional bipartite graph. It will be on CPU regardless of</span>
<span class="sd">        whether the input graph is on CPU or GPU.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([0, 1, 2], [1, 2, 3]),</span>
<span class="sd">    ...     (&#39;B&#39;, &#39;BA&#39;, &#39;A&#39;): ([1, 2, 3], [0, 1, 2])})</span>
<span class="sd">    &gt;&gt;&gt; new_g = dgl.metapath_reachable_graph(g, [&#39;AB&#39;, &#39;BA&#39;])</span>
<span class="sd">    &gt;&gt;&gt; new_g.edges(order=&#39;eid&#39;)</span>
<span class="sd">    (tensor([0, 1, 2]), tensor([0, 1, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">adj</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">etype</span> <span class="ow">in</span> <span class="n">metapath</span><span class="p">:</span>
        <span class="n">adj</span> <span class="o">=</span> <span class="n">adj</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span>
            <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span> <span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="n">adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">adj</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
    <span class="n">srctype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">metapath</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dsttype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">metapath</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">new_g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">heterograph</span><span class="p">(</span>
        <span class="p">{(</span><span class="n">srctype</span><span class="p">,</span> <span class="s2">&quot;_E&quot;</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">):</span> <span class="n">adj</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()},</span>
        <span class="p">{</span><span class="n">srctype</span><span class="p">:</span> <span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dsttype</span><span class="p">:</span> <span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]},</span>
        <span class="n">idtype</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># copy srcnode features</span>
    <span class="n">new_g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">srctype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">srctype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># copy dstnode features</span>
    <span class="k">if</span> <span class="n">srctype</span> <span class="o">!=</span> <span class="n">dsttype</span><span class="p">:</span>
        <span class="n">new_g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">dsttype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">dsttype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="add_nodes">
<a class="viewcode-back" href="../../../generated/dgl.add_nodes.html#dgl.add_nodes">[docs]</a>
<span class="k">def</span> <span class="nf">add_nodes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add the given number of nodes to the graph and return a new graph.</span>

<span class="sd">    The new nodes will have IDs starting from ``g.num_nodes(ntype)``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num : int</span>
<span class="sd">        The number of nodes to add.</span>
<span class="sd">    data : dict[str, Tensor], optional</span>
<span class="sd">        Feature data of the added nodes. The keys are feature names</span>
<span class="sd">        while the values are feature data.</span>
<span class="sd">    ntype : str, optional</span>
<span class="sd">        The node type name. Can be omitted if there is</span>
<span class="sd">        only one type of nodes in the graph.</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph with newly added nodes.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    * For features in :attr:`g` but not in :attr:`data`,</span>
<span class="sd">      DGL assigns zero features for the newly added nodes.</span>
<span class="sd">    * For feature in :attr:`data` but not in :attr:`g`, DGL assigns zero features</span>
<span class="sd">      for the existing nodes in the graph.</span>
<span class="sd">    * This function discards the batch information. Please use</span>
<span class="sd">      :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">      and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">      to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_nodes(g, 2)</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">    5</span>

<span class="sd">    If the graph has some node features and new nodes are added without</span>
<span class="sd">    features, their features will be filled with zeros.</span>

<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(5, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_nodes(g, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">    tensor([[1.], [1.], [1.], [1.], [1.], [0.]])</span>

<span class="sd">    Assign features for the new nodes.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.add_nodes(g, 1, {&#39;h&#39;: torch.ones(1, 1), &#39;w&#39;: torch.ones(1, 1)})</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">    tensor([[1.], [1.], [1.], [1.], [1.], [0.], [1.]])</span>

<span class="sd">    Since :attr:`data` contains new feature fields, the features for existing nodes</span>
<span class="sd">    will be filled with zeros.</span>

<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;w&#39;]</span>
<span class="sd">    tensor([[0.], [0.], [0.], [0.], [0.], [0.], [1.]])</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">    ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">    ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                         torch.tensor([0, 1]))</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_nodes(g, 2, ntype=&#39;user&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">    5</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    remove_nodes</span>
<span class="sd">    add_edges</span>
<span class="sd">    remove_edges</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">add_nodes</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">ntype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="add_edges">
<a class="viewcode-back" href="../../../generated/dgl.add_edges.html#dgl.add_edges">[docs]</a>
<span class="k">def</span> <span class="nf">add_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add the edges to the graph and return a new graph.</span>

<span class="sd">    The i-th new edge will be from ``u[i]`` to ``v[i]``.  The IDs of the new</span>
<span class="sd">    edges will start from ``g.num_edges(etype)``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    u : int, Tensor or iterable[int]</span>
<span class="sd">        Source node IDs, ``u[i]`` gives the source node for the i-th new edge.</span>
<span class="sd">    v : int, Tensor or iterable[int]</span>
<span class="sd">        Destination node IDs, ``v[i]`` gives the destination node for the i-th new edge.</span>
<span class="sd">    data : dict[str, Tensor], optional</span>
<span class="sd">        Feature data of the added edges. The keys are feature names</span>
<span class="sd">        while the values are feature data.</span>
<span class="sd">    etype : str or (str, str, str), optional</span>
<span class="sd">        The type names of the edges. The allowed type name formats are:</span>

<span class="sd">        * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">        * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">          triplet format in the graph.</span>

<span class="sd">        Can be omitted if the graph has only one type of edges.</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph with newly added edges.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    * If the end nodes of the given edges do not exist in :attr:`g`,</span>
<span class="sd">      :func:`dgl.add_nodes` is invoked to add those nodes.</span>
<span class="sd">      The node features of the new nodes will be filled with zeros.</span>
<span class="sd">    * For features in :attr:`g` but not in :attr:`data`,</span>
<span class="sd">      DGL assigns zero features for the newly added nodes.</span>
<span class="sd">    * For feature in :attr:`data` but not in :attr:`g`, DGL assigns zero features</span>
<span class="sd">      for the existing nodes in the graph.</span>
<span class="sd">    * This function discards the batch information. Please use</span>
<span class="sd">      :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">      and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">      to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges()</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_edges(g, torch.tensor([1, 3]), torch.tensor([0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges()</span>
<span class="sd">    4</span>

<span class="sd">    Since ``u`` or ``v`` contains a non-existing node ID, the nodes are</span>
<span class="sd">    added implicitly.</span>

<span class="sd">    &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">    4</span>

<span class="sd">    If the graph has some edge features and new edges are added without</span>
<span class="sd">    features, their features will be filled with zeros.</span>

<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.ones(4, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_edges(g, torch.tensor([1]), torch.tensor([1]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">    tensor([[1.], [1.], [1.], [1.], [0.]])</span>

<span class="sd">    You can also assign features for the new edges in adding new edges.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.add_edges(g, torch.tensor([0, 0]), torch.tensor([2, 2]),</span>
<span class="sd">    ...                   {&#39;h&#39;: torch.tensor([[1.], [2.]]), &#39;w&#39;: torch.ones(2, 1)})</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">    tensor([[1.], [1.], [1.], [1.], [0.], [1.], [2.]])</span>

<span class="sd">    Since :attr:`data` contains new feature fields, the features for old edges</span>
<span class="sd">    will be filled with zeros.</span>

<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;]</span>
<span class="sd">    tensor([[0.], [0.], [0.], [0.], [0.], [1.], [1.]])</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">    ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">    ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                         torch.tensor([0, 1]))</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">    4</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_edges(g, torch.tensor([3]), torch.tensor([3]), etype=&#39;plays&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">    5</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    add_nodes</span>
<span class="sd">    remove_nodes</span>
<span class="sd">    remove_edges</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="remove_edges">
<a class="viewcode-back" href="../../../generated/dgl.remove_edges.html#dgl.remove_edges">[docs]</a>
<span class="k">def</span> <span class="nf">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove the specified edges and return a new graph.</span>

<span class="sd">    Also delete the features of the edges. The edges must exist in the graph.</span>
<span class="sd">    The resulting graph has the same number of the nodes as the input one,</span>
<span class="sd">    even if some nodes become isolated after the the edge removal.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    eids : int, Tensor, iterable[int]</span>
<span class="sd">        The IDs of the edges to remove.</span>
<span class="sd">    etype : str or (str, str, str), optional</span>
<span class="sd">        The type names of the edges. The allowed type name formats are:</span>

<span class="sd">        * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">        * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">          triplet format in the graph.</span>

<span class="sd">        Can be omitted if the graph has only one type of edges.</span>
<span class="sd">    store_ids : bool, optional</span>
<span class="sd">        If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``</span>
<span class="sd">        and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,</span>
<span class="sd">        respectively.</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph with edges deleted.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function preserves the batch information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.remove_edges(g, torch.tensor([0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes=3, num_edges=1,</span>
<span class="sd">        ndata_schemes={}</span>
<span class="sd">        edata_schemes={&#39;he&#39;: Scheme(shape=(1,), dtype=torch.float32)})</span>
<span class="sd">    &gt;&gt;&gt; g.edges(&#39;all&#39;)</span>
<span class="sd">    (tensor([2]), tensor([2]), tensor([0]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;]</span>
<span class="sd">    tensor([[2.]])</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">    ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">    ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                         torch.tensor([0, 1]))</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.remove_edges(g, torch.tensor([0, 1]), &#39;plays&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.edges(&#39;all&#39;, etype=&#39;plays&#39;)</span>
<span class="sd">    (tensor([1, 2]), tensor([1, 1]), tensor([0, 1]))</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    add_nodes</span>
<span class="sd">    add_edges</span>
<span class="sd">    remove_nodes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">remove_edges</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="n">store_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="remove_nodes">
<a class="viewcode-back" href="../../../generated/dgl.remove_nodes.html#dgl.remove_nodes">[docs]</a>
<span class="k">def</span> <span class="nf">remove_nodes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nids</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove the specified nodes and return a new graph.</span>

<span class="sd">    Also delete the features. Edges that connect from/to the nodes will be</span>
<span class="sd">    removed as well. After the removal, DGL re-labels the remaining nodes and edges</span>
<span class="sd">    with IDs from 0.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nids : int, Tensor, iterable[int]</span>
<span class="sd">        The nodes to be removed.</span>
<span class="sd">    ntype : str, optional</span>
<span class="sd">        The type of the nodes to remove. Can be omitted if there is</span>
<span class="sd">        only one node type in the graph.</span>
<span class="sd">    store_ids : bool, optional</span>
<span class="sd">        If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``</span>
<span class="sd">        and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,</span>
<span class="sd">        respectively.</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph with nodes deleted.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;hv&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.remove_nodes(g, torch.tensor([0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes=1, num_edges=1,</span>
<span class="sd">        ndata_schemes={&#39;hv&#39;: Scheme(shape=(1,), dtype=torch.float32)}</span>
<span class="sd">        edata_schemes={&#39;he&#39;: Scheme(shape=(1,), dtype=torch.float32)})</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;hv&#39;]</span>
<span class="sd">    tensor([[2.]])</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;]</span>
<span class="sd">    tensor([[2.]])</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">    ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">    ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                         torch.tensor([0, 1]))</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.remove_nodes(g, torch.tensor([0, 1]), ntype=&#39;game&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes(&#39;game&#39;)</span>
<span class="sd">    0</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">    0</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    add_nodes</span>
<span class="sd">    add_edges</span>
<span class="sd">    remove_edges</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">g</span><span class="o">.</span><span class="n">remove_nodes</span><span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">ntype</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="n">store_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="add_self_loop">
<a class="viewcode-back" href="../../../generated/dgl.add_self_loop.html#dgl.add_self_loop">[docs]</a>
<span class="k">def</span> <span class="nf">add_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edge_feat_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fill_data</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add self-loops for each node in the graph and return a new graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The graph.</span>
<span class="sd">    edge_feat_names : list[str], optional</span>
<span class="sd">        The names of the self-loop features to apply `fill_data`. If None, it will apply `fill_data`</span>
<span class="sd">        to all self-loop features. Default: None.</span>
<span class="sd">    fill_data : int, float or str, optional</span>
<span class="sd">        The value to fill the self-loop features. Default: 1.</span>

<span class="sd">        * If ``fill_data`` is ``int`` or ``float``, self-loop features will be directly given by</span>
<span class="sd">          ``fill_data``.</span>
<span class="sd">        * if ``fill_data`` is ``str``, self-loop features will be generated by aggregating the</span>
<span class="sd">          features of the incoming edges of the corresponding nodes. The supported aggregation are:</span>
<span class="sd">          ``&#39;mean&#39;``, ``&#39;sum&#39;``, ``&#39;max&#39;``, ``&#39;min&#39;``.</span>
<span class="sd">    etype : str or (str, str, str), optional</span>
<span class="sd">        The type names of the edges. The allowed type name formats are:</span>

<span class="sd">        * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">        * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">          triplet format in the graph.</span>

<span class="sd">        Can be omitted if the graph has only one type of edges.</span>

<span class="sd">    Return</span>
<span class="sd">    ------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph with self-loops.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    * The function only supports homogeneous graphs or heterogeneous graphs but</span>
<span class="sd">      the relation graph specified by the :attr:`etype` argument is homogeneous.</span>
<span class="sd">    * The function adds self-loops regardless of whether they already exist or not.</span>
<span class="sd">      If one wishes to have exactly one self-loop for every node,</span>
<span class="sd">      call :func:`remove_self_loop` before invoking :func:`add_self_loop`.</span>
<span class="sd">    * This function discards the batch information. Please use</span>
<span class="sd">      :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">      and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">      to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([2, 1, 0])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;hv&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_self_loop(g, fill_data=&#39;sum&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes=3, num_edges=6,</span>
<span class="sd">        ndata_schemes={&#39;hv&#39;: Scheme(shape=(1,), dtype=torch.float32)}</span>
<span class="sd">        edata_schemes={&#39;he&#39;: Scheme(shape=(1,), dtype=torch.float32)})</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;]</span>
<span class="sd">    tensor([[0.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [2.],</span>
<span class="sd">            [2.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [0.]])</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([1, 2]),</span>
<span class="sd">    ...                                   torch.tensor([0, 1])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                 torch.tensor([0, 1]))})</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.add_self_loop(g, etype=&#39;follows&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes={&#39;user&#39;: 3, &#39;game&#39;: 2},</span>
<span class="sd">          num_edges={(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): 5},</span>
<span class="sd">          metagraph=[(&#39;user&#39;, &#39;user&#39;), (&#39;user&#39;, &#39;game&#39;)])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">etype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">reduce_funcs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;sum&quot;</span><span class="p">:</span> <span class="n">function</span><span class="o">.</span><span class="n">sum</span><span class="p">,</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">function</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span>
        <span class="s2">&quot;max&quot;</span><span class="p">:</span> <span class="n">function</span><span class="o">.</span><span class="n">max</span><span class="p">,</span>
        <span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="n">function</span><span class="o">.</span><span class="n">min</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">edge_feat_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edge_feat_names</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;add_self_loop does not support unidirectional bipartite graphs: </span><span class="si">{}</span><span class="s2">.&quot;</span>
            <span class="s2">&quot;Please make sure the types of head node and tail node are identical.&quot;</span>
            <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">feat_name</span> <span class="ow">in</span> <span class="n">edge_feat_names</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_data</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
            <span class="n">dshape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">tmp_fill_data</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">fill_data</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dshape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="n">feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">*</span><span class="n">dshape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
                    <span class="p">)</span>
                    <span class="o">+</span> <span class="n">tmp_fill_data</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="n">feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]),),</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="o">+</span> <span class="n">tmp_fill_data</span>
                <span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fill_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">fill_data</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">reduce_funcs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Unsupported aggregation: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fill_data</span><span class="p">))</span>
            <span class="n">reducer</span> <span class="o">=</span> <span class="n">reduce_funcs</span><span class="p">[</span><span class="n">fill_data</span><span class="p">]</span>
            <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span>
                    <span class="n">function</span><span class="o">.</span><span class="n">copy_e</span><span class="p">(</span><span class="n">feat_name</span><span class="p">,</span> <span class="s2">&quot;h&quot;</span><span class="p">),</span>
                    <span class="n">reducer</span><span class="p">(</span><span class="s2">&quot;h&quot;</span><span class="p">,</span> <span class="s2">&quot;h&quot;</span><span class="p">),</span>
                    <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">data</span><span class="p">[</span><span class="n">feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;h&quot;</span><span class="p">]</span>

    <span class="n">nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">new_g</span> <span class="o">=</span> <span class="n">add_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_g</span> <span class="o">=</span> <span class="n">add_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_g</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">add_self_loop</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">alias_func</span><span class="p">(</span><span class="n">add_self_loop</span><span class="p">)</span>


<div class="viewcode-block" id="remove_self_loop">
<a class="viewcode-back" href="../../../generated/dgl.remove_self_loop.html#dgl.remove_self_loop">[docs]</a>
<span class="k">def</span> <span class="nf">remove_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove self-loops for each node in the graph and return a new graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The graph.</span>
<span class="sd">    etype : str or (str, str, str), optional</span>
<span class="sd">        The type names of the edges. The allowed type name formats are:</span>

<span class="sd">        * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">        * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">          triplet format in the graph.</span>

<span class="sd">        Can be omitted if the graph has only one type of edges.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If a node has multiple self-loops, remove them all. Do nothing for nodes without</span>
<span class="sd">    self-loops.</span>

<span class="sd">    This function preserves the batch information.</span>

<span class="sd">    Examples</span>
<span class="sd">    ---------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([1, 0, 0, 2])))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(4).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.remove_self_loop(g)</span>
<span class="sd">    &gt;&gt;&gt; g</span>
<span class="sd">    Graph(num_nodes=3, num_edges=2,</span>
<span class="sd">        edata_schemes={&#39;he&#39;: Scheme(shape=(2,), dtype=torch.float32)})</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;]</span>
<span class="sd">    tensor([[0.],[3.]])</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1, 1, 1, 2]),</span>
<span class="sd">    ...                                   torch.tensor([0, 0, 1, 1, 1])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                 torch.tensor([0, 1]))</span>
<span class="sd">    ...     })</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.remove_self_loop(g, etype=&#39;follows&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; g.num_nodes(&#39;game&#39;)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges(&#39;follows&#39;)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">    2</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    add_self_loop</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">etype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;remove_self_loop does not support unidirectional bipartite graphs: </span><span class="si">{}</span><span class="s2">.&quot;</span>
            <span class="s2">&quot;Please make sure the types of head node and tail node are identical.&quot;</span>
            <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
    <span class="n">self_loop_eids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">u</span> <span class="o">==</span> <span class="n">v</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
    <span class="n">new_g</span> <span class="o">=</span> <span class="n">remove_edges</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">self_loop_eids</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_g</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">remove_self_loop</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">alias_func</span><span class="p">(</span><span class="n">remove_self_loop</span><span class="p">)</span>


<div class="viewcode-block" id="compact_graphs">
<a class="viewcode-back" href="../../../generated/dgl.compact_graphs.html#dgl.compact_graphs">[docs]</a>
<span class="k">def</span> <span class="nf">compact_graphs</span><span class="p">(</span>
    <span class="n">graphs</span><span class="p">,</span> <span class="n">always_preserve</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">copy_ndata</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given a list of graphs with the same set of nodes, find and eliminate the common</span>
<span class="sd">    isolated nodes across all graphs.</span>

<span class="sd">    This function requires the graphs to have the same set of nodes (i.e. the node types</span>
<span class="sd">    must be the same, and the number of nodes of each node type must be the same).  The</span>
<span class="sd">    metagraph does not have to be the same.</span>

<span class="sd">    It finds all the nodes that have zero in-degree and zero out-degree in all the given</span>
<span class="sd">    graphs, and eliminates them from all the graphs.</span>

<span class="sd">    Useful for graph sampling where you have a giant graph but you only wish to perform</span>
<span class="sd">    message passing on a smaller graph with a (tiny) subset of nodes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graphs : DGLGraph or list[DGLGraph]</span>
<span class="sd">        The graph, or list of graphs.</span>

<span class="sd">        All graphs must be on the same devices.</span>

<span class="sd">        All graphs must have the same set of nodes.</span>
<span class="sd">    always_preserve : Tensor or dict[str, Tensor], optional</span>
<span class="sd">        If a dict of node types and node ID tensors is given, the nodes of given</span>
<span class="sd">        node types would not be removed, regardless of whether they are isolated.</span>

<span class="sd">        If a Tensor is given, DGL assumes that all the graphs have one (same) node type.</span>
<span class="sd">    copy_ndata: bool, optional</span>
<span class="sd">        If True, the node features of the returned graphs are copied from the</span>
<span class="sd">        original graphs.</span>

<span class="sd">        If False, the returned graphs will not have any node features.</span>

<span class="sd">        (Default: True)</span>
<span class="sd">    copy_edata: bool, optional</span>
<span class="sd">        If True, the edge features of the reversed graph are copied from the</span>
<span class="sd">        original graph.</span>

<span class="sd">        If False, the reversed graph will not have any edge features.</span>

<span class="sd">        (Default: True)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph or list[DGLGraph]</span>
<span class="sd">        The compacted graph or list of compacted graphs.</span>

<span class="sd">        Each returned graph would have a feature ``dgl.NID`` containing the mapping</span>
<span class="sd">        of node IDs for each type from the compacted graph(s) to the original graph(s).</span>
<span class="sd">        Note that the mapping is the same for all the compacted graphs.</span>

<span class="sd">        All the returned graphs are on CPU.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function currently requires that the same node type of all graphs should have</span>
<span class="sd">    the same node type ID, i.e. the node types are *ordered* the same.</span>

<span class="sd">    If :attr:`copy_edata` is True, the resulting graph will share the edge feature</span>
<span class="sd">    tensors with the input graph. Hence, users should try to avoid in-place operations</span>
<span class="sd">    which will be visible to both graphs.</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following code constructs a bipartite graph with 20 users and 10 games, but</span>
<span class="sd">    only user #1 and #3, as well as game #3 and #5, have connections:</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([1, 3], [3, 5])},</span>
<span class="sd">    &gt;&gt;&gt;                      {&#39;user&#39;: 20, &#39;game&#39;: 10})</span>

<span class="sd">    The following would compact the graph above to another bipartite graph with only</span>
<span class="sd">    two users and two games.</span>

<span class="sd">    &gt;&gt;&gt; new_g = dgl.compact_graphs(g)</span>
<span class="sd">    &gt;&gt;&gt; new_g.ndata[dgl.NID]</span>
<span class="sd">    {&#39;user&#39;: tensor([1, 3]), &#39;game&#39;: tensor([3, 5])}</span>

<span class="sd">    The mapping tells us that only user #1 and #3 as well as game #3 and #5 are kept.</span>
<span class="sd">    Furthermore, the first user and second user in the compacted graph maps to</span>
<span class="sd">    user #1 and #3 in the original graph.  Games are similar.</span>

<span class="sd">    One can verify that the edge connections are kept the same in the compacted graph.</span>

<span class="sd">    &gt;&gt;&gt; new_g.edges(form=&#39;all&#39;, order=&#39;eid&#39;, etype=&#39;plays&#39;)</span>
<span class="sd">    (tensor([0, 1]), tensor([0, 1]), tensor([0, 1]))</span>

<span class="sd">    When compacting multiple graphs, nodes that do not have any connections in any</span>
<span class="sd">    of the given graphs are removed.  So if you compact ``g`` and the following ``g2``</span>
<span class="sd">    graphs together:</span>

<span class="sd">    &gt;&gt;&gt; g2 = dgl.heterograph({(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([1, 6], [6, 8])},</span>
<span class="sd">    &gt;&gt;&gt;                      {&#39;user&#39;: 20, &#39;game&#39;: 10})</span>
<span class="sd">    &gt;&gt;&gt; new_g, new_g2 = dgl.compact_graphs([g, g2])</span>
<span class="sd">    &gt;&gt;&gt; new_g.ndata[dgl.NID]</span>
<span class="sd">    {&#39;user&#39;: tensor([1, 3, 6]), &#39;game&#39;: tensor([3, 5, 6, 8])}</span>

<span class="sd">    Then one can see that user #1 from both graphs, users #3 from the first graph, as</span>
<span class="sd">    well as user #6 from the second graph, are kept.  Games are similar.</span>

<span class="sd">    Similarly, one can also verify the connections:</span>

<span class="sd">    &gt;&gt;&gt; new_g.edges(form=&#39;all&#39;, order=&#39;eid&#39;, etype=&#39;plays&#39;)</span>
<span class="sd">    (tensor([0, 1]), tensor([0, 1]), tensor([0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; new_g2.edges(form=&#39;all&#39;, order=&#39;eid&#39;, etype=&#39;plays&#39;)</span>
<span class="sd">    (tensor([0, 2]), tensor([2, 3]), tensor([0, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">return_single</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">graphs</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
        <span class="n">graphs</span> <span class="o">=</span> <span class="p">[</span><span class="n">graphs</span><span class="p">]</span>
        <span class="n">return_single</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">graphs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_block</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Compacting a block graph is not allowed.&quot;</span><span class="p">)</span>

    <span class="c1"># Ensure the node types are ordered the same.</span>
    <span class="c1"># TODO(BarclayII): we ideally need to remove this constraint.</span>
    <span class="n">ntypes</span> <span class="o">=</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ntypes</span>
    <span class="n">idtype</span> <span class="o">=</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">idtype</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
    <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">graphs</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">ntypes</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;All graphs should have the same node types in the same order, got </span><span class="si">%s</span><span class="s2"> and </span><span class="si">%s</span><span class="s2">&quot;</span>
            <span class="o">%</span> <span class="n">ntypes</span><span class="p">,</span>
            <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">idtype</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span>
        <span class="p">),</span> <span class="s2">&quot;Expect graph data type to be </span><span class="si">{}</span><span class="s2">, but got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">idtype</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span>
        <span class="p">)</span>
        <span class="k">assert</span> <span class="n">device</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;All graphs must be on the same devices.&quot;</span>
            <span class="s2">&quot;Expect graph device to be </span><span class="si">{}</span><span class="s2">, but got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Process the dictionary or tensor of &quot;always preserve&quot; nodes</span>
    <span class="k">if</span> <span class="n">always_preserve</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">always_preserve</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">always_preserve</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Node type must be given if multiple node types exist.&quot;</span>
            <span class="p">)</span>
        <span class="n">always_preserve</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">always_preserve</span><span class="p">}</span>

    <span class="n">always_preserve</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor_dict</span><span class="p">(</span>
        <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">always_preserve</span><span class="p">,</span> <span class="s2">&quot;always_preserve&quot;</span>
    <span class="p">)</span>
    <span class="n">always_preserve_nd</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span><span class="p">:</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="n">always_preserve</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nodes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nodes</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">([],</span> <span class="n">idtype</span><span class="p">),</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">always_preserve_nd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">to_dgl_nd</span><span class="p">(</span><span class="n">nodes</span><span class="p">))</span>

    <span class="c1"># Compact and construct heterographs</span>
    <span class="n">new_graph_indexes</span><span class="p">,</span> <span class="n">induced_nodes</span> <span class="o">=</span> <span class="n">_CAPI_DGLCompactGraphs</span><span class="p">(</span>
        <span class="p">[</span><span class="n">g</span><span class="o">.</span><span class="n">_graph</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">graphs</span><span class="p">],</span> <span class="n">always_preserve_nd</span>
    <span class="p">)</span>
    <span class="n">induced_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">from_dgl_nd</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">induced_nodes</span><span class="p">]</span>

    <span class="n">new_graphs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">DGLGraph</span><span class="p">(</span><span class="n">new_graph_index</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">new_graph_index</span><span class="p">,</span> <span class="n">graph</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">new_graph_indexes</span><span class="p">,</span> <span class="n">graphs</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="k">if</span> <span class="n">copy_ndata</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">g</span><span class="p">,</span> <span class="n">new_g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">graphs</span><span class="p">,</span> <span class="n">new_graphs</span><span class="p">):</span>
            <span class="n">node_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_node_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">induced_nodes</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">new_g</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="n">node_frames</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">copy_edata</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">g</span><span class="p">,</span> <span class="n">new_g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">graphs</span><span class="p">,</span> <span class="n">new_graphs</span><span class="p">):</span>
            <span class="n">edge_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_edge_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">new_g</span><span class="p">,</span> <span class="n">edge_frames</span><span class="o">=</span><span class="n">edge_frames</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_single</span><span class="p">:</span>
        <span class="n">new_graphs</span> <span class="o">=</span> <span class="n">new_graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">new_graphs</span></div>



<span class="k">def</span> <span class="nf">_coalesce_edge_frame</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edge_maps</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">aggregator</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Coalesce edge features of duplicate edges via given aggregator in g.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    edge_maps : List[Tensor]</span>
<span class="sd">        The edge mapping corresponding to each edge type in g.</span>
<span class="sd">    counts : List[Tensor]</span>
<span class="sd">        The number of duplicated edges from the original graph for each edge type.</span>
<span class="sd">    aggregator : str</span>
<span class="sd">        Indicates how to coalesce edge features, could be ``arbitrary``, ``sum``</span>
<span class="sd">        or ``mean``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    List[Frame]</span>
<span class="sd">        The frames corresponding to each edge type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">aggregator</span> <span class="o">==</span> <span class="s2">&quot;arbitrary&quot;</span><span class="p">:</span>
        <span class="n">eids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)):</span>
            <span class="n">feat_idx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">edge_maps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">feat_idx</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">eids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_numpy</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>

        <span class="n">edge_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_edge_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eids</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">aggregator</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">]:</span>
        <span class="n">edge_frames</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)):</span>
            <span class="n">feat_idx</span> <span class="o">=</span> <span class="n">edge_maps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">feat_idx</span><span class="p">),</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">_num_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">_data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_columns</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">col</span><span class="o">.</span><span class="n">data</span>
                <span class="n">new_data</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_add</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">feat_idx</span><span class="p">,</span> <span class="n">_num_rows</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">aggregator</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
                    <span class="n">norm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">counts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
                    <span class="n">norm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                        <span class="n">norm</span><span class="p">,</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">norm</span><span class="p">)[</span><span class="mi">0</span><span class="p">],)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">new_data</span> <span class="o">/=</span> <span class="n">norm</span>
                <span class="n">_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_data</span>

            <span class="n">newf</span> <span class="o">=</span> <span class="n">Frame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">_data</span><span class="p">,</span> <span class="n">num_rows</span><span class="o">=</span><span class="n">_num_rows</span><span class="p">)</span>
            <span class="n">edge_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">newf</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Aggregator </span><span class="si">{}</span><span class="s2"> not regonized, cannot coalesce edge feature in the &quot;</span>
            <span class="s2">&quot;specified way&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">aggregator</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">edge_frames</span>


<div class="viewcode-block" id="to_simple">
<a class="viewcode-back" href="../../../generated/dgl.to_simple.html#dgl.to_simple">[docs]</a>
<span class="k">def</span> <span class="nf">to_simple</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">return_counts</span><span class="o">=</span><span class="s2">&quot;count&quot;</span><span class="p">,</span>
    <span class="n">writeback_mapping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">copy_ndata</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">aggregator</span><span class="o">=</span><span class="s2">&quot;arbitrary&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert a graph to a simple graph without parallel edges and return.</span>

<span class="sd">    For a heterogeneous graph with multiple edge types, DGL treats edges with the same</span>
<span class="sd">    edge type and endpoints as parallel edges and removes them.</span>
<span class="sd">    Optionally, one can get the the number of parallel edges by specifying the</span>
<span class="sd">    :attr:`return_counts` argument. To get the a mapping from the edge IDs in the</span>
<span class="sd">    input graph to the edge IDs in the resulting graph, set :attr:`writeback_mapping`</span>
<span class="sd">    to true.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.  Must be on CPU.</span>
<span class="sd">    return_counts : str, optional</span>
<span class="sd">        If given, the count of each edge in the original graph</span>
<span class="sd">        will be stored as edge features under the name</span>
<span class="sd">        ``return_counts``.  The old features with the same name will be replaced.</span>

<span class="sd">        (Default: &quot;count&quot;)</span>
<span class="sd">    writeback_mapping: bool, optional</span>
<span class="sd">        If True, return an extra write-back mapping for each edge</span>
<span class="sd">        type. The write-back mapping is a tensor recording</span>
<span class="sd">        the mapping from the edge IDs in the input graph to</span>
<span class="sd">        the edge IDs in the result graph. If the graph is</span>
<span class="sd">        heterogeneous, DGL returns a dictionary of edge types and such</span>
<span class="sd">        tensors.</span>

<span class="sd">        If False, only the simple graph is returned.</span>

<span class="sd">        (Default: False)</span>
<span class="sd">    copy_ndata: bool, optional</span>
<span class="sd">        If True, the node features of the simple graph are copied</span>
<span class="sd">        from the original graph.</span>

<span class="sd">        If False, the simple graph will not have any node features.</span>

<span class="sd">        (Default: True)</span>
<span class="sd">    copy_edata: bool, optional</span>
<span class="sd">        If True, the edge features of the simple graph are copied</span>
<span class="sd">        from the original graph. If there exists duplicate edges between</span>
<span class="sd">        two nodes (u, v), the feature of the edge is the aggregation</span>
<span class="sd">        of edge feature of duplicate edges.</span>

<span class="sd">        If False, the simple graph will not have any edge features.</span>

<span class="sd">        (Default: False)</span>
<span class="sd">    aggregator: str, optional</span>
<span class="sd">        Indicate how to coalesce edge feature of duplicate edges.</span>
<span class="sd">        If ``arbitrary``, select one of the duplicate edges&#39; feature.</span>
<span class="sd">        If ``sum``, compute the summation of duplicate edges&#39; feature.</span>
<span class="sd">        If ``mean``, compute the average of duplicate edges&#39; feature.</span>

<span class="sd">        (Default: ``arbitrary``)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The graph.</span>
<span class="sd">    tensor or dict of tensor</span>
<span class="sd">        The writeback mapping. Only when ``writeback_mapping`` is True.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If :attr:`copy_ndata` is True, the resulting graph will share the node feature</span>
<span class="sd">    tensors with the input graph. Hence, users should try to avoid in-place operations</span>
<span class="sd">    which will be visible to both graphs.</span>

<span class="sd">    This function discards the batch information. Please use</span>
<span class="sd">    :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">    and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">    to maintain the information.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    **Homogeneous Graphs**</span>

<span class="sd">    Create a graph for demonstrating to_simple API.</span>
<span class="sd">    In the original graph, there are multiple edges between 1 and 2.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch as th</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph((th.tensor([0, 1, 2, 1]), th.tensor([1, 2, 0, 2])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = th.tensor([[0.], [1.], [2.]])</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;] = th.tensor([[3.], [4.], [5.], [6.]])</span>

<span class="sd">    Convert the graph to a simple graph. The return counts is</span>
<span class="sd">    stored in the edge feature &#39;cnt&#39; and the writeback mapping</span>
<span class="sd">    is returned in a tensor.</span>

<span class="sd">    &gt;&gt;&gt; sg, wm = dgl.to_simple(g, return_counts=&#39;cnt&#39;, writeback_mapping=True)</span>
<span class="sd">    &gt;&gt;&gt; sg.ndata[&#39;h&#39;]</span>
<span class="sd">    tensor([[0.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [2.]])</span>
<span class="sd">    &gt;&gt;&gt; u, v, eid = sg.edges(form=&#39;all&#39;)</span>
<span class="sd">    &gt;&gt;&gt; u</span>
<span class="sd">    tensor([0, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; v</span>
<span class="sd">    tensor([1, 2, 0])</span>
<span class="sd">    &gt;&gt;&gt; eid</span>
<span class="sd">    tensor([0, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; sg.edata[&#39;cnt&#39;]</span>
<span class="sd">    tensor([1, 2, 1])</span>
<span class="sd">    &gt;&gt;&gt; wm</span>
<span class="sd">    tensor([0, 1, 2, 1])</span>
<span class="sd">    &gt;&gt;&gt; &#39;h&#39; in g.edata</span>
<span class="sd">    False</span>

<span class="sd">    **Heterogeneous Graphs**</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;): (th.tensor([0, 2, 0, 2, 2]), th.tensor([1, 1, 2, 1, 0])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (th.tensor([1, 2, 1]), th.tensor([2, 1, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;hv&#39;] = th.ones(3, 1)</span>
<span class="sd">    &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;he&#39;] = th.zeros(3, 1)</span>

<span class="sd">    The return counts is stored in the default edge feature &#39;count&#39; for each edge type.</span>

<span class="sd">    &gt;&gt;&gt; sg, wm = dgl.to_simple(g, copy_ndata=False, writeback_mapping=True)</span>
<span class="sd">    &gt;&gt;&gt; sg</span>
<span class="sd">    Graph(num_nodes={&#39;game&#39;: 3, &#39;user&#39;: 3},</span>
<span class="sd">          num_edges={(&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;): 4, (&#39;game&#39;, &#39;plays&#39;, &#39;user&#39;): 3},</span>
<span class="sd">          metagraph=[(&#39;user&#39;, &#39;user&#39;), (&#39;game&#39;, &#39;user&#39;)])</span>
<span class="sd">    &gt;&gt;&gt; sg.edges(etype=&#39;wins&#39;)</span>
<span class="sd">    (tensor([0, 2, 0, 2]), tensor([1, 1, 2, 0]))</span>
<span class="sd">    &gt;&gt;&gt; wm[(&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;)]</span>
<span class="sd">    tensor([0, 1, 2, 1, 3])</span>
<span class="sd">    &gt;&gt;&gt; sg.edges(etype=&#39;plays&#39;)</span>
<span class="sd">    (tensor([2, 1, 1]), tensor([1, 2, 1]))</span>
<span class="sd">    &gt;&gt;&gt; wm[(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)]</span>
<span class="sd">    tensor([0, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; &#39;hv&#39; in sg.nodes[&#39;game&#39;].data</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; &#39;he&#39; in sg.edges[&#39;plays&#39;].data</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; sg.edata[&#39;count&#39;]</span>
<span class="sd">    {(&#39;user&#39;, &#39;wins&#39;, &#39;user&#39;): tensor([1, 2, 1, 1])</span>
<span class="sd">     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): tensor([1, 1, 1])}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s2">&quot;the graph must be on CPU&quot;</span>
    <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">is_block</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Cannot convert a block graph to a simple graph.&quot;</span><span class="p">)</span>
    <span class="n">simple_graph_index</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">edge_maps</span> <span class="o">=</span> <span class="n">_CAPI_DGLToSimpleHetero</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">_graph</span><span class="p">)</span>
    <span class="n">simple_graph</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">simple_graph_index</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">from_dgl_nd</span><span class="p">(</span><span class="n">count</span><span class="p">)</span> <span class="k">for</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">]</span>
    <span class="n">edge_maps</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">from_dgl_nd</span><span class="p">(</span><span class="n">edge_map</span><span class="p">)</span> <span class="k">for</span> <span class="n">edge_map</span> <span class="ow">in</span> <span class="n">edge_maps</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">copy_ndata</span><span class="p">:</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_node_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">simple_graph</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="n">node_frames</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">copy_edata</span><span class="p">:</span>
        <span class="n">new_edge_frames</span> <span class="o">=</span> <span class="n">_coalesce_edge_frame</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edge_maps</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">aggregator</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">simple_graph</span><span class="p">,</span> <span class="n">edge_frames</span><span class="o">=</span><span class="n">new_edge_frames</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_counts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">count</span><span class="p">,</span> <span class="n">canonical_etype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">):</span>
            <span class="n">simple_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">canonical_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">return_counts</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>

    <span class="k">if</span> <span class="n">writeback_mapping</span><span class="p">:</span>
        <span class="c1"># single edge type</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_maps</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">simple_graph</span><span class="p">,</span> <span class="n">edge_maps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># multiple edge type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">wb_map</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">edge_map</span><span class="p">,</span> <span class="n">canonical_etype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">edge_maps</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">):</span>
                <span class="n">wb_map</span><span class="p">[</span><span class="n">canonical_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_map</span>
            <span class="k">return</span> <span class="n">simple_graph</span><span class="p">,</span> <span class="n">wb_map</span>

    <span class="k">return</span> <span class="n">simple_graph</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">to_simple</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">alias_func</span><span class="p">(</span><span class="n">to_simple</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_unitgraph_less_than_int32</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if a graph with only one edge type has more than 2 ** 31 - 1</span>
<span class="sd">    nodes or edges.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_edges</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>
    <span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_edges</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">31</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>


<div class="viewcode-block" id="adj_product_graph">
<a class="viewcode-back" href="../../../generated/dgl.adj_product_graph.html#dgl.adj_product_graph">[docs]</a>
<span class="k">def</span> <span class="nf">adj_product_graph</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="s2">&quot;_E&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Create a weighted graph whose adjacency matrix is the product of</span>
<span class="sd">    the adjacency matrices of the given two graphs.</span>

<span class="sd">    Namely, given two weighted graphs :attr:`A` and :attr:`B`, whose rows</span>
<span class="sd">    represent source nodes and columns represent destination nodes, this function</span>
<span class="sd">    returns a new graph whose weighted adjacency matrix is</span>
<span class="sd">    :math:`\mathrm{adj}(A) \times \mathrm{adj}(B)`.</span>

<span class="sd">    The two graphs must be simple graphs, and must have only one edge type.</span>
<span class="sd">    Moreover, the number of nodes of the destination node type of :attr:`A` must</span>
<span class="sd">    be the same as the number of nodes of the source node type of :attr:`B`.</span>

<span class="sd">    The source node type of the returned graph will be the same as the source</span>
<span class="sd">    node type of graph :attr:`A`.  The destination node type of the returned</span>
<span class="sd">    graph will be the same as the destination node type of graph :attr:`B`.</span>
<span class="sd">    If the two node types are the same, the returned graph will be homogeneous.</span>
<span class="sd">    Otherwise, it will be a bipartite graph.</span>

<span class="sd">    Unlike ``scipy``, if an edge in the result graph has zero weight, it will</span>
<span class="sd">    not be removed from the graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function works on both CPU and GPU.  For GPU, the number of nodes and</span>
<span class="sd">    edges must be less than the maximum of ``int32`` (i.e. ``2 ** 31 - 1``) due</span>
<span class="sd">    to restriction of cuSPARSE.</span>

<span class="sd">    The edge weights returned by this function is differentiable w.r.t. the</span>
<span class="sd">    input edge weights.</span>

<span class="sd">    If the graph format is restricted, both graphs must have CSR available.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    A : DGLGraph</span>
<span class="sd">        The graph as left operand.</span>
<span class="sd">    B : DGLGraph</span>
<span class="sd">        The graph as right operand.</span>
<span class="sd">    weight_name : str</span>
<span class="sd">        The feature name of edge weight of both graphs.</span>

<span class="sd">        The corresponding edge feature must be scalar.</span>
<span class="sd">    etype : str, optional</span>
<span class="sd">        The edge type of the returned graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The new graph.  The edge weight of the returned graph will have the</span>
<span class="sd">        same feature name as :attr:`weight_name`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following shows weighted adjacency matrix multiplication between two</span>
<span class="sd">    bipartite graphs.  You can also perform this between two homogeneous</span>
<span class="sd">    graphs, or one homogeneous graph and one bipartite graph, as long as the</span>
<span class="sd">    numbers of nodes of the same type match.</span>

<span class="sd">    &gt;&gt;&gt; A = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([2, 2, 0, 2, 0, 1], [2, 1, 0, 0, 2, 2])},</span>
<span class="sd">    ...     num_nodes_dict={&#39;A&#39;: 3, &#39;B&#39;: 4})</span>
<span class="sd">    &gt;&gt;&gt; B = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;B&#39;, &#39;BA&#39;, &#39;A&#39;): ([0, 3, 2, 1, 3, 3], [1, 2, 0, 2, 1, 0])},</span>
<span class="sd">    ...     num_nodes_dict={&#39;A&#39;: 3, &#39;B&#39;: 4})</span>

<span class="sd">    If your graph is a multigraph, you will need to call :func:`dgl.to_simple`</span>
<span class="sd">    to convert it into a simple graph first.</span>

<span class="sd">    &gt;&gt;&gt; A = dgl.to_simple(A)</span>
<span class="sd">    &gt;&gt;&gt; B = dgl.to_simple(B)</span>

<span class="sd">    Initialize learnable edge weights.</span>

<span class="sd">    &gt;&gt;&gt; A.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>
<span class="sd">    &gt;&gt;&gt; B.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>

<span class="sd">    Take the product.</span>

<span class="sd">    &gt;&gt;&gt; C = dgl.adj_product_graph(A, B, &#39;w&#39;)</span>
<span class="sd">    &gt;&gt;&gt; C.edges()</span>
<span class="sd">    (tensor([0, 0, 1, 2, 2, 2]), tensor([0, 1, 0, 0, 2, 1]))</span>

<span class="sd">    &gt;&gt;&gt; C.edata[&#39;w&#39;]</span>
<span class="sd">    tensor([0.6906, 0.2002, 0.0591, 0.3672, 0.1066, 0.1328],</span>
<span class="sd">           grad_fn=&lt;CSRMMBackward&gt;)</span>

<span class="sd">    Note that this function is differentiable:</span>

<span class="sd">    &gt;&gt;&gt; C.edata[&#39;w&#39;].sum().backward()</span>
<span class="sd">    &gt;&gt;&gt; A.edata[&#39;w&#39;].grad</span>
<span class="sd">    tensor([0.7153, 0.2775, 0.7141, 0.7141, 0.7153, 0.7153])</span>

<span class="sd">    &gt;&gt;&gt; B.edata[&#39;w&#39;].grad</span>
<span class="sd">    tensor([0.4664, 0.0000, 1.5614, 0.3840, 0.0000, 0.0000])</span>

<span class="sd">    If the source node type of the left operand is the same as the destination</span>
<span class="sd">    node type of the right operand, this function returns a homogeneous graph:</span>

<span class="sd">    &gt;&gt;&gt; C.ntypes</span>
<span class="sd">    [&#39;A&#39;]</span>

<span class="sd">    Otherwise, it returns a bipartite graph instead:</span>

<span class="sd">    &gt;&gt;&gt; A = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([2, 2, 0, 2, 0, 1], [2, 1, 0, 0, 2, 2])},</span>
<span class="sd">    ...     num_nodes_dict={&#39;A&#39;: 3, &#39;B&#39;: 4})</span>
<span class="sd">    &gt;&gt;&gt; B = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;B&#39;, &#39;BC&#39;, &#39;C&#39;): ([0, 3, 2, 1, 3, 3], [1, 2, 0, 2, 1, 0])},</span>
<span class="sd">    ...     num_nodes_dict={&#39;C&#39;: 3, &#39;B&#39;: 4})</span>
<span class="sd">    &gt;&gt;&gt; A.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>
<span class="sd">    &gt;&gt;&gt; B.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>
<span class="sd">    &gt;&gt;&gt; C = dgl.adj_product_graph(A, B, &#39;w&#39;)</span>
<span class="sd">    &gt;&gt;&gt; C.ntypes</span>
<span class="sd">    [&#39;A&#39;, &#39;C&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_vtypes</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">srctype</span> <span class="o">==</span> <span class="n">dsttype</span> <span class="k">else</span> <span class="mi">2</span>
    <span class="n">ntypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">srctype</span><span class="p">]</span> <span class="k">if</span> <span class="n">num_vtypes</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">[</span><span class="n">srctype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">():</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="n">_unitgraph_less_than_int32</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="ow">and</span> <span class="n">_unitgraph_less_than_int32</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;For GPU graphs the number of nodes and edges must be less than 2 ** 31 - 1.&quot;</span>
            <span class="p">)</span>

    <span class="n">C_gidx</span><span class="p">,</span> <span class="n">C_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">csrmm</span><span class="p">(</span>
        <span class="n">A</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span>
        <span class="n">A</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">weight_name</span><span class="p">],</span>
        <span class="n">B</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span>
        <span class="n">B</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">weight_name</span><span class="p">],</span>
        <span class="n">num_vtypes</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">num_nodes_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">srctype</span><span class="p">:</span> <span class="n">A</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">srctype</span><span class="p">),</span>
        <span class="n">dsttype</span><span class="p">:</span> <span class="n">B</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">dsttype</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="n">C_metagraph</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_metagraph_index</span><span class="p">(</span>
        <span class="n">ntypes</span><span class="p">,</span> <span class="p">[(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span><span class="p">]</span>
    <span class="n">C_gidx</span> <span class="o">=</span> <span class="n">create_heterograph_from_relations</span><span class="p">(</span>
        <span class="n">C_metagraph</span><span class="p">,</span> <span class="p">[</span><span class="n">C_gidx</span><span class="p">],</span> <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span><span class="n">num_nodes_per_type</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">C_gidx</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">)</span>
    <span class="n">C</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">weight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">C_weights</span>
    <span class="k">return</span> <span class="n">C</span></div>



<div class="viewcode-block" id="adj_sum_graph">
<a class="viewcode-back" href="../../../generated/dgl.adj_sum_graph.html#dgl.adj_sum_graph">[docs]</a>
<span class="k">def</span> <span class="nf">adj_sum_graph</span><span class="p">(</span><span class="n">graphs</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Create a weighted graph whose adjacency matrix is the sum of the</span>
<span class="sd">    adjacency matrices of the given graphs, whose rows represent source nodes</span>
<span class="sd">    and columns represent destination nodes.</span>

<span class="sd">    All the graphs must be simple graphs, and must have only one edge type.</span>
<span class="sd">    They also must have the same metagraph, i.e. have the same source node type</span>
<span class="sd">    and the same destination node type.  Moreover, the number of nodes for every</span>
<span class="sd">    graph must also be the same.</span>

<span class="sd">    The metagraph of the returned graph will be the same as the input graphs.</span>

<span class="sd">    Unlike ``scipy``, if an edge in the result graph has zero weight, it will</span>
<span class="sd">    not be removed from the graph.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function works on both CPU and GPU.  For GPU, the number of nodes and</span>
<span class="sd">    edges must be less than the maximum of ``int32`` (i.e. ``2 ** 31 - 1``) due</span>
<span class="sd">    to restriction of cuSPARSE.</span>

<span class="sd">    The edge weights returned by this function is differentiable w.r.t. the</span>
<span class="sd">    input edge weights.</span>

<span class="sd">    If the graph format is restricted, both graphs must have CSR available.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graphs : list[DGLGraph]</span>
<span class="sd">        The list of graphs.  Must have at least one element.</span>
<span class="sd">    weight_name : str</span>
<span class="sd">        The feature name of edge weight of both graphs.</span>

<span class="sd">        The corresponding edge feature must be scalar.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The new graph.  The edge weight of the returned graph will have the</span>
<span class="sd">        same feature name as :attr:`weight_name`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    The following shows weighted adjacency matrix summation between two</span>
<span class="sd">    bipartite graphs.  You can also perform this between homogeneous graphs.</span>

<span class="sd">    &gt;&gt;&gt; A = dgl.heterograph(</span>
<span class="sd">    ...     {(&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([2, 2, 0, 2, 0, 1], [2, 1, 0, 0, 2, 2])},</span>
<span class="sd">    ...     num_nodes_dict={&#39;A&#39;: 3, &#39;B&#39;: 4})</span>
<span class="sd">    &gt;&gt;&gt; B = dgl.heterograph(</span>
<span class="sd">    ...     {(&#39;A&#39;, &#39;AB&#39;, &#39;B&#39;): ([1, 2, 0, 2, 1, 0], [0, 3, 2, 1, 3, 3])},</span>
<span class="sd">    ...     num_nodes_dict={&#39;A&#39;: 3, &#39;B&#39;: 4})</span>
<span class="sd">    &gt;&gt;&gt; A.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>
<span class="sd">    &gt;&gt;&gt; B.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>

<span class="sd">    If your graph is a multigraph, call :func:`dgl.to_simple`</span>
<span class="sd">    to convert it into a simple graph first.</span>

<span class="sd">    &gt;&gt;&gt; A = dgl.to_simple(A)</span>
<span class="sd">    &gt;&gt;&gt; B = dgl.to_simple(B)</span>

<span class="sd">    Initialize learnable edge weights.</span>

<span class="sd">    &gt;&gt;&gt; A.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>
<span class="sd">    &gt;&gt;&gt; B.edata[&#39;w&#39;] = torch.randn(6).requires_grad_()</span>

<span class="sd">    Take the sum.</span>

<span class="sd">    &gt;&gt;&gt; C = dgl.adj_sum_graph([A, B], &#39;w&#39;)</span>
<span class="sd">    &gt;&gt;&gt; C.edges()</span>
<span class="sd">    (tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 2]),</span>
<span class="sd">     tensor([0, 2, 3, 2, 0, 3, 0, 1, 2, 3]))</span>

<span class="sd">    Note that this function is differentiable:</span>

<span class="sd">    &gt;&gt;&gt; C.edata[&#39;w&#39;].sum().backward()</span>
<span class="sd">    &gt;&gt;&gt; A.edata[&#39;w&#39;].grad</span>
<span class="sd">    tensor([1., 1., 1., 1., 1., 1.])</span>

<span class="sd">    &gt;&gt;&gt; B.edata[&#39;w&#39;].grad</span>
<span class="sd">    tensor([1., 1., 1., 1., 1., 1.])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">graphs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The list of graphs must not be empty.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">():</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">_unitgraph_less_than_int32</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="k">for</span> <span class="n">A</span> <span class="ow">in</span> <span class="n">graphs</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;For GPU graphs the number of nodes and edges must be less than 2 ** 31 - 1.&quot;</span>
            <span class="p">)</span>
    <span class="n">metagraph</span> <span class="o">=</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span>
    <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_ntypes</span><span class="p">())</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">A</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">weight_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">A</span> <span class="ow">in</span> <span class="n">graphs</span><span class="p">]</span>
    <span class="n">gidxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">A</span><span class="o">.</span><span class="n">_graph</span> <span class="k">for</span> <span class="n">A</span> <span class="ow">in</span> <span class="n">graphs</span><span class="p">]</span>
    <span class="n">C_gidx</span><span class="p">,</span> <span class="n">C_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">csrsum</span><span class="p">(</span><span class="n">gidxs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">C_gidx</span> <span class="o">=</span> <span class="n">create_heterograph_from_relations</span><span class="p">(</span><span class="n">metagraph</span><span class="p">,</span> <span class="p">[</span><span class="n">C_gidx</span><span class="p">],</span> <span class="n">num_nodes</span><span class="p">)</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">C_gidx</span><span class="p">,</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">graphs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>
    <span class="n">C</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">weight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">C_weights</span>
    <span class="k">return</span> <span class="n">C</span></div>



<div class="viewcode-block" id="sort_csr_by_tag">
<a class="viewcode-back" href="../../../generated/dgl.sort_csr_by_tag.html#dgl.sort_csr_by_tag">[docs]</a>
<span class="k">def</span> <span class="nf">sort_csr_by_tag</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">tag_offset_name</span><span class="o">=</span><span class="s2">&quot;_TAG_OFFSET&quot;</span><span class="p">,</span> <span class="n">tag_type</span><span class="o">=</span><span class="s2">&quot;node&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a new graph whose CSR matrix is sorted by the given tag.</span>

<span class="sd">    Sort the internal CSR matrix of the graph so that the adjacency list of each node</span>
<span class="sd">    , which contains the out-edges, is sorted by the tag of the out-neighbors.</span>
<span class="sd">    After sorting, edges sharing the same tag will be arranged in a consecutive range in</span>
<span class="sd">    a node&#39;s adjacency list. Following is an example:</span>

<span class="sd">        Consider a graph as follows::</span>

<span class="sd">            0 -&gt; 0, 1, 2, 3, 4</span>
<span class="sd">            1 -&gt; 0, 1, 2</span>

<span class="sd">        Given node tags ``[1, 1, 0, 2, 0]``, each node&#39;s adjacency list</span>
<span class="sd">        will be sorted as follows::</span>

<span class="sd">            0 -&gt; 2, 4, 0, 1, 3</span>
<span class="sd">            1 -&gt; 2, 0, 1</span>

<span class="sd">        Given edge tags ``[1, 1, 0, 2, 0, 1, 1, 0]`` has the same effect</span>
<span class="sd">        as above node tags.</span>

<span class="sd">    The function will also returns the starting offsets of the tag</span>
<span class="sd">    segments in a tensor of shape :math:`(N, max\_tag+2)`. For node ``i``,</span>
<span class="sd">    its out-edges connecting to node tag ``j`` is stored between</span>
<span class="sd">    ``tag_offsets[i][j]`` ~ ``tag_offsets[i][j+1]``. Since the offsets</span>
<span class="sd">    can be viewed node data, we store it in the</span>
<span class="sd">    ``ndata`` of the returned graph. Users can specify the</span>
<span class="sd">    ndata name by the :attr:`tag_pos_name` argument.</span>

<span class="sd">    Note that the function will not change the edge ID neither</span>
<span class="sd">    how the edge features are stored. The input graph must</span>
<span class="sd">    allow CSR format. The graph must be on CPU.</span>

<span class="sd">    If the input graph is heterogenous, it must have only one edge</span>
<span class="sd">    type and two node types (i.e., source and destination node types).</span>
<span class="sd">    In this case, the provided node tags are for the destination nodes,</span>
<span class="sd">    and the tag offsets are stored in the source node data.</span>

<span class="sd">    The sorted graph and the calculated tag offsets are needed by</span>
<span class="sd">    certain operators that consider node tags. See</span>
<span class="sd">    :func:`~dgl.sampling.sample_neighbors_biased` for an example.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ------------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    tag : Tensor</span>
<span class="sd">        Integer tensor of shape :math:`(N,)`, :math:`N` being the number</span>
<span class="sd">        of (destination) nodes or edges.</span>
<span class="sd">    tag_offset_name : str</span>
<span class="sd">        The name of the node feature to store tag offsets.</span>
<span class="sd">    tag_type : str</span>
<span class="sd">        Tag type which could be ``node`` or ``edge``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    g_sorted : DGLGraph</span>
<span class="sd">        A new graph whose CSR is sorted. The node/edge features of the</span>
<span class="sd">        input graph is shallow-copied over.</span>

<span class="sd">        - ``g_sorted.ndata[tag_offset_name]`` : Tensor of shape :math:`(N, max\_tag + 2)`.</span>
<span class="sd">        - If ``g`` is heterogeneous, get from ``g_sorted.srcdata``.</span>

<span class="sd">    Examples</span>
<span class="sd">    -----------</span>

<span class="sd">    ``tag_type`` is ``node``.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,0,0,0,0,1,1,1],[0,1,2,3,4,0,1,2]))</span>
<span class="sd">    &gt;&gt;&gt; g.adj_external(scipy_fmt=&#39;csr&#39;).nonzero()</span>
<span class="sd">    (array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32),</span>
<span class="sd">     array([0, 1, 2, 3, 4, 0, 1, 2], dtype=int32))</span>
<span class="sd">    &gt;&gt;&gt; tag = torch.IntTensor([1,1,0,2,0])</span>
<span class="sd">    &gt;&gt;&gt; g_sorted = dgl.sort_csr_by_tag(g, tag)</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.adj_external(scipy_fmt=&#39;csr&#39;).nonzero()</span>
<span class="sd">    (array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32),</span>
<span class="sd">     array([2, 4, 0, 1, 3, 2, 0, 1], dtype=int32))</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.ndata[&#39;_TAG_OFFSET&#39;]</span>
<span class="sd">    tensor([[0, 2, 4, 5],</span>
<span class="sd">            [0, 1, 3, 3],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0]])</span>

<span class="sd">    ``tag_type`` is ``edge``.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,0,0,0,0,1,1,1],[0,1,2,3,4,0,1,2]))</span>
<span class="sd">    &gt;&gt;&gt; g.edges()</span>
<span class="sd">    (tensor([0, 0, 0, 0, 0, 1, 1, 1]), tensor([0, 1, 2, 3, 4, 0, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; tag = torch.tensor([1, 1, 0, 2, 0, 1, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; g_sorted = dgl.sort_csr_by_tag(g, tag, tag_type=&#39;edge&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.adj_external(scipy_fmt=&#39;csr&#39;).nonzero()</span>
<span class="sd">    (array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32), array([2, 4, 0, 1, 3, 2, 0, 1], dtype=int32))</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.srcdata[&#39;_TAG_OFFSET&#39;]</span>
<span class="sd">    tensor([[0, 2, 4, 5],</span>
<span class="sd">            [0, 1, 3, 3],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0]])</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dgl.sampling.sample_neighbors_biased</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Only support homograph and bipartite graph&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tag_type</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s2">&quot;node&quot;</span><span class="p">,</span>
        <span class="s2">&quot;edge&quot;</span><span class="p">,</span>
    <span class="p">],</span> <span class="s2">&quot;tag_type should be either &#39;node&#39; or &#39;edge&#39;.&quot;</span>
    <span class="k">if</span> <span class="n">tag_type</span> <span class="o">==</span> <span class="s2">&quot;node&quot;</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dst</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>
    <span class="n">num_tags</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">tag_arr</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dgl_ndarray</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">new_g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">new_g</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">tag_pos_arr</span> <span class="o">=</span> <span class="n">_CAPI_DGLHeteroSortOutEdges</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">tag_arr</span><span class="p">,</span> <span class="n">num_tags</span>
    <span class="p">)</span>
    <span class="n">new_g</span><span class="o">.</span><span class="n">srcdata</span><span class="p">[</span><span class="n">tag_offset_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">from_dgl_nd</span><span class="p">(</span><span class="n">tag_pos_arr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="sort_csc_by_tag">
<a class="viewcode-back" href="../../../generated/dgl.sort_csc_by_tag.html#dgl.sort_csc_by_tag">[docs]</a>
<span class="k">def</span> <span class="nf">sort_csc_by_tag</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">tag_offset_name</span><span class="o">=</span><span class="s2">&quot;_TAG_OFFSET&quot;</span><span class="p">,</span> <span class="n">tag_type</span><span class="o">=</span><span class="s2">&quot;node&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a new graph whose CSC matrix is sorted by the given tag.</span>

<span class="sd">    Sort the internal CSC matrix of the graph so that the adjacency list of each node</span>
<span class="sd">    , which contains the in-edges, is sorted by the tag of the in-neighbors.</span>
<span class="sd">    After sorting, edges sharing the same tag will be arranged in a consecutive range in</span>
<span class="sd">    a node&#39;s adjacency list. Following is an example:</span>


<span class="sd">        Consider a graph as follows::</span>

<span class="sd">            0 &lt;- 0, 1, 2, 3, 4</span>
<span class="sd">            1 &lt;- 0, 1, 2</span>

<span class="sd">        Given node tags ``[1, 1, 0, 2, 0]``, each node&#39;s adjacency list</span>
<span class="sd">        will be sorted as follows::</span>

<span class="sd">            0 &lt;- 2, 4, 0, 1, 3</span>
<span class="sd">            1 &lt;- 2, 0, 1</span>

<span class="sd">        Given edge tags ``[1, 1, 0, 2, 0, 1, 1, 0]`` has the same effect</span>
<span class="sd">        as above node tags.</span>

<span class="sd">    The function will also return the starting offsets of the tag</span>
<span class="sd">    segments in a tensor of shape :math:`(N, max\_tag+2)`. For a node ``i``,</span>
<span class="sd">    its in-edges connecting to node tag ``j`` is stored between</span>
<span class="sd">    ``tag_offsets[i][j]`` ~ ``tag_offsets[i][j+1]``. Since the offsets</span>
<span class="sd">    can be viewed node data, we store it in the</span>
<span class="sd">    ``ndata`` of the returned graph. Users can specify the</span>
<span class="sd">    ndata name by the ``tag_pos_name`` argument.</span>

<span class="sd">    Note that the function will not change the edge ID neither</span>
<span class="sd">    how the edge features are stored. The input graph must</span>
<span class="sd">    allow CSC format. The graph must be on CPU.</span>

<span class="sd">    If the input graph is heterogenous, it must have only one edge</span>
<span class="sd">    type and two node types (i.e., source and destination node types).</span>
<span class="sd">    In this case, the provided node tags are for the source nodes,</span>
<span class="sd">    and the tag offsets are stored in the destination node data.</span>

<span class="sd">    The sorted graph and the calculated tag offsets are needed by</span>
<span class="sd">    certain operators that consider node tags. See :func:`~dgl.sampling.sample_neighbors_biased`</span>
<span class="sd">    for an example.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ------------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    tag : Tensor</span>
<span class="sd">        Integer tensor of shape :math:`(N,)`, :math:`N` being the number</span>
<span class="sd">        of (source) nodes or edges.</span>
<span class="sd">    tag_offset_name : str</span>
<span class="sd">        The name of the node feature to store tag offsets.</span>
<span class="sd">    tag_type : str</span>
<span class="sd">        Tag type which could be ``node`` or ``edge``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    g_sorted : DGLGraph</span>
<span class="sd">        A new graph whose CSC matrix is sorted. The node/edge features of the</span>
<span class="sd">        input graph is shallow-copied over.</span>

<span class="sd">        - ``g_sorted.ndata[tag_offset_name]`` : Tensor of shape :math:`(N, max\_tag + 2)`.</span>
<span class="sd">        - If ``g`` is heterogeneous, get from ``g_sorted.dstdata``.</span>

<span class="sd">    Examples</span>
<span class="sd">    -----------</span>

<span class="sd">    ``tag_type`` is ``node``.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,0,1,2],[0,0,0,0,0,1,1,1]))</span>
<span class="sd">    &gt;&gt;&gt; g.adj_external(scipy_fmt=&#39;csr&#39;, transpose=True).nonzero()</span>
<span class="sd">    (array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32),</span>
<span class="sd">     array([0, 1, 2, 3, 4, 0, 1, 2], dtype=int32)))</span>
<span class="sd">    &gt;&gt;&gt; tag = torch.IntTensor([1,1,0,2,0])</span>
<span class="sd">    &gt;&gt;&gt; g_sorted = dgl.sort_csc_by_tag(g, tag)</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.adj_external(scipy_fmt=&#39;csr&#39;, transpose=True).nonzero()</span>
<span class="sd">    (array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32),</span>
<span class="sd">     array([2, 4, 0, 1, 3, 2, 0, 1], dtype=int32))</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.ndata[&#39;_TAG_OFFSET&#39;]</span>
<span class="sd">    tensor([[0, 2, 4, 5],</span>
<span class="sd">            [0, 1, 3, 3],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0]])</span>

<span class="sd">    ``tag_type`` is ``edge``.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,0,1,2],[0,0,0,0,0,1,1,1]))</span>
<span class="sd">    &gt;&gt;&gt; tag = torch.tensor([1, 1, 0, 2, 0, 1, 1, 0])</span>
<span class="sd">    &gt;&gt;&gt; g_sorted = dgl.sort_csc_by_tag(g, tag, tag_type=&#39;edge&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.adj_external(scipy_fmt=&#39;csr&#39;, transpose=True).nonzero()</span>
<span class="sd">    (array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32), array([2, 4, 0, 1, 3, 2, 0, 1], dtype=int32))</span>
<span class="sd">    &gt;&gt;&gt; g_sorted.dstdata[&#39;_TAG_OFFSET&#39;]</span>
<span class="sd">    tensor([[0, 2, 4, 5],</span>
<span class="sd">            [0, 1, 3, 3],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0],</span>
<span class="sd">            [0, 0, 0, 0]])</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dgl.sampling.sample_neighbors_biased</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Only support homograph and bipartite graph&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tag_type</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s2">&quot;node&quot;</span><span class="p">,</span>
        <span class="s2">&quot;edge&quot;</span><span class="p">,</span>
    <span class="p">],</span> <span class="s2">&quot;tag_type should be either &#39;node&#39; or &#39;edge&#39;.&quot;</span>
    <span class="k">if</span> <span class="n">tag_type</span> <span class="o">==</span> <span class="s2">&quot;node&quot;</span><span class="p">:</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">src</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span> <span class="o">==</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>
    <span class="n">num_tags</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">tag_arr</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_to_dgl_ndarray</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">new_g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">new_g</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">tag_pos_arr</span> <span class="o">=</span> <span class="n">_CAPI_DGLHeteroSortInEdges</span><span class="p">(</span>
        <span class="n">g</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">tag_arr</span><span class="p">,</span> <span class="n">num_tags</span>
    <span class="p">)</span>
    <span class="n">new_g</span><span class="o">.</span><span class="n">dstdata</span><span class="p">[</span><span class="n">tag_offset_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">from_dgl_nd</span><span class="p">(</span><span class="n">tag_pos_arr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="reorder_graph">
<a class="viewcode-back" href="../../../generated/dgl.reorder_graph.html#dgl.reorder_graph">[docs]</a>
<span class="k">def</span> <span class="nf">reorder_graph</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">node_permute_algo</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_permute_algo</span><span class="o">=</span><span class="s2">&quot;src&quot;</span><span class="p">,</span>
    <span class="n">store_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">permute_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a new graph with nodes and edges re-ordered/re-labeled</span>
<span class="sd">    according to the specified permute algorithm.</span>

<span class="sd">    Support homogeneous graph only for the moment.</span>

<span class="sd">    The re-ordering has two 2 steps: first re-order nodes and then re-order edges.</span>

<span class="sd">    For node permutation, users can re-order by the :attr:`node_permute_algo`</span>
<span class="sd">    argument. For edge permutation, user can re-arrange edges according to their</span>
<span class="sd">    source nodes or destination nodes by the :attr:`edge_permute_algo` argument.</span>
<span class="sd">    Some of the permutation algorithms are only implemented in CPU, so if the</span>
<span class="sd">    input graph is on GPU, it will be copied to CPU first. The storage order of</span>
<span class="sd">    the node and edge features in the graph are permuted accordingly.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The homogeneous graph.</span>
<span class="sd">    node_permute_algo: str, optional</span>
<span class="sd">        The permutation algorithm to re-order nodes. If given, the options are ``rcmk`` or</span>
<span class="sd">        ``metis`` or ``custom``.</span>

<span class="sd">        * ``None``: Keep the current node order.</span>
<span class="sd">        * ``rcmk``: Use the `Reverse Cuthill–McKee &lt;https://docs.scipy.org/doc/scipy/reference/</span>
<span class="sd">          generated/scipy.sparse.csgraph.reverse_cuthill_mckee.html#</span>
<span class="sd">          scipy-sparse-csgraph-reverse-cuthill-mckee&gt;`__ from ``scipy`` to generate nodes</span>
<span class="sd">          permutation.</span>
<span class="sd">        * ``metis``: Use the :func:`~dgl.metis_partition_assignment` function</span>
<span class="sd">          to partition the input graph, which gives a cluster assignment of each node.</span>
<span class="sd">          DGL then sorts the assignment array so the new node order will put nodes of</span>
<span class="sd">          the same cluster together. Please note that the generated nodes permutation</span>
<span class="sd">          of ``metis`` is non-deterministic due to algorithm&#39;s nature.</span>
<span class="sd">        * ``custom``: Reorder the graph according to the user-provided node permutation</span>
<span class="sd">          array (provided in :attr:`permute_config`).</span>
<span class="sd">    edge_permute_algo: str, optional</span>
<span class="sd">        The permutation algorithm to reorder edges. Options are ``src`` or ``dst`` or</span>
<span class="sd">        ``custom``. ``src`` is the default value.</span>

<span class="sd">        * ``src``: Edges are arranged according to their source nodes.</span>
<span class="sd">        * ``dst``: Edges are arranged according to their destination nodes.</span>
<span class="sd">        * ``custom``: Edges are arranged according to the user-provided edge permutation</span>
<span class="sd">          array (provided in :attr:`permute_config`).</span>
<span class="sd">    store_ids: bool, optional</span>
<span class="sd">        If True, DGL will store the original node and edge IDs in the ndata and edata</span>
<span class="sd">        of the resulting graph under name ``dgl.NID`` and ``dgl.EID``, respectively.</span>
<span class="sd">    permute_config: dict, optional</span>
<span class="sd">        Additional key-value config data for the specified permutation algorithm.</span>

<span class="sd">        * For ``rcmk``, this argument is not required.</span>
<span class="sd">        * For ``metis``, users should specify the number of partitions ``k`` (e.g.,</span>
<span class="sd">          ``permute_config={&#39;k&#39;:10}`` to partition the graph to 10 clusters).</span>
<span class="sd">        * For ``custom`` node reordering, users should provide a node permutation</span>
<span class="sd">          array ``nodes_perm``. The array must be an integer list or a tensor with</span>
<span class="sd">          the same device of the input graph.</span>
<span class="sd">        * For ``custom`` edge reordering, users should provide an edge permutation</span>
<span class="sd">          array ``edges_perm``. The array must be an integer list or a tensor with</span>
<span class="sd">          the same device of the input graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The re-ordered graph.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 2, 3, 4]), torch.tensor([2, 2, 3, 2, 3])))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.arange(g.num_nodes() * 2).view(g.num_nodes(), 2)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.arange(g.num_edges() * 1).view(g.num_edges(), 1)</span>
<span class="sd">    &gt;&gt;&gt; g.ndata</span>
<span class="sd">    {&#39;h&#39;: tensor([[0, 1],</span>
<span class="sd">            [2, 3],</span>
<span class="sd">            [4, 5],</span>
<span class="sd">            [6, 7],</span>
<span class="sd">            [8, 9]])}</span>
<span class="sd">    &gt;&gt;&gt; g.edata</span>
<span class="sd">    {&#39;w&#39;: tensor([[0],</span>
<span class="sd">            [1],</span>
<span class="sd">            [2],</span>
<span class="sd">            [3],</span>
<span class="sd">            [4]])}</span>

<span class="sd">    Reorder according to ``&#39;rcmk&#39;`` permute algorithm.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reorder_graph(g, node_permute_algo=&#39;rcmk&#39;)</span>
<span class="sd">    &gt;&gt;&gt; rg.ndata</span>
<span class="sd">    {&#39;h&#39;: tensor([[8, 9],</span>
<span class="sd">            [6, 7],</span>
<span class="sd">            [2, 3],</span>
<span class="sd">            [4, 5],</span>
<span class="sd">            [0, 1]]), &#39;_ID&#39;: tensor([4, 3, 1, 2, 0])}</span>
<span class="sd">    &gt;&gt;&gt; rg.edata</span>
<span class="sd">    {&#39;w&#39;: tensor([[4],</span>
<span class="sd">            [3],</span>
<span class="sd">            [1],</span>
<span class="sd">            [2],</span>
<span class="sd">            [0]]), &#39;_ID&#39;: tensor([4, 3, 1, 2, 0])}</span>

<span class="sd">    Reorder according to ``&#39;metis&#39;`` permute algorithm.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reorder_graph(g, node_permute_algo=&#39;metis&#39;, permute_config={&#39;k&#39;:2})</span>
<span class="sd">    &gt;&gt;&gt; rg.ndata</span>
<span class="sd">    {&#39;h&#39;: tensor([[4, 5],</span>
<span class="sd">            [2, 3],</span>
<span class="sd">            [0, 1],</span>
<span class="sd">            [8, 9],</span>
<span class="sd">            [6, 7]]), &#39;_ID&#39;: tensor([2, 1, 0, 4, 3])}</span>
<span class="sd">    &gt;&gt;&gt; rg.edata</span>
<span class="sd">    {&#39;w&#39;: tensor([[2],</span>
<span class="sd">            [1],</span>
<span class="sd">            [0],</span>
<span class="sd">            [4],</span>
<span class="sd">            [3]]), &#39;_ID&#39;: tensor([2, 1, 0, 4, 3])}</span>

<span class="sd">    Reorder according to ``&#39;custom&#39;`` permute algorithm with user-provided nodes_perm.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reorder_graph(g, node_permute_algo=&#39;custom&#39;,</span>
<span class="sd">    ...                        permute_config={&#39;nodes_perm&#39;: [3, 2, 0, 4, 1]})</span>
<span class="sd">    &gt;&gt;&gt; rg.ndata</span>
<span class="sd">    {&#39;h&#39;: tensor([[6, 7],</span>
<span class="sd">            [4, 5],</span>
<span class="sd">            [0, 1],</span>
<span class="sd">            [8, 9],</span>
<span class="sd">            [2, 3]]), &#39;_ID&#39;: tensor([3, 2, 0, 4, 1])}</span>
<span class="sd">    &gt;&gt;&gt; rg.edata</span>
<span class="sd">    {&#39;w&#39;: tensor([[3],</span>
<span class="sd">            [2],</span>
<span class="sd">            [0],</span>
<span class="sd">            [4],</span>
<span class="sd">            [1]]), &#39;_ID&#39;: tensor([3, 2, 0, 4, 1])}</span>

<span class="sd">    Reorder nodes according to ``&#39;rcmk&#39;`` and reorder edges according to ``dst``</span>
<span class="sd">    edge permute algorithm.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reorder_graph(g, node_permute_algo=&#39;rcmk&#39;, edge_permute_algo=&#39;dst&#39;)</span>
<span class="sd">    &gt;&gt;&gt; print(rg.ndata)</span>
<span class="sd">    {&#39;h&#39;: tensor([[8, 9],</span>
<span class="sd">            [6, 7],</span>
<span class="sd">            [2, 3],</span>
<span class="sd">            [4, 5],</span>
<span class="sd">            [0, 1]]), &#39;_ID&#39;: tensor([4, 3, 1, 2, 0])}</span>
<span class="sd">    &gt;&gt;&gt; print(rg.edata)</span>
<span class="sd">    {&#39;w&#39;: tensor([[4],</span>
<span class="sd">            [2],</span>
<span class="sd">            [3],</span>
<span class="sd">            [1],</span>
<span class="sd">            [0]]), &#39;_ID&#39;: tensor([4, 2, 3, 1, 0])}</span>

<span class="sd">    Nodes are not reordered but edges are reordered according to ``&#39;custom&#39;`` permute</span>
<span class="sd">    algorithm with user-provided edges_perm.</span>

<span class="sd">    &gt;&gt;&gt; rg = dgl.reorder_graph(g, edge_permute_algo=&#39;custom&#39;,</span>
<span class="sd">    ...                        permute_config={&#39;edges_perm&#39;: [1, 2, 3, 4, 0]})</span>
<span class="sd">    &gt;&gt;&gt; print(rg.ndata)</span>
<span class="sd">    {&#39;h&#39;: tensor([[0, 1],</span>
<span class="sd">            [2, 3],</span>
<span class="sd">            [4, 5],</span>
<span class="sd">            [6, 7],</span>
<span class="sd">            [8, 9]]), &#39;_ID&#39;: tensor([0, 1, 2, 3, 4])}</span>
<span class="sd">    &gt;&gt;&gt; print(rg.edata)</span>
<span class="sd">    {&#39;w&#39;: tensor([[1],</span>
<span class="sd">            [2],</span>
<span class="sd">            [3],</span>
<span class="sd">            [4],</span>
<span class="sd">            [0]]), &#39;_ID&#39;: tensor([1, 2, 3, 4, 0])}</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># sanity checks</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">g</span><span class="o">.</span><span class="n">is_homogeneous</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Only homogeneous graphs are supported.&quot;</span><span class="p">)</span>
    <span class="n">expected_node_algo</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rcmk&quot;</span><span class="p">,</span> <span class="s2">&quot;metis&quot;</span><span class="p">,</span> <span class="s2">&quot;custom&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">node_permute_algo</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="ow">and</span> <span class="n">node_permute_algo</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">expected_node_algo</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Unexpected node_permute_algo is specified: </span><span class="si">{}</span><span class="s2">. Expected algos: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">node_permute_algo</span><span class="p">,</span> <span class="n">expected_node_algo</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="n">expected_edge_algo</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">,</span> <span class="s2">&quot;dst&quot;</span><span class="p">,</span> <span class="s2">&quot;custom&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">edge_permute_algo</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">expected_edge_algo</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Unexpected edge_permute_algo is specified: </span><span class="si">{}</span><span class="s2">. Expected algos: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">edge_permute_algo</span><span class="p">,</span> <span class="n">expected_edge_algo</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="s2">&quot;__orig__&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># reorder nodes</span>
    <span class="k">if</span> <span class="n">node_permute_algo</span> <span class="o">==</span> <span class="s2">&quot;rcmk&quot;</span><span class="p">:</span>
        <span class="n">nodes_perm</span> <span class="o">=</span> <span class="n">rcmk_perm</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">node_subgraph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodes_perm</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">node_permute_algo</span> <span class="o">==</span> <span class="s2">&quot;metis&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">permute_config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s2">&quot;k&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">permute_config</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Partition parts &#39;k&#39; is required for metis. Please specify in permute_config.&quot;</span>
            <span class="p">)</span>
        <span class="n">nodes_perm</span> <span class="o">=</span> <span class="n">metis_perm</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">permute_config</span><span class="p">[</span><span class="s2">&quot;k&quot;</span><span class="p">])</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">node_subgraph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodes_perm</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">node_permute_algo</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">permute_config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s2">&quot;nodes_perm&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">permute_config</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;node_permute_algo is specified as custom, but no &#39;nodes_perm&#39; is specified in </span><span class="se">\</span>
<span class="s2">                    permute_config.&quot;</span>
            <span class="p">)</span>
        <span class="n">nodes_perm</span> <span class="o">=</span> <span class="n">permute_config</span><span class="p">[</span><span class="s2">&quot;nodes_perm&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes_perm</span><span class="p">)</span> <span class="o">!=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Length of &#39;nodes_perm&#39; (</span><span class="si">{}</span><span class="s2">) does not </span><span class="se">\</span>
<span class="s2">                    match graph num_nodes (</span><span class="si">{}</span><span class="s2">).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">nodes_perm</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">node_subgraph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodes_perm</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nodes_perm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(),</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">store_ids</span><span class="p">:</span>
        <span class="n">rg</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">nodes_perm</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;__orig__&quot;</span><span class="p">)</span>

    <span class="c1"># reorder edges</span>
    <span class="k">if</span> <span class="n">edge_permute_algo</span> <span class="o">==</span> <span class="s2">&quot;src&quot;</span><span class="p">:</span>
        <span class="n">edges_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">rg</span><span class="o">.</span><span class="n">edges</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">edge_subgraph</span><span class="p">(</span>
            <span class="n">rg</span><span class="p">,</span> <span class="n">edges_perm</span><span class="p">,</span> <span class="n">relabel_nodes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">edge_permute_algo</span> <span class="o">==</span> <span class="s2">&quot;dst&quot;</span><span class="p">:</span>
        <span class="n">edges_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">rg</span><span class="o">.</span><span class="n">edges</span><span class="p">()[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">edge_subgraph</span><span class="p">(</span>
            <span class="n">rg</span><span class="p">,</span> <span class="n">edges_perm</span><span class="p">,</span> <span class="n">relabel_nodes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">edge_permute_algo</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">permute_config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s2">&quot;edges_perm&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">permute_config</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;edge_permute_algo is specified as custom, but no &#39;edges_perm&#39; is specified in </span><span class="se">\</span>
<span class="s2">                    permute_config.&quot;</span>
            <span class="p">)</span>
        <span class="n">edges_perm</span> <span class="o">=</span> <span class="n">permute_config</span><span class="p">[</span><span class="s2">&quot;edges_perm&quot;</span><span class="p">]</span>
        <span class="c1"># First revert the edge reorder caused by node reorder and then</span>
        <span class="c1"># apply user-provided edge permutation</span>
        <span class="n">rev_id</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">rg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="s2">&quot;__orig__&quot;</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">edges_perm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">rev_id</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edges_perm</span><span class="p">)),</span> <span class="n">rg</span><span class="o">.</span><span class="n">idtype</span>
        <span class="p">)</span>
        <span class="n">rg</span> <span class="o">=</span> <span class="n">subgraph</span><span class="o">.</span><span class="n">edge_subgraph</span><span class="p">(</span>
            <span class="n">rg</span><span class="p">,</span> <span class="n">edges_perm</span><span class="p">,</span> <span class="n">relabel_nodes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">store_ids</span><span class="p">:</span>
        <span class="n">rg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span> <span class="o">=</span> <span class="n">rg</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;__orig__&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">rg</span></div>



<span class="n">DGLGraph</span><span class="o">.</span><span class="n">reorder_graph</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">alias_func</span><span class="p">(</span><span class="n">reorder_graph</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">metis_perm</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return nodes permutation according to ``&#39;metis&#39;`` algorithm.</span>

<span class="sd">    For internal use.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The homogeneous graph.</span>
<span class="sd">    k: int</span>
<span class="sd">        The partition parts number.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    iterable[int]</span>
<span class="sd">        The nodes permutation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pids</span> <span class="o">=</span> <span class="n">metis_partition_assignment</span><span class="p">(</span>
        <span class="n">g</span> <span class="k">if</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">else</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">()),</span> <span class="n">k</span>
    <span class="p">)</span>
    <span class="n">pids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">pids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">pids</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">rcmk_perm</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return nodes permutation according to ``&#39;rcmk&#39;`` algorithm.</span>

<span class="sd">    For internal use.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The homogeneous graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    iterable[int]</span>
<span class="sd">        The nodes permutation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fmat</span> <span class="o">=</span> <span class="s2">&quot;csr&quot;</span>
    <span class="n">allowed_fmats</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">formats</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="p">[])</span>
    <span class="k">if</span> <span class="n">fmat</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_fmats</span><span class="p">:</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">formats</span><span class="p">(</span><span class="n">allowed_fmats</span> <span class="o">+</span> <span class="p">[</span><span class="n">fmat</span><span class="p">])</span>
    <span class="n">csr_adj</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">scipy_fmt</span><span class="o">=</span><span class="n">fmat</span><span class="p">)</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csgraph</span><span class="o">.</span><span class="n">reverse_cuthill_mckee</span><span class="p">(</span><span class="n">csr_adj</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">perm</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


<div class="viewcode-block" id="norm_by_dst">
<a class="viewcode-back" href="../../../generated/dgl.norm_by_dst.html#dgl.norm_by_dst">[docs]</a>
<span class="k">def</span> <span class="nf">norm_by_dst</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculate normalization coefficient per edge based on destination node degree.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    etype : str or (str, str, str), optional</span>
<span class="sd">        The type of the edges to calculate. The allowed edge type formats are:</span>

<span class="sd">        * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">        * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">          triplet format in the graph.</span>

<span class="sd">        It can be omitted if the graph has a single edge type.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    1D Tensor</span>
<span class="sd">        The normalization coefficient of the edges.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 1], [1, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; print(dgl.norm_by_dst(g))</span>
<span class="sd">    tensor([0.5000, 0.5000, 1.0000])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">inv_index</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">deg</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">count</span><span class="p">[</span><span class="n">inv_index</span><span class="p">],</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">deg</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">replace_inf_with_zero</span><span class="p">(</span><span class="n">norm</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">norm</span></div>



<div class="viewcode-block" id="radius_graph">
<a class="viewcode-back" href="../../../generated/dgl.radius_graph.html#dgl.radius_graph">[docs]</a>
<span class="k">def</span> <span class="nf">radius_graph</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">r</span><span class="p">,</span>
    <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">self_loop</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;donot_use_mm_for_euclid_dist&quot;</span><span class="p">,</span>
    <span class="n">get_distances</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Construct a graph from a set of points with neighbors within given distance.</span>

<span class="sd">    The function transforms the coordinates/features of a point set</span>
<span class="sd">    into a bidirected homogeneous graph. The coordinates of the point</span>
<span class="sd">    set is specified as a matrix whose rows correspond to points and</span>
<span class="sd">    columns correspond to coordinate/feature dimensions.</span>

<span class="sd">    The nodes of the returned graph correspond to the points, where the neighbors</span>
<span class="sd">    of each point are within given distance.</span>

<span class="sd">    The function requires the PyTorch backend.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : Tensor</span>
<span class="sd">        The point coordinates. It can be either on CPU or GPU.</span>
<span class="sd">        Device of the point coordinates specifies device of the radius graph and</span>
<span class="sd">        ``x[i]`` corresponds to the i-th node in the radius graph.</span>
<span class="sd">    r : float</span>
<span class="sd">        Radius of the neighbors.</span>
<span class="sd">    p : float, optional</span>
<span class="sd">        Power parameter for the Minkowski metric. When :attr:`p = 1` it is the</span>
<span class="sd">        equivalent of Manhattan distance (L1 norm) and Euclidean distance</span>
<span class="sd">        (L2 norm) for :attr:`p = 2`.</span>

<span class="sd">        (default: 2)</span>
<span class="sd">    self_loop : bool, optional</span>
<span class="sd">        Whether the radius graph will contain self-loops.</span>

<span class="sd">        (default: False)</span>
<span class="sd">    compute_mode : str, optional</span>
<span class="sd">        ``use_mm_for_euclid_dist_if_necessary`` - will use matrix multiplication</span>
<span class="sd">        approach to calculate euclidean distance (p = 2) if P &gt; 25 or R &gt; 25</span>
<span class="sd">        ``use_mm_for_euclid_dist`` - will always use matrix multiplication</span>
<span class="sd">        approach to calculate euclidean distance (p = 2)</span>
<span class="sd">        ``donot_use_mm_for_euclid_dist`` - will never use matrix multiplication</span>
<span class="sd">        approach to calculate euclidean distance (p = 2).</span>

<span class="sd">        (default: donot_use_mm_for_euclid_dist)</span>
<span class="sd">    get_distances : bool, optional</span>
<span class="sd">        Whether to return the distances for the corresponding edges in the</span>
<span class="sd">        radius graph.</span>

<span class="sd">        (default: False)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The constructed graph. The node IDs are in the same order as :attr:`x`.</span>
<span class="sd">    torch.Tensor, optional</span>
<span class="sd">        The distances for the edges in the constructed graph. The distances are</span>
<span class="sd">        in the same order as edge IDs.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    The following examples use PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>

<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[0.0, 0.0, 1.0],</span>
<span class="sd">    ...                   [1.0, 0.5, 0.5],</span>
<span class="sd">    ...                   [0.5, 0.2, 0.2],</span>
<span class="sd">    ...                   [0.3, 0.2, 0.4]])</span>
<span class="sd">    &gt;&gt;&gt; r_g = dgl.radius_graph(x, 0.75)  # Each node has neighbors within 0.75 distance</span>
<span class="sd">    &gt;&gt;&gt; r_g.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 2, 3, 3]), tensor([3, 2, 1, 3, 0, 2]))</span>

<span class="sd">    When :attr:`get_distances` is True, function returns the radius graph and</span>
<span class="sd">    distances for the corresponding edges.</span>

<span class="sd">    &gt;&gt;&gt; x = torch.tensor([[0.0, 0.0, 1.0],</span>
<span class="sd">    ...                   [1.0, 0.5, 0.5],</span>
<span class="sd">    ...                   [0.5, 0.2, 0.2],</span>
<span class="sd">    ...                   [0.3, 0.2, 0.4]])</span>
<span class="sd">    &gt;&gt;&gt; r_g, dist = dgl.radius_graph(x, 0.75, get_distances=True)</span>
<span class="sd">    &gt;&gt;&gt; r_g.edges()</span>
<span class="sd">    (tensor([0, 1, 2, 2, 3, 3]), tensor([3, 2, 1, 3, 0, 2]))</span>
<span class="sd">    &gt;&gt;&gt; dist</span>
<span class="sd">    tensor([[0.7000],</span>
<span class="sd">            [0.6557],</span>
<span class="sd">            [0.6557],</span>
<span class="sd">            [0.2828],</span>
<span class="sd">            [0.7000],</span>
<span class="sd">            [0.2828]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># check invalid r</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid r value. expect r &gt; 0, got r = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>

    <span class="c1"># check empty point set</span>
    <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Find empty point set&quot;</span><span class="p">)</span>

    <span class="n">distances</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">self_loop</span><span class="p">:</span>
        <span class="n">distances</span><span class="o">.</span><span class="n">fill_diagonal_</span><span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">edges</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">distances</span> <span class="o">&lt;=</span> <span class="n">r</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">graph</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">get_distances</span><span class="p">:</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[</span><span class="n">edges</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span><span class="p">,</span> <span class="n">distances</span>

    <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="random_walk_pe">
<a class="viewcode-back" href="../../../generated/dgl.random_walk_pe.html#dgl.random_walk_pe">[docs]</a>
<span class="k">def</span> <span class="nf">random_walk_pe</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Random Walk Positional Encoding, as introduced in</span>
<span class="sd">    `Graph Neural Networks with Learnable Structural and Positional Representations</span>
<span class="sd">    &lt;https://arxiv.org/abs/2110.07875&gt;`__</span>

<span class="sd">    This function computes the random walk positional encodings as landing probabilities</span>
<span class="sd">    from 1-step to k-step, starting from each node to itself.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph. Must be homogeneous.</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of random walk steps. The paper found the best value to be 16 and 20</span>
<span class="sd">        for two experiments.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        The name to retrieve the edge weights. Default: None, not using the edge weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        The random walk positional encodings of shape :math:`(N, k)`, where :math:`N` is the</span>
<span class="sd">        number of nodes in the input graph.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,1], [1,1,0]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.random_walk_pe(g, 2)</span>
<span class="sd">    tensor([[0.0000, 0.5000],</span>
<span class="sd">            [0.5000, 0.7500]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>  <span class="c1"># number of nodes</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>  <span class="c1"># number of edges</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>  <span class="c1"># adjacency matrix</span>
    <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># add edge weights if required</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">(</span>
            <span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">eweight_name</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">g</span><span class="o">.</span><span class="n">find_edges</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)))),</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="c1"># 1-step transition probability</span>
    <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;1.11.0&quot;</span><span class="p">):</span>
        <span class="n">RW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A</span> <span class="o">/</span> <span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-30</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Sparse matrix divided by a dense array returns a sparse matrix in</span>
        <span class="c1"># scipy since 1.11.0.</span>
        <span class="n">RW</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span> <span class="o">/</span> <span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-30</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

    <span class="c1"># Iterate for k steps</span>
    <span class="n">PE</span> <span class="o">=</span> <span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">RW</span><span class="o">.</span><span class="n">diagonal</span><span class="p">())),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span>
    <span class="n">RW_power</span> <span class="o">=</span> <span class="n">RW</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">RW_power</span> <span class="o">=</span> <span class="n">RW_power</span> <span class="o">@</span> <span class="n">RW</span>
        <span class="n">PE</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">RW_power</span><span class="o">.</span><span class="n">diagonal</span><span class="p">())),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">PE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">PE</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">PE</span></div>



<div class="viewcode-block" id="lap_pe">
<a class="viewcode-back" href="../../../generated/dgl.lap_pe.html#dgl.lap_pe">[docs]</a>
<span class="k">def</span> <span class="nf">lap_pe</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_eigval</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Laplacian Positional Encoding, as introduced in</span>
<span class="sd">    `Benchmarking Graph Neural Networks</span>
<span class="sd">    &lt;https://arxiv.org/abs/2003.00982&gt;`__</span>

<span class="sd">    This function computes the laplacian positional encodings as the</span>
<span class="sd">    k smallest non-trivial eigenvectors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph. Must be homogeneous and bidirected.</span>
<span class="sd">    k : int</span>
<span class="sd">        Number of smallest non-trivial eigenvectors to use for positional</span>
<span class="sd">        encoding.</span>
<span class="sd">    padding : bool, optional</span>
<span class="sd">        If False, raise an exception when k&gt;=n. Otherwise, add zero paddings</span>
<span class="sd">        in the end of eigenvectors and &#39;nan&#39; paddings in the end of eigenvalues</span>
<span class="sd">        when k&gt;=n. Default: False. n is the number of nodes in the given graph.</span>
<span class="sd">    return_eigval : bool, optional</span>
<span class="sd">        If True, return laplacian eigenvalues together with eigenvectors.</span>
<span class="sd">        Otherwise, return laplacian eigenvectors only.</span>
<span class="sd">        Default: False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor or (Tensor, Tensor)</span>
<span class="sd">        Return the laplacian positional encodings of shape :math:`(N, k)`,</span>
<span class="sd">        where :math:`N` is the number of nodes in the input graph, when</span>
<span class="sd">        :attr:`return_eigval` is False. The eigenvalues of shape :math:`N` is</span>
<span class="sd">        additionally returned as the second element when :attr:`return_eigval`</span>
<span class="sd">        is True.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,1,2,3,0], [1,2,3,0,0,1,2,3]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.lap_pe(g, 2)</span>
<span class="sd">    tensor([[ 7.0711e-01, -6.4921e-17],</span>
<span class="sd">            [ 3.0483e-16, -7.0711e-01],</span>
<span class="sd">            [-7.0711e-01, -2.4910e-16],</span>
<span class="sd">            [ 9.9288e-17,  7.0711e-01]])</span>
<span class="sd">    &gt;&gt;&gt; dgl.lap_pe(g, 5, padding=True)</span>
<span class="sd">    tensor([[ 7.0711e-01, -6.4921e-17,  5.0000e-01,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">            [ 3.0483e-16, -7.0711e-01, -5.0000e-01,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">            [-7.0711e-01, -2.4910e-16,  5.0000e-01,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">            [ 9.9288e-17,  7.0711e-01, -5.0000e-01,  0.0000e+00,  0.0000e+00]])</span>
<span class="sd">    &gt;&gt;&gt; dgl.lap_pe(g, 5, padding=True, return_eigval=True)</span>
<span class="sd">    (tensor([[-7.0711e-01,  6.4921e-17, -5.0000e-01,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">             [-3.0483e-16,  7.0711e-01,  5.0000e-01,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">             [ 7.0711e-01,  2.4910e-16, -5.0000e-01,  0.0000e+00,  0.0000e+00],</span>
<span class="sd">             [-9.9288e-17, -7.0711e-01,  5.0000e-01,  0.0000e+00,  0.0000e+00]]),</span>
<span class="sd">     tensor([1., 1., 2., nan, nan]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># check for the &quot;k &lt; n&quot; constraint</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">padding</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">k</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="s2">&quot;the number of eigenvectors k must be smaller than the number of &quot;</span>
            <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;nodes n, </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> detected.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># get laplacian matrix as I - D^-0.5 * A * D^-0.5</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>  <span class="c1"># adjacency matrix</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">())</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span>
    <span class="p">)</span>  <span class="c1"># D^-1/2</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">())</span> <span class="o">-</span> <span class="n">N</span> <span class="o">*</span> <span class="n">A</span> <span class="o">*</span> <span class="n">N</span>

    <span class="c1"># select eigenvectors with smaller eigenvalues O(n + klogk)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Use scipy if k + 1 &lt; n - 1 for memory efficiency.</span>
        <span class="n">EigVal</span><span class="p">,</span> <span class="n">EigVec</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigs</span><span class="p">(</span>
            <span class="n">L</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;SR&quot;</span><span class="p">,</span> <span class="n">ncv</span><span class="o">=</span><span class="mi">4</span> <span class="o">*</span> <span class="n">k</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-2</span>
        <span class="p">)</span>
        <span class="n">max_freqs</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">topk_indices</span> <span class="o">=</span> <span class="n">EigVal</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Fallback to numpy since scipy.sparse do not support this case.</span>
        <span class="n">EigVal</span><span class="p">,</span> <span class="n">EigVec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
        <span class="n">max_freqs</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">kpartition_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">EigVal</span><span class="p">,</span> <span class="n">max_freqs</span><span class="p">)[:</span> <span class="n">max_freqs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">topk_eigvals</span> <span class="o">=</span> <span class="n">EigVal</span><span class="p">[</span><span class="n">kpartition_indices</span><span class="p">]</span>
        <span class="n">topk_indices</span> <span class="o">=</span> <span class="n">kpartition_indices</span><span class="p">[</span><span class="n">topk_eigvals</span><span class="o">.</span><span class="n">argsort</span><span class="p">()][</span><span class="mi">1</span><span class="p">:]</span>

    <span class="c1"># Since scipy may return complex value, to avoid crashing in NN code,</span>
    <span class="c1"># convert them to real number.</span>
    <span class="n">topk_EigVal</span> <span class="o">=</span> <span class="n">EigVal</span><span class="p">[</span><span class="n">topk_indices</span><span class="p">]</span><span class="o">.</span><span class="n">real</span>
    <span class="n">topk_EigVec</span> <span class="o">=</span> <span class="n">EigVec</span><span class="p">[:,</span> <span class="n">topk_indices</span><span class="p">]</span><span class="o">.</span><span class="n">real</span>
    <span class="n">eigvals</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">topk_EigVal</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># get random flip signs</span>
    <span class="n">rand_sign</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">max_freqs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span>
    <span class="n">PE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">rand_sign</span> <span class="o">*</span> <span class="n">topk_EigVec</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># add paddings</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">k</span><span class="p">:</span>
        <span class="n">temp_EigVec</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">PE</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">PE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">PE</span><span class="p">,</span> <span class="n">temp_EigVec</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">temp_EigVal</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">eigvals</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">eigvals</span><span class="p">,</span> <span class="n">temp_EigVal</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_eigval</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">PE</span><span class="p">,</span> <span class="n">eigvals</span>
    <span class="k">return</span> <span class="n">PE</span></div>



<span class="k">def</span> <span class="nf">laplacian_pe</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_eigval</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Alias of `dgl.lap_pe`.&quot;&quot;&quot;</span>
    <span class="n">dgl_warning</span><span class="p">(</span><span class="s2">&quot;dgl.laplacian_pe will be deprecated. Use dgl.lap_pe please.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lap_pe</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">return_eigval</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">to_bfloat16</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cast this graph to use bfloat16 for any</span>
<span class="sd">    floating-point edge and node feature data.</span>

<span class="sd">    A shallow copy is returned so that the original graph is not modified.</span>
<span class="sd">    Feature tensors that are not floating-point will not be modified.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        Clone of graph with the feature data converted to float16.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ret</span>


<div class="viewcode-block" id="to_half">
<a class="viewcode-back" href="../../../generated/dgl.to_half.html#dgl.to_half">[docs]</a>
<span class="k">def</span> <span class="nf">to_half</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cast this graph to use float16 (half-precision) for any</span>
<span class="sd">    floating-point edge and node feature data.</span>

<span class="sd">    A shallow copy is returned so that the original graph is not modified.</span>
<span class="sd">    Feature tensors that are not floating-point will not be modified.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        Clone of graph with the feature data converted to float16.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ret</span></div>



<div class="viewcode-block" id="to_float">
<a class="viewcode-back" href="../../../generated/dgl.to_float.html#dgl.to_float">[docs]</a>
<span class="k">def</span> <span class="nf">to_float</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cast this graph to use float32 (single-precision) for any</span>
<span class="sd">    floating-point edge and node feature data.</span>

<span class="sd">    A shallow copy is returned so that the original graph is not modified.</span>
<span class="sd">    Feature tensors that are not floating-point will not be modified.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        Clone of graph with the feature data converted to float32.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ret</span></div>



<div class="viewcode-block" id="to_double">
<a class="viewcode-back" href="../../../generated/dgl.to_double.html#dgl.to_double">[docs]</a>
<span class="k">def</span> <span class="nf">to_double</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cast this graph to use float64 (double-precision) for any</span>
<span class="sd">    floating-point edge and node feature data.</span>

<span class="sd">    A shallow copy is returned so that the original graph is not modified.</span>
<span class="sd">    Feature tensors that are not floating-point will not be modified.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        Clone of graph with the feature data converted to float64.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
    <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ret</span></div>



<div class="viewcode-block" id="double_radius_node_labeling">
<a class="viewcode-back" href="../../../generated/dgl.double_radius_node_labeling.html#dgl.double_radius_node_labeling">[docs]</a>
<span class="k">def</span> <span class="nf">double_radius_node_labeling</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Double Radius Node Labeling, as introduced in `Link Prediction</span>
<span class="sd">    Based on Graph Neural Networks &lt;https://arxiv.org/abs/1802.09691&gt;`__.</span>

<span class="sd">    This function computes the double radius node labeling for each node to mark</span>
<span class="sd">    nodes&#39; different roles in an enclosing subgraph, given a target link.</span>

<span class="sd">    The node labels of source :math:`s` and destination :math:`t` are set to 1 and</span>
<span class="sd">    those of unreachable nodes from source or destination are set to 0. The labels</span>
<span class="sd">    of other nodes :math:`l` are defined according to the following hash function:</span>

<span class="sd">    :math:`l = 1 + min(d_s, d_t) + (d//2)[(d//2) + (d%2) - 1]`</span>

<span class="sd">    where :math:`d_s` and :math:`d_t` denote the shortest distance to the source and</span>
<span class="sd">    the target, respectively. :math:`d = d_s + d_t`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    src : int</span>
<span class="sd">        The source node ID of the target link.</span>
<span class="sd">    dst : int</span>
<span class="sd">        The destination node ID of the target link.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        Labels of all nodes. The tensor is of shape :math:`(N,)`, where</span>
<span class="sd">        :math:`N` is the number of nodes in the input graph.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,0,0,0,1,1,2,4], [1,2,3,6,3,4,4,5]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.double_radius_node_labeling(g, 0, 1)</span>
<span class="sd">    tensor([1, 1, 3, 2, 3, 7, 0])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">adj</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span> <span class="k">if</span> <span class="n">src</span> <span class="o">&gt;</span> <span class="n">dst</span> <span class="k">else</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>

    <span class="n">idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">src</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">src</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">adj_wo_src</span> <span class="o">=</span> <span class="n">adj</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:][:,</span> <span class="n">idx</span><span class="p">]</span>

    <span class="n">idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dst</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dst</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">adj</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">adj_wo_dst</span> <span class="o">=</span> <span class="n">adj</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:][:,</span> <span class="n">idx</span><span class="p">]</span>

    <span class="c1"># distance to the source node</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csgraph</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span>
        <span class="n">adj_wo_dst</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unweighted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">src</span>
    <span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># distance to the destination node</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csgraph</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span>
        <span class="n">adj_wo_src</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unweighted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">dst</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">ds</span> <span class="o">+</span> <span class="n">dt</span>
    <span class="c1"># suppress invalid value (nan) warnings</span>
    <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">errstate</span><span class="p">(</span><span class="n">invalid</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ds</span><span class="p">,</span> <span class="n">dt</span><span class="p">])</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">d</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">d</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">d</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z</span><span class="p">[</span><span class="n">src</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">z</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">z</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">z</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># unreachable nodes</span>

    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span></div>



<div class="viewcode-block" id="shortest_dist">
<a class="viewcode-back" href="../../../generated/dgl.shortest_dist.html#dgl.shortest_dist">[docs]</a>
<span class="k">def</span> <span class="nf">shortest_dist</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_paths</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute shortest distance and paths on the given graph.</span>

<span class="sd">    Only unweighted cases are supported. Only directed paths (in which the</span>
<span class="sd">    edges are all oriented in the same direction) are considered effective.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The input graph. Must be homogeneous.</span>
<span class="sd">    root : int, optional</span>
<span class="sd">        Given a root node ID, it returns the shortest distance and paths</span>
<span class="sd">        (optional) between the root node and all the nodes. If None, it returns</span>
<span class="sd">        the results for all node pairs. Default: None.</span>
<span class="sd">    return_paths : bool, optional</span>
<span class="sd">        If True, it returns the shortest paths corresponding to the shortest</span>
<span class="sd">        distances. Default: False.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dist : Tensor</span>
<span class="sd">        The shortest distance tensor.</span>

<span class="sd">        * If :attr:`root` is a node ID, it is a tensor of shape :math:`(N,)`,</span>
<span class="sd">          where :math:`N` is the number of nodes. :attr:`dist[j]` gives the</span>
<span class="sd">          shortest distance from :attr:`root` to node :attr:`j`.</span>
<span class="sd">        * Otherwise, it is a tensor of shape :math:`(N, N)`. :attr:`dist[i][j]`</span>
<span class="sd">          gives the shortest distance from node :attr:`i` to node :attr:`j`.</span>
<span class="sd">        * The distance values of unreachable node pairs are filled with -1.</span>
<span class="sd">    paths : Tensor, optional</span>
<span class="sd">        The shortest path tensor. It is only returned when :attr:`return_paths`</span>
<span class="sd">        is True.</span>

<span class="sd">        * If :attr:`root` is a node ID, it is a tensor of shape :math:`(N, L)`,</span>
<span class="sd">          where :math:`L` is the length of the longest path. :attr:`path[j]` is</span>
<span class="sd">          the shortest path from node :attr:`root` to node :attr:`j`.</span>
<span class="sd">        * Otherwise, it is a tensor of shape :math:`(N, N, L)`.</span>
<span class="sd">          :attr:`path[i][j]` is the shortest path from node :attr:`i` to node</span>
<span class="sd">          :attr:`j`.</span>
<span class="sd">        * Each path is a vector that consists of edge IDs with paddings of -1</span>
<span class="sd">          at the end.</span>
<span class="sd">        * Shortest path between a node and itself is a vector filled with -1&#39;s.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 1, 2], [2, 0, 3, 3]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.shortest_dist(g, root=0)</span>
<span class="sd">    tensor([ 0,  -1,  1, 2])</span>
<span class="sd">    &gt;&gt;&gt; dist, paths = dgl.shortest_dist(g, root=None, return_paths=True)</span>
<span class="sd">    &gt;&gt;&gt; print(dist)</span>
<span class="sd">    tensor([[ 0, -1,  1,  2],</span>
<span class="sd">            [ 1,  0,  2,  1],</span>
<span class="sd">            [-1, -1,  0,  1],</span>
<span class="sd">            [-1, -1, -1,  0]])</span>
<span class="sd">    &gt;&gt;&gt; print(paths)</span>
<span class="sd">    tensor([[[-1, -1],</span>
<span class="sd">             [-1, -1],</span>
<span class="sd">             [ 0, -1],</span>
<span class="sd">             [ 0,  3]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">            [[ 1, -1],</span>
<span class="sd">             [-1, -1],</span>
<span class="sd">             [ 1,  0],</span>
<span class="sd">             [ 2, -1]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">            [[-1, -1],</span>
<span class="sd">             [-1, -1],</span>
<span class="sd">             [-1, -1],</span>
<span class="sd">             [ 3, -1]],</span>
<span class="sd">    &lt;BLANKLINE&gt;</span>
<span class="sd">            [[-1, -1],</span>
<span class="sd">             [-1, -1],</span>
<span class="sd">             [-1, -1],</span>
<span class="sd">             [-1, -1]]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">root</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dist</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csgraph</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">),</span>
            <span class="n">return_predecessors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">unweighted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dist</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">csgraph</span><span class="o">.</span><span class="n">dijkstra</span><span class="p">(</span>
            <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">),</span>
            <span class="n">directed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">indices</span><span class="o">=</span><span class="n">root</span><span class="p">,</span>
            <span class="n">return_predecessors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">unweighted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="n">dist</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_paths</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_nodes</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;return node IDs of a path from i to j given predecessors&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="n">prev</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">prev</span><span class="p">]</span>
        <span class="k">while</span> <span class="n">prev</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">prev</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">prev</span><span class="p">]</span>
            <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev</span><span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="c1"># construct paths with given predecessors</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
    <span class="n">roots</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">))</span> <span class="k">if</span> <span class="n">root</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">root</span><span class="p">]</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">roots</span><span class="p">),</span> <span class="n">N</span><span class="p">,</span> <span class="n">max_len</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">masks</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">roots</span><span class="p">:</span>
        <span class="n">pred_</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">root</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pred</span>
        <span class="n">masks_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">max_len</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pred_</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">nodes</span> <span class="o">=</span> <span class="n">_get_nodes</span><span class="p">(</span><span class="n">pred_</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
            <span class="n">u</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">nodes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">v</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="k">if</span> <span class="n">nodes</span><span class="p">:</span>
                <span class="n">masks_i</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">masks_i</span><span class="p">)</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">edge_ids</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_ids</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">paths</span><span class="p">[</span><span class="n">masks</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">edge_ids</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">root</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">paths</span> <span class="o">=</span> <span class="n">paths</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
        <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">paths</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="svd_pe">
<a class="viewcode-back" href="../../../generated/dgl.svd_pe.html#dgl.svd_pe">[docs]</a>
<span class="k">def</span> <span class="nf">svd_pe</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;SVD-based Positional Encoding, as introduced in</span>
<span class="sd">    `Global Self-Attention as a Replacement for Graph Convolution</span>
<span class="sd">    &lt;https://arxiv.org/pdf/2108.03348.pdf&gt;`__</span>

<span class="sd">    This function computes the largest :math:`k` singular values and</span>
<span class="sd">    corresponding left and right singular vectors to form positional encodings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        A DGLGraph to be encoded, which must be a homogeneous one.</span>
<span class="sd">    k : int</span>
<span class="sd">        Number of largest singular values and corresponding singular vectors</span>
<span class="sd">        used for positional encoding.</span>
<span class="sd">    padding : bool, optional</span>
<span class="sd">        If False, raise an error when :math:`k &gt; N`,</span>
<span class="sd">        where :math:`N` is the number of nodes in :attr:`g`.</span>
<span class="sd">        If True, add zero paddings in the end of encoding vectors when</span>
<span class="sd">        :math:`k &gt; N`.</span>
<span class="sd">        Default : False.</span>
<span class="sd">    random_flip : bool, optional</span>
<span class="sd">        If True, randomly flip the signs of encoding vectors.</span>
<span class="sd">        Proposed to be activated during training for better generalization.</span>
<span class="sd">        Default : True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tensor</span>
<span class="sd">        Return SVD-based positional encodings of shape :math:`(N, 2k)`.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,2,3,1,4,0], [2,3,1,4,0,0,1,2,3,4]))</span>
<span class="sd">    &gt;&gt;&gt; dgl.svd_pe(g, k=2, padding=False, random_flip=True)</span>
<span class="sd">    tensor([[-6.3246e-01, -1.1373e-07, -6.3246e-01,  0.0000e+00],</span>
<span class="sd">            [-6.3246e-01,  7.6512e-01, -6.3246e-01, -7.6512e-01],</span>
<span class="sd">            [ 6.3246e-01,  4.7287e-01,  6.3246e-01, -4.7287e-01],</span>
<span class="sd">            [-6.3246e-01, -7.6512e-01, -6.3246e-01,  7.6512e-01],</span>
<span class="sd">            [ 6.3246e-01, -4.7287e-01,  6.3246e-01,  4.7287e-01]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">padding</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The number of singular values k must be no greater than the &quot;</span>
            <span class="s2">&quot;number of nodes n, but &quot;</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> respectively.&quot;</span>
        <span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">adj_external</span><span class="p">(</span><span class="n">ctx</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">scipy_fmt</span><span class="o">=</span><span class="s2">&quot;coo&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">vh</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">vh</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">topm_u</span> <span class="o">=</span> <span class="n">u</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">m</span><span class="p">]</span>
    <span class="n">topm_v</span> <span class="o">=</span> <span class="n">v</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">m</span><span class="p">]</span>
    <span class="n">topm_sqrt_d</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">diags</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">m</span><span class="p">]))</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">((</span><span class="n">topm_u</span> <span class="o">@</span> <span class="n">topm_sqrt_d</span><span class="p">),</span> <span class="p">(</span><span class="n">topm_v</span> <span class="o">@</span> <span class="n">topm_sqrt_d</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="c1"># randomly flip row vectors</span>
    <span class="k">if</span> <span class="n">random_flip</span><span class="p">:</span>
        <span class="n">rand_sign</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">flipped_encoding</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="n">rand_sign</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">float32</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">flipped_encoding</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">:</span>
        <span class="n">zero_padding</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">n</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">flipped_encoding</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">flipped_encoding</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">flipped_encoding</span><span class="p">,</span> <span class="n">zero_padding</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">flipped_encoding</span></div>



<span class="n">_init_api</span><span class="p">(</span><span class="s2">&quot;dgl.transform&quot;</span><span class="p">,</span> <span class="vm">__name__</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>