<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dgl.transforms.module &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dgl.transforms.module</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dgl.transforms.module</h1><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">#   Copyright 2019-2021 Contributors</span>
<span class="c1">#</span>
<span class="c1">#   Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1">#   you may not use this file except in compliance with the License.</span>
<span class="c1">#   You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#       http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1">#   Unless required by applicable law or agreed to in writing, software</span>
<span class="c1">#   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1">#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1">#   See the License for the specific language governing permissions and</span>
<span class="c1">#   limitations under the License.</span>
<span class="c1">#</span>
<span class="sd">&quot;&quot;&quot;Modules for transform&quot;&quot;&quot;</span>
<span class="c1"># pylint: disable= no-member, arguments-differ, invalid-name, missing-function-docstring</span>

<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">expm</span>

<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">convert</span><span class="p">,</span> <span class="n">function</span> <span class="k">as</span> <span class="n">fn</span><span class="p">,</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">dgl_warning</span><span class="p">,</span> <span class="n">DGLError</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">functional</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Bernoulli</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;BaseTransform&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RowFeatNormalizer&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FeatMask&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RandomWalkPE&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LaplacianPE&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LapPE&quot;</span><span class="p">,</span>
    <span class="s2">&quot;AddSelfLoop&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RemoveSelfLoop&quot;</span><span class="p">,</span>
    <span class="s2">&quot;AddReverse&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ToSimple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LineGraph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;KHopGraph&quot;</span><span class="p">,</span>
    <span class="s2">&quot;AddMetaPaths&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Compose&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GCNNorm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PPR&quot;</span><span class="p">,</span>
    <span class="s2">&quot;HeatKernel&quot;</span><span class="p">,</span>
    <span class="s2">&quot;GDC&quot;</span><span class="p">,</span>
    <span class="s2">&quot;NodeShuffle&quot;</span><span class="p">,</span>
    <span class="s2">&quot;DropNode&quot;</span><span class="p">,</span>
    <span class="s2">&quot;DropEdge&quot;</span><span class="p">,</span>
    <span class="s2">&quot;AddEdge&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SIGNDiffusion&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ToLevi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SVDPE&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Update the structure of a graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : DGLGraph</span>
<span class="sd">        The graph to update.</span>
<span class="sd">    data_dict : graph data</span>
<span class="sd">        The dictionary data for constructing a heterogeneous graph.</span>
<span class="sd">    copy_edata : bool</span>
<span class="sd">        If True, it will copy the edge features to the updated graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        The updated graph.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
    <span class="n">idtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span>
    <span class="n">num_nodes_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
        <span class="n">num_nodes_dict</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>

    <span class="n">new_g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">heterograph</span><span class="p">(</span>
        <span class="n">data_dict</span><span class="p">,</span> <span class="n">num_nodes_dict</span><span class="o">=</span><span class="n">num_nodes_dict</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
    <span class="p">)</span>

    <span class="c1"># Copy features</span>
    <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span>

    <span class="k">if</span> <span class="n">copy_edata</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">new_g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span>

    <span class="k">return</span> <span class="n">new_g</span>


<div class="viewcode-block" id="BaseTransform">
<a class="viewcode-back" href="../../../generated/dgl.transforms.BaseTransform.html#dgl.transforms.BaseTransform">[docs]</a>
<span class="k">class</span> <span class="nc">BaseTransform</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;An abstract class for writing transforms.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;()&quot;</span></div>



<div class="viewcode-block" id="RowFeatNormalizer">
<a class="viewcode-back" href="../../../generated/dgl.transforms.RowFeatNormalizer.html#dgl.transforms.RowFeatNormalizer">[docs]</a>
<span class="k">class</span> <span class="nc">RowFeatNormalizer</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Row-normalizes the features given in ``node_feat_names`` and ``edge_feat_names``.</span>

<span class="sd">    The row normalization formular is:</span>

<span class="sd">    .. math::</span>
<span class="sd">      x = \frac{x}{\sum_i x_i}</span>

<span class="sd">    where :math:`x` denotes a row of the feature tensor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    subtract_min: bool</span>
<span class="sd">        If True, the minimum value of whole feature tensor will be subtracted before normalization.</span>
<span class="sd">        Default: False.</span>
<span class="sd">        Subtraction will make all values non-negative. If all values are negative, after</span>
<span class="sd">        normalisation, the sum of each row of the feature tensor will be 1.</span>
<span class="sd">    node_feat_names : list[str], optional</span>
<span class="sd">        The names of the node feature tensors to be row-normalized. Default: `None`, which will</span>
<span class="sd">        not normalize any node feature tensor.</span>
<span class="sd">    edge_feat_names : list[str], optional</span>
<span class="sd">        The names of the edge feature tensors to be row-normalized. Default: `None`, which will</span>
<span class="sd">        not normalize any edge feature tensor.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import RowFeatNormalizer</span>

<span class="sd">    Case1: Row normalize features of a homogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; transform = RowFeatNormalizer(subtract_min=True,</span>
<span class="sd">    ...                               node_feat_names=[&#39;h&#39;], edge_feat_names=[&#39;w&#39;])</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.rand_graph(5, 20)</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.randn((g.num_nodes(), 5))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.randn((g.num_edges(), 5))</span>
<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h&#39;].sum(1))</span>
<span class="sd">    tensor([1., 1., 1., 1., 1.])</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;].sum(1))</span>
<span class="sd">    tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.,</span>
<span class="sd">            1., 1., 1., 1., 1., 1., 1., 1., 1.,</span>
<span class="sd">            1., 1.])</span>

<span class="sd">    Case2: Row normalize features of a heterogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([1, 2]), torch.tensor([3, 4])),</span>
<span class="sd">    ...     (&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = {&#39;game&#39;: torch.randn(2, 5), &#39;player&#39;: torch.randn(3, 5)}</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = {</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.randn(2, 5),</span>
<span class="sd">    ...     (&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;): torch.randn(2, 5)</span>
<span class="sd">    ... }</span>
<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h&#39;][&#39;game&#39;].sum(1), g.ndata[&#39;h&#39;][&#39;player&#39;].sum(1))</span>
<span class="sd">    tensor([1., 1.]) tensor([1., 1., 1.])</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;][(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;)].sum(1),</span>
<span class="sd">    ...     g.edata[&#39;w&#39;][(&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;)].sum(1))</span>
<span class="sd">    tensor([1., 1.]) tensor([1., 1.])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">subtract_min</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">node_feat_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_feat_names</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[]</span> <span class="k">if</span> <span class="n">node_feat_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">node_feat_names</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[]</span> <span class="k">if</span> <span class="n">edge_feat_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">edge_feat_names</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subtract_min</span> <span class="o">=</span> <span class="n">subtract_min</span>

    <span class="k">def</span> <span class="nf">row_normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Row-normalize the given feature.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        feat : Tensor</span>
<span class="sd">            The feature to be normalized.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The normalized feature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">subtract_min</span><span class="p">:</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">-</span> <span class="n">feat</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">feat</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">feat</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">node_feat_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_normalize</span><span class="p">(</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_normalize</span><span class="p">(</span>
                        <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span>
                    <span class="p">)</span>

        <span class="k">for</span> <span class="n">edge_feat_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_normalize</span><span class="p">(</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_normalize</span><span class="p">(</span>
                        <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span>
                    <span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="FeatMask">
<a class="viewcode-back" href="../../../generated/dgl.transforms.FeatMask.html#dgl.transforms.FeatMask">[docs]</a>
<span class="k">class</span> <span class="nc">FeatMask</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Randomly mask columns of the node and edge feature tensors, as described in `Graph</span>
<span class="sd">    Contrastive Learning with Augmentations &lt;https://arxiv.org/abs/2010.13902&gt;`__.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : float, optional</span>
<span class="sd">        Probability of masking a column of a feature tensor. Default: `0.5`.</span>
<span class="sd">    node_feat_names : list[str], optional</span>
<span class="sd">        The names of the node feature tensors to be masked. Default: `None`, which will</span>
<span class="sd">        not mask any node feature tensor.</span>
<span class="sd">    edge_feat_names : list[str], optional</span>
<span class="sd">        The names of the edge features to be masked. Default: `None`, which will not mask</span>
<span class="sd">        any edge feature tensor.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import FeatMask</span>

<span class="sd">    Case1 : Mask node and edge feature tensors of a homogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; transform = FeatMask(node_feat_names=[&#39;h&#39;], edge_feat_names=[&#39;w&#39;])</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.rand_graph(5, 10)</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones((g.num_nodes(), 10))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.ones((g.num_edges(), 10))</span>

<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h&#39;])</span>
<span class="sd">    tensor([[0., 0., 1., 1., 0., 0., 1., 1., 1., 0.],</span>
<span class="sd">            [0., 0., 1., 1., 0., 0., 1., 1., 1., 0.],</span>
<span class="sd">            [0., 0., 1., 1., 0., 0., 1., 1., 1., 0.],</span>
<span class="sd">            [0., 0., 1., 1., 0., 0., 1., 1., 1., 0.],</span>
<span class="sd">            [0., 0., 1., 1., 0., 0., 1., 1., 1., 0.]])</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([[1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],</span>
<span class="sd">            [1., 1., 0., 1., 0., 1., 0., 0., 0., 1.]])</span>

<span class="sd">    Case2 : Mask node and edge feature tensors of a heterogeneous graph.</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([1, 2]), torch.tensor([3, 4])),</span>
<span class="sd">    ...     (&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1]))</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = {&#39;game&#39;: torch.ones(2, 5), &#39;player&#39;: torch.ones(3, 5)}</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.ones(2, 5)}</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h&#39;][&#39;game&#39;])</span>
<span class="sd">    tensor([[1., 1., 1., 1., 1.],</span>
<span class="sd">            [1., 1., 1., 1., 1.]])</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;][(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;)])</span>
<span class="sd">    tensor([[1., 1., 1., 1., 1.],</span>
<span class="sd">            [1., 1., 1., 1., 1.]])</span>
<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h&#39;][&#39;game&#39;])</span>
<span class="sd">    tensor([[1., 1., 0., 1., 0.],</span>
<span class="sd">            [1., 1., 0., 1., 0.]])</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;][(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;)])</span>
<span class="sd">    tensor([[0., 1., 0., 1., 0.],</span>
<span class="sd">            [0., 1., 0., 1., 0.]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">node_feat_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_feat_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[]</span> <span class="k">if</span> <span class="n">node_feat_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">node_feat_names</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_names</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[]</span> <span class="k">if</span> <span class="n">edge_feat_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">edge_feat_names</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="c1"># Fast path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">g</span>

        <span class="k">for</span> <span class="n">node_feat_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_feat_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">feat_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">][:,</span> <span class="n">feat_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">mask_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">][</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">feat_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">mask_shape</span><span class="p">,</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="n">node_feat_name</span><span class="p">][</span><span class="n">ntype</span><span class="p">][</span>
                        <span class="p">:,</span> <span class="n">feat_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">edge_feat_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">feat_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">][:,</span> <span class="n">feat_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">mask_shape</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">][</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">feat_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">mask_shape</span><span class="p">,</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">edge_feat_name</span><span class="p">][</span><span class="n">etype</span><span class="p">][</span>
                        <span class="p">:,</span> <span class="n">feat_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="RandomWalkPE">
<a class="viewcode-back" href="../../../generated/dgl.transforms.RandomWalkPE.html#dgl.transforms.RandomWalkPE">[docs]</a>
<span class="k">class</span> <span class="nc">RandomWalkPE</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Random Walk Positional Encoding, as introduced in</span>
<span class="sd">    `Graph Neural Networks with Learnable Structural and Positional Representations</span>
<span class="sd">    &lt;https://arxiv.org/abs/2110.07875&gt;`__</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : int</span>
<span class="sd">        Number of random walk steps. The paper found the best value to be 16 and 20</span>
<span class="sd">        for two experiments.</span>
<span class="sd">    feat_name : str, optional</span>
<span class="sd">        Name to store the computed positional encodings in ndata.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        Name to retrieve the edge weights. Default: None, not using the edge weights.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import RandomWalkPE</span>

<span class="sd">    &gt;&gt;&gt; transform = RandomWalkPE(k=2)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 1], [1, 1, 0]))</span>
<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;PE&#39;])</span>
<span class="sd">    tensor([[0.0000, 0.5000],</span>
<span class="sd">            [0.5000, 0.7500]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">feat_name</span><span class="o">=</span><span class="s2">&quot;PE&quot;</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_name</span> <span class="o">=</span> <span class="n">feat_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="o">=</span> <span class="n">eweight_name</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">PE</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">random_walk_pe</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span>
        <span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">PE</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="LapPE">
<a class="viewcode-back" href="../../../generated/dgl.transforms.LapPE.html#dgl.transforms.LapPE">[docs]</a>
<span class="k">class</span> <span class="nc">LapPE</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Laplacian Positional Encoding, as introduced in</span>
<span class="sd">    `Benchmarking Graph Neural Networks</span>
<span class="sd">    &lt;https://arxiv.org/abs/2003.00982&gt;`__</span>

<span class="sd">    This module only works for homogeneous bidirected graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : int</span>
<span class="sd">        Number of smallest non-trivial eigenvectors to use for positional encoding.</span>
<span class="sd">    feat_name : str, optional</span>
<span class="sd">        Name to store the computed positional encodings in ndata.</span>
<span class="sd">    eigval_name : str, optional</span>
<span class="sd">        If None, store laplacian eigenvectors only. Otherwise, it&#39;s the name to</span>
<span class="sd">        store corresponding laplacian eigenvalues in ndata. Default: None.</span>
<span class="sd">    padding : bool, optional</span>
<span class="sd">        If False, raise an exception when k&gt;=n.</span>
<span class="sd">        Otherwise, add zero paddings in the end of eigenvectors and &#39;nan&#39;</span>
<span class="sd">        paddings in the end of eigenvalues when k&gt;=n. Default: False.</span>
<span class="sd">        n is the number of nodes in the given graph.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import LapPE</span>
<span class="sd">    &gt;&gt;&gt; transform1 = LapPE(k=3)</span>
<span class="sd">    &gt;&gt;&gt; transform2 = LapPE(k=5, padding=True)</span>
<span class="sd">    &gt;&gt;&gt; transform3 = LapPE(k=5, feat_name=&#39;eigvec&#39;, eigval_name=&#39;eigval&#39;, padding=True)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,2,3,1,4,0], [2,3,1,4,0,0,1,2,3,4]))</span>
<span class="sd">    &gt;&gt;&gt; g1 = transform1(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g1.ndata[&#39;PE&#39;])</span>
<span class="sd">    tensor([[ 0.6325,  0.1039,  0.3489],</span>
<span class="sd">            [-0.5117,  0.2826,  0.6095],</span>
<span class="sd">            [ 0.1954,  0.6254, -0.5923],</span>
<span class="sd">            [-0.5117, -0.4508, -0.3938],</span>
<span class="sd">            [ 0.1954, -0.5612,  0.0278]])</span>
<span class="sd">    &gt;&gt;&gt; g2 = transform2(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g2.ndata[&#39;PE&#39;])</span>
<span class="sd">    tensor([[-0.6325, -0.1039,  0.3489, -0.2530,  0.0000],</span>
<span class="sd">            [ 0.5117, -0.2826,  0.6095,  0.4731,  0.0000],</span>
<span class="sd">            [-0.1954, -0.6254, -0.5923, -0.1361,  0.0000],</span>
<span class="sd">            [ 0.5117,  0.4508, -0.3938, -0.6295,  0.0000],</span>
<span class="sd">            [-0.1954,  0.5612,  0.0278,  0.5454,  0.0000]])</span>
<span class="sd">    &gt;&gt;&gt; g3 = transform3(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g3.ndata[&#39;eigval&#39;])</span>
<span class="sd">    tensor([[0.6910, 0.6910, 1.8090, 1.8090,    nan],</span>
<span class="sd">            [0.6910, 0.6910, 1.8090, 1.8090,    nan],</span>
<span class="sd">            [0.6910, 0.6910, 1.8090, 1.8090,    nan],</span>
<span class="sd">            [0.6910, 0.6910, 1.8090, 1.8090,    nan],</span>
<span class="sd">            [0.6910, 0.6910, 1.8090, 1.8090,    nan]])</span>
<span class="sd">    &gt;&gt;&gt; print(g3.ndata[&#39;eigvec&#39;])</span>
<span class="sd">    tensor([[ 0.6325, -0.1039,  0.3489,  0.2530,  0.0000],</span>
<span class="sd">            [-0.5117, -0.2826,  0.6095, -0.4731,  0.0000],</span>
<span class="sd">            [ 0.1954, -0.6254, -0.5923,  0.1361,  0.0000],</span>
<span class="sd">            [-0.5117,  0.4508, -0.3938,  0.6295,  0.0000],</span>
<span class="sd">            [ 0.1954,  0.5612,  0.0278, -0.5454,  0.0000]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">feat_name</span><span class="o">=</span><span class="s2">&quot;PE&quot;</span><span class="p">,</span> <span class="n">eigval_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_name</span> <span class="o">=</span> <span class="n">feat_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eigval_name</span> <span class="o">=</span> <span class="n">eigval_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eigval_name</span><span class="p">:</span>
            <span class="n">PE</span><span class="p">,</span> <span class="n">eigval</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">lap_pe</span><span class="p">(</span>
                <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">return_eigval</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">eigval</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">eigval</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eigval_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">eigval</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">PE</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">lap_pe</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">PE</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span></div>



<span class="k">class</span> <span class="nc">LaplacianPE</span><span class="p">(</span><span class="n">LapPE</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Alias of `LapPE`.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">feat_name</span><span class="o">=</span><span class="s2">&quot;PE&quot;</span><span class="p">,</span> <span class="n">eigval_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">feat_name</span><span class="p">,</span> <span class="n">eigval_name</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
        <span class="n">dgl_warning</span><span class="p">(</span><span class="s2">&quot;LaplacianPE will be deprecated. Use LapPE please.&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="AddSelfLoop">
<a class="viewcode-back" href="../../../generated/dgl.transforms.AddSelfLoop.html#dgl.transforms.AddSelfLoop">[docs]</a>
<span class="k">class</span> <span class="nc">AddSelfLoop</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add self-loops for each node in the graph and return a new graph.</span>

<span class="sd">    For heterogeneous graphs, self-loops are added only for edge types with same</span>
<span class="sd">    source and destination node types.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    allow_duplicate : bool, optional</span>
<span class="sd">        If False, it will first remove self-loops to prevent duplicate self-loops.</span>
<span class="sd">    new_etypes : bool, optional</span>
<span class="sd">        If True, it will add an edge type &#39;self&#39; per node type, which holds self-loops.</span>
<span class="sd">    edge_feat_names : list[str], optional</span>
<span class="sd">        The names of the self-loop features to apply `fill_data`. If None, it</span>
<span class="sd">        will apply `fill_data` to all self-loop features. Default: None.</span>
<span class="sd">    fill_data : int, float or str, optional</span>
<span class="sd">        The value to fill the self-loop features. Default: 1.</span>

<span class="sd">        * If ``fill_data`` is ``int`` or ``float``, self-loop features will be directly given by</span>
<span class="sd">          ``fill_data``.</span>
<span class="sd">        * if ``fill_data`` is ``str``, self-loop features will be generated by aggregating the</span>
<span class="sd">          features of the incoming edges of the corresponding nodes. The supported aggregation are:</span>
<span class="sd">          ``&#39;mean&#39;``, ``&#39;sum&#39;``, ``&#39;max&#39;``, ``&#39;min&#39;``.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import AddSelfLoop</span>

<span class="sd">    Case1: Add self-loops for a homogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; transform = AddSelfLoop(fill_data=&#39;sum&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 0, 2], [2, 1, 0]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([0, 0, 2, 0, 1, 2]), tensor([2, 1, 0, 0, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata(&#39;he&#39;))</span>
<span class="sd">    tensor([[0.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [2.],</span>
<span class="sd">            [2.],</span>
<span class="sd">            [1.],</span>
<span class="sd">            [0.]])</span>

<span class="sd">    Case2: Add self-loops for a heterogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; transform = AddSelfLoop(fill_data=&#39;sum&#39;)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([1, 2]),</span>
<span class="sd">    ...                                   torch.tensor([0, 1])),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">    ...                                 torch.tensor([0, 1]))})</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;feat&#39;] = {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.randn(2, 5),</span>
<span class="sd">    ...                    (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): torch.randn(2, 5)}</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;feat1&#39;] = {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.randn(2, 15),</span>
<span class="sd">    ...                     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): torch.randn(2, 15)}</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;plays&#39;))</span>
<span class="sd">    (tensor([0, 1]), tensor([0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;follows&#39;))</span>
<span class="sd">    (tensor([1, 2, 0, 1, 2]), tensor([0, 1, 0, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;feat&#39;][(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;)].shape)</span>
<span class="sd">    torch.Size([5, 5])</span>

<span class="sd">    Case3: Add self-etypes for a heterogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; transform = AddSelfLoop(new_etypes=True)</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;follows&#39;))</span>
<span class="sd">    (tensor([1, 2, 0, 1, 2]), tensor([0, 1, 0, 1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=(&#39;game&#39;, &#39;self&#39;, &#39;game&#39;)))</span>
<span class="sd">    (tensor([0, 1]), tensor([0, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">allow_duplicate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">new_etypes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">edge_feat_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">fill_data</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allow_duplicate</span> <span class="o">=</span> <span class="n">allow_duplicate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_etypes</span> <span class="o">=</span> <span class="n">new_etypes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_names</span> <span class="o">=</span> <span class="n">edge_feat_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fill_data</span> <span class="o">=</span> <span class="n">fill_data</span>

    <span class="k">def</span> <span class="nf">transform_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Transform the graph corresponding to a canonical edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        c_etype : tuple of str</span>
<span class="sd">            A canonical edge type.</span>
<span class="sd">        g : DGLGraph</span>
<span class="sd">            The graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The transformed graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">utype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
        <span class="k">if</span> <span class="n">utype</span> <span class="o">!=</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">g</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">allow_duplicate</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">remove_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">add_self_loop</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">edge_feat_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_feat_names</span><span class="p">,</span>
            <span class="n">fill_data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fill_data</span><span class="p">,</span>
            <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_etypes</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
            <span class="n">idtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span>
            <span class="n">data_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

            <span class="c1"># Add self etypes</span>
            <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
                <span class="n">nids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">),</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">data_dict</span><span class="p">[(</span><span class="n">ntype</span><span class="p">,</span> <span class="s2">&quot;self&quot;</span><span class="p">,</span> <span class="n">ntype</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="n">nids</span><span class="p">)</span>

            <span class="c1"># Copy edges</span>
            <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
                <span class="n">data_dict</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>

            <span class="n">g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="RemoveSelfLoop">
<a class="viewcode-back" href="../../../generated/dgl.transforms.RemoveSelfLoop.html#dgl.transforms.RemoveSelfLoop">[docs]</a>
<span class="k">class</span> <span class="nc">RemoveSelfLoop</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove self-loops for each node in the graph and return a new graph.</span>

<span class="sd">    For heterogeneous graphs, this operation only applies to edge types with same</span>
<span class="sd">    source and destination node types.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import RemoveSelfLoop</span>

<span class="sd">    Case1: Remove self-loops for a homogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; transform = RemoveSelfLoop()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([1, 1], [1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([1]), tensor([2]))</span>

<span class="sd">    Case2: Remove self-loops for a heterogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 1], [1, 1]),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([1, 2], [2, 2])</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;plays&#39;))</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 1]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;follows&#39;))</span>
<span class="sd">    (tensor([1]), tensor([2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">transform_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the graph corresponding to a canonical edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        c_etype : tuple of str</span>
<span class="sd">            A canonical edge type.</span>
<span class="sd">        g : DGLGraph</span>
<span class="sd">            The graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The transformed graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">utype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
        <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">remove_self_loop</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="AddReverse">
<a class="viewcode-back" href="../../../generated/dgl.transforms.AddReverse.html#dgl.transforms.AddReverse">[docs]</a>
<span class="k">class</span> <span class="nc">AddReverse</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add a reverse edge :math:`(i,j)` for each edge :math:`(j,i)` in the input graph and</span>
<span class="sd">    return a new graph.</span>

<span class="sd">    For a heterogeneous graph, it adds a &quot;reverse&quot; edge type for each edge type</span>
<span class="sd">    to hold the reverse edges. For example, for a canonical edge type (&#39;A&#39;, &#39;r&#39;, &#39;B&#39;),</span>
<span class="sd">    it adds a canonical edge type (&#39;B&#39;, &#39;rev_r&#39;, &#39;A&#39;).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    copy_edata : bool, optional</span>
<span class="sd">        If True, the features of the reverse edges will be identical to the original ones.</span>
<span class="sd">    sym_new_etype : bool, optional</span>
<span class="sd">        If False, it will not add a reverse edge type if the source and destination node type</span>
<span class="sd">        in a canonical edge type are identical. Instead, it will directly add edges to the</span>
<span class="sd">        original edge type.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import AddReverse</span>

<span class="sd">    Case1: Add reverse edges for a homogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; transform = AddReverse()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0], [1]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.ones(1, 2)</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 0]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([[1., 1.],</span>
<span class="sd">            [0., 0.]])</span>

<span class="sd">    Case2: Add reverse edges for a homogeneous graph and copy edata</span>

<span class="sd">    &gt;&gt;&gt; transform = AddReverse(copy_edata=True)</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([[1., 1.],</span>
<span class="sd">            [1., 1.]])</span>

<span class="sd">    Case3: Add reverse edges for a heterogeneous graph</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 1], [1, 1]),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([1, 2], [2, 2])</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.canonical_etypes)</span>
<span class="sd">    [(&#39;game&#39;, &#39;rev_plays&#39;, &#39;user&#39;), (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;), (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)]</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;rev_plays&#39;))</span>
<span class="sd">    (tensor([1, 1]), tensor([0, 1]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=&#39;follows&#39;))</span>
<span class="sd">    (tensor([1, 2, 2, 2]), tensor([2, 2, 1, 2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sym_new_etype</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy_edata</span> <span class="o">=</span> <span class="n">copy_edata</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sym_new_etype</span> <span class="o">=</span> <span class="n">sym_new_etype</span>

    <span class="k">def</span> <span class="nf">transform_symmetric_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the graph corresponding to a symmetric canonical edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        c_etype : tuple of str</span>
<span class="sd">            A canonical edge type.</span>
<span class="sd">        g : DGLGraph</span>
<span class="sd">            The graph.</span>
<span class="sd">        data_dict : dict</span>
<span class="sd">            The edge data to update.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sym_new_etype</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform_asymmetric_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
            <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">data_dict</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform_asymmetric_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the graph corresponding to an asymmetric canonical edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        c_etype : tuple of str</span>
<span class="sd">            A canonical edge type.</span>
<span class="sd">        g : DGLGraph</span>
<span class="sd">            The graph.</span>
<span class="sd">        data_dict : dict</span>
<span class="sd">            The edge data to update.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
        <span class="n">data_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="n">c_etype</span><span class="p">:</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">),</span>
                <span class="p">(</span><span class="n">vtype</span><span class="p">,</span> <span class="s2">&quot;rev_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">utype</span><span class="p">):</span> <span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Transform the graph corresponding to a canonical edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        c_etype : tuple of str</span>
<span class="sd">            A canonical edge type.</span>
<span class="sd">        g : DGLGraph</span>
<span class="sd">            The graph.</span>
<span class="sd">        data_dict : dict</span>
<span class="sd">            The edge data to update.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">utype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
        <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform_symmetric_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform_asymmetric_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">)</span>
        <span class="n">new_g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Copy and expand edata</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">utype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
            <span class="k">if</span> <span class="n">utype</span> <span class="o">!=</span> <span class="n">vtype</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">sym_new_etype</span><span class="p">:</span>
                <span class="n">rev_c_etype</span> <span class="o">=</span> <span class="p">(</span><span class="n">vtype</span><span class="p">,</span> <span class="s2">&quot;rev_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">utype</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">new_g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_edata</span><span class="p">:</span>
                        <span class="n">new_g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">rev_c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">new_feat</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">feat</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_edata</span>
                        <span class="k">else</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">feat</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">feat</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">new_g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">feat</span><span class="p">,</span> <span class="n">new_feat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
                    <span class="p">)</span>

        <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="ToSimple">
<a class="viewcode-back" href="../../../generated/dgl.transforms.ToSimple.html#dgl.transforms.ToSimple">[docs]</a>
<span class="k">class</span> <span class="nc">ToSimple</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert a graph to a simple graph without parallel edges and return a new graph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    return_counts : str, optional</span>
<span class="sd">        The edge feature name to hold the edge count in the original graph.</span>
<span class="sd">    aggregator : str, optional</span>
<span class="sd">        The way to coalesce features of duplicate edges.</span>

<span class="sd">        * ``&#39;arbitrary&#39;``: select arbitrarily from one of the duplicate edges</span>
<span class="sd">        * ``&#39;sum&#39;``: take the sum over the duplicate edges</span>
<span class="sd">        * ``&#39;mean&#39;``: take the mean over the duplicate edges</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import ToSimple</span>

<span class="sd">    Case1: Convert a homogeneous graph to a simple graph</span>

<span class="sd">    &gt;&gt;&gt; transform = ToSimple()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 1], [1, 2, 2]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.tensor([[0.1], [0.2], [0.3]])</span>
<span class="sd">    &gt;&gt;&gt; sg = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(sg.edges())</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; print(sg.edata[&#39;count&#39;])</span>
<span class="sd">    tensor([1, 2])</span>
<span class="sd">    &gt;&gt;&gt; print(sg.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([[0.1000], [0.2000]])</span>

<span class="sd">    Case2: Convert a heterogeneous graph to a simple graph</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1, 1], [1, 2, 2]),</span>
<span class="sd">    ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 1, 0], [1, 1, 1])</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; sg = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(sg.edges(etype=&#39;follows&#39;))</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; print(sg.edges(etype=&#39;plays&#39;))</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="n">aggregator</span><span class="o">=</span><span class="s2">&quot;arbitrary&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_counts</span> <span class="o">=</span> <span class="n">return_counts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span> <span class="o">=</span> <span class="n">aggregator</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">to_simple</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span>
            <span class="n">return_counts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">return_counts</span><span class="p">,</span>
            <span class="n">copy_edata</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">aggregator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">aggregator</span><span class="p">,</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="LineGraph">
<a class="viewcode-back" href="../../../generated/dgl.transforms.LineGraph.html#dgl.transforms.LineGraph">[docs]</a>
<span class="k">class</span> <span class="nc">LineGraph</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the line graph of the input graph.</span>

<span class="sd">    The line graph :math:`L(G)` of a given graph :math:`G` is a graph where</span>
<span class="sd">    the nodes in :math:`L(G)` correspond to the edges in :math:`G`. For a pair</span>
<span class="sd">    of edges :math:`(u, v)` and :math:`(v, w)` in :math:`G`, there will be an</span>
<span class="sd">    edge from the node corresponding to :math:`(u, v)` to the node corresponding to</span>
<span class="sd">    :math:`(v, w)` in :math:`L(G)`.</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    backtracking : bool, optional</span>
<span class="sd">        If False, there will be an edge from the line graph node corresponding to</span>
<span class="sd">        :math:`(u, v)` to the line graph node corresponding to :math:`(v, u)`.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    The following example uses PyTorch backend.</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import LineGraph</span>

<span class="sd">    Case1: Backtracking is True</span>

<span class="sd">    &gt;&gt;&gt; transform = LineGraph()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 1], [1, 0, 2]))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.tensor([[0.], [1.], [2.]])</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.tensor([[0.], [0.1], [0.2]])</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g)</span>
<span class="sd">    Graph(num_nodes=3, num_edges=3,</span>
<span class="sd">          ndata_schemes={&#39;w&#39;: Scheme(shape=(1,), dtype=torch.float32)}</span>
<span class="sd">          edata_schemes={})</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([0, 0, 1]), tensor([1, 2, 0]))</span>

<span class="sd">    Case2: Backtracking is False</span>

<span class="sd">    &gt;&gt;&gt; transform = LineGraph(backtracking=False)</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([0]), tensor([2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backtracking</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backtracking</span> <span class="o">=</span> <span class="n">backtracking</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">line_graph</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">backtracking</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backtracking</span><span class="p">,</span> <span class="n">shared</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="KHopGraph">
<a class="viewcode-back" href="../../../generated/dgl.transforms.KHopGraph.html#dgl.transforms.KHopGraph">[docs]</a>
<span class="k">class</span> <span class="nc">KHopGraph</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the graph whose edges connect the :math:`k`-hop neighbors of the original graph.</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : int</span>
<span class="sd">        The number of hops.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import KHopGraph</span>

<span class="sd">    &gt;&gt;&gt; transform = KHopGraph(2)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1], [1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([0]), tensor([2]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">khop_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span></div>



<div class="viewcode-block" id="AddMetaPaths">
<a class="viewcode-back" href="../../../generated/dgl.transforms.AddMetaPaths.html#dgl.transforms.AddMetaPaths">[docs]</a>
<span class="k">class</span> <span class="nc">AddMetaPaths</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add new edges to an input graph based on given metapaths, as described in</span>
<span class="sd">    `Heterogeneous Graph Attention Network &lt;https://arxiv.org/abs/1903.07293&gt;`__.</span>

<span class="sd">    Formally, a metapath is a path of the form</span>

<span class="sd">    .. math::</span>

<span class="sd">        \mathcal{V}_1 \xrightarrow{R_1} \mathcal{V}_2 \xrightarrow{R_2} \ldots</span>
<span class="sd">        \xrightarrow{R_{\ell-1}} \mathcal{V}_{\ell}</span>

<span class="sd">    in which :math:`\mathcal{V}_i` represents a node type and :math:`\xrightarrow{R_j}`</span>
<span class="sd">    represents a relation type connecting its two adjacent node types. The adjacency matrix</span>
<span class="sd">    corresponding to the metapath is obtained by sequential multiplication of adjacency matrices</span>
<span class="sd">    along the metapath.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metapaths : dict[str, list]</span>
<span class="sd">        The metapaths to add, mapping a metapath name to a metapath. For example,</span>
<span class="sd">        :attr:`{&#39;co-author&#39;: [(&#39;person&#39;, &#39;author&#39;, &#39;paper&#39;), (&#39;paper&#39;, &#39;authored by&#39;, &#39;person&#39;)]}`</span>
<span class="sd">    keep_orig_edges : bool, optional</span>
<span class="sd">        If True, it will keep the edges of the original graph. Otherwise, it will drop them.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import AddMetaPaths</span>

<span class="sd">    &gt;&gt;&gt; transform = AddMetaPaths({</span>
<span class="sd">    ...     &#39;accepted&#39;: [(&#39;person&#39;, &#39;author&#39;, &#39;paper&#39;), (&#39;paper&#39;, &#39;accepted&#39;, &#39;venue&#39;)],</span>
<span class="sd">    ...     &#39;rejected&#39;: [(&#39;person&#39;, &#39;author&#39;, &#39;paper&#39;), (&#39;paper&#39;, &#39;rejected&#39;, &#39;venue&#39;)]</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">    ...     (&#39;person&#39;, &#39;author&#39;, &#39;paper&#39;): ([0, 0, 1], [1, 2, 2]),</span>
<span class="sd">    ...     (&#39;paper&#39;, &#39;accepted&#39;, &#39;venue&#39;): ([1], [0]),</span>
<span class="sd">    ...     (&#39;paper&#39;, &#39;rejected&#39;, &#39;venue&#39;): ([2], [1])</span>
<span class="sd">    ... })</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=(&#39;person&#39;, &#39;accepted&#39;, &#39;venue&#39;)))</span>
<span class="sd">    (tensor([0]), tensor([0]))</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges(etype=(&#39;person&#39;, &#39;rejected&#39;, &#39;venue&#39;)))</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metapaths</span><span class="p">,</span> <span class="n">keep_orig_edges</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metapaths</span> <span class="o">=</span> <span class="n">metapaths</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keep_orig_edges</span> <span class="o">=</span> <span class="n">keep_orig_edges</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">meta_etype</span><span class="p">,</span> <span class="n">metapath</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metapaths</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">meta_g</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">metapath_reachable_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">metapath</span><span class="p">)</span>
            <span class="n">u_type</span> <span class="o">=</span> <span class="n">metapath</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">v_type</span> <span class="o">=</span> <span class="n">metapath</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">data_dict</span><span class="p">[(</span><span class="n">u_type</span><span class="p">,</span> <span class="n">meta_etype</span><span class="p">,</span> <span class="n">v_type</span><span class="p">)]</span> <span class="o">=</span> <span class="n">meta_g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_orig_edges</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
                <span class="n">data_dict</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
            <span class="n">new_g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="Compose">
<a class="viewcode-back" href="../../../generated/dgl.transforms.Compose.html#dgl.transforms.Compose">[docs]</a>
<span class="k">class</span> <span class="nc">Compose</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Create a transform composed of multiple transforms in sequence.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    transforms : list of Callable</span>
<span class="sd">        A list of transform objects to apply in order. A transform object should inherit</span>
<span class="sd">        :class:`~dgl.BaseTransform` and implement :func:`~dgl.BaseTransform.__call__`.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import transforms as T</span>

<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 0], [1, 1]))</span>
<span class="sd">    &gt;&gt;&gt; transform = T.Compose([T.ToSimple(), T.AddReverse()])</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edges())</span>
<span class="sd">    (tensor([0, 1]), tensor([1, 0]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;  &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">transform</span><span class="p">)</span> <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;([</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">])&quot;</span></div>



<div class="viewcode-block" id="GCNNorm">
<a class="viewcode-back" href="../../../generated/dgl.transforms.GCNNorm.html#dgl.transforms.GCNNorm">[docs]</a>
<span class="k">class</span> <span class="nc">GCNNorm</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Apply symmetric adjacency normalization to an input graph and save the result edge</span>
<span class="sd">    weights, as described in `Semi-Supervised Classification with Graph Convolutional Networks</span>
<span class="sd">    &lt;https://arxiv.org/abs/1609.02907&gt;`__.</span>

<span class="sd">    For a heterogeneous graph, this only applies to symmetric canonical edge types, whose source</span>
<span class="sd">    and destination node types are identical.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        :attr:`edata` name to retrieve and store edge weights. The edge weights are optional.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import GCNNorm</span>
<span class="sd">    &gt;&gt;&gt; transform = GCNNorm()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 2], [0, 0, 1]))</span>

<span class="sd">    Case1: Transform an unweighted graph</span>

<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([0.5000, 0.7071, 0.0000])</span>

<span class="sd">    Case2: Transform a weighted graph</span>

<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.tensor([0.1, 0.2, 0.3])</span>
<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([0.3333, 0.6667, 0.0000])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="o">=</span> <span class="n">eweight_name</span>

    <span class="k">def</span> <span class="nf">calc_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Description</span>
<span class="sd">        -----------</span>
<span class="sd">        Get edge weights for an edge type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ntype</span> <span class="o">=</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">copy_e</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">),</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="s2">&quot;deg&quot;</span><span class="p">),</span>
                    <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">deg_inv_sqrt</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;deg&quot;</span><span class="p">])</span>
                <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">replace_inf_with_zero</span><span class="p">(</span><span class="n">deg_inv_sqrt</span><span class="p">)</span>
                <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">edge</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s2">&quot;w&quot;</span><span class="p">:</span> <span class="n">edge</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span>
                        <span class="o">*</span> <span class="n">edge</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">]</span>
                        <span class="o">*</span> <span class="n">edge</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span>
                    <span class="p">},</span>
                    <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">deg</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
                <span class="n">deg_inv_sqrt</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">F</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">deg</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
                <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">replace_inf_with_zero</span><span class="p">(</span><span class="n">deg_inv_sqrt</span><span class="p">)</span>
                <span class="n">g</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">edges</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;w&quot;</span><span class="p">:</span> <span class="n">edges</span><span class="o">.</span><span class="n">src</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">edges</span><span class="o">.</span><span class="n">dst</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]},</span>
                    <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;w&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">utype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
            <span class="k">if</span> <span class="n">utype</span> <span class="o">==</span> <span class="n">vtype</span><span class="p">:</span>
                <span class="n">result</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calc_etype</span><span class="p">(</span><span class="n">c_etype</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">c_etype</span><span class="p">,</span> <span class="n">eweight</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">eweight</span>
        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="PPR">
<a class="viewcode-back" href="../../../generated/dgl.transforms.PPR.html#dgl.transforms.PPR">[docs]</a>
<span class="k">class</span> <span class="nc">PPR</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Apply personalized PageRank (PPR) to an input graph for diffusion, as introduced in</span>
<span class="sd">    `The pagerank citation ranking: Bringing order to the web</span>
<span class="sd">    &lt;http://ilpubs.stanford.edu:8090/422/&gt;`__.</span>

<span class="sd">    A sparsification will be applied to the weighted adjacency matrix after diffusion.</span>
<span class="sd">    Specifically, edges whose weight is below a threshold will be dropped.</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha : float, optional</span>
<span class="sd">        Restart probability, which commonly lies in :math:`[0.05, 0.2]`.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        :attr:`edata` name to retrieve and store edge weights. If it does</span>
<span class="sd">        not exist in an input graph, this module initializes a weight of 1</span>
<span class="sd">        for all edges. The edge weights should be a tensor of shape :math:`(E)`,</span>
<span class="sd">        where E is the number of edges.</span>
<span class="sd">    eps : float, optional</span>
<span class="sd">        The threshold to preserve edges in sparsification after diffusion. Edges of a</span>
<span class="sd">        weight smaller than eps will be dropped.</span>
<span class="sd">    avg_degree : int, optional</span>
<span class="sd">        The desired average node degree of the result graph. This is the other way to</span>
<span class="sd">        control the sparsity of the result graph and will only be effective if</span>
<span class="sd">        :attr:`eps` is not given.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import PPR</span>

<span class="sd">    &gt;&gt;&gt; transform = PPR(avg_degree=2)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3, 4], [2, 3, 4, 5, 3]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([0.1500, 0.1500, 0.1500, 0.0255, 0.0163, 0.1500, 0.0638, 0.0383, 0.1500,</span>
<span class="sd">            0.0510, 0.0217, 0.1500])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">avg_degree</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="o">=</span> <span class="n">eweight_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">=</span> <span class="n">avg_degree</span>

    <span class="k">def</span> <span class="nf">get_eps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">mat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get the threshold for graph sparsification.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Infer from self.avg_degree</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">&gt;</span> <span class="n">num_nodes</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>
            <span class="n">sorted_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="k">return</span> <span class="n">sorted_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="c1"># Step1: PPR diffusion</span>
        <span class="c1"># (α - 1) A</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
        <span class="n">eweight</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">]</span> <span class="o">=</span> <span class="n">eweight</span>
        <span class="c1"># I_n + (α - 1) A</span>
        <span class="n">nids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">nids</span><span class="p">,</span> <span class="n">nids</span><span class="p">]</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="n">nids</span><span class="p">,</span> <span class="n">nids</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># α (I_n + (α - 1) A)^-1</span>
        <span class="n">diff_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>

        <span class="c1"># Step2: sparsification</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_eps</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">diff_mat</span><span class="p">)</span>
        <span class="n">dst</span><span class="p">,</span> <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_mat</span> <span class="o">&gt;=</span> <span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)}</span>
        <span class="n">new_g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">new_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">diff_mat</span><span class="p">[</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">new_g</span></div>



<span class="k">def</span> <span class="nf">is_bidirected</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return whether the graph is a bidirected graph.</span>

<span class="sd">    A graph is bidirected if for any edge :math:`(u, v)` in :math:`G` with weight :math:`w`,</span>
<span class="sd">    there exists an edge :math:`(v, u)` in :math:`G` with the same weight.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
    <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>

    <span class="c1"># Sort first by src then dst</span>
    <span class="n">idx_src_dst</span> <span class="o">=</span> <span class="n">src</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">+</span> <span class="n">dst</span>
    <span class="n">perm_src_dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">idx_src_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">src1</span><span class="p">,</span> <span class="n">dst1</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">perm_src_dst</span><span class="p">],</span> <span class="n">dst</span><span class="p">[</span><span class="n">perm_src_dst</span><span class="p">]</span>

    <span class="c1"># Sort first by dst then src</span>
    <span class="n">idx_dst_src</span> <span class="o">=</span> <span class="n">dst</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">+</span> <span class="n">src</span>
    <span class="n">perm_dst_src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">idx_dst_src</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">src2</span><span class="p">,</span> <span class="n">dst2</span> <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="n">perm_dst_src</span><span class="p">],</span> <span class="n">dst</span><span class="p">[</span><span class="n">perm_dst_src</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">src1</span><span class="p">,</span> <span class="n">dst2</span><span class="p">)</span> <span class="ow">and</span> <span class="n">F</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">src2</span><span class="p">,</span> <span class="n">dst1</span><span class="p">)</span>


<span class="c1"># pylint: disable=C0103</span>
<div class="viewcode-block" id="HeatKernel">
<a class="viewcode-back" href="../../../generated/dgl.transforms.HeatKernel.html#dgl.transforms.HeatKernel">[docs]</a>
<span class="k">class</span> <span class="nc">HeatKernel</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Apply heat kernel to an input graph for diffusion, as introduced in</span>
<span class="sd">    `Diffusion kernels on graphs and other discrete structures</span>
<span class="sd">    &lt;https://www.ml.cmu.edu/research/dap-papers/kondor-diffusion-kernels.pdf&gt;`__.</span>

<span class="sd">    A sparsification will be applied to the weighted adjacency matrix after diffusion.</span>
<span class="sd">    Specifically, edges whose weight is below a threshold will be dropped.</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    t : float, optional</span>
<span class="sd">        Diffusion time, which commonly lies in :math:`[2, 10]`.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        :attr:`edata` name to retrieve and store edge weights. If it does</span>
<span class="sd">        not exist in an input graph, this module initializes a weight of 1</span>
<span class="sd">        for all edges. The edge weights should be a tensor of shape :math:`(E)`,</span>
<span class="sd">        where E is the number of edges.</span>
<span class="sd">    eps : float, optional</span>
<span class="sd">        The threshold to preserve edges in sparsification after diffusion. Edges of a</span>
<span class="sd">        weight smaller than eps will be dropped.</span>
<span class="sd">    avg_degree : int, optional</span>
<span class="sd">        The desired average node degree of the result graph. This is the other way to</span>
<span class="sd">        control the sparsity of the result graph and will only be effective if</span>
<span class="sd">        :attr:`eps` is not given.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import HeatKernel</span>

<span class="sd">    &gt;&gt;&gt; transform = HeatKernel(avg_degree=2)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3, 4], [2, 3, 4, 5, 3]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([0.1353, 0.1353, 0.1353, 0.0541, 0.0406, 0.1353, 0.1353, 0.0812, 0.1353,</span>
<span class="sd">            0.1083, 0.0541, 0.1353])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">avg_degree</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="o">=</span> <span class="n">eweight_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">=</span> <span class="n">avg_degree</span>

    <span class="k">def</span> <span class="nf">get_eps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">mat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get the threshold for graph sparsification.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Infer from self.avg_degree</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">&gt;</span> <span class="n">num_nodes</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>
            <span class="n">sorted_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="k">return</span> <span class="n">sorted_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="c1"># Step1: heat kernel diffusion</span>
        <span class="c1"># t A</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
        <span class="n">eweight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">]</span> <span class="o">=</span> <span class="n">eweight</span>
        <span class="c1"># t (A - I_n)</span>
        <span class="n">nids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">nids</span><span class="p">,</span> <span class="n">nids</span><span class="p">]</span> <span class="o">=</span> <span class="n">mat</span><span class="p">[</span><span class="n">nids</span><span class="p">,</span> <span class="n">nids</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span>

        <span class="k">if</span> <span class="n">is_bidirected</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
            <span class="n">e</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">UPLO</span><span class="o">=</span><span class="s2">&quot;U&quot;</span><span class="p">)</span>
            <span class="n">diff_mat</span> <span class="o">=</span> <span class="n">V</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span> <span class="o">@</span> <span class="n">V</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">diff_mat_np</span> <span class="o">=</span> <span class="n">expm</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">diff_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">diff_mat_np</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Step2: sparsification</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_eps</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">diff_mat</span><span class="p">)</span>
        <span class="n">dst</span><span class="p">,</span> <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_mat</span> <span class="o">&gt;=</span> <span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)}</span>
        <span class="n">new_g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">new_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">diff_mat</span><span class="p">[</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="GDC">
<a class="viewcode-back" href="../../../generated/dgl.transforms.GDC.html#dgl.transforms.GDC">[docs]</a>
<span class="k">class</span> <span class="nc">GDC</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Apply graph diffusion convolution (GDC) to an input graph, as introduced in</span>
<span class="sd">    `Diffusion Improves Graph Learning &lt;https://www.in.tum.de/daml/gdc/&gt;`__.</span>

<span class="sd">    A sparsification will be applied to the weighted adjacency matrix after diffusion.</span>
<span class="sd">    Specifically, edges whose weight is below a threshold will be dropped.</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coefs : list[float], optional</span>
<span class="sd">        List of coefficients. :math:`\theta_k` for each power of the adjacency matrix.</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        :attr:`edata` name to retrieve and store edge weights. If it does</span>
<span class="sd">        not exist in an input graph, this module initializes a weight of 1</span>
<span class="sd">        for all edges. The edge weights should be a tensor of shape :math:`(E)`,</span>
<span class="sd">        where E is the number of edges.</span>
<span class="sd">    eps : float, optional</span>
<span class="sd">        The threshold to preserve edges in sparsification after diffusion. Edges of a</span>
<span class="sd">        weight smaller than eps will be dropped.</span>
<span class="sd">    avg_degree : int, optional</span>
<span class="sd">        The desired average node degree of the result graph. This is the other way to</span>
<span class="sd">        control the sparsity of the result graph and will only be effective if</span>
<span class="sd">        :attr:`eps` is not given.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import GDC</span>

<span class="sd">    &gt;&gt;&gt; transform = GDC([0.3, 0.2, 0.1], avg_degree=2)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3, 4], [2, 3, 4, 5, 3]))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5])</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;w&#39;])</span>
<span class="sd">    tensor([0.3000, 0.3000, 0.0200, 0.3000, 0.0400, 0.3000, 0.1000, 0.0600, 0.3000,</span>
<span class="sd">            0.0800, 0.0200, 0.3000])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">avg_degree</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coefs</span> <span class="o">=</span> <span class="n">coefs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="o">=</span> <span class="n">eweight_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">=</span> <span class="n">avg_degree</span>

    <span class="k">def</span> <span class="nf">get_eps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">mat</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get the threshold for graph sparsification.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Infer from self.avg_degree</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">&gt;</span> <span class="n">num_nodes</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>
            <span class="n">sorted_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="k">return</span> <span class="n">sorted_weights</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">avg_degree</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="c1"># Step1: diffusion</span>
        <span class="c1"># A</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
        <span class="n">eweight</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">adj</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">adj</span><span class="p">[</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">]</span> <span class="o">=</span> <span class="n">eweight</span>

        <span class="c1"># theta_0 I_n</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">diff_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">mat</span>
        <span class="c1"># add theta_k A^k</span>
        <span class="k">for</span> <span class="n">coef</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">mat</span> <span class="o">=</span> <span class="n">mat</span> <span class="o">@</span> <span class="n">adj</span>
            <span class="n">diff_mat</span> <span class="o">+=</span> <span class="n">coef</span> <span class="o">*</span> <span class="n">mat</span>

        <span class="c1"># Step2: sparsification</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_eps</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">diff_mat</span><span class="p">)</span>
        <span class="n">dst</span><span class="p">,</span> <span class="n">src</span> <span class="o">=</span> <span class="p">(</span><span class="n">diff_mat</span> <span class="o">&gt;=</span> <span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)}</span>
        <span class="n">new_g</span> <span class="o">=</span> <span class="n">update_graph_structure</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">,</span> <span class="n">copy_edata</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">new_g</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">diff_mat</span><span class="p">[</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">new_g</span></div>



<div class="viewcode-block" id="NodeShuffle">
<a class="viewcode-back" href="../../../generated/dgl.transforms.NodeShuffle.html#dgl.transforms.NodeShuffle">[docs]</a>
<span class="k">class</span> <span class="nc">NodeShuffle</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Randomly shuffle the nodes.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import NodeShuffle</span>

<span class="sd">    &gt;&gt;&gt; transform = NodeShuffle()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1], [1, 2]))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h1&#39;] = torch.tensor([[1., 2.], [3., 4.], [5., 6.]])</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h2&#39;] = torch.tensor([[7., 8.], [9., 10.], [11., 12.]])</span>
<span class="sd">    &gt;&gt;&gt; g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h1&#39;])</span>
<span class="sd">    tensor([[5., 6.],</span>
<span class="sd">            [3., 4.],</span>
<span class="sd">            [1., 2.]])</span>
<span class="sd">    &gt;&gt;&gt; print(g.ndata[&#39;h2&#39;])</span>
<span class="sd">    tensor([[11., 12.],</span>
<span class="sd">            [ 9., 10.],</span>
<span class="sd">            [ 7.,  8.]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="n">nids</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="n">perm</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">rand_shuffle</span><span class="p">(</span><span class="n">nids</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">g</span></div>



<span class="c1"># pylint: disable=C0103</span>
<div class="viewcode-block" id="DropNode">
<a class="viewcode-back" href="../../../generated/dgl.transforms.DropNode.html#dgl.transforms.DropNode">[docs]</a>
<span class="k">class</span> <span class="nc">DropNode</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Randomly drop nodes, as described in</span>
<span class="sd">    `Graph Contrastive Learning with Augmentations &lt;https://arxiv.org/abs/2010.13902&gt;`__.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : float, optional</span>
<span class="sd">        Probability of a node to be dropped.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import DropNode</span>

<span class="sd">    &gt;&gt;&gt; transform = DropNode()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.rand_graph(5, 20)</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.arange(g.num_nodes())</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.arange(g.num_edges())</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g)</span>
<span class="sd">    Graph(num_nodes=3, num_edges=7,</span>
<span class="sd">          ndata_schemes={&#39;h&#39;: Scheme(shape=(), dtype=torch.int64)}</span>
<span class="sd">          edata_schemes={&#39;h&#39;: Scheme(shape=(), dtype=torch.int64)})</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.ndata[&#39;h&#39;])</span>
<span class="sd">    tensor([0, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;h&#39;])</span>
<span class="sd">    tensor([0, 6, 14, 5, 17, 3, 11])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># Fast path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">g</span>

        <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)]))</span>
            <span class="n">nids_to_remove</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)[</span><span class="n">samples</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)]</span>
            <span class="n">g</span><span class="o">.</span><span class="n">remove_nodes</span><span class="p">(</span><span class="n">nids_to_remove</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">ntype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span></div>



<span class="c1"># pylint: disable=C0103</span>
<div class="viewcode-block" id="DropEdge">
<a class="viewcode-back" href="../../../generated/dgl.transforms.DropEdge.html#dgl.transforms.DropEdge">[docs]</a>
<span class="k">class</span> <span class="nc">DropEdge</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Randomly drop edges, as described in</span>
<span class="sd">    `DropEdge: Towards Deep Graph Convolutional Networks on Node Classification</span>
<span class="sd">    &lt;https://arxiv.org/abs/1907.10903&gt;`__ and `Graph Contrastive Learning with Augmentations</span>
<span class="sd">    &lt;https://arxiv.org/abs/2010.13902&gt;`__.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : float, optional</span>
<span class="sd">        Probability of an edge to be dropped.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import DropEdge</span>

<span class="sd">    &gt;&gt;&gt; transform = DropEdge()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.rand_graph(5, 20)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.arange(g.num_edges())</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g)</span>
<span class="sd">    Graph(num_nodes=5, num_edges=12,</span>
<span class="sd">          ndata_schemes={}</span>
<span class="sd">          edata_schemes={&#39;h&#39;: Scheme(shape=(), dtype=torch.int64)})</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.edata[&#39;h&#39;])</span>
<span class="sd">    tensor([0, 1, 3, 7, 8, 10, 11, 12, 13, 15, 18, 19])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="c1"># Fast path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">g</span>

        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)]))</span>
            <span class="n">eids_to_remove</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)[</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">g</span><span class="o">.</span><span class="n">remove_edges</span><span class="p">(</span><span class="n">eids_to_remove</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="AddEdge">
<a class="viewcode-back" href="../../../generated/dgl.transforms.AddEdge.html#dgl.transforms.AddEdge">[docs]</a>
<span class="k">class</span> <span class="nc">AddEdge</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Randomly add edges, as described in `Graph Contrastive Learning with Augmentations</span>
<span class="sd">    &lt;https://arxiv.org/abs/2010.13902&gt;`__.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    ratio : float, optional</span>
<span class="sd">        Number of edges to add divided by the number of existing edges.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import AddEdge</span>

<span class="sd">    &gt;&gt;&gt; transform = AddEdge()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.rand_graph(5, 20)</span>
<span class="sd">    &gt;&gt;&gt; new_g = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(new_g.num_edges())</span>
<span class="sd">    24</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="c1"># Fast path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">g</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
        <span class="n">idtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">utype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vtype</span> <span class="o">=</span> <span class="n">c_etype</span>
            <span class="n">num_edges_to_add</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">c_etype</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">)</span>
            <span class="n">src</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                <span class="p">[</span><span class="n">num_edges_to_add</span><span class="p">],</span>
                <span class="n">idtype</span><span class="p">,</span>
                <span class="n">device</span><span class="p">,</span>
                <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">utype</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">dst</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                <span class="p">[</span><span class="n">num_edges_to_add</span><span class="p">],</span>
                <span class="n">idtype</span><span class="p">,</span>
                <span class="n">device</span><span class="p">,</span>
                <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">high</span><span class="o">=</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">vtype</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">g</span><span class="o">.</span><span class="n">add_edges</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span></div>



<div class="viewcode-block" id="SIGNDiffusion">
<a class="viewcode-back" href="../../../generated/dgl.transforms.SIGNDiffusion.html#dgl.transforms.SIGNDiffusion">[docs]</a>
<span class="k">class</span> <span class="nc">SIGNDiffusion</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;The diffusion operator from `SIGN: Scalable Inception Graph Neural Networks</span>
<span class="sd">    &lt;https://arxiv.org/abs/2004.11198&gt;`__</span>

<span class="sd">    It performs node feature diffusion with :math:`TX, \cdots, T^{k}X`, where :math:`T`</span>
<span class="sd">    is a diffusion matrix and :math:`X` is the input node features.</span>

<span class="sd">    Specifically, this module provides four options for :math:`T`.</span>

<span class="sd">    **raw**: raw adjacency matrix :math:`A`</span>

<span class="sd">    **rw**: random walk (row-normalized) adjacency matrix :math:`D^{-1}A`, where</span>
<span class="sd">    :math:`D` is the degree matrix.</span>

<span class="sd">    **gcn**: symmetrically normalized adjacency matrix used by</span>
<span class="sd">    `GCN &lt;https://arxiv.org/abs/1609.02907&gt;`__, :math:`D^{-1/2}AD^{-1/2}`</span>

<span class="sd">    **ppr**: approximate personalized PageRank used by</span>
<span class="sd">    `APPNP &lt;https://arxiv.org/abs/1810.05997&gt;`__</span>

<span class="sd">    .. math::</span>
<span class="sd">        H^{0} &amp;= X</span>

<span class="sd">        H^{l+1} &amp;= (1-\alpha)\left(D^{-1/2}AD^{-1/2} H^{l}\right) + \alpha X</span>

<span class="sd">    This module only works for homogeneous graphs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : int</span>
<span class="sd">        The maximum number of times for node feature diffusion.</span>
<span class="sd">    in_feat_name : str, optional</span>
<span class="sd">        :attr:`g.ndata[{in_feat_name}]` should store the input node features. Default: &#39;feat&#39;</span>
<span class="sd">    out_feat_name : str, optional</span>
<span class="sd">        :attr:`g.ndata[{out_feat_name}_i]` will store the result of diffusing</span>
<span class="sd">        input node features for i times. Default: &#39;out_feat&#39;</span>
<span class="sd">    eweight_name : str, optional</span>
<span class="sd">        Name to retrieve edge weights from :attr:`g.edata`. Default: None,</span>
<span class="sd">        treating the graph as unweighted.</span>
<span class="sd">    diffuse_op : str, optional</span>
<span class="sd">        The diffusion operator to use, which can be &#39;raw&#39;, &#39;rw&#39;, &#39;gcn&#39;, or &#39;ppr&#39;.</span>
<span class="sd">        Default: &#39;raw&#39;</span>
<span class="sd">    alpha : float, optional</span>
<span class="sd">        Restart probability if :attr:`diffuse_op` is :attr:`&#39;ppr&#39;`,</span>
<span class="sd">        which commonly lies in :math:`[0.05, 0.2]`. Default: 0.2</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>

<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from dgl import SIGNDiffusion</span>

<span class="sd">    &gt;&gt;&gt; transform = SIGNDiffusion(k=2, eweight_name=&#39;w&#39;)</span>
<span class="sd">    &gt;&gt;&gt; num_nodes = 5</span>
<span class="sd">    &gt;&gt;&gt; num_edges = 20</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.rand_graph(num_nodes, num_edges)</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;feat&#39;] = torch.randn(num_nodes, 10)</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = torch.randn(num_edges)</span>
<span class="sd">    &gt;&gt;&gt; transform(g)</span>
<span class="sd">    Graph(num_nodes=5, num_edges=20,</span>
<span class="sd">          ndata_schemes={&#39;feat&#39;: Scheme(shape=(10,), dtype=torch.float32),</span>
<span class="sd">                         &#39;out_feat_1&#39;: Scheme(shape=(10,), dtype=torch.float32),</span>
<span class="sd">                         &#39;out_feat_2&#39;: Scheme(shape=(10,), dtype=torch.float32)}</span>
<span class="sd">          edata_schemes={&#39;w&#39;: Scheme(shape=(), dtype=torch.float32)})</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">k</span><span class="p">,</span>
        <span class="n">in_feat_name</span><span class="o">=</span><span class="s2">&quot;feat&quot;</span><span class="p">,</span>
        <span class="n">out_feat_name</span><span class="o">=</span><span class="s2">&quot;out_feat&quot;</span><span class="p">,</span>
        <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">diffuse_op</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span> <span class="o">=</span> <span class="n">in_feat_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_feat_name</span> <span class="o">=</span> <span class="n">out_feat_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="o">=</span> <span class="n">eweight_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diffuse_op</span> <span class="o">=</span> <span class="n">diffuse_op</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="k">if</span> <span class="n">diffuse_op</span> <span class="o">==</span> <span class="s2">&quot;raw&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">diffuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw</span>
        <span class="k">elif</span> <span class="n">diffuse_op</span> <span class="o">==</span> <span class="s2">&quot;rw&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">diffuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rw</span>
        <span class="k">elif</span> <span class="n">diffuse_op</span> <span class="o">==</span> <span class="s2">&quot;gcn&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">diffuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn</span>
        <span class="k">elif</span> <span class="n">diffuse_op</span> <span class="o">==</span> <span class="s2">&quot;ppr&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">diffuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ppr</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Expect diffuse_op to be from [&#39;raw&#39;, &#39;rw&#39;, &#39;gcn&#39;, &#39;ppr&#39;], </span><span class="se">\</span>
<span class="s2">                got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">diffuse_op</span>
                <span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">feat_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diffuse</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">out_feat_name</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">feat_list</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">g</span>

    <span class="k">def</span> <span class="nf">raw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">use_eweight</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">:</span>
            <span class="n">use_eweight</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">feat_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">use_eweight</span><span class="p">:</span>
                <span class="n">message_func</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">message_func</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">copy_u</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span><span class="n">message_func</span><span class="p">,</span> <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">))</span>
                <span class="n">feat_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">feat_list</span>

    <span class="k">def</span> <span class="nf">rw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">use_eweight</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">:</span>
            <span class="n">use_eweight</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">feat_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;h&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">use_eweight</span><span class="p">:</span>
                <span class="n">message_func</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span><span class="s2">&quot;h&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">)</span>
                <span class="n">reduce_func</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="s2">&quot;h&quot;</span><span class="p">)</span>
                <span class="c1"># Compute the diagonal entries of D from the weighted A</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">copy_e</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">),</span> <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="s2">&quot;z&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">message_func</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">copy_u</span><span class="p">(</span><span class="s2">&quot;h&quot;</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">)</span>
                <span class="n">reduce_func</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="s2">&quot;h&quot;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span><span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">use_eweight</span><span class="p">:</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;h&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;h&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;z&quot;</span><span class="p">],</span> <span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">feat_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="s2">&quot;h&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">feat_list</span>

    <span class="k">def</span> <span class="nf">gcn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">feat_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">eweight_name</span> <span class="o">=</span> <span class="s2">&quot;w&quot;</span>
                <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">:</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">eweight_name</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eweight_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span>

            <span class="n">transform</span> <span class="o">=</span> <span class="n">GCNNorm</span><span class="p">(</span><span class="n">eweight_name</span><span class="o">=</span><span class="n">eweight_name</span><span class="p">)</span>
            <span class="n">transform</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">,</span> <span class="n">eweight_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">),</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">feat_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">feat_list</span>

    <span class="k">def</span> <span class="nf">ppr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">feat_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">eweight_name</span> <span class="o">=</span> <span class="s2">&quot;w&quot;</span>
                <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="p">:</span>
                    <span class="n">g</span><span class="o">.</span><span class="n">edata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">eweight_name</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">eweight_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eweight_name</span>
            <span class="n">transform</span> <span class="o">=</span> <span class="n">GCNNorm</span><span class="p">(</span><span class="n">eweight_name</span><span class="o">=</span><span class="n">eweight_name</span><span class="p">)</span>
            <span class="n">transform</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

            <span class="n">in_feat</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                <span class="n">g</span><span class="o">.</span><span class="n">update_all</span><span class="p">(</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">u_mul_e</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">,</span> <span class="n">eweight_name</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">),</span>
                    <span class="n">fn</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span>
                <span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">in_feat</span>
                <span class="n">feat_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feat_name</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">feat_list</span></div>



<div class="viewcode-block" id="ToLevi">
<a class="viewcode-back" href="../../../generated/dgl.transforms.ToLevi.html#dgl.transforms.ToLevi">[docs]</a>
<span class="k">class</span> <span class="nc">ToLevi</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;This function transforms the original graph to its heterogeneous Levi graph,</span>
<span class="sd">    by converting edges to intermediate nodes, only support homogeneous directed graph.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; import torch as th</span>
<span class="sd">    &gt;&gt;&gt; from dgl import ToLevi</span>

<span class="sd">    &gt;&gt;&gt; transform = ToLevi()</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 0]))</span>
<span class="sd">    &gt;&gt;&gt; g.ndata[&#39;h&#39;] = th.randn((g.num_nodes(), 2))</span>
<span class="sd">    &gt;&gt;&gt; g.edata[&#39;w&#39;] = th.randn((g.num_edges(), 2))</span>
<span class="sd">    &gt;&gt;&gt; lg = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; lg</span>
<span class="sd">    Grpah(num_nodes={&#39;edge&#39;: 4, &#39;node&#39;: 4},</span>
<span class="sd">          num_edges={(&#39;edge&#39;, &#39;e2n&#39;, &#39;node&#39;): 4,</span>
<span class="sd">                     (&#39;node&#39;, &#39;n2e&#39;, &#39;edge&#39;): 4},</span>
<span class="sd">          metagraph=[(&#39;edge&#39;, &#39;node&#39;, &#39;e2n&#39;),</span>
<span class="sd">                     (&#39;node&#39;, &#39;edge&#39;, &#39;n2e&#39;)])</span>
<span class="sd">    &gt;&gt;&gt; lg.nodes(&#39;node&#39;)</span>
<span class="sd">    tensor([0, 1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; lg.nodes(&#39;edge&#39;)</span>
<span class="sd">    tensor([0, 1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; lg.nodes[&#39;node&#39;].data[&#39;h&#39;].shape</span>
<span class="sd">    torch.Size([4, 2])</span>
<span class="sd">    &gt;&gt;&gt; lg.nodes[&#39;edge&#39;].data[&#39;w&#39;].shape</span>
<span class="sd">    torch.Size([4, 2])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        g : DGLGraph</span>
<span class="sd">            The input graph, should be a homogeneous directed graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The Levi graph of input, will be a heterogeneous graph, where nodes of</span>
<span class="sd">            ntypes ``&#39;node&#39;`` and ``&#39;edge&#39;`` have corresponding IDs of nodes and edges</span>
<span class="sd">            in the original graph. Edge features of the input graph are copied to</span>
<span class="sd">            corresponding new nodes of ntype ``&#39;edge&#39;``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span>
        <span class="n">idtype</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">idtype</span>

        <span class="n">edge_list</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
        <span class="n">n2e</span> <span class="o">=</span> <span class="n">edge_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">e2n</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),</span> <span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="p">),</span> <span class="n">edge_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">graph_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">,</span> <span class="s2">&quot;n2e&quot;</span><span class="p">,</span> <span class="s2">&quot;edge&quot;</span><span class="p">):</span> <span class="n">n2e</span><span class="p">,</span>
            <span class="p">(</span><span class="s2">&quot;edge&quot;</span><span class="p">,</span> <span class="s2">&quot;e2n&quot;</span><span class="p">,</span> <span class="s2">&quot;node&quot;</span><span class="p">):</span> <span class="n">e2n</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">levi_g</span> <span class="o">=</span> <span class="n">convert</span><span class="o">.</span><span class="n">heterograph</span><span class="p">(</span><span class="n">graph_data</span><span class="p">,</span> <span class="n">idtype</span><span class="o">=</span><span class="n">idtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Copy ndata and edata</span>
        <span class="c1"># Since the node types in dgl.heterograph are in alphabetical order</span>
        <span class="c1"># (&#39;edge&#39; &lt; &#39;node&#39;), edge_frames should be in front of node_frames.</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_node_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodes_or_device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">edge_frames</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">extract_edge_subframes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">edges_or_device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">set_new_frames</span><span class="p">(</span><span class="n">levi_g</span><span class="p">,</span> <span class="n">node_frames</span><span class="o">=</span><span class="n">edge_frames</span> <span class="o">+</span> <span class="n">node_frames</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">levi_g</span></div>



<div class="viewcode-block" id="SVDPE">
<a class="viewcode-back" href="../../../generated/dgl.transforms.SVDPE.html#dgl.transforms.SVDPE">[docs]</a>
<span class="k">class</span> <span class="nc">SVDPE</span><span class="p">(</span><span class="n">BaseTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;SVD-based Positional Encoding, as introduced in</span>
<span class="sd">    `Global Self-Attention as a Replacement for Graph Convolution</span>
<span class="sd">    &lt;https://arxiv.org/pdf/2108.03348.pdf&gt;`__</span>

<span class="sd">    This function computes the largest :math:`k` singular values and</span>
<span class="sd">    corresponding left and right singular vectors to form positional encodings,</span>
<span class="sd">    which could be stored in ndata.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k : int</span>
<span class="sd">        Number of largest singular values and corresponding singular vectors</span>
<span class="sd">        used for positional encoding.</span>
<span class="sd">    feat_name : str, optional</span>
<span class="sd">        Name to store the computed positional encodings in ndata.</span>
<span class="sd">        Default : ``svd_pe``</span>
<span class="sd">    padding : bool, optional</span>
<span class="sd">        If False, raise an error when :math:`k &gt; N`,</span>
<span class="sd">        where :math:`N` is the number of nodes in :attr:`g`.</span>
<span class="sd">        If True, add zero paddings in the end of encodings when :math:`k &gt; N`.</span>
<span class="sd">        Default : False.</span>
<span class="sd">    random_flip : bool, optional</span>
<span class="sd">        If True, randomly flip the signs of encoding vectors.</span>
<span class="sd">        Proposed to be activated during training for better generalization.</span>
<span class="sd">        Default : True.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; import dgl</span>
<span class="sd">    &gt;&gt;&gt; from dgl import SVDPE</span>

<span class="sd">    &gt;&gt;&gt; transform = SVDPE(k=2, feat_name=&quot;svd_pe&quot;)</span>
<span class="sd">    &gt;&gt;&gt; g = dgl.graph(([0,1,2,3,4,2,3,1,4,0], [2,3,1,4,0,0,1,2,3,4]))</span>
<span class="sd">    &gt;&gt;&gt; g_ = transform(g)</span>
<span class="sd">    &gt;&gt;&gt; print(g_.ndata[&#39;svd_pe&#39;])</span>
<span class="sd">    tensor([[-6.3246e-01, -1.1373e-07, -6.3246e-01,  0.0000e+00],</span>
<span class="sd">            [-6.3246e-01,  7.6512e-01, -6.3246e-01, -7.6512e-01],</span>
<span class="sd">            [ 6.3246e-01,  4.7287e-01,  6.3246e-01, -4.7287e-01],</span>
<span class="sd">            [-6.3246e-01, -7.6512e-01, -6.3246e-01,  7.6512e-01],</span>
<span class="sd">            [ 6.3246e-01, -4.7287e-01,  6.3246e-01,  4.7287e-01]])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">feat_name</span><span class="o">=</span><span class="s2">&quot;svd_pe&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_flip</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_name</span> <span class="o">=</span> <span class="n">feat_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_flip</span> <span class="o">=</span> <span class="n">random_flip</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">svd_pe</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">random_flip</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_flip</span>
        <span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">ndata</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">encoding</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">g</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>