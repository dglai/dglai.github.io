<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dgl.heterograph &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../stochastic_training/index.html">üÜï Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_cn/index.html">Áî®Êà∑ÊåáÂçó„ÄêÂåÖÂê´ËøáÊó∂‰ø°ÊÅØ„Äë</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_ko/index.html">ÏÇ¨Ïö©Ïûê Í∞ÄÏù¥Îìú[ÏãúÎåÄÏóê Îí§Ï≥êÏßÑ]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../graphtransformer/index.html">üÜï Tutorial: Graph Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/sparse/index.html">Tutorials: dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.graphbolt.html">üÜï dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dgl.heterograph</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dgl.heterograph</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Classes for heterogeneous graphs.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numbers</span>

<span class="c1"># pylint: disable= too-many-lines</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Mapping</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>

<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">core</span><span class="p">,</span> <span class="n">graph_index</span><span class="p">,</span> <span class="n">heterograph_index</span><span class="p">,</span> <span class="n">utils</span>

<span class="kn">from</span> <span class="nn">._ffi.function</span> <span class="kn">import</span> <span class="n">_init_api</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ALL</span><span class="p">,</span>
    <span class="n">dgl_warning</span><span class="p">,</span>
    <span class="n">DGLError</span><span class="p">,</span>
    <span class="n">EID</span><span class="p">,</span>
    <span class="n">ETYPE</span><span class="p">,</span>
    <span class="n">is_all</span><span class="p">,</span>
    <span class="n">NID</span><span class="p">,</span>
    <span class="n">NTYPE</span><span class="p">,</span>
    <span class="n">SLICE_FULL</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.frame</span> <span class="kn">import</span> <span class="n">Frame</span>
<span class="kn">from</span> <span class="nn">.ops</span> <span class="kn">import</span> <span class="n">segment</span>
<span class="kn">from</span> <span class="nn">.view</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">HeteroEdgeDataView</span><span class="p">,</span>
    <span class="n">HeteroEdgeView</span><span class="p">,</span>
    <span class="n">HeteroNodeDataView</span><span class="p">,</span>
    <span class="n">HeteroNodeView</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;DGLGraph&quot;</span><span class="p">,</span> <span class="s2">&quot;combine_names&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="DGLGraph">
<a class="viewcode-back" href="../../api/python/dgl.DGLGraph.html#dgl.DGLGraph">[docs]</a>
<span class="k">class</span> <span class="nc">DGLGraph</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for storing graph structure and node/edge feature data.</span>

<span class="sd">    There are a few ways to create a DGLGraph:</span>

<span class="sd">    * To create a homogeneous graph from Tensor data, use :func:`dgl.graph`.</span>
<span class="sd">    * To create a heterogeneous graph from Tensor data, use :func:`dgl.heterograph`.</span>
<span class="sd">    * To create a graph from other data sources, use ``dgl.*`` create ops. See</span>
<span class="sd">      :ref:`api-graph-create-ops`.</span>

<span class="sd">    Read the user guide chapter :ref:`guide-graph` for an in-depth explanation about its</span>
<span class="sd">    usage.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">is_block</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># pylint: disable=unused-argument, dangerous-default-value</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">gidx</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">ntypes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;_N&quot;</span><span class="p">],</span>
        <span class="n">etypes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;_E&quot;</span><span class="p">],</span>
        <span class="n">node_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">edge_frames</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">deprecate_kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal constructor for creating a DGLGraph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gidx : HeteroGraphIndex</span>
<span class="sd">            Graph index object.</span>
<span class="sd">        ntypes : list of str, pair of list of str</span>
<span class="sd">            Node type list. ``ntypes[i]`` stores the name of node type i.</span>
<span class="sd">            If a pair is given, the graph created is a uni-directional bipartite graph,</span>
<span class="sd">            and its SRC node types and DST node types are given as in the pair.</span>
<span class="sd">        etypes : list of str</span>
<span class="sd">            Edge type list. ``etypes[i]`` stores the name of edge type i.</span>
<span class="sd">        node_frames : list[Frame], optional</span>
<span class="sd">            Node feature storage. If None, empty frame is created.</span>
<span class="sd">            Otherwise, ``node_frames[i]`` stores the node features</span>
<span class="sd">            of node type i. (default: None)</span>
<span class="sd">        edge_frames : list[Frame], optional</span>
<span class="sd">            Edge feature storage. If None, empty frame is created.</span>
<span class="sd">            Otherwise, ``edge_frames[i]`` stores the edge features</span>
<span class="sd">            of edge type i. (default: None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gidx</span><span class="p">,</span> <span class="n">DGLGraph</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;The input is already a DGLGraph. No need to create it again.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gidx</span><span class="p">,</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">HeteroGraphIndex</span><span class="p">):</span>
            <span class="n">dgl_warning</span><span class="p">(</span>
                <span class="s2">&quot;Recommend creating graphs by `dgl.graph(data)`&quot;</span>
                <span class="s2">&quot; instead of `dgl.DGLGraph(data)`.&quot;</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">sparse_fmt</span><span class="p">,</span> <span class="n">arrays</span><span class="p">),</span> <span class="n">num_src</span><span class="p">,</span> <span class="n">num_dst</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">graphdata2tensors</span><span class="p">(</span>
                <span class="n">gidx</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">sparse_fmt</span> <span class="o">==</span> <span class="s2">&quot;coo&quot;</span><span class="p">:</span>
                <span class="n">gidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_coo</span><span class="p">(</span>
                    <span class="mi">1</span><span class="p">,</span>
                    <span class="n">num_src</span><span class="p">,</span>
                    <span class="n">num_dst</span><span class="p">,</span>
                    <span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">arrays</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">gidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_csr</span><span class="p">(</span>
                    <span class="mi">1</span><span class="p">,</span>
                    <span class="n">num_src</span><span class="p">,</span>
                    <span class="n">num_dst</span><span class="p">,</span>
                    <span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">arrays</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">arrays</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                    <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span>
                    <span class="n">sparse_fmt</span> <span class="o">==</span> <span class="s2">&quot;csc&quot;</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">deprecate_kwargs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">dgl_warning</span><span class="p">(</span>
                <span class="s2">&quot;Keyword arguments </span><span class="si">{}</span><span class="s2"> are deprecated in v0.5, and can be safely&quot;</span>
                <span class="s2">&quot; removed in all cases.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">deprecate_kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">(</span><span class="n">gidx</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">,</span> <span class="n">node_frames</span><span class="p">,</span> <span class="n">edge_frames</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gidx</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">etypes</span><span class="p">,</span> <span class="n">node_frames</span><span class="p">,</span> <span class="n">edge_frames</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Init internal states.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">gidx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Handle node types</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ntypes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">errmsg</span> <span class="o">=</span> <span class="s2">&quot;Invalid input. Expect a pair (srctypes, dsttypes) but got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">ntypes</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">errmsg</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">is_metagraph_unibipartite</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Invalid input. The metagraph must be a uni-directional&quot;</span>
                    <span class="s2">&quot; bipartite graph.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span> <span class="o">=</span> <span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ntypes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">])}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">t</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_unibipartite</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ntypes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span> <span class="o">=</span> <span class="n">ntypes</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">src_dst_map</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">src_dst_map</span> <span class="o">=</span> <span class="n">find_src_dst_ntypes</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_unibipartite</span> <span class="o">=</span> <span class="n">src_dst_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_unibipartite</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span> <span class="o">=</span> <span class="n">src_dst_map</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">t</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span><span class="p">)</span>
                <span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span>

        <span class="c1"># Handle edge types</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_etypes</span> <span class="o">=</span> <span class="n">etypes</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span> <span class="o">=</span> <span class="n">make_canonical_etypes</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_etypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span>
                <span class="p">)</span>

        <span class="c1"># An internal map from etype to canonical etype tuple.</span>
        <span class="c1"># If two etypes have the same name, an empty tuple is stored instead to indicate</span>
        <span class="c1"># ambiguity.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_etype2canonical</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ety</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_etypes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">ety</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etype2canonical</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_etype2canonical</span><span class="p">[</span><span class="n">ety</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_etype2canonical</span><span class="p">[</span><span class="n">ety</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_etypes_invmap</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">t</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="c1"># node and edge frame</span>
        <span class="k">if</span> <span class="n">node_frames</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span><span class="p">)</span>
        <span class="n">node_frames</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Frame</span><span class="p">(</span><span class="n">num_rows</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">if</span> <span class="n">frame</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">frame</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_frames</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="n">node_frames</span>

        <span class="k">if</span> <span class="n">edge_frames</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_etypes</span><span class="p">)</span>
        <span class="n">edge_frames</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Frame</span><span class="p">(</span><span class="n">num_rows</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">if</span> <span class="n">frame</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">frame</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">edge_frames</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="n">edge_frames</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Compatibility check</span>
        <span class="c1"># TODO: version the storage</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># Since 0.5 we use the default __dict__ method</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="c1"># DGL == 0.4.3</span>
            <span class="n">dgl_warning</span><span class="p">(</span>
                <span class="s2">&quot;The object is pickled with DGL == 0.4.3.  &quot;</span>
                <span class="s2">&quot;Some of the original attributes are ignored.&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">(</span><span class="o">*</span><span class="n">state</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># DGL &lt;= 0.4.2</span>
            <span class="n">dgl_warning</span><span class="p">(</span>
                <span class="s2">&quot;The object is pickled with DGL &lt;= 0.4.2.  &quot;</span>
                <span class="s2">&quot;Some of the original attributes are ignored.&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">(</span>
                <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_graph&quot;</span><span class="p">],</span>
                <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_ntypes&quot;</span><span class="p">],</span>
                <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_etypes&quot;</span><span class="p">],</span>
                <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_node_frames&quot;</span><span class="p">],</span>
                <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_edge_frames&quot;</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s2">&quot;Unrecognized pickle format.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Graph(num_nodes=</span><span class="si">{node}</span><span class="s2">, num_edges=</span><span class="si">{edge}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      ndata_schemes=</span><span class="si">{ndata}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      edata_schemes=</span><span class="si">{edata}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">node</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(),</span>
                <span class="n">edge</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),</span>
                <span class="n">ndata</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_attr_schemes</span><span class="p">()),</span>
                <span class="n">edata</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_attr_schemes</span><span class="p">()),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Graph(num_nodes=</span><span class="si">{node}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      num_edges=</span><span class="si">{edge}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      metagraph=</span><span class="si">{meta}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
            <span class="n">nnode_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">))</span>
            <span class="p">}</span>
            <span class="n">nedge_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">))</span>
            <span class="p">}</span>
            <span class="n">meta</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metagraph</span><span class="p">()</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">keys</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">nnode_dict</span><span class="p">,</span> <span class="n">edge</span><span class="o">=</span><span class="n">nedge_dict</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="n">meta</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__copy__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shallow copy implementation.&quot;&quot;&quot;</span>
        <span class="c1"># TODO(minjie): too many states in python; should clean up and lower to C</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
        <span class="n">obj</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj</span>

    <span class="c1">#################################################################</span>
    <span class="c1"># Mutation operations</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.add_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.add_nodes.html#dgl.DGLGraph.add_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">add_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add new nodes of the same node type</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        num : int</span>
<span class="sd">            Number of nodes to add.</span>
<span class="sd">        data : dict, optional</span>
<span class="sd">            Feature data of the added nodes.</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The type of the new nodes. Can be omitted if there is</span>
<span class="sd">            only one node type in the graph.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>

<span class="sd">        * Inplace update is applied to the current graph.</span>
<span class="sd">        * If the key of ``data`` does not contain some existing feature fields,</span>
<span class="sd">          those features for the new nodes will be created by initializers</span>
<span class="sd">          defined with :func:`set_n_initializer` (default initializer fills zeros).</span>
<span class="sd">        * If the key of ``data`` contains new feature fields, those features for</span>
<span class="sd">          the old nodes will be created by initializers defined with</span>
<span class="sd">          :func:`set_n_initializer` (default initializer fills zeros).</span>
<span class="sd">        * This function discards the batch information. Please use</span>
<span class="sd">          :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">          and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">          to maintain the information.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous Graphs or Heterogeneous Graphs with A Single Node Type**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">        3</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(2)</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">        5</span>

<span class="sd">        If the graph has some node features and new nodes are added without</span>
<span class="sd">        features, their features will be created by initializers defined</span>
<span class="sd">        with :func:`set_n_initializer`.</span>

<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(5, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(1)</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.], [1.], [1.], [1.], [1.], [0.]])</span>

<span class="sd">        We can also assign features for the new nodes in adding new nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.add_nodes(1, {&#39;h&#39;: torch.ones(1, 1), &#39;w&#39;: torch.ones(1, 1)})</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.], [1.], [1.], [1.], [1.], [0.], [1.]])</span>

<span class="sd">        Since ``data`` contains new feature fields, the features for old nodes</span>
<span class="sd">        will be created by initializers defined with :func:`set_n_initializer`.</span>

<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;w&#39;]</span>
<span class="sd">        tensor([[0.], [0.], [0.], [0.], [0.], [0.], [1.]])</span>


<span class="sd">        **Heterogeneous Graphs with Multiple Node Types**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(2)</span>
<span class="sd">        DGLError: Node type name must be specified</span>
<span class="sd">        if there are more than one node types.</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">        3</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(2, ntype=&#39;user&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">        5</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        remove_nodes</span>
<span class="sd">        add_edges</span>
<span class="sd">        remove_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(xiangsx): block do not support add_nodes</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_ntypes</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Node type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;node types.&quot;</span>
                <span class="p">)</span>

        <span class="c1"># nothing happen</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">assert</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Number of new nodes should be larger than one.&quot;</span>
        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="c1"># update graph idx</span>
        <span class="n">metagraph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span>
        <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c_ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">)</span> <span class="o">==</span> <span class="n">ntid</span><span class="p">:</span>
                <span class="n">num_nodes_per_type</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">)</span> <span class="o">+</span> <span class="n">num</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">num_nodes_per_type</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">))</span>

        <span class="n">relation_graphs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="c1"># src or dst == ntype, update the relation graph</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">ntid</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">==</span> <span class="n">ntid</span>
            <span class="p">):</span>
                <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
                <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_coo</span><span class="p">(</span>
                    <span class="mi">1</span> <span class="k">if</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">else</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="o">+</span> <span class="p">(</span><span class="n">num</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">ntid</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                    <span class="o">+</span> <span class="p">(</span><span class="n">num</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">==</span> <span class="n">ntid</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">u</span><span class="p">,</span>
                    <span class="n">v</span><span class="p">,</span>
                    <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">relation_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hgidx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># do nothing</span>
                <span class="n">relation_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">get_relation_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">))</span>
                <span class="p">)</span>
        <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
            <span class="n">metagraph</span><span class="p">,</span>
            <span class="n">relation_graphs</span><span class="p">,</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span><span class="n">num_nodes_per_type</span><span class="p">,</span> <span class="s2">&quot;int64&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">hgidx</span>

        <span class="c1"># update data frames</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Initialize feature with :func:`set_n_initializer`</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">add_rows</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_cached_info</span><span class="p">()</span></div>


<div class="viewcode-block" id="DGLGraph.add_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.add_edges.html#dgl.DGLGraph.add_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">add_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add multiple new edges for the specified edge type</span>

<span class="sd">        The i-th new edge will be from ``u[i]`` to ``v[i]``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u : int, tensor, numpy.ndarray, list</span>
<span class="sd">            Source node IDs, ``u[i]`` gives the source node for the i-th new edge.</span>
<span class="sd">        v : int, tensor, numpy.ndarray, list</span>
<span class="sd">            Destination node IDs, ``v[i]`` gives the destination node for the i-th new edge.</span>
<span class="sd">        data : dict, optional</span>
<span class="sd">            Feature data of the added edges. The i-th row of the feature data</span>
<span class="sd">            corresponds to the i-th new edge.</span>
<span class="sd">        etype : str or tuple of str, optional</span>
<span class="sd">            The type of the new edges. Can be omitted if there is</span>
<span class="sd">            only one edge type in the graph.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>

<span class="sd">        * Inplace update is applied to the current graph.</span>
<span class="sd">        * If end nodes of adding edges does not exists, add_nodes is invoked</span>
<span class="sd">          to add new nodes. The node features of the new nodes will be created</span>
<span class="sd">          by initializers defined with :func:`set_n_initializer` (default</span>
<span class="sd">          initializer fills zeros). In certain cases, it is recommanded to</span>
<span class="sd">          add_nodes first and then add_edges.</span>
<span class="sd">        * If the key of ``data`` does not contain some existing feature fields,</span>
<span class="sd">          those features for the new edges will be created by initializers</span>
<span class="sd">          defined with :func:`set_n_initializer` (default initializer fills zeros).</span>
<span class="sd">        * If the key of ``data`` contains new feature fields, those features for</span>
<span class="sd">          the old edges will be created by initializers defined with</span>
<span class="sd">          :func:`set_n_initializer` (default initializer fills zeros).</span>
<span class="sd">        * This function discards the batch information. Please use</span>
<span class="sd">          :func:`dgl.DGLGraph.set_batch_num_nodes`</span>
<span class="sd">          and :func:`dgl.DGLGraph.set_batch_num_edges` on the transformed graph</span>
<span class="sd">          to maintain the information.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous Graphs or Heterogeneous Graphs with A Single Edge Type**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges()</span>
<span class="sd">        2</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([1, 3]), torch.tensor([0, 1]))</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges()</span>
<span class="sd">        4</span>

<span class="sd">        Since ``u`` or ``v`` contains a non-existing node ID, the nodes are</span>
<span class="sd">        added implicitly.</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">        4</span>

<span class="sd">        If the graph has some edge features and new edges are added without</span>
<span class="sd">        features, their features will be created by initializers defined</span>
<span class="sd">        with :func:`set_n_initializer`.</span>

<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.ones(4, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([1]), torch.tensor([1]))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.], [1.], [1.], [1.], [0.]])</span>

<span class="sd">        We can also assign features for the new edges in adding new edges.</span>

<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([0, 0]), torch.tensor([2, 2]),</span>
<span class="sd">        ...             {&#39;h&#39;: torch.tensor([[1.], [2.]]), &#39;w&#39;: torch.ones(2, 1)})</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.], [1.], [1.], [1.], [0.], [1.], [2.]])</span>

<span class="sd">        Since ``data`` contains new feature fields, the features for old edges</span>
<span class="sd">        will be created by initializers defined with :func:`set_n_initializer`.</span>

<span class="sd">        &gt;&gt;&gt; g.edata[&#39;w&#39;]</span>
<span class="sd">        tensor([[0.], [0.], [0.], [0.], [0.], [1.], [1.]])</span>

<span class="sd">        **Heterogeneous Graphs with Multiple Edge Types**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([3]), torch.tensor([3]))</span>
<span class="sd">        DGLError: Edge type name must be specified</span>
<span class="sd">        if there are more than one edge types.</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">        4</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([3]), torch.tensor([3]), etype=&#39;plays&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">        5</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_nodes</span>
<span class="sd">        remove_nodes</span>
<span class="sd">        remove_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(xiangsx): block do not support add_edges</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Edge type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;edge types.&quot;</span>
                <span class="p">)</span>

        <span class="c1"># nothing changed</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;The number of source nodes and the number of destination nodes should be same, &quot;</span>
            <span class="s2">&quot;or either the number of source nodes or the number of destination nodes is 1.&quot;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">u_type</span><span class="p">,</span> <span class="n">e_type</span><span class="p">,</span> <span class="n">v_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="c1"># if end nodes of adding edges does not exists</span>
        <span class="c1"># use add_nodes to add new nodes first.</span>
        <span class="n">num_of_u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">u_type</span><span class="p">)</span>
        <span class="n">num_of_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">v_type</span><span class="p">)</span>
        <span class="n">u_max</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">v_max</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">u_type</span> <span class="o">==</span> <span class="n">v_type</span><span class="p">:</span>
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">u_max</span><span class="p">,</span> <span class="n">v_max</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&gt;</span> <span class="n">num_of_u</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_nodes</span><span class="p">(</span><span class="n">num_nodes</span> <span class="o">-</span> <span class="n">num_of_u</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">u_type</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">u_max</span> <span class="o">&gt;</span> <span class="n">num_of_u</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_nodes</span><span class="p">(</span><span class="n">u_max</span> <span class="o">-</span> <span class="n">num_of_u</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">u_type</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">v_max</span> <span class="o">&gt;</span> <span class="n">num_of_v</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_nodes</span><span class="p">(</span><span class="n">v_max</span> <span class="o">-</span> <span class="n">num_of_v</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">v_type</span><span class="p">)</span>

        <span class="c1"># metagraph is not changed</span>
        <span class="n">metagraph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span>
        <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="n">num_nodes_per_type</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span>
        <span class="c1"># update graph idx</span>
        <span class="n">relation_graphs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="c1"># the target edge type</span>
            <span class="k">if</span> <span class="n">c_etype</span> <span class="o">==</span> <span class="p">(</span><span class="n">u_type</span><span class="p">,</span> <span class="n">e_type</span><span class="p">,</span> <span class="n">v_type</span><span class="p">):</span>
                <span class="n">old_u</span><span class="p">,</span> <span class="n">old_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
                <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_coo</span><span class="p">(</span>
                    <span class="mi">1</span> <span class="k">if</span> <span class="n">u_type</span> <span class="o">==</span> <span class="n">v_type</span> <span class="k">else</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">u_type</span><span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">v_type</span><span class="p">),</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">old_u</span><span class="p">,</span> <span class="n">u</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">old_v</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                    <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">],</span>
                <span class="p">)</span>
                <span class="n">relation_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hgidx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># do nothing</span>
                <span class="c1"># Note: node range change has been handled in add_nodes()</span>
                <span class="n">relation_graphs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">get_relation_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">))</span>
                <span class="p">)</span>

        <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
            <span class="n">metagraph</span><span class="p">,</span>
            <span class="n">relation_graphs</span><span class="p">,</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span><span class="n">num_nodes_per_type</span><span class="p">,</span> <span class="s2">&quot;int64&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">hgidx</span>

        <span class="c1"># handle data</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">add_rows</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_cached_info</span><span class="p">()</span></div>


<div class="viewcode-block" id="DGLGraph.remove_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.remove_edges.html#dgl.DGLGraph.remove_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">remove_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eids</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove multiple edges with the specified edge type</span>

<span class="sd">        Nodes will not be removed. After removing edges, the rest</span>
<span class="sd">        edges will be re-indexed using consecutive integers from 0,</span>
<span class="sd">        with their relative order preserved.</span>

<span class="sd">        The features for the removed edges will be removed accordingly.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        eids : int, tensor, numpy.ndarray, list</span>
<span class="sd">            IDs for the edges to remove.</span>
<span class="sd">        etype : str or tuple of str, optional</span>
<span class="sd">            The type of the edges to remove. Can be omitted if there is</span>
<span class="sd">            only one edge type in the graph.</span>
<span class="sd">        store_ids : bool, optional</span>
<span class="sd">            If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``</span>
<span class="sd">            and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,</span>
<span class="sd">            respectively.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function preserves the batch information.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous Graphs or Heterogeneous Graphs with A Single Edge Type**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.remove_edges(torch.tensor([0, 1]))</span>
<span class="sd">        &gt;&gt;&gt; g</span>
<span class="sd">        Graph(num_nodes=3, num_edges=1,</span>
<span class="sd">            ndata_schemes={}</span>
<span class="sd">            edata_schemes={&#39;he&#39;: Scheme(shape=(1,), dtype=torch.float32)})</span>
<span class="sd">        &gt;&gt;&gt; g.edges(&#39;all&#39;)</span>
<span class="sd">        (tensor([2]), tensor([2]), tensor([0]))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;he&#39;]</span>
<span class="sd">        tensor([[2.]])</span>

<span class="sd">        Removing edges from a batched graph preserves batch information.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g2 = dgl.graph((torch.tensor([1, 2, 3]), torch.tensor([1, 3, 4])))</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([g, g2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_edges()</span>
<span class="sd">        tensor([3, 3])</span>
<span class="sd">        &gt;&gt;&gt; bg.remove_edges([1, 4])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_edges()</span>
<span class="sd">        tensor([2, 2])</span>

<span class="sd">        **Heterogeneous Graphs with Multiple Edge Types**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.remove_edges(torch.tensor([0, 1]))</span>
<span class="sd">        DGLError: Edge type name must be specified</span>
<span class="sd">        if there are more than one edge types.</span>
<span class="sd">        &gt;&gt;&gt; g.remove_edges(torch.tensor([0, 1]), &#39;plays&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.edges(&#39;all&#39;, etype=&#39;plays&#39;)</span>
<span class="sd">        (tensor([0, 1]), tensor([0, 0]), tensor([0, 1]))</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_nodes</span>
<span class="sd">        add_edges</span>
<span class="sd">        remove_nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(xiangsx): block do not support remove_edges</span>
        <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Edge type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;edge types.&quot;</span>
                <span class="p">)</span>
        <span class="n">eids</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eids</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># no edge to delete</span>
            <span class="k">return</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;The input eid </span><span class="si">{}</span><span class="s2"> is out of the range [0:</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># edge_subgraph</span>
        <span class="n">edges</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">u_type</span><span class="p">,</span> <span class="n">e_type</span><span class="p">,</span> <span class="n">v_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="c1"># the target edge type</span>
            <span class="k">if</span> <span class="n">c_etype</span> <span class="o">==</span> <span class="p">(</span><span class="n">u_type</span><span class="p">,</span> <span class="n">e_type</span><span class="p">,</span> <span class="n">v_type</span><span class="p">):</span>
                <span class="n">origin_eids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">form</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span><span class="p">)</span>
                <span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">compensate</span><span class="p">(</span><span class="n">eids</span><span class="p">,</span> <span class="n">origin_eids</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span>
                    <span class="n">form</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">c_etype</span>
                <span class="p">)</span>

        <span class="c1"># If the graph is batched, update batch_num_edges</span>
        <span class="n">batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">batched</span><span class="p">:</span>
            <span class="n">c_etype</span> <span class="o">=</span> <span class="p">(</span><span class="n">u_type</span><span class="p">,</span> <span class="n">e_type</span><span class="p">,</span> <span class="n">v_type</span><span class="p">)</span>
            <span class="n">one_hot_removed_edges</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">c_etype</span><span class="p">),),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">one_hot_removed_edges</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span>
                <span class="n">one_hot_removed_edges</span><span class="p">,</span>
                <span class="n">eids</span><span class="p">,</span>
                <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eids</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">c_etype_batch_num_edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span>
            <span class="n">batch_num_removed_edges</span> <span class="o">=</span> <span class="n">segment</span><span class="o">.</span><span class="n">segment_reduce</span><span class="p">(</span>
                <span class="n">c_etype_batch_num_edges</span><span class="p">,</span> <span class="n">one_hot_removed_edges</span><span class="p">,</span> <span class="n">reducer</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_etype_batch_num_edges</span> <span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                <span class="n">batch_num_removed_edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span>
            <span class="p">)</span>

        <span class="n">sub_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_subgraph</span><span class="p">(</span>
            <span class="n">edges</span><span class="p">,</span> <span class="n">relabel_nodes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="n">store_ids</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">sub_g</span><span class="o">.</span><span class="n">_graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="n">sub_g</span><span class="o">.</span><span class="n">_node_frames</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="n">sub_g</span><span class="o">.</span><span class="n">_edge_frames</span></div>


<div class="viewcode-block" id="DGLGraph.remove_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.remove_nodes.html#dgl.DGLGraph.remove_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">remove_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nids</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove multiple nodes with the specified node type</span>

<span class="sd">        Edges that connect to the nodes will be removed as well. After removing</span>
<span class="sd">        nodes and edges, the rest nodes and edges will be re-indexed using</span>
<span class="sd">        consecutive integers from 0, with their relative order preserved.</span>

<span class="sd">        The features for the removed nodes/edges will be removed accordingly.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nids : int, tensor, numpy.ndarray, list</span>
<span class="sd">            Nodes to remove.</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The type of the nodes to remove. Can be omitted if there is</span>
<span class="sd">            only one node type in the graph.</span>
<span class="sd">        store_ids : bool, optional</span>
<span class="sd">            If True, it will store the raw IDs of the extracted nodes and edges in the ``ndata``</span>
<span class="sd">            and ``edata`` of the resulting graph under name ``dgl.NID`` and ``dgl.EID``,</span>
<span class="sd">            respectively.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function preserves the batch information.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous Graphs or Heterogeneous Graphs with A Single Node Type**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;hv&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;he&#39;] = torch.arange(3).float().reshape(-1, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.remove_nodes(torch.tensor([0, 1]))</span>
<span class="sd">        &gt;&gt;&gt; g</span>
<span class="sd">        Graph(num_nodes=1, num_edges=1,</span>
<span class="sd">            ndata_schemes={&#39;hv&#39;: Scheme(shape=(1,), dtype=torch.float32)}</span>
<span class="sd">            edata_schemes={&#39;he&#39;: Scheme(shape=(1,), dtype=torch.float32)})</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;hv&#39;]</span>
<span class="sd">        tensor([[2.]])</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;he&#39;]</span>
<span class="sd">        tensor([[2.]])</span>

<span class="sd">        Removing nodes from a batched graph preserves batch information.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 2]), torch.tensor([0, 1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g2 = dgl.graph((torch.tensor([1, 2, 3]), torch.tensor([1, 3, 4])))</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([g, g2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_nodes()</span>
<span class="sd">        tensor([3, 5])</span>
<span class="sd">        &gt;&gt;&gt; bg.remove_nodes([1, 4])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_nodes()</span>
<span class="sd">        tensor([2, 4])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_edges()</span>
<span class="sd">        tensor([2, 2])</span>

<span class="sd">        **Heterogeneous Graphs with Multiple Node Types**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.remove_nodes(torch.tensor([0, 1]))</span>
<span class="sd">        DGLError: Node type name must be specified</span>
<span class="sd">        if there are more than one node types.</span>
<span class="sd">        &gt;&gt;&gt; g.remove_nodes(torch.tensor([0, 1]), ntype=&#39;game&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">        3</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes(&#39;game&#39;)</span>
<span class="sd">        0</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">        0</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        add_nodes</span>
<span class="sd">        add_edges</span>
<span class="sd">        remove_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(xiangsx): block do not support remove_nodes</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_ntypes</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Node type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;node types.&quot;</span>
                <span class="p">)</span>

        <span class="n">nids</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nids</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># no node to delete</span>
            <span class="k">return</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;The input nids </span><span class="si">{}</span><span class="s2"> is out of the range [0:</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">c_ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">)</span> <span class="o">==</span> <span class="n">ntid</span><span class="p">:</span>
                <span class="n">target_ntype</span> <span class="o">=</span> <span class="n">c_ntype</span>
                <span class="n">original_nids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">)</span>
                <span class="n">nodes</span><span class="p">[</span><span class="n">c_ntype</span><span class="p">]</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">compensate</span><span class="p">(</span><span class="n">nids</span><span class="p">,</span> <span class="n">original_nids</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">nodes</span><span class="p">[</span><span class="n">c_ntype</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">)</span>

        <span class="c1"># If the graph is batched, update batch_num_nodes</span>
        <span class="n">batched</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">batched</span><span class="p">:</span>
            <span class="n">one_hot_removed_nodes</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">target_ntype</span><span class="p">),),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">one_hot_removed_nodes</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span>
                <span class="n">one_hot_removed_nodes</span><span class="p">,</span>
                <span class="n">nids</span><span class="p">,</span>
                <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nids</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">c_ntype_batch_num_nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span><span class="p">[</span><span class="n">target_ntype</span><span class="p">]</span>
            <span class="n">batch_num_removed_nodes</span> <span class="o">=</span> <span class="n">segment</span><span class="o">.</span><span class="n">segment_reduce</span><span class="p">(</span>
                <span class="n">c_ntype_batch_num_nodes</span><span class="p">,</span> <span class="n">one_hot_removed_nodes</span><span class="p">,</span> <span class="n">reducer</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span><span class="p">[</span>
                <span class="n">target_ntype</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">c_ntype_batch_num_nodes</span> <span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                <span class="n">batch_num_removed_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span>
            <span class="p">)</span>
            <span class="c1"># Record old num_edges to check later whether some edges were removed</span>
            <span class="n">old_num_edges</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">c_etype</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span>
            <span class="p">}</span>

        <span class="c1"># node_subgraph</span>
        <span class="c1"># If batch_num_edges is to be updated, record the original edge IDs</span>
        <span class="n">sub_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">store_ids</span><span class="o">=</span><span class="n">store_ids</span> <span class="ow">or</span> <span class="n">batched</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">sub_g</span><span class="o">.</span><span class="n">_graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="n">sub_g</span><span class="o">.</span><span class="n">_node_frames</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="n">sub_g</span><span class="o">.</span><span class="n">_edge_frames</span>

        <span class="c1"># If the graph is batched, update batch_num_edges</span>
        <span class="k">if</span> <span class="n">batched</span><span class="p">:</span>
            <span class="n">canonical_etypes</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">c_etype</span>
                <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">))</span>
                <span class="o">!=</span> <span class="n">old_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span>
            <span class="p">]</span>

            <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="n">canonical_etypes</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,),</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">one_hot_left_edges</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">old_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">],),</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="n">eids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span>
                <span class="n">one_hot_left_edges</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">scatter_row</span><span class="p">(</span>
                    <span class="n">one_hot_left_edges</span><span class="p">,</span>
                    <span class="n">eids</span><span class="p">,</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">full_1d</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eids</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">batch_num_left_edges</span> <span class="o">=</span> <span class="n">segment</span><span class="o">.</span><span class="n">segment_reduce</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">],</span>
                    <span class="n">one_hot_left_edges</span><span class="p">,</span>
                    <span class="n">reducer</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
                    <span class="n">batch_num_left_edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">batched</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">store_ids</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">c_ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">c_ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">NID</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">c_etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">EID</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_reset_cached_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Some info like batch_num_nodes may be stale after mutation</span>
<span class="sd">        Clean these cached info</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1">#################################################################</span>
    <span class="c1"># Metagraph query</span>
    <span class="c1">#################################################################</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_unibipartite</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the graph is a uni-bipartite graph.</span>

<span class="sd">        A uni-bipartite heterograph can further divide its node types into two sets:</span>
<span class="sd">        SRC and DST. All edges are from nodes in SRC to nodes in DST. The following APIs</span>
<span class="sd">        can be used to get the type, data, and nodes that belong to SRC and DST sets:</span>

<span class="sd">        * :func:`srctype` and :func:`dsttype`</span>
<span class="sd">        * :func:`srcdata` and :func:`dstdata`</span>
<span class="sd">        * :func:`srcnodes` and :func:`dstnodes`</span>

<span class="sd">        Note that we allow two node types to have the same name as long as one</span>
<span class="sd">        belongs to SRC while the other belongs to DST. To distinguish them, prepend</span>
<span class="sd">        the name with ``&quot;SRC/&quot;`` or ``&quot;DST/&quot;`` when specifying a node type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_unibipartite</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ntypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all the node type names in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[str]</span>
<span class="sd">            All the node type names in a list.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL internally assigns an integer ID for each node type. The returned</span>
<span class="sd">        node type names are sorted according to their IDs.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.ntypes</span>
<span class="sd">        [&#39;game&#39;, &#39;user&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ntypes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">etypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all the edge type names in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[str]</span>
<span class="sd">            All the edge type names in a list.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL internally assigns an integer ID for each edge type. The returned</span>
<span class="sd">        edge type names are sorted according to their IDs.</span>

<span class="sd">        The complete format to specify an relation is a string triplet ``(str, str, str)``</span>
<span class="sd">        for source node type, edge type and destination node type. DGL calls this</span>
<span class="sd">        format *canonical edge type*. An edge type can appear in multiple canonical edge types.</span>
<span class="sd">        For example, ``&#39;interacts&#39;`` can appear in two canonical edge types</span>
<span class="sd">        ``(&#39;drug&#39;, &#39;interacts&#39;, &#39;drug&#39;)`` and ``(&#39;protein&#39;, &#39;interacts&#39;, &#39;protein&#39;)``.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        canonical_etypes</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.etypes</span>
<span class="sd">        [&#39;follows&#39;, &#39;follows&#39;, &#39;plays&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etypes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">canonical_etypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all the canonical edge types in the graph.</span>

<span class="sd">        A canonical edge type is a string triplet ``(str, str, str)``</span>
<span class="sd">        for source node type, edge type and destination node type.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[(str, str, str)]</span>
<span class="sd">            All the canonical edge type triplets in a list.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL internally assigns an integer ID for each edge type. The returned</span>
<span class="sd">        edge type names are sorted according to their IDs.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        etypes</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.canonical_etypes</span>
<span class="sd">        [(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;),</span>
<span class="sd">         (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;),</span>
<span class="sd">         (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">srctypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all the source node type names in this graph.</span>

<span class="sd">        If the graph can further divide its node types into two subsets A and B where</span>
<span class="sd">        all the edeges are from nodes of types in A to nodes of types in B, we call</span>
<span class="sd">        this graph a *uni-bipartite* graph and the nodes in A being the *source*</span>
<span class="sd">        nodes and the ones in B being the *destination* nodes. If the graph is not</span>
<span class="sd">        uni-bipartite, the source and destination nodes are just the entire set of</span>
<span class="sd">        nodes in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[str]</span>
<span class="sd">            All the source node type names in a list.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        dsttypes</span>
<span class="sd">        is_unibipartite</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for a uni-bipartite graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.srctypes</span>
<span class="sd">        [&#39;developer&#39;, &#39;user&#39;]</span>

<span class="sd">        Query for a graph that is not uni-bipartite.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.srctypes</span>
<span class="sd">        [&#39;developer&#39;, &#39;game&#39;, &#39;user&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_unibipartite</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dsttypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all the destination node type names in this graph.</span>

<span class="sd">        If the graph can further divide its node types into two subsets A and B where</span>
<span class="sd">        all the edeges are from nodes of types in A to nodes of types in B, we call</span>
<span class="sd">        this graph a *uni-bipartite* graph and the nodes in A being the *source*</span>
<span class="sd">        nodes and the ones in B being the *destination* nodes. If the graph is not</span>
<span class="sd">        uni-bipartite, the source and destination nodes are just the entire set of</span>
<span class="sd">        nodes in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[str]</span>
<span class="sd">            All the destination node type names in a list.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        srctypes</span>
<span class="sd">        is_unibipartite</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for a uni-bipartite graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.dsttypes</span>
<span class="sd">        [&#39;game&#39;]</span>

<span class="sd">        Query for a graph that is not uni-bipartite.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.dsttypes</span>
<span class="sd">        [&#39;developer&#39;, &#39;game&#39;, &#39;user&#39;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_unibipartite</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span>

<div class="viewcode-block" id="DGLGraph.metagraph">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.metagraph.html#dgl.DGLGraph.metagraph">[docs]</a>
    <span class="k">def</span> <span class="nf">metagraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the metagraph of the heterograph.</span>

<span class="sd">        The metagraph (or network schema) of a heterogeneous network specifies type constraints</span>
<span class="sd">        on the sets of nodes and edges between the nodes. For a formal definition, refer to</span>
<span class="sd">        `Yizhou et al. &lt;https://www.kdd.org/exploration_files/V14-02-03-Sun.pdf&gt;`_.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        networkx.MultiDiGraph</span>
<span class="sd">            The metagraph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; meta_g = g.metagraph()</span>
<span class="sd">        &gt;&gt;&gt; meta_g.nodes()</span>
<span class="sd">        NodeView((&#39;user&#39;, &#39;game&#39;))</span>
<span class="sd">        &gt;&gt;&gt; meta_g.edges()</span>
<span class="sd">        OutMultiEdgeDataView([(&#39;user&#39;, &#39;user&#39;), (&#39;user&#39;, &#39;game&#39;), (&#39;user&#39;, &#39;game&#39;)])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nx_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span><span class="o">.</span><span class="n">to_networkx</span><span class="p">()</span>
        <span class="n">nx_metagraph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">MultiDiGraph</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">u_v</span> <span class="ow">in</span> <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span>
                <span class="n">nx_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">u_v</span><span class="p">][</span><span class="s2">&quot;id&quot;</span><span class="p">]</span>
            <span class="p">]</span>
            <span class="n">nx_metagraph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">,</span> <span class="n">etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx_metagraph</span></div>


<div class="viewcode-block" id="DGLGraph.to_canonical_etype">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.to_canonical_etype.html#dgl.DGLGraph.to_canonical_etype">[docs]</a>
    <span class="k">def</span> <span class="nf">to_canonical_etype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert an edge type to the corresponding canonical edge type in the graph.</span>

<span class="sd">        A canonical edge type is a string triplet ``(str, str, str)``</span>
<span class="sd">        for source node type, edge type and destination node type.</span>

<span class="sd">        The function expects the given edge type name can uniquely identify a canonical edge</span>
<span class="sd">        type. DGL will raise error if this is not the case.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype : str or (str, str, str)</span>
<span class="sd">            If :attr:`etype` is an edge type (str), it returns the corresponding canonical edge</span>
<span class="sd">            type in the graph. If :attr:`etype` is already a canonical edge type,</span>
<span class="sd">            it directly returns the input unchanged.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        (str, str, str)</span>
<span class="sd">            The canonical edge type corresponding to the edge type.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a heterograph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 2]),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 1, 1, 2], [0, 0, 1, 1]),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;follows&#39;, &#39;game&#39;): ([0, 1], [0, 1])</span>
<span class="sd">        ... })</span>

<span class="sd">        Map an edge type to its corresponding canonical edge type.</span>

<span class="sd">        &gt;&gt;&gt; g.to_canonical_etype(&#39;plays&#39;)</span>
<span class="sd">        (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.to_canonical_etype((&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;))</span>
<span class="sd">        (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        canonical_etypes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Edge type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;edge types.&quot;</span>
                <span class="p">)</span>
            <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">etype</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">etype</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etype2canonical</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">etype</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ret</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s1">&#39;Edge type &quot;</span><span class="si">{}</span><span class="s1">&quot; does not exist.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s1">&#39;Edge type &quot;</span><span class="si">%s</span><span class="s1">&quot; is ambiguous. Please use canonical edge type &#39;</span>
                    <span class="s2">&quot;in the form of (srctype, etype, dsttype)&quot;</span> <span class="o">%</span> <span class="n">etype</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span></div>


    <span class="k">def</span> <span class="nf">get_ntype_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the ID of the given node type.</span>

<span class="sd">        ntype can also be None. If so, there should be only one node type in the</span>
<span class="sd">        graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str</span>
<span class="sd">            Node type</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_unibipartite</span> <span class="ow">and</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Only check &#39;SRC/&#39; and &#39;DST/&#39; prefix when is_unibipartite graph is True.</span>
            <span class="k">if</span> <span class="n">ntype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;SRC/&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">(</span><span class="n">ntype</span><span class="p">[</span><span class="mi">4</span><span class="p">:])</span>
            <span class="k">elif</span> <span class="n">ntype</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;DST/&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">(</span><span class="n">ntype</span><span class="p">[</span><span class="mi">4</span><span class="p">:])</span>
            <span class="c1"># If there is no prefix, fallback to normal lookup.</span>

        <span class="c1"># Lookup both SRC and DST</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_unibipartite</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Node type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;node types.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">ntype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">ntid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s1">&#39;Node type &quot;</span><span class="si">{}</span><span class="s1">&quot; does not exist.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ntid</span>

    <span class="k">def</span> <span class="nf">get_ntype_id_from_src</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal function to return the ID of the given SRC node type.</span>

<span class="sd">        ntype can also be None. If so, there should be only one node type in the</span>
<span class="sd">        SRC category. Callable even when the self graph is not uni-bipartite.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str</span>
<span class="sd">            Node type</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;SRC node type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;SRC node types.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_srctypes_invmap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ntid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s1">&#39;SRC node type &quot;</span><span class="si">{}</span><span class="s1">&quot; does not exist.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ntid</span>

    <span class="k">def</span> <span class="nf">get_ntype_id_from_dst</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal function to return the ID of the given DST node type.</span>

<span class="sd">        ntype can also be None. If so, there should be only one node type in the</span>
<span class="sd">        DST category. Callable even when the self graph is not uni-bipartite.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str</span>
<span class="sd">            Node type</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;DST node type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;DST node types.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dsttypes_invmap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ntype</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ntid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s1">&#39;DST node type &quot;</span><span class="si">{}</span><span class="s1">&quot; does not exist.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ntid</span>

    <span class="k">def</span> <span class="nf">get_etype_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the id of the given edge type.</span>

<span class="sd">        etype can also be None. If so, there should be only one edge type in the</span>
<span class="sd">        graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype : str or tuple of str</span>
<span class="sd">            Edge type</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Edge type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;edge types.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etypes_invmap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">etid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s1">&#39;Edge type &quot;</span><span class="si">{}</span><span class="s1">&quot; does not exist.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">etid</span>

    <span class="c1">#################################################################</span>
    <span class="c1"># Batching</span>
    <span class="c1">#################################################################</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of graphs in the batched graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The Number of graphs in the batch. If the graph is not a batched one,</span>
<span class="sd">            it will return 1.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for homogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g1.batch_size</span>
<span class="sd">        1</span>
<span class="sd">        &gt;&gt;&gt; g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([g1, g2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_size</span>
<span class="sd">        2</span>

<span class="sd">        Query for heterogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; hg1 = dgl.heterograph({</span>
<span class="sd">        ...       (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : (torch.tensor([0, 1]), torch.tensor([0, 0]))})</span>
<span class="sd">        &gt;&gt;&gt; hg1.batch_size</span>
<span class="sd">        1</span>
<span class="sd">        &gt;&gt;&gt; hg2 = dgl.heterograph({</span>
<span class="sd">        ...       (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : (torch.tensor([0, 0]), torch.tensor([1, 0]))})</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([hg1, hg2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_size</span>
<span class="sd">        2</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<div class="viewcode-block" id="DGLGraph.batch_num_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.batch_num_nodes.html#dgl.DGLGraph.batch_num_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">batch_num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of nodes for each graph in the batch with the specified node type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The node type for query. If the graph has multiple node types, one must</span>
<span class="sd">            specify the argument. Otherwise, it can be omitted. If the graph is not a batched</span>
<span class="sd">            one, it will return a list of length 1 that holds the number of nodes in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The number of nodes with the specified type for each graph in the batch. The i-th</span>
<span class="sd">            element of it is the number of nodes with the specified type for the i-th graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for homogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g1.batch_num_nodes()</span>
<span class="sd">        tensor([4])</span>
<span class="sd">        &gt;&gt;&gt; g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([g1, g2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_nodes()</span>
<span class="sd">        tensor([4, 3])</span>

<span class="sd">        Query for heterogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; hg1 = dgl.heterograph({</span>
<span class="sd">        ...       (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : (torch.tensor([0, 1]), torch.tensor([0, 0]))})</span>
<span class="sd">        &gt;&gt;&gt; hg2 = dgl.heterograph({</span>
<span class="sd">        ...       (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : (torch.tensor([0, 0]), torch.tensor([1, 0]))})</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([hg1, hg2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_nodes(&#39;user&#39;)</span>
<span class="sd">        tensor([2, 1])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ntype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Expect ntype in </span><span class="si">{}</span><span class="s2">, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">ntype</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">ty</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">:</span>
                <span class="n">bnn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ty</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span><span class="p">[</span><span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">bnn</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Node type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;node types.&quot;</span>
                <span class="p">)</span>
            <span class="n">ntype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span></div>


<div class="viewcode-block" id="DGLGraph.set_batch_num_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.set_batch_num_nodes.html#dgl.DGLGraph.set_batch_num_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">set_batch_num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Manually set the number of nodes for each graph in the batch with the specified node</span>
<span class="sd">        type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        val : Tensor or Mapping[str, Tensor]</span>
<span class="sd">            The dictionary storing number of nodes for each graph in the batch for all node types.</span>
<span class="sd">            If the graph has only one node type, ``val`` can also be a single array indicating the</span>
<span class="sd">            number of nodes per graph in the batch.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This API is always used together with ``set_batch_num_edges`` to specify batching</span>
<span class="sd">        information of a graph, it also do not check the correspondance between the graph structure</span>
<span class="sd">        and batching information and user must guarantee there will be no cross-graph edges in the</span>
<span class="sd">        batch.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3, 4, 5], [1, 2, 0, 4, 5, 3]))</span>

<span class="sd">        Manually set batch information</span>

<span class="sd">        &gt;&gt;&gt; g.set_batch_num_nodes(torch.tensor([3, 3]))</span>
<span class="sd">        &gt;&gt;&gt; g.set_batch_num_edges(torch.tensor([3, 3]))</span>

<span class="sd">        Unbatch the graph.</span>

<span class="sd">        &gt;&gt;&gt; dgl.unbatch(g)</span>
<span class="sd">        [Graph(num_nodes=3, num_edges=3,</span>
<span class="sd">              ndata_schemes={}</span>
<span class="sd">              edata_schemes={}), Graph(num_nodes=3, num_edges=3,</span>
<span class="sd">              ndata_schemes={}</span>
<span class="sd">              edata_schemes={})]</span>

<span class="sd">        Create a heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...      (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : ([0, 1, 2, 3, 4, 5], [0, 1, 1, 3, 3, 2]),</span>
<span class="sd">        ...      (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;) : ([0, 1, 2, 3], [1, 0, 3, 2])})</span>

<span class="sd">        Manually set batch information.</span>

<span class="sd">        &gt;&gt;&gt; hg.set_batch_num_nodes({</span>
<span class="sd">        ...     &#39;user&#39;: torch.tensor([3, 3]),</span>
<span class="sd">        ...     &#39;game&#39;: torch.tensor([2, 2]),</span>
<span class="sd">        ...     &#39;developer&#39;: torch.tensor([2, 2])})</span>
<span class="sd">        &gt;&gt;&gt; hg.set_batch_num_edges({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): torch.tensor([3, 3]),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): torch.tensor([2, 2])})</span>

<span class="sd">        Unbatch the graph.</span>

<span class="sd">        &gt;&gt;&gt; g1, g2 = dgl.unbatch(hg)</span>
<span class="sd">        &gt;&gt;&gt; g1</span>
<span class="sd">        Graph(num_nodes={&#39;developer&#39;: 2, &#39;game&#39;: 2, &#39;user&#39;: 3},</span>
<span class="sd">              num_edges={(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): 3},</span>
<span class="sd">              metagraph=[(&#39;developer&#39;, &#39;game&#39;, &#39;develops&#39;), (&#39;user&#39;, &#39;game&#39;, &#39;plays&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; g2</span>
<span class="sd">        Graph(num_nodes={&#39;developer&#39;: 2, &#39;game&#39;: 2, &#39;user&#39;: 3},</span>
<span class="sd">              num_edges={(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): 3},</span>
<span class="sd">              metagraph=[(&#39;developer&#39;, &#39;game&#39;, &#39;develops&#39;), (&#39;user&#39;, &#39;game&#39;, &#39;plays&#39;)])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_batch_num_edges</span>
<span class="sd">        batch</span>
<span class="sd">        unbatch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor_or_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="s2">&quot;batch_num_nodes&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Must provide a dictionary when there are multiple node types.&quot;</span>
                <span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">val</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="o">=</span> <span class="n">val</span></div>


<div class="viewcode-block" id="DGLGraph.batch_num_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.batch_num_edges.html#dgl.DGLGraph.batch_num_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">batch_num_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of edges for each graph in the batch with the specified edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype : str or tuple of str, optional</span>
<span class="sd">            The edge type for query, which can be an edge type (str) or a canonical edge type</span>
<span class="sd">            (3-tuple of str). When an edge type appears in multiple canonical edge types, one</span>
<span class="sd">            must use a canonical edge type. If the graph has multiple edge types, one must</span>
<span class="sd">            specify the argument. Otherwise, it can be omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The number of edges with the specified type for each graph in the batch. The i-th</span>
<span class="sd">            element of it is the number of edges with the specified type for the i-th graph.</span>
<span class="sd">            If the graph is not a batched one, it will return a list of length 1 that holds</span>
<span class="sd">            the number of edges in the graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for homogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; g1 = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g1.batch_num_edges()</span>
<span class="sd">        tensor([3])</span>
<span class="sd">        &gt;&gt;&gt; g2 = dgl.graph((torch.tensor([0, 0, 0, 1]), torch.tensor([0, 1, 2, 0])))</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([g1, g2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_edges()</span>
<span class="sd">        tensor([3, 4])</span>

<span class="sd">        Query for heterogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; hg1 = dgl.heterograph({</span>
<span class="sd">        ...       (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : (torch.tensor([0, 1]), torch.tensor([0, 0]))})</span>
<span class="sd">        &gt;&gt;&gt; hg2 = dgl.heterograph({</span>
<span class="sd">        ...       (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : (torch.tensor([0, 0]), torch.tensor([1, 0]))})</span>
<span class="sd">        &gt;&gt;&gt; bg = dgl.batch([hg1, hg2])</span>
<span class="sd">        &gt;&gt;&gt; bg.batch_num_edges(&#39;plays&#39;)</span>
<span class="sd">        tensor([2, 2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">ty</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
                <span class="n">bne</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span>
                    <span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">ty</span><span class="p">)],</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">bne</span>
        <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Edge type name must be specified if there are more than one &quot;</span>
                    <span class="s2">&quot;edge types.&quot;</span>
                <span class="p">)</span>
            <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span></div>


<div class="viewcode-block" id="DGLGraph.set_batch_num_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.set_batch_num_edges.html#dgl.DGLGraph.set_batch_num_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">set_batch_num_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Manually set the number of edges for each graph in the batch with the specified edge</span>
<span class="sd">        type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        val : Tensor or Mapping[str, Tensor]</span>
<span class="sd">            The dictionary storing number of edges for each graph in the batch for all edge types.</span>
<span class="sd">            If the graph has only one edge type, ``val`` can also be a single array indicating the</span>
<span class="sd">            number of edges per graph in the batch.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This API is always used together with ``set_batch_num_nodes`` to specify batching</span>
<span class="sd">        information of a graph, it also do not check the correspondance between the graph structure</span>
<span class="sd">        and batching information and user must guarantee there will be no cross-graph edges in the</span>
<span class="sd">        batch.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3, 4, 5], [1, 2, 0, 4, 5, 3]))</span>

<span class="sd">        Manually set batch information</span>

<span class="sd">        &gt;&gt;&gt; g.set_batch_num_nodes(torch.tensor([3, 3]))</span>
<span class="sd">        &gt;&gt;&gt; g.set_batch_num_edges(torch.tensor([3, 3]))</span>

<span class="sd">        Unbatch the graph.</span>

<span class="sd">        &gt;&gt;&gt; dgl.unbatch(g)</span>
<span class="sd">        [Graph(num_nodes=3, num_edges=3,</span>
<span class="sd">              ndata_schemes={}</span>
<span class="sd">              edata_schemes={}), Graph(num_nodes=3, num_edges=3,</span>
<span class="sd">              ndata_schemes={}</span>
<span class="sd">              edata_schemes={})]</span>

<span class="sd">        Create a heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...      (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;) : ([0, 1, 2, 3, 4, 5], [0, 1, 1, 3, 3, 2]),</span>
<span class="sd">        ...      (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;) : ([0, 1, 2, 3], [1, 0, 3, 2])})</span>

<span class="sd">        Manually set batch information.</span>

<span class="sd">        &gt;&gt;&gt; hg.set_batch_num_nodes({</span>
<span class="sd">        ...     &#39;user&#39;: torch.tensor([3, 3]),</span>
<span class="sd">        ...     &#39;game&#39;: torch.tensor([2, 2]),</span>
<span class="sd">        ...     &#39;developer&#39;: torch.tensor([2, 2])})</span>
<span class="sd">        &gt;&gt;&gt; hg.set_batch_num_edges(</span>
<span class="sd">        ...     {(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): torch.tensor([3, 3]),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): torch.tensor([2, 2])})</span>

<span class="sd">        Unbatch the graph.</span>

<span class="sd">        &gt;&gt;&gt; g1, g2 = dgl.unbatch(hg)</span>
<span class="sd">        &gt;&gt;&gt; g1</span>
<span class="sd">        Graph(num_nodes={&#39;developer&#39;: 2, &#39;game&#39;: 2, &#39;user&#39;: 3},</span>
<span class="sd">              num_edges={(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): 3},</span>
<span class="sd">              metagraph=[(&#39;developer&#39;, &#39;game&#39;, &#39;develops&#39;), (&#39;user&#39;, &#39;game&#39;, &#39;plays&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; g2</span>
<span class="sd">        Graph(num_nodes={&#39;developer&#39;: 2, &#39;game&#39;: 2, &#39;user&#39;: 3},</span>
<span class="sd">              num_edges={(&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): 2, (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): 3},</span>
<span class="sd">              metagraph=[(&#39;developer&#39;, &#39;game&#39;, &#39;develops&#39;), (&#39;user&#39;, &#39;game&#39;, &#39;plays&#39;)])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        set_batch_num_nodes</span>
<span class="sd">        batch</span>
<span class="sd">        unbatch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">val</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor_or_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="s2">&quot;batch_num_edges&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Must provide a dictionary when there are multiple edge types.&quot;</span>
                <span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">val</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="o">=</span> <span class="n">val</span></div>


    <span class="c1">#################################################################</span>
    <span class="c1"># View</span>
    <span class="c1">#################################################################</span>

    <span class="k">def</span> <span class="nf">get_node_storage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get storage object of node feature of type :attr:`ntype` and name :attr:`key`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)]</span><span class="o">.</span><span class="n">_columns</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_edge_storage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get storage object of edge feature of type :attr:`etype` and name :attr:`key`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)]</span><span class="o">.</span><span class="n">_columns</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a node view</span>

<span class="sd">        One can use it for:</span>

<span class="sd">        1. Getting the node IDs for a single node type.</span>
<span class="sd">        2. Setting/getting features for all nodes of a single node type.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph and a heterogeneous graph of two node types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Get the node IDs of the homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g.nodes()</span>
<span class="sd">        tensor([0, 1, 2])</span>

<span class="sd">        Get the node IDs of the heterogeneous graph. With multiple node types introduced,</span>
<span class="sd">        one needs to specify the node type for query.</span>

<span class="sd">        &gt;&gt;&gt; hg.nodes(&#39;user&#39;)</span>
<span class="sd">        tensor([0, 1, 2, 3, 4])</span>

<span class="sd">        Set and get a feature &#39;h&#39; for all nodes of a single type in the heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; hg.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.ones(5, 1)</span>
<span class="sd">        &gt;&gt;&gt; hg.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.], [1.], [1.], [1.], [1.]])</span>

<span class="sd">        To set node features for a graph with a single node type, use :func:`DGLGraph.ndata`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        ndata</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Todo (Mufei) Replace the syntax g.nodes[...].ndata[...] with g.nodes[...][...]</span>
        <span class="k">return</span> <span class="n">HeteroNodeView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">srcnodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a node view for source nodes</span>

<span class="sd">        If the graph is a uni-bipartite graph (see :func:`is_unibipartite` for reference),</span>
<span class="sd">        this is :func:`nodes` restricted to source node types. Otherwise, it is an alias</span>
<span class="sd">        for :func:`nodes`.</span>

<span class="sd">        One can use it for:</span>

<span class="sd">        1. Getting the node IDs for a single node type.</span>
<span class="sd">        2. Setting/getting features for all nodes of a single node type.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a uni-bipartite graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Get the node IDs for source node types.</span>

<span class="sd">        &gt;&gt;&gt; g.srcnodes(&#39;user&#39;)</span>
<span class="sd">        tensor([0])</span>
<span class="sd">        &gt;&gt;&gt; g.srcnodes(&#39;developer&#39;)</span>
<span class="sd">        tensor([0, 1])</span>

<span class="sd">        Set/get features for source node types.</span>

<span class="sd">        &gt;&gt;&gt; g.srcnodes[&#39;user&#39;].data[&#39;h&#39;] = torch.ones(1, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.srcnodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.]])</span>

<span class="sd">        Create a graph that is not uni-bipartite.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>

<span class="sd">        :func:`dgl.DGLGraph.srcnodes` falls back to :func:`dgl.DGLGraph.nodes` and one can</span>
<span class="sd">        get the node IDs for both source and destination node types.</span>

<span class="sd">        &gt;&gt;&gt; g.srcnodes(&#39;game&#39;)</span>
<span class="sd">        tensor([0, 1, 2])</span>

<span class="sd">        One can also set/get features for destination node types in this case.</span>

<span class="sd">        &gt;&gt;&gt; g.srcnodes[&#39;game&#39;].data[&#39;h&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.srcnodes[&#39;game&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        srcdata</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">HeteroNodeView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dstnodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a node view for destination nodes</span>

<span class="sd">        If the graph is a uni-bipartite graph (see :func:`is_unibipartite` for reference),</span>
<span class="sd">        this is :func:`nodes` restricted to destination node types. Otherwise, it is an alias</span>
<span class="sd">        for :func:`nodes`.</span>

<span class="sd">        One can use it for:</span>

<span class="sd">        1. Getting the node IDs for a single node type.</span>
<span class="sd">        2. Setting/getting features for all nodes of a single node type.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a uni-bipartite graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Get the node IDs for destination node types.</span>

<span class="sd">        &gt;&gt;&gt; g.dstnodes(&#39;game&#39;)</span>
<span class="sd">        tensor([0, 1, 2])</span>

<span class="sd">        Set/get features for destination node types.</span>

<span class="sd">        &gt;&gt;&gt; g.dstnodes[&#39;game&#39;].data[&#39;h&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.dstnodes[&#39;game&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        Create a graph that is not uni-bipartite.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0]), torch.tensor([1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([1]), torch.tensor([2]))</span>
<span class="sd">        ... })</span>

<span class="sd">        :func:`dgl.DGLGraph.dstnodes` falls back to :func:`dgl.DGLGraph.nodes` and one can</span>
<span class="sd">        get the node IDs for both source and destination node types.</span>

<span class="sd">        &gt;&gt;&gt; g.dstnodes(&#39;developer&#39;)</span>
<span class="sd">        tensor([0, 1])</span>

<span class="sd">        One can also set/get features for source node types in this case.</span>

<span class="sd">        &gt;&gt;&gt; g.dstnodes[&#39;developer&#39;].data[&#39;h&#39;] = torch.ones(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.dstnodes[&#39;developer&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        dstdata</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">HeteroNodeView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ndata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a node data view for setting/getting node features</span>

<span class="sd">        Let ``g`` be a DGLGraph. If ``g`` is a graph of a single node type, ``g.ndata[feat]``</span>
<span class="sd">        returns the node feature associated with the name ``feat``. One can also set a node</span>
<span class="sd">        feature associated with the name ``feat`` by setting ``g.ndata[feat]`` to a tensor.</span>

<span class="sd">        If ``g`` is a graph of multiple node types, ``g.ndata[feat]`` returns a</span>
<span class="sd">        dict[str, Tensor] mapping node types to the node features associated with the name</span>
<span class="sd">        ``feat`` for the corresponding type. One can also set a node feature associated</span>
<span class="sd">        with the name ``feat`` for some node type(s) by setting ``g.ndata[feat]`` to a</span>
<span class="sd">        dictionary as described.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For setting features, the device of the features must be the same as the device</span>
<span class="sd">        of the graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of a single node type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of multiple node types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([1, 2]), torch.tensor([3, 4])),</span>
<span class="sd">        ...     (&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = {&#39;game&#39;: torch.zeros(2, 1), &#39;player&#39;: torch.ones(3, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        {&#39;game&#39;: tensor([[0.], [0.]]),</span>
<span class="sd">         &#39;player&#39;: tensor([[1.], [1.], [1.]])}</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = {&#39;game&#39;: torch.ones(2, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        {&#39;game&#39;: tensor([[1.], [1.]]),</span>
<span class="sd">         &#39;player&#39;: tensor([[1.], [1.], [1.]])}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">ntype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">HeteroNodeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ntids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">]</span>
            <span class="n">ntypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span>
            <span class="k">return</span> <span class="n">HeteroNodeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">ntids</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">srcdata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a node data view for setting/getting source node features.</span>

<span class="sd">        Let ``g`` be a DGLGraph. If ``g`` is a graph of a single source node type,</span>
<span class="sd">        ``g.srcdata[feat]`` returns the source node feature associated with the name ``feat``.</span>
<span class="sd">        One can also set a source node feature associated with the name ``feat`` by</span>
<span class="sd">        setting ``g.srcdata[feat]`` to a tensor.</span>

<span class="sd">        If ``g`` is a graph of multiple source node types, ``g.srcdata[feat]`` returns a</span>
<span class="sd">        dict[str, Tensor] mapping source node types to the node features associated with</span>
<span class="sd">        the name ``feat`` for the corresponding type. One can also set a node feature</span>
<span class="sd">        associated with the name ``feat`` for some source node type(s) by setting</span>
<span class="sd">        ``g.srcdata[feat]`` to a dictionary as described.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For setting features, the device of the features must be the same as the device</span>
<span class="sd">        of the graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of a single source node type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2]))})</span>
<span class="sd">        &gt;&gt;&gt; g.srcdata[&#39;h&#39;] = torch.ones(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.srcdata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of multiple source node types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 2]), torch.tensor([3, 4])),</span>
<span class="sd">        ...     (&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.srcdata[&#39;h&#39;] = {&#39;user&#39;: torch.zeros(3, 1), &#39;player&#39;: torch.ones(3, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.srcdata[&#39;h&#39;]</span>
<span class="sd">        {&#39;player&#39;: tensor([[1.], [1.], [1.]]),</span>
<span class="sd">         &#39;user&#39;: tensor([[0.], [0.], [0.]])}</span>
<span class="sd">        &gt;&gt;&gt; g.srcdata[&#39;h&#39;] = {&#39;user&#39;: torch.ones(3, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.srcdata[&#39;h&#39;]</span>
<span class="sd">        {&#39;player&#39;: tensor([[1.], [1.], [1.]]),</span>
<span class="sd">         &#39;user&#39;: tensor([[1.], [1.], [1.]])}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        nodes</span>
<span class="sd">        ndata</span>
<span class="sd">        srcnodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">srctypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ntype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">srctypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">HeteroNodeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ntypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">srctypes</span>
            <span class="n">ntids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">HeteroNodeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">ntids</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dstdata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a node data view for setting/getting destination node features.</span>

<span class="sd">        Let ``g`` be a DGLGraph. If ``g`` is a graph of a single destination node type,</span>
<span class="sd">        ``g.dstdata[feat]`` returns the destination node feature associated with the name</span>
<span class="sd">        ``feat``. One can also set a destination node feature associated with the name</span>
<span class="sd">        ``feat`` by setting ``g.dstdata[feat]`` to a tensor.</span>

<span class="sd">        If ``g`` is a graph of multiple destination node types, ``g.dstdata[feat]`` returns a</span>
<span class="sd">        dict[str, Tensor] mapping destination node types to the node features associated with</span>
<span class="sd">        the name ``feat`` for the corresponding type. One can also set a node feature</span>
<span class="sd">        associated with the name ``feat`` for some destination node type(s) by setting</span>
<span class="sd">        ``g.dstdata[feat]`` to a dictionary as described.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For setting features, the device of the features must be the same as the device</span>
<span class="sd">        of the graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of a single destination node type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2]))})</span>
<span class="sd">        &gt;&gt;&gt; g.dstdata[&#39;h&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.dstdata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of multiple destination node types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 2]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;watches&#39;, &#39;movie&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.dstdata[&#39;h&#39;] = {&#39;game&#39;: torch.zeros(3, 1), &#39;movie&#39;: torch.ones(2, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.dstdata[&#39;h&#39;]</span>
<span class="sd">        {&#39;game&#39;: tensor([[0.], [0.], [0.]]),</span>
<span class="sd">         &#39;movie&#39;: tensor([[1.], [1.]])}</span>
<span class="sd">        &gt;&gt;&gt; g.dstdata[&#39;h&#39;] = {&#39;game&#39;: torch.ones(3, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.dstdata[&#39;h&#39;]</span>
<span class="sd">        {&#39;game&#39;: tensor([[1.], [1.], [1.]]),</span>
<span class="sd">         &#39;movie&#39;: tensor([[1.], [1.]])}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        nodes</span>
<span class="sd">        ndata</span>
<span class="sd">        dstnodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dsttypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ntype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dsttypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">HeteroNodeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ntypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dsttypes</span>
            <span class="n">ntids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="n">ntypes</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">HeteroNodeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">ntids</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return an edge view</span>

<span class="sd">        One can use it for:</span>

<span class="sd">        1. Getting the edges for a single edge type. In this case, it can take the</span>
<span class="sd">           following optional arguments:</span>

<span class="sd">            - form : str, optional</span>
<span class="sd">                  The return form, which can be one of the following:</span>

<span class="sd">                  - ``&#39;uv&#39;`` (default): The returned result is a 2-tuple of 1D tensors</span>
<span class="sd">                    :math:`(U, V)`, representing the source and destination nodes of all edges.</span>
<span class="sd">                    For each :math:`i`, :math:`(U[i], V[i])` forms an edge.</span>
<span class="sd">                  - ``&#39;eid&#39;``: The returned result is a 1D tensor :math:`EID`, representing</span>
<span class="sd">                    the IDs of all edges.</span>
<span class="sd">                  - ``&#39;all&#39;``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,</span>
<span class="sd">                    representing the source nodes, destination nodes and IDs of all edges.</span>
<span class="sd">                    For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.</span>
<span class="sd">            - order : str, optional</span>
<span class="sd">                  The order of the returned edges, which can be one of the following:</span>

<span class="sd">                  - ``&#39;eid&#39;`` (default): The edges are sorted by their IDs.</span>
<span class="sd">                  - ``&#39;srcdst&#39;``: The edges are sorted first by their source node IDs and then</span>
<span class="sd">                    by their destination node IDs to break ties.</span>
<span class="sd">            - etype : str or tuple of str, optional</span>
<span class="sd">                  The edge type for query, which can be an edge type (str) or a canonical edge</span>
<span class="sd">                  type (3-tuple of str). When an edge type appears in multiple canonical edge</span>
<span class="sd">                  types, one must use a canonical edge type. If the graph has multiple edge</span>
<span class="sd">                  types, one must specify the argument. Otherwise, it can be omitted.</span>
<span class="sd">        2. Setting/getting features for all edges of a single edge type. To set/get a feature</span>
<span class="sd">           ``feat`` for edges of type ``etype`` in a graph ``g``, one can use</span>
<span class="sd">           ``g.edges[etype].data[feat]``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Get the Edges for a Single Edge Type**</span>

<span class="sd">        Create a graph with a single edge type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 0, 0]), torch.tensor([1, 1, 0])))</span>
<span class="sd">        &gt;&gt;&gt; g.edges()</span>
<span class="sd">        (tensor([1, 0, 0]), tensor([1, 1, 0]))</span>

<span class="sd">        Specify a different value for :attr:`form` and :attr:`order`.</span>

<span class="sd">        &gt;&gt;&gt; g.edges(form=&#39;all&#39;, order=&#39;srcdst&#39;)</span>
<span class="sd">        (tensor([0, 0, 1]), tensor([0, 1, 1]), tensor([2, 1, 0]))</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.edges(etype=&#39;plays&#39;)</span>
<span class="sd">        (tensor([3, 4]), tensor([5, 6]))</span>

<span class="sd">        **Set/get Features for All Edges of a Single Edge Type**</span>

<span class="sd">        Create a heterogeneous graph of two edge types.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Set and get a feature &#39;h&#39; for all edges of a single type in the heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; hg.edges[&#39;follows&#39;].data[&#39;h&#39;] = torch.ones(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; hg.edges[&#39;follows&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.], [1.]])</span>

<span class="sd">        To set edge features for a graph with a single edge type, use :func:`DGLGraph.edata`.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        edata</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(Mufei): Replace the syntax g.edges[...].edata[...] with g.edges[...][...]</span>
        <span class="k">return</span> <span class="n">HeteroEdgeView</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return an edge data view for setting/getting edge features.</span>

<span class="sd">        Let ``g`` be a DGLGraph. If ``g`` is a graph of a single edge type, ``g.edata[feat]``</span>
<span class="sd">        returns the edge feature associated with the name ``feat``. One can also set an</span>
<span class="sd">        edge feature associated with the name ``feat`` by setting ``g.edata[feat]`` to a tensor.</span>

<span class="sd">        If ``g`` is a graph of multiple edge types, ``g.edata[feat]`` returns a</span>
<span class="sd">        dict[str, Tensor] mapping canonical edge types to the edge features associated with</span>
<span class="sd">        the name ``feat`` for the corresponding type. One can also set an edge feature</span>
<span class="sd">        associated with the name ``feat`` for some edge type(s) by setting</span>
<span class="sd">        ``g.edata[feat]`` to a dictionary as described.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        For setting features, the device of the features must be the same as the device</span>
<span class="sd">        of the graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of a single edge type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.ones(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        Set and get feature &#39;h&#39; for a graph of multiple edge types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([1, 2]), torch.tensor([3, 4])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;user&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1])),</span>
<span class="sd">        ...     (&#39;player&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([2, 2]), torch.tensor([1, 1]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.zeros(2, 1),</span>
<span class="sd">        ...                 (&#39;user&#39;, &#39;plays&#39;, &#39;user&#39;): torch.ones(2, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">        {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): tensor([[0.], [0.]]),</span>
<span class="sd">         (&#39;user&#39;, &#39;plays&#39;, &#39;user&#39;): tensor([[1.], [1.]])}</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.ones(2, 1)}</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;]</span>
<span class="sd">        {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): tensor([[1.], [1.]]),</span>
<span class="sd">         (&#39;user&#39;, &#39;plays&#39;, &#39;user&#39;): tensor([[1.], [1.]])}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">HeteroEdgeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">HeteroEdgeDataView</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">,</span> <span class="n">ALL</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_find_etypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="n">etypes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">i</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">SLICE_FULL</span> <span class="ow">or</span> <span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">srctype</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">SLICE_FULL</span> <span class="ow">or</span> <span class="n">key</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">etype</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">key</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">SLICE_FULL</span> <span class="ow">or</span> <span class="n">key</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">dsttype</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">etypes</span>

<div class="viewcode-block" id="DGLGraph.__getitem__">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.__getitem__.html#dgl.DGLGraph.__getitem__">[docs]</a>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the relation slice of this graph.</span>

<span class="sd">        You can get a relation slice with ``self[srctype, etype, dsttype]``, where</span>
<span class="sd">        ``srctype``, ``etype``, and ``dsttype`` can be either a string or a full</span>
<span class="sd">        slice (``:``) representing wildcard (i.e. any source/edge/destination type).</span>

<span class="sd">        A relation slice is a homogeneous (with one node type and one edge type) or</span>
<span class="sd">        bipartite (with two node types and one edge type) graph, transformed from</span>
<span class="sd">        the original heterogeneous graph.</span>

<span class="sd">        If there is only one canonical edge type found, then the returned relation</span>
<span class="sd">        slice would be a subgraph induced from the original graph.  That is, it is</span>
<span class="sd">        equivalent to ``self.edge_type_subgraph(etype)``.  The node and edge features</span>
<span class="sd">        of the returned graph would be shared with thew original graph.</span>

<span class="sd">        If there are multiple canonical edge types found, then the source/edge/destination</span>
<span class="sd">        node types would be a *concatenation* of original node/edge types.  The</span>
<span class="sd">        new source/destination node type would have the concatenation determined by</span>
<span class="sd">        :func:`dgl.combine_names() &lt;dgl.combine_names&gt;` called on original source/destination</span>
<span class="sd">        types as its name.  The source/destination node would be formed by concatenating the</span>
<span class="sd">        common features of the original source/destination types.  Therefore they are not</span>
<span class="sd">        shared with the original graph.  Edge type is similar.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        key : str or tuple</span>
<span class="sd">            Either a string representing the edge type name, or a tuple in the form of</span>
<span class="sd">            ``(srctype, etype, dsttype)`` where ``srctype``, ``etype``, ``dsttype`` can be either</span>
<span class="sd">            strings representing type names or a full slice object (`:`).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The relation slice.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This function returns a new graph.  Changing the content of this graph does not reflect</span>
<span class="sd">        onto the original graph.</span>

<span class="sd">        If the graph combines multiple node types or edge types together, it will have the</span>
<span class="sd">        mapping of node/edge types and IDs from the new graph to the original graph.</span>
<span class="sd">        The mappings have the name ``dgl.NTYPE``, ``dgl.NID``, ``dgl.ETYPE`` and ``dgl.EID``,</span>
<span class="sd">        similar to the function :func:`dgl.to_homogenenous`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;A1&#39;, &#39;AB1&#39;, &#39;B&#39;): ([0, 1, 2], [1, 2, 3]),</span>
<span class="sd">        ...     (&#39;A1&#39;, &#39;AB2&#39;, &#39;B&#39;): ([1, 2, 3], [3, 4, 5]),</span>
<span class="sd">        ...     (&#39;A2&#39;, &#39;AB2&#39;, &#39;B&#39;): ([1, 3, 5], [2, 4, 6])})</span>
<span class="sd">        &gt;&gt;&gt; new_g = g[&#39;A1&#39;, :, &#39;B&#39;]         # combines all edge types between A1 and B</span>
<span class="sd">        &gt;&gt;&gt; new_g</span>
<span class="sd">        Graph(num_nodes={&#39;A1&#39;: 4, &#39;B&#39;: 7},</span>
<span class="sd">              num_edges={(&#39;A1&#39;, &#39;AB1+AB2&#39;, &#39;B&#39;): 6},</span>
<span class="sd">              metagraph=[(&#39;A1&#39;, &#39;B&#39;, &#39;AB1+AB2&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; new_g.edges()</span>
<span class="sd">        (tensor([0, 1, 2, 1, 2, 3]), tensor([1, 2, 3, 3, 4, 5]))</span>
<span class="sd">        &gt;&gt;&gt; new_g2 = g[:, &#39;AB2&#39;, &#39;B&#39;]        # combines all node types that are source of AB2</span>
<span class="sd">        &gt;&gt;&gt; new_g2</span>
<span class="sd">        Graph(num_nodes={&#39;A1+A2&#39;: 10, &#39;B&#39;: 7},</span>
<span class="sd">              num_edges={(&#39;A1+A2&#39;, &#39;AB2+AB2&#39;, &#39;B&#39;): 6},</span>
<span class="sd">              metagraph=[(&#39;A1+A2&#39;, &#39;B&#39;, &#39;AB2+AB2&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; new_g2.edges()</span>
<span class="sd">        (tensor([1, 2, 3, 5, 7, 9]), tensor([3, 4, 5, 2, 4, 6]))</span>

<span class="sd">        If a combination of multiple node types and edge types occur, one can find</span>
<span class="sd">        the mapping to the original node type and IDs like the following:</span>

<span class="sd">        &gt;&gt;&gt; new_g1.edges[&#39;AB1+AB2&#39;].data[dgl.EID]</span>
<span class="sd">        tensor([0, 1, 2, 0, 1, 2])</span>
<span class="sd">        &gt;&gt;&gt; new_g1.edges[&#39;AB1+AB2&#39;].data[dgl.ETYPE]</span>
<span class="sd">        tensor([0, 0, 0, 1, 1, 1])</span>
<span class="sd">        &gt;&gt;&gt; new_g2.nodes[&#39;A1+A2&#39;].data[dgl.NID]</span>
<span class="sd">        tensor([0, 1, 2, 3, 0, 1, 2, 3, 4, 5])</span>
<span class="sd">        &gt;&gt;&gt; new_g2.nodes[&#39;A1+A2&#39;].data[dgl.NTYPE]</span>
<span class="sd">        tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">err_msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;Invalid slice syntax. Use G[&#39;etype&#39;] or G[&#39;srctype&#39;, &#39;etype&#39;, &#39;dsttype&#39;] &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;to get view of one relation type. Use : to slice multiple types (e.g. &quot;</span>
            <span class="o">+</span> <span class="s2">&quot;G[&#39;srctype&#39;, :, &#39;dsttype&#39;]).&quot;</span>
        <span class="p">)</span>

        <span class="n">orig_key</span> <span class="o">=</span> <span class="n">key</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">SLICE_FULL</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">SLICE_FULL</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="n">err_msg</span><span class="p">)</span>

        <span class="n">etypes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_find_etypes</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s1">&#39;Invalid key &quot;</span><span class="si">{}</span><span class="s1">&quot;. Must be one of the edge types.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">orig_key</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># no ambiguity: return the unitgraph itself</span>
            <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_canonical_etypes</span><span class="p">[</span><span class="n">etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="n">stid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">(</span><span class="n">srctype</span><span class="p">)</span>
            <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">((</span><span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span><span class="p">))</span>
            <span class="n">dtid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">(</span><span class="n">dsttype</span><span class="p">)</span>
            <span class="n">new_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">get_relation_graph</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">stid</span> <span class="o">==</span> <span class="n">dtid</span><span class="p">:</span>
                <span class="n">new_ntypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">srctype</span><span class="p">]</span>
                <span class="n">new_nframes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">stid</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_ntypes</span> <span class="o">=</span> <span class="p">([</span><span class="n">srctype</span><span class="p">],</span> <span class="p">[</span><span class="n">dsttype</span><span class="p">])</span>
                <span class="n">new_nframes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">stid</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">dtid</span><span class="p">]]</span>
            <span class="n">new_etypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">etype</span><span class="p">]</span>
            <span class="n">new_eframes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]]</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
                <span class="n">new_g</span><span class="p">,</span> <span class="n">new_ntypes</span><span class="p">,</span> <span class="n">new_etypes</span><span class="p">,</span> <span class="n">new_nframes</span><span class="p">,</span> <span class="n">new_eframes</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">flat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">flatten_relations</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span>
            <span class="n">new_g</span> <span class="o">=</span> <span class="n">flat</span><span class="o">.</span><span class="n">graph</span>

            <span class="c1"># merge frames</span>
            <span class="n">stids</span> <span class="o">=</span> <span class="n">flat</span><span class="o">.</span><span class="n">induced_srctype_set</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">dtids</span> <span class="o">=</span> <span class="n">flat</span><span class="o">.</span><span class="n">induced_dsttype_set</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">etids</span> <span class="o">=</span> <span class="n">flat</span><span class="o">.</span><span class="n">induced_etype_set</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="n">new_ntypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">combine_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">stids</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">new_g</span><span class="o">.</span><span class="n">number_of_ntypes</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">new_ntypes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">combine_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">dtids</span><span class="p">))</span>
                <span class="n">new_nframes</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">combine_frames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="n">stids</span><span class="p">),</span>
                    <span class="n">combine_frames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="n">dtids</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">stids</span><span class="p">,</span> <span class="n">dtids</span><span class="p">)</span>
                <span class="n">new_nframes</span> <span class="o">=</span> <span class="p">[</span><span class="n">combine_frames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="n">stids</span><span class="p">)]</span>
            <span class="n">new_etypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">combine_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">,</span> <span class="n">etids</span><span class="p">)]</span>
            <span class="n">new_eframes</span> <span class="o">=</span> <span class="p">[</span><span class="n">combine_frames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">,</span> <span class="n">etids</span><span class="p">)]</span>

            <span class="c1"># create new heterograph</span>
            <span class="n">new_hg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
                <span class="n">new_g</span><span class="p">,</span> <span class="n">new_ntypes</span><span class="p">,</span> <span class="n">new_etypes</span><span class="p">,</span> <span class="n">new_nframes</span><span class="p">,</span> <span class="n">new_eframes</span>
            <span class="p">)</span>

            <span class="n">src</span> <span class="o">=</span> <span class="n">new_ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">dst</span> <span class="o">=</span> <span class="n">new_ntypes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">new_g</span><span class="o">.</span><span class="n">number_of_ntypes</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">src</span>
            <span class="c1"># put the parent node/edge type and IDs</span>
            <span class="n">new_hg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">src</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">NTYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dgl_ndarray</span><span class="p">(</span>
                <span class="n">flat</span><span class="o">.</span><span class="n">induced_srctype</span>
            <span class="p">)</span>
            <span class="n">new_hg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">src</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dgl_ndarray</span><span class="p">(</span>
                <span class="n">flat</span><span class="o">.</span><span class="n">induced_srcid</span>
            <span class="p">)</span>
            <span class="n">new_hg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">NTYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dgl_ndarray</span><span class="p">(</span>
                <span class="n">flat</span><span class="o">.</span><span class="n">induced_dsttype</span>
            <span class="p">)</span>
            <span class="n">new_hg</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dgl_ndarray</span><span class="p">(</span>
                <span class="n">flat</span><span class="o">.</span><span class="n">induced_dstid</span>
            <span class="p">)</span>
            <span class="n">new_hg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">ETYPE</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dgl_ndarray</span><span class="p">(</span>
                <span class="n">flat</span><span class="o">.</span><span class="n">induced_etype</span>
            <span class="p">)</span>
            <span class="n">new_hg</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">zerocopy_from_dgl_ndarray</span><span class="p">(</span><span class="n">flat</span><span class="o">.</span><span class="n">induced_eid</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">new_hg</span></div>


    <span class="c1">#################################################################</span>
    <span class="c1"># Graph query</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.number_of_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.number_of_nodes.html#dgl.DGLGraph.number_of_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">number_of_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias of :meth:`num_nodes`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.num_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.num_nodes.html#dgl.DGLGraph.num_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of nodes in the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The node type name. If given, it returns the number of nodes of the</span>
<span class="sd">            type. If not given (default), it returns the total number of nodes of all types.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The number of nodes.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a graph with two node types -- &#39;user&#39; and &#39;game&#39;.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Query for the number of nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.num_nodes(&#39;user&#39;)</span>
<span class="sd">        5</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes(&#39;game&#39;)</span>
<span class="sd">        7</span>
<span class="sd">        &gt;&gt;&gt; g.num_nodes()</span>
<span class="sd">        12</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntid</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">ntid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">))</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span></div>


<div class="viewcode-block" id="DGLGraph.number_of_src_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.number_of_src_nodes.html#dgl.DGLGraph.number_of_src_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">number_of_src_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias of :meth:`num_src_nodes`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_src_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.num_src_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.num_src_nodes.html#dgl.DGLGraph.num_src_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">num_src_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of source nodes in the graph.</span>

<span class="sd">        If the graph can further divide its node types into two subsets A and B where</span>
<span class="sd">        all the edeges are from nodes of types in A to nodes of types in B, we call</span>
<span class="sd">        this graph a *uni-bipartite* graph and the nodes in A being the *source*</span>
<span class="sd">        nodes and the ones in B being the *destination* nodes. If the graph is not</span>
<span class="sd">        uni-bipartite, the source and destination nodes are just the entire set of</span>
<span class="sd">        nodes in the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The source node type name. If given, it returns the number of nodes for</span>
<span class="sd">            the source node type. If not given (default), it returns the number of</span>
<span class="sd">            nodes summed over all source node types.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The number of nodes</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        num_dst_nodes</span>
<span class="sd">        is_unibipartite</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph for query.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.num_src_nodes()</span>
<span class="sd">        3</span>

<span class="sd">        Create a heterogeneous graph with two source node types -- &#39;developer&#39; and &#39;user&#39;.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Query for the number of nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.num_src_nodes(&#39;developer&#39;)</span>
<span class="sd">        2</span>
<span class="sd">        &gt;&gt;&gt; g.num_src_nodes(&#39;user&#39;)</span>
<span class="sd">        5</span>
<span class="sd">        &gt;&gt;&gt; g.num_src_nodes()</span>
<span class="sd">        7</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">(</span><span class="n">nty</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">nty</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">srctypes</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_src</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span></div>


<div class="viewcode-block" id="DGLGraph.number_of_dst_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.number_of_dst_nodes.html#dgl.DGLGraph.number_of_dst_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">number_of_dst_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias of :func:`num_dst_nodes`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dst_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.num_dst_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.num_dst_nodes.html#dgl.DGLGraph.num_dst_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">num_dst_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of destination nodes in the graph.</span>

<span class="sd">        If the graph can further divide its node types into two subsets A and B where</span>
<span class="sd">        all the edeges are from nodes of types in A to nodes of types in B, we call</span>
<span class="sd">        this graph a *uni-bipartite* graph and the nodes in A being the *source*</span>
<span class="sd">        nodes and the ones in B being the *destination* nodes. If the graph is not</span>
<span class="sd">        uni-bipartite, the source and destination nodes are just the entire set of</span>
<span class="sd">        nodes in the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The destination node type name. If given, it returns the number of nodes of</span>
<span class="sd">            the destination node type. If not given (default), it returns the number of</span>
<span class="sd">            nodes summed over all the destination node types.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The number of nodes</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        num_src_nodes</span>
<span class="sd">        is_unibipartite</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph for query.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.num_dst_nodes()</span>
<span class="sd">        3</span>

<span class="sd">        Create a heterogeneous graph with two destination node types -- &#39;user&#39; and &#39;game&#39;.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Query for the number of nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.num_dst_nodes(&#39;user&#39;)</span>
<span class="sd">        5</span>
<span class="sd">        &gt;&gt;&gt; g.num_dst_nodes(&#39;game&#39;)</span>
<span class="sd">        7</span>
<span class="sd">        &gt;&gt;&gt; g.num_dst_nodes()</span>
<span class="sd">        12</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">(</span><span class="n">nty</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">nty</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dsttypes</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id_from_dst</span><span class="p">(</span><span class="n">ntype</span><span class="p">))</span></div>


<div class="viewcode-block" id="DGLGraph.number_of_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.number_of_edges.html#dgl.DGLGraph.number_of_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">number_of_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias of :func:`num_edges`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.num_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.num_edges.html#dgl.DGLGraph.num_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">num_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of edges in the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            If not provided, return the total number of edges regardless of the types</span>
<span class="sd">            in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The number of edges.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a graph with three canonical edge types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Query for the number of edges.</span>

<span class="sd">        &gt;&gt;&gt; g.num_edges(&#39;plays&#39;)</span>
<span class="sd">        2</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges()</span>
<span class="sd">        7</span>

<span class="sd">        Use a canonical edge type instead when there is ambiguity for an edge type.</span>

<span class="sd">        &gt;&gt;&gt; g.num_edges((&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;))</span>
<span class="sd">        2</span>
<span class="sd">        &gt;&gt;&gt; g.num_edges((&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;))</span>
<span class="sd">        3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">etid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">))</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">))</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_multigraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the graph is a multigraph with parallel edges.</span>

<span class="sd">        A multigraph has more than one edges between the same pair of nodes, called</span>
<span class="sd">        *parallel edges*.  For heterogeneous graphs, parallel edge further requires</span>
<span class="sd">        the canonical edge type to be the same (see :meth:`canonical_etypes` for the</span>
<span class="sd">        definition).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if the graph is a multigraph.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Checking whether the graph is a multigraph could be expensive for a large one.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Check for homogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g.is_multigraph</span>
<span class="sd">        False</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([1, 3, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g.is_multigraph</span>
<span class="sd">        True</span>

<span class="sd">        Check for heterogeneous graphs.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.is_multigraph</span>
<span class="sd">        False</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1, 1]), torch.tensor([1, 2, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.is_multigraph</span>
<span class="sd">        True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">is_multigraph</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_homogeneous</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the graph is a homogeneous graph.</span>

<span class="sd">        A homogeneous graph only has one node type and one edge type.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if the graph is a homogeneous graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph for check.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g.is_homogeneous</span>
<span class="sd">        True</span>

<span class="sd">        Create a heterogeneous graph for check.</span>

<span class="sd">        If the graph has multiple edge types, one need to specify the edge type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3]))})</span>
<span class="sd">        &gt;&gt;&gt; g.is_homogeneous</span>
<span class="sd">        False</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">idtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The data type for storing the structure-related graph information</span>
<span class="sd">        such as node and edge IDs.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Framework-specific device object</span>
<span class="sd">            For example, this can be ``torch.int32`` or ``torch.int64`` for PyTorch.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; src_ids = torch.tensor([0, 0, 1])</span>
<span class="sd">        &gt;&gt;&gt; dst_ids = torch.tensor([1, 2, 2])</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids))</span>
<span class="sd">        &gt;&gt;&gt; g.idtype</span>
<span class="sd">        torch.int64</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph((src_ids, dst_ids), idtype=torch.int32)</span>
<span class="sd">        &gt;&gt;&gt; g.idtype</span>
<span class="sd">        torch.int32</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        long</span>
<span class="sd">        int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_idtype_str</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The dtype of graph index</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        backend dtype object</span>
<span class="sd">            th.int32/th.int64 or tf.int32/tf.int64 etc.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">dtype</span>

<div class="viewcode-block" id="DGLGraph.has_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.has_nodes.html#dgl.DGLGraph.has_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">has_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vid</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the graph contains the given nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        vid : node ID(s)</span>
<span class="sd">            The nodes IDs. The allowed nodes ID formats are:</span>

<span class="sd">            * ``int``: The ID of a single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">        ntype : str, optional</span>
<span class="sd">            The node type name. Can be omitted if there is</span>
<span class="sd">            only one type of nodes in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool or bool Tensor</span>
<span class="sd">            A tensor of bool flags where each element is True if the node is in the graph.</span>
<span class="sd">            If the input is a single node, return one bool value.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a graph with two node types -- &#39;user&#39; and &#39;game&#39;.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([0, 1]))</span>
<span class="sd">        ... })</span>

<span class="sd">        Query for the nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.has_nodes(0, &#39;user&#39;)</span>
<span class="sd">        True</span>
<span class="sd">        &gt;&gt;&gt; g.has_nodes(3, &#39;game&#39;)</span>
<span class="sd">        False</span>
<span class="sd">        &gt;&gt;&gt; g.has_nodes(torch.tensor([3, 0, 1]), &#39;game&#39;)</span>
<span class="sd">        tensor([False,  True,  True])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">vid_tensor</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vid</span><span class="p">,</span> <span class="s2">&quot;vid&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">vid_tensor</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vid_tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">vid_tensor</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;All IDs must be non-negative integers.&quot;</span><span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">),</span> <span class="n">vid_tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vid</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">ret</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.has_edges_between">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.has_edges_between.html#dgl.DGLGraph.has_edges_between">[docs]</a>
    <span class="k">def</span> <span class="nf">has_edges_between</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether the graph contains the given edges.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u : node IDs</span>
<span class="sd">            The source node IDs of the edges. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">        v : node IDs</span>
<span class="sd">            The destination node IDs of the edges. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool or bool Tensor</span>
<span class="sd">            A tensor of bool flags where each element is True if the node is in the graph.</span>
<span class="sd">            If the input is a single node, return one bool value.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))</span>

<span class="sd">        Query for the edges.</span>

<span class="sd">        &gt;&gt;&gt; g.has_edges_between(1, 2)</span>
<span class="sd">        True</span>
<span class="sd">        &gt;&gt;&gt; g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]))</span>
<span class="sd">        tensor([ True, False])</span>

<span class="sd">        If the graph has multiple edge types, one need to specify the edge type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]), &#39;plays&#39;)</span>
<span class="sd">        tensor([ True, False])</span>

<span class="sd">        Use a canonical edge type instead when there is ambiguity for an edge type.</span>

<span class="sd">        &gt;&gt;&gt; g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]),</span>
<span class="sd">        ...                     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;))</span>
<span class="sd">        tensor([ True, False])</span>
<span class="sd">        &gt;&gt;&gt; g.has_edges_between(torch.tensor([1, 2]), torch.tensor([2, 3]),</span>
<span class="sd">        ...                     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;))</span>
<span class="sd">        tensor([True, True])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">u_tensor</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">u_tensor</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">srctype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">u_tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;u contains invalid node IDs&quot;</span><span class="p">)</span>
        <span class="n">v_tensor</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">v_tensor</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">dsttype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">v_tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;v contains invalid node IDs&quot;</span><span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">has_edges_between</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">u_tensor</span><span class="p">,</span> <span class="n">v_tensor</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">ret</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.predecessors">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.predecessors.html#dgl.DGLGraph.predecessors">[docs]</a>
    <span class="k">def</span> <span class="nf">predecessors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the predecessor(s) of a particular node with the specified edge type.</span>

<span class="sd">        Node ``u`` is a predecessor of node ``v`` if there is an edge ``(u, v)`` with type</span>
<span class="sd">        ``etype`` in the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v : int</span>
<span class="sd">            The node ID. If the graph has multiple edge types, the ID is for the destination</span>
<span class="sd">            type corresponding to the edge type.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The predecessors of :attr:`v` with the specified edge type.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))</span>

<span class="sd">        Query for node 1.</span>

<span class="sd">        &gt;&gt;&gt; g.predecessors(1)</span>
<span class="sd">        tensor([0, 0])</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.predecessors(1, etype=&#39;follows&#39;)</span>
<span class="sd">        tensor([0])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        successors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Non-existing node ID </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">v</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.successors">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.successors.html#dgl.DGLGraph.successors">[docs]</a>
    <span class="k">def</span> <span class="nf">successors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the successor(s) of a particular node with the specified edge type.</span>

<span class="sd">        Node ``u`` is a successor of node ``v`` if there is an edge ``(v, u)`` with type</span>
<span class="sd">        ``etype`` in the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v : int</span>
<span class="sd">            The node ID. If the graph has multiple edge types, the ID is for the source</span>
<span class="sd">            type corresponding to the edge type.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The successors of :attr:`v` with the specified edge type.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))</span>

<span class="sd">        Query for node 1.</span>

<span class="sd">        &gt;&gt;&gt; g.successors(1)</span>
<span class="sd">        tensor([2, 3])</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.successors(1, etype=&#39;follows&#39;)</span>
<span class="sd">        tensor([2])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        predecessors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Non-existing node ID </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">successors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">v</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.edge_ids">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.edge_ids.html#dgl.DGLGraph.edge_ids">[docs]</a>
    <span class="k">def</span> <span class="nf">edge_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">return_uv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the edge ID(s) given the two endpoints of the edge(s).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u : node IDs</span>
<span class="sd">            The source node IDs of the edges. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">        v : node IDs</span>
<span class="sd">            The destination node IDs of the edges. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>
<span class="sd">        return_uv : bool, optional</span>
<span class="sd">            Whether to return the source and destination node IDs along with the edges. If</span>
<span class="sd">            False (default), it assumes that the graph is a simple graph and there is only</span>
<span class="sd">            one edge from one node to another. If True, there can be multiple edges found</span>
<span class="sd">            from one node to another.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor, or (Tensor, Tensor, Tensor)</span>

<span class="sd">            * If ``return_uv=False``, it returns the edge IDs in a tensor, where the i-th</span>
<span class="sd">              element is the ID of the edge ``(u[i], v[i])``.</span>
<span class="sd">            * If ``return_uv=True``, it returns a tuple of three 1D tensors ``(eu, ev, e)``.</span>
<span class="sd">              ``e[i]`` is the ID of an edge from ``eu[i]`` to ``ev[i]``. It returns all edges</span>
<span class="sd">              (including parallel edges) from ``eu[i]`` to ``ev[i]`` in this case.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        If the graph is a simple graph, ``return_uv=False``, and there are no edges</span>
<span class="sd">        between some pairs of node(s), it will raise an error.</span>

<span class="sd">        If the graph is a multigraph, ``return_uv=False``, and there are multiple edges</span>
<span class="sd">        between some pairs of node(s), it returns an arbitrary one from them.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1, 1]), torch.tensor([1, 0, 2, 3, 2])))</span>

<span class="sd">        Query for the edges.</span>

<span class="sd">        &gt;&gt;&gt; g.edge_ids(0, 0)</span>
<span class="sd">        1</span>
<span class="sd">        &gt;&gt;&gt; g.edge_ids(torch.tensor([1, 0]), torch.tensor([3, 1]))</span>
<span class="sd">        tensor([3, 0])</span>

<span class="sd">        Get all edges for pairs of nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.edge_ids(torch.tensor([1, 0]), torch.tensor([3, 1]), return_uv=True)</span>
<span class="sd">        (tensor([1, 0]), tensor([3, 1]), tensor([3, 0]))</span>

<span class="sd">        If the graph has multiple edge types, one need to specify the edge type.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;): (torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([1, 3]), torch.tensor([2, 3]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.edge_ids(torch.tensor([1]), torch.tensor([2]), etype=&#39;plays&#39;)</span>
<span class="sd">        tensor([0])</span>

<span class="sd">        Use a canonical edge type instead when there is ambiguity for an edge type.</span>

<span class="sd">        &gt;&gt;&gt; g.edge_ids(torch.tensor([0, 1]), torch.tensor([1, 2]),</span>
<span class="sd">        ...            etype=(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;))</span>
<span class="sd">        tensor([0, 1])</span>
<span class="sd">        &gt;&gt;&gt; g.edge_ids(torch.tensor([1, 2]), torch.tensor([2, 3]),</span>
<span class="sd">        ...            etype=(&#39;user&#39;, &#39;follows&#39;, &#39;game&#39;))</span>
<span class="sd">        tensor([1, 2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">is_int</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">v</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span>
        <span class="p">)</span>
        <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">srctype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">u</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;u contains invalid node IDs&quot;</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">dsttype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">v</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;v contains invalid node IDs&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_uv</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">edge_ids_all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">edge_ids_one</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
            <span class="n">is_neg_one</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">is_neg_one</span><span class="p">,</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="c1"># Raise error since some (u, v) pair is not a valid edge.</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">is_neg_one</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Error: (</span><span class="si">%d</span><span class="s2">, </span><span class="si">%d</span><span class="s2">) does not form a valid edge.&quot;</span>
                    <span class="o">%</span> <span class="p">(</span>
                        <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">idx</span><span class="p">)),</span>
                        <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">idx</span><span class="p">)),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_int</span> <span class="k">else</span> <span class="n">eid</span></div>


<div class="viewcode-block" id="DGLGraph.find_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.find_edges.html#dgl.DGLGraph.find_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">find_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the source and destination node ID(s) given the edge ID(s).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        eid : edge ID(s)</span>
<span class="sd">            The edge IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single ID.</span>
<span class="sd">            * Int Tensor: Each element is an ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is an ID.</span>

<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The source node IDs of the edges. The i-th element is the source node ID of</span>
<span class="sd">            the i-th edge.</span>
<span class="sd">        Tensor</span>
<span class="sd">            The destination node IDs of the edges. The i-th element is the destination node</span>
<span class="sd">            ID of the i-th edge.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))</span>

<span class="sd">        Find edges of IDs 0 and 2.</span>

<span class="sd">        &gt;&gt;&gt; g.find_edges(torch.tensor([0, 2]))</span>
<span class="sd">        (tensor([0, 1]), tensor([1, 2]))</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.find_edges(torch.tensor([1, 0]), &#39;plays&#39;)</span>
<span class="sd">        (tensor([4, 3]), tensor([6, 5]))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">eid</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="s2">&quot;eid&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">min_eid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">min_eid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid edge ID </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">min_eid</span><span class="p">))</span>
            <span class="n">max_eid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">max_eid</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid edge ID </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_eid</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">empty</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">tensor</span><span class="p">([],</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">empty</span><span class="p">,</span> <span class="n">empty</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">find_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">eid</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span></div>


<div class="viewcode-block" id="DGLGraph.in_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.in_edges.html#dgl.DGLGraph.in_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">in_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the incoming edges of the given nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v : node ID(s)</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>
<span class="sd">        form : str, optional</span>
<span class="sd">            The result format, which can be one of the following:</span>

<span class="sd">            - ``&#39;eid&#39;``: The returned result is a 1D tensor :math:`EID`, representing</span>
<span class="sd">              the IDs of all edges.</span>
<span class="sd">            - ``&#39;uv&#39;`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,</span>
<span class="sd">              representing the source and destination nodes of all edges. For each :math:`i`,</span>
<span class="sd">              :math:`(U[i], V[i])` forms an edge.</span>
<span class="sd">            - ``&#39;all&#39;``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,</span>
<span class="sd">              representing the source nodes, destination nodes and IDs of all edges.</span>
<span class="sd">              For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)</span>
<span class="sd">            All incoming edges of the nodes with the specified type. For a description of the</span>
<span class="sd">            returned result, see the description of :attr:`form`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))</span>

<span class="sd">        Query for the nodes 1 and 0.</span>

<span class="sd">        &gt;&gt;&gt; g.in_edges(torch.tensor([1, 0]))</span>
<span class="sd">        (tensor([0, 0]), tensor([1, 0]))</span>

<span class="sd">        Specify a different value for :attr:`form`.</span>

<span class="sd">        &gt;&gt;&gt; g.in_edges(torch.tensor([1, 0]), form=&#39;all&#39;)</span>
<span class="sd">        (tensor([0, 0]), tensor([1, 0]), tensor([0, 1]))</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.in_edges(torch.tensor([1, 0]), etype=&#39;follows&#39;)</span>
<span class="sd">        (tensor([0]), tensor([1]))</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        edges</span>
<span class="sd">        out_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">in_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span>
        <span class="k">elif</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;uv&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span>
        <span class="k">elif</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;eid&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">eid</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s1">&#39;Invalid form: </span><span class="si">{}</span><span class="s1">. Must be &quot;all&quot;, &quot;uv&quot; or &quot;eid&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">form</span><span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.out_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.out_edges.html#dgl.DGLGraph.out_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">out_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the outgoing edges of the given nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u : node ID(s)</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>
<span class="sd">        form : str, optional</span>
<span class="sd">            The return form, which can be one of the following:</span>

<span class="sd">            - ``&#39;eid&#39;``: The returned result is a 1D tensor :math:`EID`, representing</span>
<span class="sd">              the IDs of all edges.</span>
<span class="sd">            - ``&#39;uv&#39;`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,</span>
<span class="sd">              representing the source and destination nodes of all edges. For each :math:`i`,</span>
<span class="sd">              :math:`(U[i], V[i])` forms an edge.</span>
<span class="sd">            - ``&#39;all&#39;``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,</span>
<span class="sd">              representing the source nodes, destination nodes and IDs of all edges.</span>
<span class="sd">              For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)</span>
<span class="sd">            All outgoing edges of the nodes with the specified type. For a description of the</span>
<span class="sd">            returned result, see the description of :attr:`form`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))</span>

<span class="sd">        Query for the nodes 1 and 2.</span>

<span class="sd">        &gt;&gt;&gt; g.out_edges(torch.tensor([1, 2]))</span>
<span class="sd">        (tensor([1, 1]), tensor([2, 3]))</span>

<span class="sd">        Specify a different value for :attr:`form`.</span>

<span class="sd">        &gt;&gt;&gt; g.out_edges(torch.tensor([1, 2]), form=&#39;all&#39;)</span>
<span class="sd">        (tensor([1, 1]), tensor([2, 3]), tensor([2, 3]))</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.out_edges(torch.tensor([1, 2]), etype=&#39;follows&#39;)</span>
<span class="sd">        (tensor([1]), tensor([2]))</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        edges</span>
<span class="sd">        in_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">srctype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">u</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;u contains invalid node IDs&quot;</span><span class="p">)</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">out_edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">u</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span>
        <span class="k">elif</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;uv&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span>
        <span class="k">elif</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;eid&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">eid</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s1">&#39;Invalid form: </span><span class="si">{}</span><span class="s1">. Must be &quot;all&quot;, &quot;uv&quot; or &quot;eid&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">form</span><span class="p">)</span>
            <span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">all_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;uv&quot;</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all edges with the specified edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        form : str, optional</span>
<span class="sd">            The return form, which can be one of the following:</span>

<span class="sd">            - ``&#39;eid&#39;``: The returned result is a 1D tensor :math:`EID`, representing</span>
<span class="sd">              the IDs of all edges.</span>
<span class="sd">            - ``&#39;uv&#39;`` (default): The returned result is a 2-tuple of 1D tensors :math:`(U, V)`,</span>
<span class="sd">              representing the source and destination nodes of all edges. For each :math:`i`,</span>
<span class="sd">              :math:`(U[i], V[i])` forms an edge.</span>
<span class="sd">            - ``&#39;all&#39;``: The returned result is a 3-tuple of 1D tensors :math:`(U, V, EID)`,</span>
<span class="sd">              representing the source nodes, destination nodes and IDs of all edges.</span>
<span class="sd">              For each :math:`i`, :math:`(U[i], V[i])` forms an edge with ID :math:`EID[i]`.</span>
<span class="sd">        order : str, optional</span>
<span class="sd">            The order of the returned edges, which can be one of the following:</span>

<span class="sd">            - ``&#39;srcdst&#39;``: The edges are sorted first by their source node IDs and then</span>
<span class="sd">              by their destination node IDs to break ties.</span>
<span class="sd">            - ``&#39;eid&#39;`` (default): The edges are sorted by their IDs.</span>
<span class="sd">        etype : str or tuple of str, optional</span>
<span class="sd">            The edge type for query, which can be an edge type (str) or a canonical edge type</span>
<span class="sd">            (3-tuple of str). When an edge type appears in multiple canonical edge types, one</span>
<span class="sd">            must use a canonical edge type. If the graph has multiple edge types, one must</span>
<span class="sd">            specify the argument. Otherwise, it can be omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor or (Tensor, Tensor) or (Tensor, Tensor, Tensor)</span>
<span class="sd">            All edges of the specified edge type. For a description of the returned result,</span>
<span class="sd">            see the description of :attr:`form`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 0, 2, 3])))</span>

<span class="sd">        Query for edges.</span>

<span class="sd">        &gt;&gt;&gt; g.all_edges()</span>
<span class="sd">        (tensor([0, 0, 1, 1]), tensor([1, 0, 2, 3]))</span>

<span class="sd">        Specify a different value for :attr:`form` and :attr:`order`.</span>

<span class="sd">        &gt;&gt;&gt; g.all_edges(form=&#39;all&#39;, order=&#39;srcdst&#39;)</span>
<span class="sd">        (tensor([0, 0, 1, 1]), tensor([0, 1, 2, 3]), tensor([1, 0, 2, 3]))</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.all_edges(etype=&#39;plays&#39;)</span>
<span class="sd">        (tensor([3, 4]), tensor([5, 6]))</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        edges</span>
<span class="sd">        in_edges</span>
<span class="sd">        out_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">),</span> <span class="n">order</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span>
        <span class="k">elif</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;uv&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span>
        <span class="k">elif</span> <span class="n">form</span> <span class="o">==</span> <span class="s2">&quot;eid&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">eid</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s1">&#39;Invalid form: </span><span class="si">{}</span><span class="s1">. Must be &quot;all&quot;, &quot;uv&quot; or &quot;eid&quot;.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">form</span><span class="p">)</span>
            <span class="p">)</span>

<div class="viewcode-block" id="DGLGraph.in_degrees">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.in_degrees.html#dgl.DGLGraph.in_degrees">[docs]</a>
    <span class="k">def</span> <span class="nf">in_degrees</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">ALL</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the in-degree(s) of the given nodes.</span>

<span class="sd">        It computes the in-degree(s) w.r.t. to the edges of the given edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v : node IDs</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">            If not given, return the in-degrees of all the nodes.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or Tensor</span>
<span class="sd">            The in-degree(s) of the node(s) in a Tensor. The i-th element is the in-degree</span>
<span class="sd">            of the i-th input node. If :attr:`v` is an ``int``, return an ``int`` too.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))</span>

<span class="sd">        Query for all nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.in_degrees()</span>
<span class="sd">        tensor([0, 2, 1, 1])</span>

<span class="sd">        Query for nodes 1 and 2.</span>

<span class="sd">        &gt;&gt;&gt; g.in_degrees(torch.tensor([1, 2]))</span>
<span class="sd">        tensor([2, 1])</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.in_degrees(torch.tensor([1, 0]), etype=&#39;follows&#39;)</span>
<span class="sd">        tensor([1, 0])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        out_degrees</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dsttype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dstnodes</span><span class="p">(</span><span class="n">dsttype</span><span class="p">)</span>
        <span class="n">v_tensor</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">in_degrees</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="n">v_tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">deg</span></div>


<div class="viewcode-block" id="DGLGraph.out_degrees">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.out_degrees.html#dgl.DGLGraph.out_degrees">[docs]</a>
    <span class="k">def</span> <span class="nf">out_degrees</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="n">ALL</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the out-degree(s) of the given nodes.</span>

<span class="sd">        It computes the out-degree(s) w.r.t. to the edges of the given edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        u : node IDs</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">            If not given, return the in-degrees of all the nodes.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or Tensor</span>
<span class="sd">            The out-degree(s) of the node(s) in a Tensor. The i-th element is the out-degree</span>
<span class="sd">            of the i-th input node. If :attr:`v` is an ``int``, return an ``int`` too.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1, 1]), torch.tensor([1, 1, 2, 3])))</span>

<span class="sd">        Query for all nodes.</span>

<span class="sd">        &gt;&gt;&gt; g.out_degrees()</span>
<span class="sd">        tensor([2, 2, 0, 0])</span>

<span class="sd">        Query for nodes 1 and 2.</span>

<span class="sd">        &gt;&gt;&gt; g.out_degrees(torch.tensor([1, 2]))</span>
<span class="sd">        tensor([2, 0])</span>

<span class="sd">        For a graph of multiple edge types, it is required to specify the edge type in query.</span>

<span class="sd">        &gt;&gt;&gt; hg = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([3, 4]), torch.tensor([5, 6]))</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; hg.out_degrees(torch.tensor([1, 0]), etype=&#39;follows&#39;)</span>
<span class="sd">        tensor([1, 1])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        in_degrees</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">srctype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
            <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">srcnodes</span><span class="p">(</span><span class="n">srctype</span><span class="p">)</span>
        <span class="n">u_tensor</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">u_tensor</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">srctype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">u_tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;u contains invalid node IDs&quot;</span><span class="p">)</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">out_degrees</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">deg</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">deg</span></div>


<div class="viewcode-block" id="DGLGraph.adjacency_matrix">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.adjacency_matrix.html#dgl.DGLGraph.adjacency_matrix">[docs]</a>
    <span class="k">def</span> <span class="nf">adjacency_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Alias of :meth:`adj`&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">adj</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.adj">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.adj.html#dgl.DGLGraph.adj">[docs]</a>
    <span class="k">def</span> <span class="nf">adj</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eweight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the adjacency matrix of the graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and</span>
<span class="sd">            destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        eweight_name : str, optional</span>
<span class="sd">            The name of edge feature used as the non-zero values. If not given,</span>
<span class="sd">            the non-zero values are all 1.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        SparseMatrix</span>
<span class="sd">            The adjacency matrix.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2], [1, 2, 3]))</span>
<span class="sd">        &gt;&gt;&gt; g.adj()</span>
<span class="sd">        SparseMatrix(indices=tensor([[0, 1, 2],</span>
<span class="sd">                                     [1, 2, 3]]),</span>
<span class="sd">                     values=tensor([1., 1., 1.]),</span>
<span class="sd">                     shape=(4, 4), nnz=3)</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [0, 1]),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): ([0, 1], [0, 2])</span>
<span class="sd">        ... })</span>

<span class="sd">        &gt;&gt;&gt; g.adj(etype=&#39;develops&#39;)</span>
<span class="sd">        SparseMatrix(indices=tensor([[0, 1],</span>
<span class="sd">                                     [0, 2]]),</span>
<span class="sd">                     values=tensor([1., 1.]),</span>
<span class="sd">                     shape=(2, 3), nnz=2)</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = {(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): torch.tensor([3, 2])}</span>
<span class="sd">        &gt;&gt;&gt; g.adj(etype=&#39;follows&#39;, eweight_name=&#39;h&#39;)</span>
<span class="sd">        SparseMatrix(indices=tensor([[0, 1],</span>
<span class="sd">                                     [0, 1]]),</span>
<span class="sd">                     values=tensor([3, 2]),</span>
<span class="sd">                     shape=(2, 2), nnz=2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">F</span><span class="o">.</span><span class="n">backend_name</span> <span class="o">==</span> <span class="s2">&quot;pytorch&quot;</span><span class="p">,</span> <span class="s2">&quot;Only PyTorch backend supports adj.&quot;</span>
        <span class="c1"># Temporal fix to introduce a dependency on torch</span>
        <span class="kn">import</span> <span class="nn">torch</span>

        <span class="kn">from</span> <span class="nn">.sparse</span> <span class="kn">import</span> <span class="n">spmatrix</span>

        <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_edges</span><span class="p">(</span><span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">))</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">etype</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">(</span><span class="n">etype</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">eweight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edata</span><span class="p">[</span><span class="n">eweight_name</span><span class="p">][</span><span class="n">etype</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">val</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">spmatrix</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">val</span><span class="o">=</span><span class="n">val</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.adj_external">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.adj_external.html#dgl.DGLGraph.adj_external">[docs]</a>
    <span class="k">def</span> <span class="nf">adj_external</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">scipy_fmt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the adjacency matrix in an external format, such as Scipy or</span>
<span class="sd">        backend dependent sparse tensor.</span>

<span class="sd">        By default, a row of returned adjacency matrix represents the</span>
<span class="sd">        source of an edge and the column represents the destination.</span>

<span class="sd">        When transpose is True, a row represents the destination and a column</span>
<span class="sd">        represents the source.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        transpose : bool, optional</span>
<span class="sd">            A flag to transpose the returned adjacency matrix. (Default: False)</span>
<span class="sd">        ctx : context, optional</span>
<span class="sd">            The context of returned adjacency matrix. (Default: cpu)</span>
<span class="sd">        scipy_fmt : str, optional</span>
<span class="sd">            If specified, return a scipy sparse matrix in the given format.</span>
<span class="sd">            Otherwise, return a backend dependent sparse tensor. (Default: None)</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        SparseTensor or scipy.sparse.spmatrix</span>
<span class="sd">            Adjacency matrix.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Instantiate a heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [0, 1]),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): ([0, 1], [0, 2])</span>
<span class="sd">        ... })</span>

<span class="sd">        Get a backend dependent sparse tensor. Here we use PyTorch for example.</span>

<span class="sd">        &gt;&gt;&gt; g.adj_external(etype=&#39;develops&#39;)</span>
<span class="sd">        tensor(indices=tensor([[0, 1],</span>
<span class="sd">                               [0, 2]]),</span>
<span class="sd">               values=tensor([1., 1.]),</span>
<span class="sd">               size=(2, 3), nnz=2, layout=torch.sparse_coo)</span>

<span class="sd">        Get a scipy coo sparse matrix.</span>

<span class="sd">        &gt;&gt;&gt; g.adj_external(scipy_fmt=&#39;coo&#39;, etype=&#39;develops&#39;)</span>
<span class="sd">        &lt;2x3 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;</span>
<span class="sd">           with 2 stored elements in COOrdinate format&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">scipy_fmt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">adjacency_matrix_scipy</span><span class="p">(</span>
                <span class="n">etid</span><span class="p">,</span> <span class="n">transpose</span><span class="p">,</span> <span class="n">scipy_fmt</span><span class="p">,</span> <span class="kc">False</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.adj_tensors">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.adj_tensors.html#dgl.DGLGraph.adj_tensors">[docs]</a>
    <span class="k">def</span> <span class="nf">adj_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fmt</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the adjacency matrix of edges of the given edge type as tensors of</span>
<span class="sd">        a sparse matrix representation.</span>
<span class="sd">        By default, a row of returned adjacency matrix represents the</span>
<span class="sd">        source of an edge and the column represents the destination.</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fmt : str</span>
<span class="sd">            Either ``coo``, ``csr`` or ``csc``.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>
<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>
<span class="sd">            Can be omitted if the graph has only one type of edges.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple[Tensor]</span>
<span class="sd">            If :attr:`fmt` is ``coo``, returns a pair of source and destination node ID</span>
<span class="sd">            tensors.</span>
<span class="sd">            If :attr:`fmt` is ``csr`` or ``csc``, return the CSR or CSC representation</span>
<span class="sd">            of the adjacency matrix as a triplet of tensors</span>
<span class="sd">            ``(indptr, indices, edge_ids)``.  Namely ``edge_ids`` could be an empty</span>
<span class="sd">            tensor with 0 elements, in which case the edge IDs are consecutive</span>
<span class="sd">            integers starting from 0.</span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2], [1, 2, 3]))</span>
<span class="sd">        &gt;&gt;&gt; g.adj_tensors(&#39;coo&#39;)</span>
<span class="sd">        (tensor([0, 1, 2]), tensor([1, 2, 3]))</span>
<span class="sd">        &gt;&gt;&gt; g.adj_tensors(&#39;csr&#39;)</span>
<span class="sd">        (tensor([0, 1, 2, 3, 3]), tensor([1, 2, 3]), tensor([0, 1, 2]))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">fmt</span> <span class="o">==</span> <span class="s2">&quot;csc&quot;</span><span class="p">:</span>
            <span class="c1"># The first two elements are number of rows and columns</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">adjacency_matrix_tensors</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">adjacency_matrix_tensors</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">fmt</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span></div>


<div class="viewcode-block" id="DGLGraph.inc">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.inc.html#dgl.DGLGraph.inc">[docs]</a>
    <span class="k">def</span> <span class="nf">inc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">typestr</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the incidence matrix representation of edges with the given</span>
<span class="sd">        edge type.</span>

<span class="sd">        An incidence matrix is an n-by-m sparse matrix, where n is</span>
<span class="sd">        the number of nodes and m is the number of edges. Each nnz</span>
<span class="sd">        value indicating whether the edge is incident to the node</span>
<span class="sd">        or not.</span>

<span class="sd">        There are three types of incidence matrices :math:`I`:</span>

<span class="sd">        * ``in``:</span>

<span class="sd">            - :math:`I[v, e] = 1` if :math:`e` is the in-edge of :math:`v`</span>
<span class="sd">              (or :math:`v` is the dst node of :math:`e`);</span>
<span class="sd">            - :math:`I[v, e] = 0` otherwise.</span>

<span class="sd">        * ``out``:</span>

<span class="sd">            - :math:`I[v, e] = 1` if :math:`e` is the out-edge of :math:`v`</span>
<span class="sd">              (or :math:`v` is the src node of :math:`e`);</span>
<span class="sd">            - :math:`I[v, e] = 0` otherwise.</span>

<span class="sd">        * ``both`` (only if source and destination node type are the same):</span>

<span class="sd">            - :math:`I[v, e] = 1` if :math:`e` is the in-edge of :math:`v`;</span>
<span class="sd">            - :math:`I[v, e] = -1` if :math:`e` is the out-edge of :math:`v`;</span>
<span class="sd">            - :math:`I[v, e] = 0` otherwise (including self-loop).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        typestr : str</span>
<span class="sd">            Can be either ``in``, ``out`` or ``both``</span>
<span class="sd">        ctx : context, optional</span>
<span class="sd">            The context of returned incidence matrix. (Default: cpu)</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Framework SparseTensor</span>
<span class="sd">            The incidence matrix.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1], [0, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g.inc(&#39;in&#39;)</span>
<span class="sd">        tensor(indices=tensor([[0, 2],</span>
<span class="sd">                               [0, 1]]),</span>
<span class="sd">               values=tensor([1., 1.]),</span>
<span class="sd">               size=(3, 2), nnz=2, layout=torch.sparse_coo)</span>
<span class="sd">        &gt;&gt;&gt; g.inc(&#39;out&#39;)</span>
<span class="sd">        tensor(indices=tensor([[0, 1],</span>
<span class="sd">                               [0, 1]]),</span>
<span class="sd">               values=tensor([1., 1.]),</span>
<span class="sd">               size=(3, 2), nnz=2, layout=torch.sparse_coo)</span>
<span class="sd">        &gt;&gt;&gt; g.inc(&#39;both&#39;)</span>
<span class="sd">        tensor(indices=tensor([[1, 2],</span>
<span class="sd">                               [1, 1]]),</span>
<span class="sd">               values=tensor([-1.,  1.]),</span>
<span class="sd">               size=(3, 2), nnz=2, layout=torch.sparse_coo)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="n">typestr</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span></div>


    <span class="n">incidence_matrix</span> <span class="o">=</span> <span class="n">inc</span>

    <span class="c1">#################################################################</span>
    <span class="c1"># Features</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.node_attr_schemes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.node_attr_schemes.html#dgl.DGLGraph.node_attr_schemes">[docs]</a>
    <span class="k">def</span> <span class="nf">node_attr_schemes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the node feature schemes for the specified type.</span>

<span class="sd">        The scheme of a feature describes the shape and data type of it.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The node type name. Can be omitted if there is only one type of nodes</span>
<span class="sd">            in the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, Scheme]</span>
<span class="sd">            A dictionary mapping a feature name to its associated feature scheme.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h1&#39;] = torch.randn(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h2&#39;] = torch.randn(3, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.node_attr_schemes()</span>
<span class="sd">        {&#39;h1&#39;: Scheme(shape=(1,), dtype=torch.float32),</span>
<span class="sd">         &#39;h2&#39;: Scheme(shape=(2,), dtype=torch.float32)}</span>

<span class="sd">        Query for a heterogeneous graph of multiple node types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;):</span>
<span class="sd">        ...                      (torch.tensor([1, 2]), torch.tensor([3, 4]))})</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h1&#39;] = torch.randn(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h2&#39;] = torch.randn(3, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.node_attr_schemes(&#39;user&#39;)</span>
<span class="sd">        {&#39;h1&#39;: Scheme(shape=(1,), dtype=torch.float32),</span>
<span class="sd">         &#39;h2&#39;: Scheme(shape=(2,), dtype=torch.float32)}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        edge_attr_schemes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)]</span><span class="o">.</span><span class="n">schemes</span></div>


<div class="viewcode-block" id="DGLGraph.edge_attr_schemes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.edge_attr_schemes.html#dgl.DGLGraph.edge_attr_schemes">[docs]</a>
    <span class="k">def</span> <span class="nf">edge_attr_schemes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the edge feature schemes for the specified type.</span>

<span class="sd">        The scheme of a feature describes the shape and data type of it.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict[str, Scheme]</span>
<span class="sd">            A dictionary mapping a feature name to its associated feature scheme.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Query for a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h1&#39;] = torch.randn(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h2&#39;] = torch.randn(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.edge_attr_schemes()</span>
<span class="sd">        {&#39;h1&#39;: Scheme(shape=(1,), dtype=torch.float32),</span>
<span class="sd">         &#39;h2&#39;: Scheme(shape=(2,), dtype=torch.float32)}</span>

<span class="sd">        Query for a heterogeneous graph of multiple edge types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;):</span>
<span class="sd">        ...                      (torch.tensor([1, 2]), torch.tensor([3, 4])),</span>
<span class="sd">        ...                      (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;):</span>
<span class="sd">        ...                      (torch.tensor([3, 4]), torch.tensor([5, 6]))})</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;h1&#39;] = torch.randn(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;h2&#39;] = torch.randn(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.edge_attr_schemes(&#39;plays&#39;)</span>
<span class="sd">        {&#39;h1&#39;: Scheme(shape=(1,), dtype=torch.float32),</span>
<span class="sd">         &#39;h2&#39;: Scheme(shape=(2,), dtype=torch.float32)}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        node_attr_schemes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)]</span><span class="o">.</span><span class="n">schemes</span></div>


    <span class="k">def</span> <span class="nf">set_n_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">field</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the initializer for node features.</span>

<span class="sd">        When only part of the nodes have a feature (e.g. new nodes are added,</span>
<span class="sd">        features are set for a subset of nodes), the initializer initializes</span>
<span class="sd">        features for the rest nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initializer : callable</span>
<span class="sd">            A function of signature ``func(shape, dtype, ctx, id_range) -&gt; Tensor``.</span>
<span class="sd">            The tensor will be the initialized features. The arguments are:</span>

<span class="sd">            - ``shape``: The shape of the tensor to return, which is a tuple of int.</span>
<span class="sd">              The first dimension is the number of nodes for feature initialization.</span>
<span class="sd">            - ``dtype``: The data type of the tensor to return, which is a</span>
<span class="sd">              framework-specific data type object.</span>
<span class="sd">            - ``ctx``: The device of the tensor to return, which is a framework-specific</span>
<span class="sd">              device object.</span>
<span class="sd">            - ``id_range``: The start and end ID of the nodes for feature initialization,</span>
<span class="sd">              which is a slice.</span>
<span class="sd">        field : str, optional</span>
<span class="sd">            The name of the feature that the initializer applies. If not given, the</span>
<span class="sd">            initializer applies to all features.</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The type name of the nodes. Can be omitted if the graph has only one type of nodes.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Without setting a node feature initializer, zero tensors are generated</span>
<span class="sd">        for nodes without a feature.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Define a function for initializer.</span>

<span class="sd">        &gt;&gt;&gt; def init_feats(shape, dtype, device, id_range):</span>
<span class="sd">        ...     return torch.ones(shape, dtype=dtype, device=device)</span>

<span class="sd">        An example for a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0]), torch.tensor([1])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h1&#39;] = torch.zeros(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h2&#39;] = torch.ones(2, 1)</span>
<span class="sd">        &gt;&gt;&gt; # Apply the initializer to feature &#39;h2&#39; only.</span>
<span class="sd">        &gt;&gt;&gt; g.set_n_initializer(init_feats, field=&#39;h2&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(1)</span>
<span class="sd">        &gt;&gt;&gt; print(g.ndata[&#39;h1&#39;])</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; print(g.ndata[&#39;h2&#39;])</span>
<span class="sd">        tensor([[1.], [1.], [1.]])</span>

<span class="sd">        An example for a heterogeneous graph of multiple node types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.zeros(3, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;w&#39;] = torch.ones(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.set_n_initializer(init_feats, ntype=&#39;game&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(1, ntype=&#39;user&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Initializer not set for &#39;user&#39;, use zero tensors by default</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; # Initializer set for &#39;game&#39;</span>
<span class="sd">        &gt;&gt;&gt; g.add_nodes(1, ntype=&#39;game&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;w&#39;]</span>
<span class="sd">        tensor([[1., 1.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">set_initializer</span><span class="p">(</span><span class="n">initializer</span><span class="p">,</span> <span class="n">field</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_e_initializer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">field</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the initializer for edge features.</span>

<span class="sd">        When only part of the edges have a feature (e.g. new edges are added,</span>
<span class="sd">        features are set for a subset of edges), the initializer initializes</span>
<span class="sd">        features for the rest edges.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        initializer : callable</span>
<span class="sd">            A function of signature ``func(shape, dtype, ctx, id_range) -&gt; Tensor``.</span>
<span class="sd">            The tensor will be the initialized features. The arguments are:</span>

<span class="sd">            - ``shape``: The shape of the tensor to return, which is a tuple of int.</span>
<span class="sd">              The first dimension is the number of edges for feature initialization.</span>
<span class="sd">            - ``dtype``: The data type of the tensor to return, which is a</span>
<span class="sd">              framework-specific data type object.</span>
<span class="sd">            - ``ctx``: The device of the tensor to return, which is a framework-specific</span>
<span class="sd">              device object.</span>
<span class="sd">            - ``id_range``: The start and end ID of the edges for feature initialization,</span>
<span class="sd">              which is a slice.</span>
<span class="sd">        field : str, optional</span>
<span class="sd">            The name of the feature that the initializer applies. If not given, the</span>
<span class="sd">            initializer applies to all features.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type names of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>


<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Without setting an edge feature initializer, zero tensors are generated</span>
<span class="sd">        for edges without a feature.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Define a function for initializer.</span>

<span class="sd">        &gt;&gt;&gt; def init_feats(shape, dtype, device, id_range):</span>
<span class="sd">        ...     return torch.ones(shape, dtype=dtype, device=device)</span>

<span class="sd">        An example for a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0]), torch.tensor([1])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h1&#39;] = torch.zeros(1, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h2&#39;] = torch.ones(1, 1)</span>
<span class="sd">        &gt;&gt;&gt; # Apply the initializer to feature &#39;h2&#39; only.</span>
<span class="sd">        &gt;&gt;&gt; g.set_e_initializer(init_feats, field=&#39;h2&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([1]), torch.tensor([1]))</span>
<span class="sd">        &gt;&gt;&gt; print(g.edata[&#39;h1&#39;])</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; print(g.edata[&#39;h2&#39;])</span>
<span class="sd">        tensor([[1.], [1.]])</span>

<span class="sd">        An example for a heterogeneous graph of multiple edge types.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;h&#39;] = torch.zeros(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;develops&#39;].data[&#39;w&#39;] = torch.ones(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.set_e_initializer(init_feats, etype=&#39;plays&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Initializer not set for &#39;develops&#39;, use zero tensors by default</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([1]), torch.tensor([1]), etype=&#39;develops&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;develops&#39;].data[&#39;w&#39;]</span>
<span class="sd">        tensor([[1., 1.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; # Initializer set for &#39;plays&#39;</span>
<span class="sd">        &gt;&gt;&gt; g.add_edges(torch.tensor([1]), torch.tensor([1]), etype=&#39;plays&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [1., 1.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">set_initializer</span><span class="p">(</span><span class="n">initializer</span><span class="p">,</span> <span class="n">field</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_n_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal API to set node features.</span>

<span class="sd">        `data` is a dictionary from the feature name to feature tensor. Each tensor</span>
<span class="sd">        is of shape (B, D1, D2, ...), where B is the number of nodes to be updated,</span>
<span class="sd">        and (D1, D2, ...) be the shape of the node representation tensor. The</span>
<span class="sd">        length of the given node ids must match B (i.e, len(u) == B).</span>

<span class="sd">        All updates will be done out of place to work with autograd.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntid : int</span>
<span class="sd">            Node type id.</span>
<span class="sd">        u : node, container or tensor</span>
<span class="sd">            The node(s).</span>
<span class="sd">        data : dict of tensor</span>
<span class="sd">            Node representation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">ntid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
            <span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">nfeats</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">val</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">nfeats</span> <span class="o">!=</span> <span class="n">num_nodes</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Expect number of features to match number of nodes (len(u)).&quot;</span>
                    <span class="s2">&quot; Got </span><span class="si">%d</span><span class="s2"> and </span><span class="si">%d</span><span class="s2"> instead.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">nfeats</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s1">&#39;Cannot assign node feature &quot;</span><span class="si">{}</span><span class="s1">&quot; on device </span><span class="si">{}</span><span class="s1"> to a graph on&#39;</span>
                    <span class="s2">&quot; device </span><span class="si">{}</span><span class="s2">. Call DGLGraph.to() to copy the graph to the&quot;</span>
                    <span class="s2">&quot; same device.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># To prevent users from doing things like:</span>
            <span class="c1">#</span>
            <span class="c1">#     g.pin_memory_()</span>
            <span class="c1">#     g.ndata[&#39;x&#39;] = torch.randn(...)</span>
            <span class="c1">#     sg = g.sample_neighbors(torch.LongTensor([...]).cuda())</span>
            <span class="c1">#     sg.ndata[&#39;x&#39;]    # Becomes a CPU tensor even if sg is on GPU due to lazy slicing</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">()</span>
                <span class="ow">and</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">F</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Pinned graph requires the node data to be pinned as well. &quot;</span>
                    <span class="s2">&quot;Please pin the node data before assignment.&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">update_row</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_n_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get node(s) representation of a single node type.</span>

<span class="sd">        The returned feature tensor batches multiple node features on the first dimension.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntid : int</span>
<span class="sd">            Node type id.</span>
<span class="sd">        u : node, container or tensor</span>
<span class="sd">            The node(s).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Representation dict from feature name to feature tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_pop_n_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntid</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal API to get and remove the specified node feature.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ntid : int</span>
<span class="sd">            Node type id.</span>
<span class="sd">        key : str</span>
<span class="sd">            The attribute name.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The popped representation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_e_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal API to set edge(s) features.</span>

<span class="sd">        `data` is a dictionary from the feature name to feature tensor. Each tensor</span>
<span class="sd">        is of shape (B, D1, D2, ...), where B is the number of edges to be updated,</span>
<span class="sd">        and (D1, D2, ...) be the shape of the edge representation tensor.</span>

<span class="sd">        All update will be done out of place to work with autograd.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etid : int</span>
<span class="sd">            Edge type id.</span>
<span class="sd">        edges : edges</span>
<span class="sd">            Edges can be either</span>

<span class="sd">            * A pair of endpoint nodes (u, v), where u is the node ID of source</span>
<span class="sd">              node type and v is that of destination node type.</span>
<span class="sd">            * A tensor of edge ids of the given type.</span>

<span class="sd">            The default value is all the edges.</span>
<span class="sd">        data : tensor or dict of tensor</span>
<span class="sd">            Edge representation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># parse argument</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">parse_edges_arg_to_eid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">)</span>

        <span class="c1"># sanity check</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">utils</span><span class="o">.</span><span class="n">is_dict_like</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Expect dictionary type for feature data.&quot;</span>
                <span class="s1">&#39; Got &quot;</span><span class="si">%s</span><span class="s1">&quot; instead.&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="n">num_edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">nfeats</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">val</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">nfeats</span> <span class="o">!=</span> <span class="n">num_edges</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Expect number of features to match number of edges.&quot;</span>
                    <span class="s2">&quot; Got </span><span class="si">%d</span><span class="s2"> and </span><span class="si">%d</span><span class="s2"> instead.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">nfeats</span><span class="p">,</span> <span class="n">num_edges</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s1">&#39;Cannot assign edge feature &quot;</span><span class="si">{}</span><span class="s1">&quot; on device </span><span class="si">{}</span><span class="s1"> to a graph on&#39;</span>
                    <span class="s2">&quot; device </span><span class="si">{}</span><span class="s2">. Call DGLGraph.to() to copy the graph to the&quot;</span>
                    <span class="s2">&quot; same device.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># To prevent users from doing things like:</span>
            <span class="c1">#</span>
            <span class="c1">#     g.pin_memory_()</span>
            <span class="c1">#     g.edata[&#39;x&#39;] = torch.randn(...)</span>
            <span class="c1">#     sg = g.sample_neighbors(torch.LongTensor([...]).cuda())</span>
            <span class="c1">#     sg.edata[&#39;x&#39;]    # Becomes a CPU tensor even if sg is on GPU due to lazy slicing</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">()</span>
                <span class="ow">and</span> <span class="n">F</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">F</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;Pinned graph requires the edge data to be pinned as well. &quot;</span>
                    <span class="s2">&quot;Please pin the edge data before assignment.&quot;</span>
                <span class="p">)</span>

        <span class="c1"># set</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">update_row</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_e_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="n">edges</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Internal API to get edge features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etid : int</span>
<span class="sd">            Edge type id.</span>
<span class="sd">        edges : edges</span>
<span class="sd">            Edges can be a pair of endpoint nodes (u, v), or a</span>
<span class="sd">            tensor of edge ids. The default value is all the edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Representation dict</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># parse argument</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">parse_edges_arg_to_eid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_pop_e_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get and remove the specified edge repr of a single edge type.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etid : int</span>
<span class="sd">            Edge type id.</span>
<span class="sd">        key : str</span>
<span class="sd">          The attribute name.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            The popped representation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="c1">#################################################################</span>
    <span class="c1"># Message passing</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.apply_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.apply_nodes.html#dgl.DGLGraph.apply_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">apply_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">ALL</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the features of the specified nodes by the provided function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        func : callable</span>
<span class="sd">            The function to update node features. It must be</span>
<span class="sd">            a :ref:`apiudf`.</span>
<span class="sd">        v : node IDs</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">            If not given (default), use all the nodes in the graph.</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The node type name. Can be omitted if there is</span>
<span class="sd">            only one type of nodes in the graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.apply_nodes(lambda nodes: {&#39;x&#39; : nodes.data[&#39;h&#39;] * 2})</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;]</span>
<span class="sd">        tensor([[2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.]])</span>

<span class="sd">        **Heterogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 2])})</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.ones(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; g.apply_nodes(lambda nodes: {&#39;h&#39;: nodes.data[&#39;h&#39;] * 2}, ntype=&#39;user&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[2., 2., 2., 2., 2.],</span>
<span class="sd">                [2., 2., 2., 2., 2.],</span>
<span class="sd">                [2., 2., 2., 2., 2.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        apply_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ntid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="n">ntype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="n">ntid</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="n">v_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">v_id</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
        <span class="n">ndata</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">invoke_node_udf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v_id</span><span class="p">,</span> <span class="n">ntype</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">orig_nid</span><span class="o">=</span><span class="n">v_id</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_n_repr</span><span class="p">(</span><span class="n">ntid</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">ndata</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.apply_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.apply_edges.html#dgl.DGLGraph.apply_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">apply_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">edges</span><span class="o">=</span><span class="n">ALL</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update the features of the specified edges by the provided function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The function to generate new edge features. It must be either</span>
<span class="sd">            a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        edges : edges</span>
<span class="sd">            The edges to update features on. The allowed input formats are:</span>

<span class="sd">            * ``int``: A single edge ID.</span>
<span class="sd">            * Int Tensor: Each element is an edge ID.  The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is an edge ID.</span>
<span class="sd">            * (Tensor, Tensor): The node-tensors format where the i-th elements</span>
<span class="sd">              of the two tensors specify an edge.</span>
<span class="sd">            * (iterable[int], iterable[int]): Similar to the node-tensors format but</span>
<span class="sd">              stores edge endpoints in python iterables.</span>

<span class="sd">            Default value specifies all the edges in the graph.</span>

<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL recommends using DGL&#39;s bulit-in function for the :attr:`func` argument,</span>
<span class="sd">        because DGL will invoke efficient kernels that avoids copying node features to</span>
<span class="sd">        edge features in this case.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.apply_edges(lambda edges: {&#39;x&#39; : edges.src[&#39;h&#39;] + edges.dst[&#39;h&#39;]})</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;x&#39;]</span>
<span class="sd">        tensor([[2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.]])</span>

<span class="sd">        Use built-in function</span>

<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>
<span class="sd">        &gt;&gt;&gt; g.apply_edges(fn.u_add_v(&#39;h&#39;, &#39;h&#39;, &#39;x&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;x&#39;]</span>
<span class="sd">        tensor([[2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.],</span>
<span class="sd">                [2., 2.]])</span>

<span class="sd">        **Heterogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 1, 1, 2], [0, 0, 2, 1])})</span>
<span class="sd">        &gt;&gt;&gt; g.edges[(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)].data[&#39;h&#39;] = torch.ones(4, 5)</span>
<span class="sd">        &gt;&gt;&gt; g.apply_edges(lambda edges: {&#39;h&#39;: edges.data[&#39;h&#39;] * 2})</span>
<span class="sd">        &gt;&gt;&gt; g.edges[(&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;)].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[2., 2., 2., 2., 2.],</span>
<span class="sd">                [2., 2., 2., 2., 2.],</span>
<span class="sd">                [2., 2., 2., 2., 2.],</span>
<span class="sd">                [2., 2., 2., 2., 2.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        apply_nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Graph with one relation type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">etype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
            <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span> <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># heterogeneous graph with number of relation types &gt; 1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;User defined functions are not yet &quot;</span>
                    <span class="s2">&quot;supported in apply_edges for heterogeneous graphs. &quot;</span>
                    <span class="s2">&quot;Please use (apply_edges(func), etype = rel) instead.&quot;</span>
                <span class="p">)</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="n">ALL</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eid</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">parse_edges_arg_to_eid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_all</span><span class="p">(</span><span class="n">eid</span><span class="p">):</span>
                <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_subgraph</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="n">relabel_nodes</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">edata</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">invoke_gsddmm</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">edata</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">invoke_edge_udf</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">etype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_e_repr</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="n">edata</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">edata_tensor</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">key</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">edata</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">out_tensor_tuples</span> <span class="o">=</span> <span class="n">edata</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">etid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()):</span>
                <span class="c1"># TODO (Israt): Check the logic why some output tensor is None</span>
                <span class="k">if</span> <span class="n">out_tensor_tuples</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">edata_tensor</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_tensor_tuples</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_set_e_repr</span><span class="p">(</span><span class="n">etid</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="n">edata_tensor</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.send_and_recv">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.send_and_recv.html#dgl.DGLGraph.send_and_recv">[docs]</a>
    <span class="k">def</span> <span class="nf">send_and_recv</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Send messages along the specified edges and reduce them on</span>
<span class="sd">        the destination nodes to update their features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        edges : edges</span>
<span class="sd">            The edges to send and receive messages on. The allowed input formats are:</span>

<span class="sd">            * ``int``: A single edge ID.</span>
<span class="sd">            * Int Tensor: Each element is an edge ID.  The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is an edge ID.</span>
<span class="sd">            * (Tensor, Tensor): The node-tensors format where the i-th elements</span>
<span class="sd">              of the two tensors specify an edge.</span>
<span class="sd">            * (iterable[int], iterable[int]): Similar to the node-tensors format but</span>
<span class="sd">              stores edge endpoints in python iterables.</span>

<span class="sd">        message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The message function to generate messages along the edges.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The reduce function to aggregate the messages.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function to further update the node features</span>
<span class="sd">            after the message reduction. It must be a :ref:`apiudf`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL recommends using DGL&#39;s bulit-in function for the :attr:`message_func`</span>
<span class="sd">        and the :attr:`reduce_func` arguments,</span>
<span class="sd">        because DGL will invoke efficient kernels that avoids copying node features to</span>
<span class="sd">        edge features in this case.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;] = torch.ones(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; # Specify edges using (Tensor, Tensor).</span>
<span class="sd">        &gt;&gt;&gt; g.send_and_recv(([1, 2], [2, 3]), fn.copy_u(&#39;x&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; # Specify edges using IDs.</span>
<span class="sd">        &gt;&gt;&gt; g.send_and_recv([0, 2, 3], fn.copy_u(&#39;x&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.]])</span>

<span class="sd">        **Heterogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 2]),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 1, 1, 2], [0, 0, 1, 1])</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.], [2.]])</span>
<span class="sd">        &gt;&gt;&gt; g.send_and_recv(g[&#39;follows&#39;].edges(), fn.copy_u(&#39;h&#39;, &#39;m&#39;),</span>
<span class="sd">        ...                 fn.sum(&#39;m&#39;, &#39;h&#39;), etype=&#39;follows&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0.],</span>
<span class="sd">                [0.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        **``send_and_recv`` using user-defined functions**</span>

<span class="sd">        &gt;&gt;&gt; import torch as th</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1], [1, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;] = th.tensor([[1.], [2.], [3.]])</span>

<span class="sd">        &gt;&gt;&gt; # Define the function for sending node features as messages.</span>
<span class="sd">        &gt;&gt;&gt; def send_source(edges):</span>
<span class="sd">        ...     return {&#39;m&#39;: edges.src[&#39;x&#39;]}</span>
<span class="sd">        &gt;&gt;&gt; # Sum the messages received and use this to replace the original node feature.</span>
<span class="sd">        &gt;&gt;&gt; def simple_reduce(nodes):</span>
<span class="sd">        ...     return {&#39;x&#39;: nodes.mailbox[&#39;m&#39;].sum(1)}</span>

<span class="sd">        Send and receive messages.</span>

<span class="sd">        &gt;&gt;&gt; g.send_and_recv(g.edges())</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [2.]])</span>

<span class="sd">        Note that the feature of node 0 remains the same as it has no incoming edges.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># edge type</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">dtid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span><span class="o">.</span><span class="n">find_edge</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>
        <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span>
        <span class="c1"># edge IDs</span>
        <span class="n">eid</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">parse_edges_arg_to_eid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">etid</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># no computation</span>
            <span class="k">return</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_edges</span><span class="p">(</span><span class="n">eid</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
        <span class="c1"># call message passing onsubgraph</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span> <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
        <span class="n">compute_graph</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dstnodes</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_create_compute_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">eid</span><span class="p">)</span>
        <span class="n">ndata</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">message_passing</span><span class="p">(</span>
            <span class="n">compute_graph</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_n_repr</span><span class="p">(</span><span class="n">dtid</span><span class="p">,</span> <span class="n">dstnodes</span><span class="p">,</span> <span class="n">ndata</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.pull">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.pull.html#dgl.DGLGraph.pull">[docs]</a>
    <span class="k">def</span> <span class="nf">pull</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pull messages from the specified node(s)&#39; predecessors along the</span>
<span class="sd">        specified edge type, aggregate them to update the node features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v : node IDs</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">        message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The message function to generate messages along the edges.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The reduce function to aggregate the messages.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function to further update the node features</span>
<span class="sd">            after the message reduction. It must be a :ref:`apiudf`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        * If some of the given nodes :attr:`v` has no in-edges, DGL does not invoke</span>
<span class="sd">          message and reduce functions for these nodes and fill their aggregated messages</span>
<span class="sd">          with zero. Users can control the filled values via :meth:`set_n_initializer`.</span>
<span class="sd">          DGL still invokes :attr:`apply_node_func` if provided.</span>
<span class="sd">        * DGL recommends using DGL&#39;s bulit-in function for the :attr:`message_func`</span>
<span class="sd">          and the :attr:`reduce_func` arguments,</span>
<span class="sd">          because DGL will invoke efficient kernels that avoids copying node features to</span>
<span class="sd">          edge features in this case.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;] = torch.ones(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.pull([0, 3, 4], fn.copy_u(&#39;x&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.]])</span>

<span class="sd">        **Heterogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 2]),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): ([0, 2], [0, 1])</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.], [2.]])</span>

<span class="sd">        Pull.</span>

<span class="sd">        &gt;&gt;&gt; g[&#39;follows&#39;].pull(2, fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;), etype=&#39;follows&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># no computation</span>
            <span class="k">return</span>
        <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">dtid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span><span class="o">.</span><span class="n">find_edge</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>
        <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span> <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
        <span class="c1"># call message passing on subgraph</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">in_edges</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
        <span class="n">compute_graph</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dstnodes</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_create_compute_graph</span><span class="p">(</span>
            <span class="n">g</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="n">v</span>
        <span class="p">)</span>
        <span class="n">ndata</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">message_passing</span><span class="p">(</span>
            <span class="n">compute_graph</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_n_repr</span><span class="p">(</span><span class="n">dtid</span><span class="p">,</span> <span class="n">dstnodes</span><span class="p">,</span> <span class="n">ndata</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.push">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.push.html#dgl.DGLGraph.push">[docs]</a>
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Send message from the specified node(s) to their successors</span>
<span class="sd">        along the specified edge type and update their node features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        v : node IDs</span>
<span class="sd">            The node IDs. The allowed formats are:</span>

<span class="sd">            * ``int``: A single node.</span>
<span class="sd">            * Int Tensor: Each element is a node ID. The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is a node ID.</span>

<span class="sd">        message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The message function to generate messages along the edges.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The reduce function to aggregate the messages.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function to further update the node features</span>
<span class="sd">            after the message reduction. It must be a :ref:`apiudf`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL recommends using DGL&#39;s bulit-in function for the :attr:`message_func`</span>
<span class="sd">        and the :attr:`reduce_func` arguments,</span>
<span class="sd">        because DGL will invoke efficient kernels that avoids copying node features to</span>
<span class="sd">        edge features in this case.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;] = torch.ones(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.push([0, 1], fn.copy_u(&#39;x&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [0., 0.],</span>
<span class="sd">                [0., 0.]])</span>

<span class="sd">        **Heterogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 0], [1, 2])})</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.], [2.]])</span>

<span class="sd">        Push.</span>

<span class="sd">        &gt;&gt;&gt; g[&#39;follows&#39;].push(0, fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;), etype=&#39;follows&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0.],</span>
<span class="sd">                [0.],</span>
<span class="sd">                [0.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_edges</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">send_and_recv</span><span class="p">(</span>
            <span class="n">edges</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.update_all">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.update_all.html#dgl.DGLGraph.update_all">[docs]</a>
    <span class="k">def</span> <span class="nf">update_all</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Send messages along all the edges of the specified type</span>
<span class="sd">        and update all the nodes of the corresponding destination type.</span>

<span class="sd">        For heterogeneous graphs with number of relation types &gt; 1, send messages</span>
<span class="sd">        along all the edges, reduce them by type-wisely and across different types</span>
<span class="sd">        at the same time. Then, update the node features of all the nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The message function to generate messages along the edges.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The reduce function to aggregate the messages.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function to further update the node features</span>
<span class="sd">            after the message reduction. It must be a :ref:`apiudf`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        * If some of the nodes in the graph has no in-edges, DGL does not invoke</span>
<span class="sd">          message and reduce functions for these nodes and fill their aggregated messages</span>
<span class="sd">          with zero. Users can control the filled values via :meth:`set_n_initializer`.</span>
<span class="sd">          DGL still invokes :attr:`apply_node_func` if provided.</span>
<span class="sd">        * DGL recommends using DGL&#39;s bulit-in function for the :attr:`message_func`</span>
<span class="sd">          and the :attr:`reduce_func` arguments,</span>
<span class="sd">          because DGL will invoke efficient kernels that avoids copying node features to</span>
<span class="sd">          edge features in this case.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 1, 2, 3], [1, 2, 3, 4]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;x&#39;] = torch.ones(5, 2)</span>
<span class="sd">        &gt;&gt;&gt; g.update_all(fn.copy_u(&#39;x&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[0., 0.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.],</span>
<span class="sd">                [1., 1.]])</span>

<span class="sd">        **Heterogeneous graph**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1, 2], [1, 2, 2])})</span>

<span class="sd">        Update all.</span>

<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.], [2.]])</span>
<span class="sd">        &gt;&gt;&gt; g[&#39;follows&#39;].update_all(fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;), etype=&#39;follows&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0.],</span>
<span class="sd">                [0.],</span>
<span class="sd">                [3.]])</span>

<span class="sd">        **Heterogenenous graph (number relation types &gt; 1)**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 1]),</span>
<span class="sd">        ...     (&#39;game&#39;, &#39;attracts&#39;, &#39;user&#39;): ([0], [1])</span>
<span class="sd">        ... })</span>

<span class="sd">        Update all.</span>

<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[1.], [2.]])</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;h&#39;] = torch.tensor([[1.]])</span>
<span class="sd">        &gt;&gt;&gt; g.update_all(fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0.],</span>
<span class="sd">                [4.]])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Graph with one relation type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">number_of_etypes</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">etype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
            <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="n">etid</span><span class="p">]</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">dtid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span><span class="o">.</span><span class="n">find_edge</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span> <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
            <span class="n">ndata</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">message_passing</span><span class="p">(</span>
                <span class="n">g</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span><span class="n">reduce_func</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">reduce_func</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]</span>
                <span class="ow">and</span> <span class="n">ndata</span>
            <span class="p">):</span>
                <span class="c1"># Replace infinity with zero for isolated nodes</span>
                <span class="n">key</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ndata</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ndata</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">replace_inf_with_zero</span><span class="p">(</span><span class="n">ndata</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_n_repr</span><span class="p">(</span><span class="n">dtid</span><span class="p">,</span> <span class="n">ALL</span><span class="p">,</span> <span class="n">ndata</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># heterogeneous graph with number of relation types &gt; 1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span><span class="n">message_func</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span>
                <span class="n">reduce_func</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;User defined functions are not yet &quot;</span>
                    <span class="s2">&quot;supported in update_all for heterogeneous graphs. &quot;</span>
                    <span class="s2">&quot;Please use multi_update_all instead.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">reduce_func</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot set both intra-type and inter-type reduce &quot;</span>
                    <span class="s2">&quot;operators as &#39;mean&#39; using update_all. Please use &quot;</span>
                    <span class="s2">&quot;multi_update_all instead.&quot;</span>
                <span class="p">)</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span>
            <span class="n">all_out</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">message_passing</span><span class="p">(</span>
                <span class="n">g</span><span class="p">,</span> <span class="n">message_func</span><span class="p">,</span> <span class="n">reduce_func</span><span class="p">,</span> <span class="n">apply_node_func</span>
            <span class="p">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_out</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">out_tensor_tuples</span> <span class="o">=</span> <span class="n">all_out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

            <span class="n">dst_tensor</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
                <span class="n">dtid</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">dsttype</span><span class="p">)</span>
                <span class="n">dst_tensor</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_tensor_tuples</span><span class="p">[</span><span class="n">dtid</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span><span class="n">reduce_func</span><span class="p">)</span> <span class="ow">and</span> <span class="n">reduce_func</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span>
                    <span class="s2">&quot;min&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;max&quot;</span><span class="p">,</span>
                <span class="p">]:</span>
                    <span class="n">dst_tensor</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">replace_inf_with_zero</span><span class="p">(</span><span class="n">dst_tensor</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">dtid</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dst_tensor</span><span class="p">)</span></div>


    <span class="c1">#################################################################</span>
    <span class="c1"># Message passing on heterograph</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.multi_update_all">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.multi_update_all.html#dgl.DGLGraph.multi_update_all">[docs]</a>
    <span class="k">def</span> <span class="nf">multi_update_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">etype_dict</span><span class="p">,</span> <span class="n">cross_reducer</span><span class="p">,</span> <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Send messages along all the edges, reduce them by first type-wisely</span>
<span class="sd">        then across different types, and then update the node features of all</span>
<span class="sd">        the nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        etype_dict : dict</span>
<span class="sd">            Arguments for edge-type-wise message passing. The keys are edge types</span>
<span class="sd">            while the values are message passing arguments.</span>

<span class="sd">            The allowed key formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            The value must be a tuple ``(message_func, reduce_func, [apply_node_func])``, where</span>

<span class="sd">            * message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">                The message function to generate messages along the edges.</span>
<span class="sd">                It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">            * reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">                The reduce function to aggregate the messages.</span>
<span class="sd">                It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">            * apply_node_func : callable, optional</span>
<span class="sd">                An optional apply function to further update the node features</span>
<span class="sd">                after the message reduction. It must be a :ref:`apiudf`.</span>

<span class="sd">        cross_reducer : str or callable function</span>
<span class="sd">            Cross type reducer. One of ``&quot;sum&quot;``, ``&quot;min&quot;``, ``&quot;max&quot;``, ``&quot;mean&quot;``, ``&quot;stack&quot;``</span>
<span class="sd">            or a callable function. If a callable function is provided, the input argument must be</span>
<span class="sd">            a single list of tensors containing aggregation results from each edge type, and the</span>
<span class="sd">            output of function must be a single tensor.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function after the messages are reduced both</span>
<span class="sd">            type-wisely and across different types.</span>
<span class="sd">            It must be a :ref:`apiudf`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        DGL recommends using DGL&#39;s bulit-in function for the message_func</span>
<span class="sd">        and the reduce_func in the type-wise message passing arguments,</span>
<span class="sd">        because DGL will invoke efficient kernels that avoids copying node features to</span>
<span class="sd">        edge features in this case.</span>


<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Instantiate a heterograph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1], [1, 1]),</span>
<span class="sd">        ...     (&#39;game&#39;, &#39;attracts&#39;, &#39;user&#39;): ([0], [1])</span>
<span class="sd">        ... })</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[1.], [2.]])</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;h&#39;] = torch.tensor([[1.]])</span>

<span class="sd">        Update all.</span>

<span class="sd">        &gt;&gt;&gt; g.multi_update_all(</span>
<span class="sd">        ...     {&#39;follows&#39;: (fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;)),</span>
<span class="sd">        ...      &#39;attracts&#39;: (fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))},</span>
<span class="sd">        ... &quot;sum&quot;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[0.],</span>
<span class="sd">                [4.]])</span>

<span class="sd">        User-defined cross reducer equivalent to &quot;sum&quot;.</span>

<span class="sd">        &gt;&gt;&gt; def cross_sum(flist):</span>
<span class="sd">        ...     return torch.sum(torch.stack(flist, dim=0), dim=0) if len(flist) &gt; 1 else flist[0]</span>

<span class="sd">        Use the user-defined cross reducer.</span>

<span class="sd">        &gt;&gt;&gt; g.multi_update_all(</span>
<span class="sd">        ...     {&#39;follows&#39;: (fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;)),</span>
<span class="sd">        ...      &#39;attracts&#39;: (fn.copy_u(&#39;h&#39;, &#39;m&#39;), fn.sum(&#39;m&#39;, &#39;h&#39;))},</span>
<span class="sd">        ... cross_sum)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">all_out</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="n">merge_order</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">etype</span><span class="p">,</span> <span class="n">args</span> <span class="ow">in</span> <span class="n">etype_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

            <span class="n">etid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">dtid</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">metagraph</span><span class="o">.</span><span class="n">find_edge</span><span class="p">(</span><span class="n">etid</span><span class="p">)</span>
            <span class="n">args</span> <span class="o">=</span> <span class="n">pad_tuple</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s1">&#39;Invalid arguments for edge type &quot;</span><span class="si">{}</span><span class="s1">&quot;. Should be &#39;</span>
                    <span class="s2">&quot;(msg_func, reduce_func, [apply_node_func])&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">mfunc</span><span class="p">,</span> <span class="n">rfunc</span><span class="p">,</span> <span class="n">afunc</span> <span class="o">=</span> <span class="n">args</span>
            <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span> <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span>
            <span class="n">all_out</span><span class="p">[</span><span class="n">dtid</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">message_passing</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">mfunc</span><span class="p">,</span> <span class="n">rfunc</span><span class="p">,</span> <span class="n">afunc</span><span class="p">))</span>
            <span class="n">merge_order</span><span class="p">[</span><span class="n">dtid</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">etid</span>
            <span class="p">)</span>  <span class="c1"># use edge type id as merge order hint</span>
        <span class="k">for</span> <span class="n">dtid</span><span class="p">,</span> <span class="n">frames</span> <span class="ow">in</span> <span class="n">all_out</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># merge by cross_reducer</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">reduce_dict_data</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">cross_reducer</span><span class="p">,</span> <span class="n">merge_order</span><span class="p">[</span><span class="n">dtid</span><span class="p">])</span>
            <span class="c1"># Replace infinity with zero for isolated nodes when reducer is min/max</span>
            <span class="k">if</span> <span class="n">core</span><span class="o">.</span><span class="n">is_builtin</span><span class="p">(</span><span class="n">rfunc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">rfunc</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">F</span><span class="o">.</span><span class="n">replace_inf_with_zero</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
                        <span class="k">if</span> <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">dtid</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="c1"># apply</span>
            <span class="k">if</span> <span class="n">apply_node_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">apply_nodes</span><span class="p">(</span><span class="n">apply_node_func</span><span class="p">,</span> <span class="n">ALL</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="n">dtid</span><span class="p">])</span></div>


    <span class="c1">#################################################################</span>
    <span class="c1"># Message propagation</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.prop_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.prop_nodes.html#dgl.DGLGraph.prop_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">prop_nodes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nodes_generator</span><span class="p">,</span>
        <span class="n">message_func</span><span class="p">,</span>
        <span class="n">reduce_func</span><span class="p">,</span>
        <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Propagate messages using graph traversal by sequentially triggering</span>
<span class="sd">        :func:`pull()` on nodes.</span>

<span class="sd">        The traversal order is specified by the ``nodes_generator``. It generates</span>
<span class="sd">        node frontiers, which is a list or a tensor of nodes. The nodes in the</span>
<span class="sd">        same frontier will be triggered together, while nodes in different frontiers</span>
<span class="sd">        will be triggered according to the generating order.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nodes_generator : iterable[node IDs]</span>
<span class="sd">            The generator of node frontiers. Each frontier is a set of node IDs</span>
<span class="sd">            stored in Tensor or python iterables.</span>
<span class="sd">            It specifies which nodes perform :func:`pull` at each step.</span>
<span class="sd">        message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The message function to generate messages along the edges.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The reduce function to aggregate the messages.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function to further update the node features</span>
<span class="sd">            after the message reduction. It must be a :ref:`apiudf`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>

<span class="sd">        Instantiate a heterogrph and perform multiple rounds of message passing.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1, 2, 3], [2, 3, 4, 4])})</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[1.], [2.], [3.], [4.], [5.]])</span>
<span class="sd">        &gt;&gt;&gt; g[&#39;follows&#39;].prop_nodes([[2, 3], [4]], fn.copy_u(&#39;h&#39;, &#39;m&#39;),</span>
<span class="sd">        ...                         fn.sum(&#39;m&#39;, &#39;h&#39;), etype=&#39;follows&#39;)</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [2.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [2.],</span>
<span class="sd">                [3.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        prop_edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">node_frontier</span> <span class="ow">in</span> <span class="n">nodes_generator</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span>
                <span class="n">node_frontier</span><span class="p">,</span>
                <span class="n">message_func</span><span class="p">,</span>
                <span class="n">reduce_func</span><span class="p">,</span>
                <span class="n">apply_node_func</span><span class="p">,</span>
                <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.prop_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.prop_edges.html#dgl.DGLGraph.prop_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">prop_edges</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">edges_generator</span><span class="p">,</span>
        <span class="n">message_func</span><span class="p">,</span>
        <span class="n">reduce_func</span><span class="p">,</span>
        <span class="n">apply_node_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Propagate messages using graph traversal by sequentially triggering</span>
<span class="sd">        :func:`send_and_recv()` on edges.</span>

<span class="sd">        The traversal order is specified by the ``edges_generator``. It generates</span>
<span class="sd">        edge frontiers. The edge frontiers should be of *valid edges type*.</span>
<span class="sd">        See :func:`send` for more details.</span>

<span class="sd">        Edges in the same frontier will be triggered together, and edges in</span>
<span class="sd">        different frontiers will be triggered according to the generating order.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        edges_generator : generator</span>
<span class="sd">            The generator of edge frontiers.</span>
<span class="sd">        message_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The message function to generate messages along the edges.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        reduce_func : dgl.function.BuiltinFunction or callable</span>
<span class="sd">            The reduce function to aggregate the messages.</span>
<span class="sd">            It must be either a :ref:`api-built-in` or a :ref:`apiudf`.</span>
<span class="sd">        apply_node_func : callable, optional</span>
<span class="sd">            An optional apply function to further update the node features</span>
<span class="sd">            after the message reduction. It must be a :ref:`apiudf`.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import dgl.function as fn</span>

<span class="sd">        Instantiate a heterogrph and perform multiple rounds of message passing.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({(&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): ([0, 1, 2, 3], [2, 3, 4, 4])})</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[1.], [2.], [3.], [4.], [5.]])</span>
<span class="sd">        &gt;&gt;&gt; g[&#39;follows&#39;].prop_edges([[0, 1], [2, 3]], fn.copy_u(&#39;h&#39;, &#39;m&#39;),</span>
<span class="sd">        ...                         fn.sum(&#39;m&#39;, &#39;h&#39;), etype=&#39;follows&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [2.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [2.],</span>
<span class="sd">                [3.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        prop_nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">edge_frontier</span> <span class="ow">in</span> <span class="n">edges_generator</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">send_and_recv</span><span class="p">(</span>
                <span class="n">edge_frontier</span><span class="p">,</span>
                <span class="n">message_func</span><span class="p">,</span>
                <span class="n">reduce_func</span><span class="p">,</span>
                <span class="n">apply_node_func</span><span class="p">,</span>
                <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">,</span>
            <span class="p">)</span></div>


    <span class="c1">#################################################################</span>
    <span class="c1"># Misc</span>
    <span class="c1">#################################################################</span>

<div class="viewcode-block" id="DGLGraph.filter_nodes">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.filter_nodes.html#dgl.DGLGraph.filter_nodes">[docs]</a>
    <span class="k">def</span> <span class="nf">filter_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">nodes</span><span class="o">=</span><span class="n">ALL</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the IDs of the nodes with the given node type that satisfy</span>
<span class="sd">        the given predicate.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        predicate : callable</span>
<span class="sd">            A function of signature ``func(nodes) -&gt; Tensor``.</span>
<span class="sd">            ``nodes`` are :class:`dgl.NodeBatch` objects.</span>
<span class="sd">            Its output tensor should be a 1D boolean tensor with</span>
<span class="sd">            each element indicating whether the corresponding node in</span>
<span class="sd">            the batch satisfies the predicate.</span>
<span class="sd">        nodes : node ID(s), optional</span>
<span class="sd">            The node(s) for query. The allowed formats are:</span>

<span class="sd">            - Tensor: A 1D tensor that contains the node(s) for query, whose data type</span>
<span class="sd">              and device should be the same as the :py:attr:`idtype` and device of the graph.</span>
<span class="sd">            - iterable[int] : Similar to the tensor, but stores node IDs in a sequence</span>
<span class="sd">              (e.g. list, tuple, numpy.ndarray).</span>

<span class="sd">            By default, it considers all nodes.</span>
<span class="sd">        ntype : str, optional</span>
<span class="sd">            The node type for query. If the graph has multiple node types, one must</span>
<span class="sd">            specify the argument. Otherwise, it can be omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            A 1D tensor that contains the ID(s) of the node(s) that satisfy the predicate.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Define a predicate function.</span>

<span class="sd">        &gt;&gt;&gt; def nodes_with_feature_one(nodes):</span>
<span class="sd">        ...     # Whether a node has feature 1</span>
<span class="sd">        ...     return (nodes.data[&#39;h&#39;] == 1.).squeeze(1)</span>

<span class="sd">        Filter nodes for a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.tensor([[0.], [1.], [1.], [0.]])</span>
<span class="sd">        &gt;&gt;&gt; print(g.filter_nodes(nodes_with_feature_one))</span>
<span class="sd">        tensor([1, 2])</span>

<span class="sd">        Filter on nodes with IDs 0 and 1</span>

<span class="sd">        &gt;&gt;&gt; print(g.filter_nodes(nodes_with_feature_one, nodes=torch.tensor([0, 1])))</span>
<span class="sd">        tensor([1])</span>

<span class="sd">        Filter nodes for a heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1]))})</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;user&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.], [1.]])</span>
<span class="sd">        &gt;&gt;&gt; g.nodes[&#39;game&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.]])</span>
<span class="sd">        &gt;&gt;&gt; # Filter for &#39;user&#39; nodes</span>
<span class="sd">        &gt;&gt;&gt; print(g.filter_nodes(nodes_with_feature_one, ntype=&#39;user&#39;))</span>
<span class="sd">        tensor([1, 2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
            <span class="n">nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="s2">&quot;nodes&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">ntype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;v contains invalid node IDs&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">apply_nodes</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">nbatch</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;_mask&quot;</span><span class="p">:</span> <span class="n">predicate</span><span class="p">(</span><span class="n">nbatch</span><span class="p">)},</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">ntype</span>
            <span class="p">)</span>
            <span class="n">ntype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">ntype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">ntype</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ntype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;_mask&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span></div>


<div class="viewcode-block" id="DGLGraph.filter_edges">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.filter_edges.html#dgl.DGLGraph.filter_edges">[docs]</a>
    <span class="k">def</span> <span class="nf">filter_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predicate</span><span class="p">,</span> <span class="n">edges</span><span class="o">=</span><span class="n">ALL</span><span class="p">,</span> <span class="n">etype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the IDs of the edges with the given edge type that satisfy</span>
<span class="sd">        the given predicate.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        predicate : callable</span>
<span class="sd">            A function of signature ``func(edges) -&gt; Tensor``.</span>
<span class="sd">            ``edges`` are :class:`dgl.EdgeBatch` objects.</span>
<span class="sd">            Its output tensor should be a 1D boolean tensor with</span>
<span class="sd">            each element indicating whether the corresponding edge in</span>
<span class="sd">            the batch satisfies the predicate.</span>
<span class="sd">        edges : edges</span>
<span class="sd">            The edges to send and receive messages on. The allowed input formats are:</span>

<span class="sd">            * ``int``: A single edge ID.</span>
<span class="sd">            * Int Tensor: Each element is an edge ID.  The tensor must have the same device type</span>
<span class="sd">              and ID data type as the graph&#39;s.</span>
<span class="sd">            * iterable[int]: Each element is an edge ID.</span>
<span class="sd">            * (Tensor, Tensor): The node-tensors format where the i-th elements</span>
<span class="sd">              of the two tensors specify an edge.</span>
<span class="sd">            * (iterable[int], iterable[int]): Similar to the node-tensors format but</span>
<span class="sd">              stores edge endpoints in python iterables.</span>

<span class="sd">            By default, it considers all the edges.</span>
<span class="sd">        etype : str or (str, str, str), optional</span>
<span class="sd">            The type name of the edges. The allowed type name formats are:</span>

<span class="sd">            * ``(str, str, str)`` for source node type, edge type and destination node type.</span>
<span class="sd">            * or one ``str`` edge type name if the name can uniquely identify a</span>
<span class="sd">              triplet format in the graph.</span>

<span class="sd">            Can be omitted if the graph has only one type of edges.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tensor</span>
<span class="sd">            A 1D tensor that contains the ID(s) of the edge(s) that satisfy the predicate.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Define a predicate function.</span>

<span class="sd">        &gt;&gt;&gt; def edges_with_feature_one(edges):</span>
<span class="sd">        ...     # Whether an edge has feature 1</span>
<span class="sd">        ...     return (edges.data[&#39;h&#39;] == 1.).squeeze(1)</span>

<span class="sd">        Filter edges for a homogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 2]), torch.tensor([1, 2, 3])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.tensor([[0.], [1.], [1.]])</span>
<span class="sd">        &gt;&gt;&gt; print(g.filter_edges(edges_with_feature_one))</span>
<span class="sd">        tensor([1, 2])</span>

<span class="sd">        Filter on edges with IDs 0 and 1</span>

<span class="sd">        &gt;&gt;&gt; print(g.filter_edges(edges_with_feature_one, edges=torch.tensor([0, 1])))</span>
<span class="sd">        tensor([1])</span>

<span class="sd">        Filter edges for a heterogeneous graph.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;follows&#39;, &#39;user&#39;): (torch.tensor([0, 1]), torch.tensor([1, 2]))})</span>
<span class="sd">        &gt;&gt;&gt; g.edges[&#39;plays&#39;].data[&#39;h&#39;] = torch.tensor([[0.], [1.], [1.], [0.]])</span>
<span class="sd">        &gt;&gt;&gt; # Filter for &#39;plays&#39; nodes</span>
<span class="sd">        &gt;&gt;&gt; print(g.filter_edges(edges_with_feature_one, etype=&#39;plays&#39;))</span>
<span class="sd">        tensor([1, 2])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">edges</span>
            <span class="n">srctype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_canonical_etype</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s2">&quot;u&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">srctype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;edges[0] contains invalid node IDs&quot;</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">has_nodes</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">dsttype</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;edges[1] contains invalid node IDs&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">or</span> <span class="n">F</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">)</span>
            <span class="n">min_eid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&gt;</span> <span class="n">min_eid</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid edge ID </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">min_eid</span><span class="p">))</span>
            <span class="n">max_eid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">as_scalar</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">max_eid</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;Invalid edge ID </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_eid</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported type of edges:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">edges</span><span class="p">))</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">apply_edges</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">ebatch</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;_mask&quot;</span><span class="p">:</span> <span class="n">predicate</span><span class="p">(</span><span class="n">ebatch</span><span class="p">)},</span> <span class="n">edges</span><span class="p">,</span> <span class="n">etype</span>
            <span class="p">)</span>
            <span class="n">etype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">etype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">etype</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="n">etype</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;_mask&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">is_all</span><span class="p">(</span><span class="n">edges</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">nonzero_1d</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_ids</span><span class="p">(</span><span class="n">edges</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">etype</span><span class="o">=</span><span class="n">etype</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">e</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">prepare_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="s2">&quot;edges&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the device of the graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        device context</span>
<span class="sd">            The device of the graph, which should be a framework-specific device object</span>
<span class="sd">            (e.g., ``torch.device``).</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a homogeneous graph for demonstration.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; print(g.device)</span>
<span class="sd">        device(type=&#39;cpu&#39;)</span>

<span class="sd">        The case of heterogeneous graphs is the same.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">to_backend_ctx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">ctx</span><span class="p">)</span>

<div class="viewcode-block" id="DGLGraph.to">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.to.html#dgl.DGLGraph.to">[docs]</a>
    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Move ndata, edata and graph structure to the targeted device (cpu/gpu).</span>

<span class="sd">        If the graph is already on the specified device, the function directly returns it.</span>
<span class="sd">        Otherwise, it returns a cloned graph on the specified device.</span>

<span class="sd">        Note that data of node and edge features are not moved to the specified</span>
<span class="sd">        device before being accessed or `materialize_data()` is called.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device : Framework-specific device context object</span>
<span class="sd">            The context to move data to (e.g., ``torch.device``).</span>
<span class="sd">        kwargs : Key-word arguments.</span>
<span class="sd">            Key-word arguments fed to the framework copy function.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph on the specified device.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 0]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.zeros(2, 2)</span>
<span class="sd">        &gt;&gt;&gt; g1 = g.to(torch.device(&#39;cuda:0&#39;))</span>
<span class="sd">        &gt;&gt;&gt; print(g1.device)</span>
<span class="sd">        device(type=&#39;cuda&#39;, index=0)</span>
<span class="sd">        &gt;&gt;&gt; print(g1.ndata[&#39;h&#39;].device)</span>
<span class="sd">        device(type=&#39;cuda&#39;, index=0)</span>
<span class="sd">        &gt;&gt;&gt; print(g1.nodes().device)</span>
<span class="sd">        device(type=&#39;cuda&#39;, index=0)</span>

<span class="sd">        The original graph is still on CPU.</span>

<span class="sd">        &gt;&gt;&gt; print(g.device)</span>
<span class="sd">        device(type=&#39;cpu&#39;)</span>
<span class="sd">        &gt;&gt;&gt; print(g.ndata[&#39;h&#39;].device)</span>
<span class="sd">        device(type=&#39;cpu&#39;)</span>
<span class="sd">        &gt;&gt;&gt; print(g.nodes().device)</span>
<span class="sd">        device(type=&#39;cpu&#39;)</span>

<span class="sd">        The case of heterogeneous graphs is the same.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">device</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># 1. Copy graph structure</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">to_dgl_context</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1"># 2. Copy features</span>
        <span class="c1"># TODO(minjie): handle initializer</span>
        <span class="n">new_nframes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">nframe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">:</span>
            <span class="n">new_nframes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nframe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="n">new_nframes</span>

        <span class="n">new_eframes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">eframe</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">:</span>
            <span class="n">new_eframes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eframe</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="n">new_eframes</span>

        <span class="c1"># 2. Copy misc info</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_bnn</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">ret</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="o">=</span> <span class="n">new_bnn</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_bne</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">copy_to</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">ret</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="o">=</span> <span class="n">new_bne</span>

        <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="DGLGraph.cpu">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.cpu.html#dgl.DGLGraph.cpu">[docs]</a>
    <span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a new copy of this graph on CPU.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            Graph on CPU.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        to</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span></div>


    <span class="k">def</span> <span class="nf">materialize_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Materialize the graph data on the current device.</span>

<span class="sd">        This method is a no-op if the graph data is already materialized.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph on the current device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">_columns</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">col</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># pylint: disable=pointless-statement</span>
        <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="DGLGraph.pin_memory_">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.pin_memory_.html#dgl.DGLGraph.pin_memory_">[docs]</a>
    <span class="k">def</span> <span class="nf">pin_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Pin the graph structure and node/edge data to the page-locked memory for</span>
<span class="sd">        GPU zero-copy access.</span>

<span class="sd">        This is an **inplace** method. The graph structure must be on CPU to be pinned.</span>
<span class="sd">        If the graph struture is already pinned, the function directly returns it.</span>

<span class="sd">        Materialization of new sparse formats for pinned graphs is not allowed.</span>
<span class="sd">        To avoid implicit formats materialization during training,</span>
<span class="sd">        you should create all the needed formats before pinning.</span>
<span class="sd">        But cloning and materialization is fine. See the examples below.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The pinned graph.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([1, 0]), torch.tensor([1, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.pin_memory_()</span>

<span class="sd">        Materialization of new sparse formats is not allowed for pinned graphs.</span>

<span class="sd">        &gt;&gt;&gt; g.create_formats_()  # This would raise an error! You should do this before pinning.</span>

<span class="sd">        Cloning and materializing new formats is allowed. The returned graph is **not** pinned.</span>

<span class="sd">        &gt;&gt;&gt; g1 = g.formats([&#39;csc&#39;])</span>
<span class="sd">        &gt;&gt;&gt; assert not g1.is_pinned()</span>

<span class="sd">        The pinned graph can be access from both CPU and GPU. The concrete device depends</span>
<span class="sd">        on the context of ``query``. For example, ``eid`` in ``find_edges()`` is a query.</span>
<span class="sd">        When ``eid`` is on CPU, ``find_edges()`` is executed on CPU, and the returned</span>
<span class="sd">        values are CPU tensors</span>

<span class="sd">        &gt;&gt;&gt; g.unpin_memory_()</span>
<span class="sd">        &gt;&gt;&gt; g.create_formats_()</span>
<span class="sd">        &gt;&gt;&gt; g.pin_memory_()</span>
<span class="sd">        &gt;&gt;&gt; eid = torch.tensor([1])</span>
<span class="sd">        &gt;&gt;&gt; g.find_edges(eids)</span>
<span class="sd">        (tensor([0]), tensor([2]))</span>

<span class="sd">        Moving ``eid`` to GPU, ``find_edges()`` will be executed on GPU, and the returned</span>
<span class="sd">        values are GPU tensors.</span>

<span class="sd">        &gt;&gt;&gt; eid = eid.to(&#39;cuda:0&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.find_edges(eids)</span>
<span class="sd">        (tensor([0], device=&#39;cuda:0&#39;), tensor([2], device=&#39;cuda:0&#39;))</span>

<span class="sd">        If you don&#39;t provide a ``query``, methods will be executed on CPU by default.</span>

<span class="sd">        &gt;&gt;&gt; g.in_degrees()</span>
<span class="sd">        tensor([0, 1, 1])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">device_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                    <span class="s2">&quot;The graph structure must be on CPU to be pinned.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">pin_memory_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">_columns</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">col</span><span class="o">.</span><span class="n">pin_memory_</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DGLGraph.unpin_memory_">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.unpin_memory_.html#dgl.DGLGraph.unpin_memory_">[docs]</a>
    <span class="k">def</span> <span class="nf">unpin_memory_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Unpin the graph structure and node/edge data from the page-locked memory.</span>

<span class="sd">        This is an **inplace** method. If the graph struture is not pinned,</span>
<span class="sd">        e.g., on CPU or GPU, the function directly returns it.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The unpinned graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">unpin_memory_</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">_columns</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">col</span><span class="o">.</span><span class="n">unpin_memory_</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DGLGraph.is_pinned">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.is_pinned.html#dgl.DGLGraph.is_pinned">[docs]</a>
    <span class="k">def</span> <span class="nf">is_pinned</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if the graph structure is pinned to the page-locked memory.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if the graph structure is pinned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="nf">record_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Record the stream that is using this graph.</span>
<span class="sd">        This method only supports the PyTorch backend and requires graphs on the GPU.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        stream : torch.cuda.Stream</span>
<span class="sd">            The stream that is using this graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">get_preferred_backend</span><span class="p">()</span> <span class="o">!=</span> <span class="s2">&quot;pytorch&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;record_stream only support the PyTorch backend.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">F</span><span class="o">.</span><span class="n">device_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span><span class="s2">&quot;The graph must be on GPU to be recorded.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">_columns</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">col</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a heterograph object that is a clone of current graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph object that is a clone of current graph.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># XXX(minjie): Do a shallow copy first to clone some internal metagraph information.</span>
        <span class="c1">#   Not a beautiful solution though.</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Clone the graph structure</span>
        <span class="n">meta_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">s_ntype</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">d_ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">:</span>
            <span class="n">meta_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">s_ntype</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">d_ntype</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="n">metagraph</span> <span class="o">=</span> <span class="n">graph_index</span><span class="o">.</span><span class="n">from_edge_list</span><span class="p">(</span><span class="n">meta_edges</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="c1"># rebuild graph idx</span>
        <span class="n">num_nodes_per_type</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">(</span><span class="n">c_ntype</span><span class="p">)</span> <span class="k">for</span> <span class="n">c_ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span>
        <span class="p">]</span>
        <span class="n">relation_graphs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">get_relation_graph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_etype_id</span><span class="p">(</span><span class="n">c_etype</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">c_etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span>
        <span class="p">]</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_heterograph_from_relations</span><span class="p">(</span>
            <span class="n">metagraph</span><span class="p">,</span>
            <span class="n">relation_graphs</span><span class="p">,</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">toindex</span><span class="p">(</span><span class="n">num_nodes_per_type</span><span class="p">,</span> <span class="s2">&quot;int64&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Clone the frames</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">fr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">fr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>

        <span class="c1"># Copy the batch information</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_batch_num_nodes</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_nodes</span><span class="p">)</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_batch_num_edges</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_num_edges</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">def</span> <span class="nf">local_var</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a graph object for usage in a local function scope.</span>

<span class="sd">        The returned graph object shares the feature data and graph structure of this graph.</span>
<span class="sd">        However, any out-place mutation to the feature data will not reflect to this graph,</span>
<span class="sd">        thus making it easier to use in a function scope (e.g. forward computation of a model).</span>

<span class="sd">        If set, the local graph object will use same initializers for node features and</span>
<span class="sd">        edge features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph object for a local variable.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Inplace operations do reflect to the original graph. This function also has little</span>
<span class="sd">        overhead when the number of feature tensors in this graph is small.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a function for computation on graphs.</span>

<span class="sd">        &gt;&gt;&gt; def foo(g):</span>
<span class="sd">        ...     g = g.local_var()</span>
<span class="sd">        ...     g.edata[&#39;h&#39;] = torch.ones((g.num_edges(), 3))</span>
<span class="sd">        ...     g.edata[&#39;h2&#39;] = torch.ones((g.num_edges(), 3))</span>
<span class="sd">        ...     return g.edata[&#39;h&#39;]</span>

<span class="sd">        ``local_var`` avoids changing the graph features when exiting the function.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.zeros((g.num_edges(), 3))</span>
<span class="sd">        &gt;&gt;&gt; newh = foo(g)</span>
<span class="sd">        &gt;&gt;&gt; print(g.edata[&#39;h&#39;])  # still get tensor of all zeros</span>
<span class="sd">        tensor([[0., 0., 0.],</span>
<span class="sd">                [0., 0., 0.],</span>
<span class="sd">                [0., 0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; &#39;h2&#39; in g.edata      # new feature set in the function scope is not found</span>
<span class="sd">        False</span>

<span class="sd">        In-place operations will still reflect to the original graph.</span>

<span class="sd">        &gt;&gt;&gt; def foo(g):</span>
<span class="sd">        ...     g = g.local_var()</span>
<span class="sd">        ...     # in-place operation</span>
<span class="sd">        ...     g.edata[&#39;h&#39;] += 1</span>
<span class="sd">        ...     return g.edata[&#39;h&#39;]</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.zeros((g.num_edges(), 1))</span>
<span class="sd">        &gt;&gt;&gt; newh = foo(g)</span>
<span class="sd">        &gt;&gt;&gt; print(g.edata[&#39;h&#39;])  # the result changes</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        local_scope</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">fr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">fr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ret</span>

<div class="viewcode-block" id="DGLGraph.local_scope">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.local_scope.html#dgl.DGLGraph.local_scope">[docs]</a>
    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">local_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Enter a local scope context for the graph.</span>

<span class="sd">        By entering a local scope, any out-place mutation to the feature data will</span>
<span class="sd">        not reflect to the original graph, thus making it easier to use in a function scope</span>
<span class="sd">        (e.g. forward computation of a model).</span>

<span class="sd">        If set, the local scope will use same initializers for node features and</span>
<span class="sd">        edge features.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Inplace operations do reflect to the original graph. This function also has little</span>
<span class="sd">        overhead when the number of feature tensors in this graph is small.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a function for computation on graphs.</span>

<span class="sd">        &gt;&gt;&gt; def foo(g):</span>
<span class="sd">        ...     with g.local_scope():</span>
<span class="sd">        ...         g.edata[&#39;h&#39;] = torch.ones((g.num_edges(), 3))</span>
<span class="sd">        ...         g.edata[&#39;h2&#39;] = torch.ones((g.num_edges(), 3))</span>
<span class="sd">        ...         return g.edata[&#39;h&#39;]</span>

<span class="sd">        ``local_scope`` avoids changing the graph features when exiting the function.</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.zeros((g.num_edges(), 3))</span>
<span class="sd">        &gt;&gt;&gt; newh = foo(g)</span>
<span class="sd">        &gt;&gt;&gt; print(g.edata[&#39;h&#39;])  # still get tensor of all zeros</span>
<span class="sd">        tensor([[0., 0., 0.],</span>
<span class="sd">                [0., 0., 0.],</span>
<span class="sd">                [0., 0., 0.]])</span>
<span class="sd">        &gt;&gt;&gt; &#39;h2&#39; in g.edata      # new feature set in the function scope is not found</span>
<span class="sd">        False</span>

<span class="sd">        In-place operations will still reflect to the original graph.</span>

<span class="sd">        &gt;&gt;&gt; def foo(g):</span>
<span class="sd">        ...     with g.local_scope():</span>
<span class="sd">        ...         # in-place operation</span>
<span class="sd">        ...         g.edata[&#39;h&#39;] += 1</span>
<span class="sd">        ...         return g.edata[&#39;h&#39;]</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.edata[&#39;h&#39;] = torch.zeros((g.num_edges(), 1))</span>
<span class="sd">        &gt;&gt;&gt; newh = foo(g)</span>
<span class="sd">        &gt;&gt;&gt; print(g.edata[&#39;h&#39;])  # the result changes</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        local_var</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">old_nframes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span>
        <span class="n">old_eframes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">fr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="p">[</span><span class="n">fr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">fr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node_frames</span> <span class="o">=</span> <span class="n">old_nframes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edge_frames</span> <span class="o">=</span> <span class="n">old_eframes</span></div>


<div class="viewcode-block" id="DGLGraph.formats">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.formats.html#dgl.DGLGraph.formats">[docs]</a>
    <span class="k">def</span> <span class="nf">formats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">formats</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Get a cloned graph with the specified allowed sparse format(s) or</span>
<span class="sd">        query for the usage status of sparse formats.</span>

<span class="sd">        The API copies both the graph structure and the features.</span>

<span class="sd">        If the input graph has multiple edge types, they will have the same</span>
<span class="sd">        sparse format.</span>

<span class="sd">        When ``formats`` is not None, if the intersection between `formats` and</span>
<span class="sd">        the current graph&#39;s created sparse format(s) is not empty, the returned</span>
<span class="sd">        cloned graph only retains all sparse format(s) in the intersection. If</span>
<span class="sd">        the intersection is empty, a sparse format will be selected to be</span>
<span class="sd">        created following the order of ``&#39;coo&#39; -&gt; &#39;csr&#39; -&gt; &#39;csc&#39;``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        formats : str or list of str or None</span>

<span class="sd">            * If formats is None, return the usage status of sparse formats</span>
<span class="sd">            * Otherwise, it can be ``&#39;coo&#39;``/``&#39;csr&#39;``/``&#39;csc&#39;`` or a sublist of</span>
<span class="sd">              them, specifying the sparse formats to use.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict or DGLGraph</span>

<span class="sd">            * If formats is None, the result will be a dict recording the usage</span>
<span class="sd">              status of sparse formats.</span>
<span class="sd">            * Otherwise, a DGLGraph will be returned, which is a clone of the</span>
<span class="sd">              original graph with the specified allowed sparse format(s)</span>
<span class="sd">              ``formats``.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homographs or Heterographs with A Single Edge Type**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 0, 1], [2, 3, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;h&#39;] = torch.ones(4, 1)</span>
<span class="sd">        &gt;&gt;&gt; # Check status of format usage.</span>
<span class="sd">        &gt;&gt;&gt; g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;], &#39;not created&#39;: [&#39;csr&#39;, &#39;csc&#39;]}</span>
<span class="sd">        &gt;&gt;&gt; # Get a clone of the graph with &#39;csr&#39; format.</span>
<span class="sd">        &gt;&gt;&gt; csr_g = g.formats(&#39;csr&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Only allowed formats will be displayed in the status query.</span>
<span class="sd">        &gt;&gt;&gt; csr_g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;csr&#39;], &#39;not created&#39;: []}</span>
<span class="sd">        &gt;&gt;&gt; # Features are copied as well.</span>
<span class="sd">        &gt;&gt;&gt; csr_g.ndata[&#39;h&#39;]</span>
<span class="sd">        tensor([[1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.],</span>
<span class="sd">                [1.]])</span>

<span class="sd">        **Heterographs with Multiple Edge Types**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;], &#39;not created&#39;: [&#39;csr&#39;, &#39;csc&#39;]}</span>
<span class="sd">        &gt;&gt;&gt; # Get a clone of the graph with &#39;csr&#39; format.</span>
<span class="sd">        &gt;&gt;&gt; csr_g = g.formats(&#39;csr&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Only allowed formats will be displayed in the status query.</span>
<span class="sd">        &gt;&gt;&gt; csr_g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;csr&#39;], &#39;not created&#39;: []}</span>

<span class="sd">        **When formats intersects with created formats**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 0, 1], [2, 3, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g = g.formats([&#39;coo&#39;, &#39;csr&#39;])</span>
<span class="sd">        &gt;&gt;&gt; g.create_formats_()</span>
<span class="sd">        &gt;&gt;&gt; g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;, &#39;csr&#39;], &#39;not created&#39;: []}</span>
<span class="sd">        &gt;&gt;&gt; # Get a clone of the graph allowed formats &#39;csr&#39; and &#39;csc&#39;.</span>
<span class="sd">        &gt;&gt;&gt; csr_csc_g = g.formats([&#39;csr&#39;, &#39;csc&#39;])</span>
<span class="sd">        &gt;&gt;&gt; # Only the intersection &#39;csr&#39; will be retained.</span>
<span class="sd">        &gt;&gt;&gt; csr_csc_g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;csr&#39;], &#39;not created&#39;: [&#39;csc&#39;]}</span>

<span class="sd">        **When formats doesn&#39;t intersect with created formats**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 0, 1], [2, 3, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g = g.formats(&#39;coo&#39;)</span>
<span class="sd">        &gt;&gt;&gt; g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;], &#39;not created&#39;: []}</span>
<span class="sd">        &gt;&gt;&gt; # Get a clone of the graph allowed formats &#39;csr&#39; and &#39;csc&#39;.</span>
<span class="sd">        &gt;&gt;&gt; csr_csc_g = g.formats([&#39;csr&#39;, &#39;csc&#39;])</span>
<span class="sd">        &gt;&gt;&gt; # Since the intersection is empty, &#39;csr&#39; will be created as it is</span>
<span class="sd">        &gt;&gt;&gt; # first in the order of &#39;coo&#39; -&gt; &#39;csr&#39; -&gt; &#39;csc&#39;.</span>
<span class="sd">        &gt;&gt;&gt; csr_csc_g.formats()</span>
<span class="sd">        {&#39;created&#39;: [&#39;csr&#39;], &#39;not created&#39;: [&#39;csc&#39;]}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">formats</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Return the format information.</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">formats</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Convert the graph to use another allowed format.</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">ret</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">formats</span><span class="p">(</span><span class="n">formats</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="DGLGraph.create_formats_">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.create_formats_.html#dgl.DGLGraph.create_formats_">[docs]</a>
    <span class="k">def</span> <span class="nf">create_formats_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Create all sparse matrices allowed for the graph.</span>

<span class="sd">        By default, we create sparse matrices for a graph only when necessary.</span>
<span class="sd">        In some cases we may want to create them immediately (e.g. in a</span>
<span class="sd">        multi-process data loader), which can be achieved via this API.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        **Homographs or Heterographs with A Single Edge Type**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.graph(([0, 0, 1], [2, 3, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g.format()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;], &#39;not created&#39;: [&#39;csr&#39;, &#39;csc&#39;]}</span>
<span class="sd">        &gt;&gt;&gt; g.create_formats_()</span>
<span class="sd">        &gt;&gt;&gt; g.format()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;, &#39;csr&#39;, &#39;csc&#39;], &#39;not created&#39;: []}</span>

<span class="sd">        **Heterographs with Multiple Edge Types**</span>

<span class="sd">        &gt;&gt;&gt; g = dgl.heterograph({</span>
<span class="sd">        ...     (&#39;user&#39;, &#39;plays&#39;, &#39;game&#39;): (torch.tensor([0, 1, 1, 2]),</span>
<span class="sd">        ...                                 torch.tensor([0, 0, 1, 1])),</span>
<span class="sd">        ...     (&#39;developer&#39;, &#39;develops&#39;, &#39;game&#39;): (torch.tensor([0, 1]),</span>
<span class="sd">        ...                                         torch.tensor([0, 1]))</span>
<span class="sd">        ...     })</span>
<span class="sd">        &gt;&gt;&gt; g.format()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;], &#39;not created&#39;: [&#39;csr&#39;, &#39;csc&#39;]}</span>
<span class="sd">        &gt;&gt;&gt; g.create_formats_()</span>
<span class="sd">        &gt;&gt;&gt; g.format()</span>
<span class="sd">        {&#39;created&#39;: [&#39;coo&#39;, &#39;csr&#39;, &#39;csc&#39;], &#39;not created&#39;: []}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">create_formats_</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="nf">astype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idtype</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cast this graph to use another ID type.</span>

<span class="sd">        Features are copied (shallow copy) to the new graph.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        idtype : Data type object.</span>
<span class="sd">            New ID type. Can only be int32 or int64.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            Graph in the new ID type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">idtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">check_valid_idtype</span><span class="p">(</span><span class="n">idtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">idtype</span> <span class="o">==</span> <span class="n">idtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">bits</span> <span class="o">=</span> <span class="mi">32</span> <span class="k">if</span> <span class="n">idtype</span> <span class="o">==</span> <span class="n">F</span><span class="o">.</span><span class="n">int32</span> <span class="k">else</span> <span class="mi">64</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">ret</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">asbits</span><span class="p">(</span><span class="n">bits</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="c1"># TODO: Formats should not be specified, just saving all the materialized formats</span>
    <span class="k">def</span> <span class="nf">shared_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">formats</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a copy of this graph in shared memory, without node data or edge data.</span>

<span class="sd">        It moves the graph index to shared memory and returns a DGLGraph object which</span>
<span class="sd">        has the same graph structure, node types and edge types but does not contain node data</span>
<span class="sd">        or edge data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name : str</span>
<span class="sd">            The name of the shared memory.</span>
<span class="sd">        formats : str or a list of str (optional)</span>
<span class="sd">            Desired formats to be materialized.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph in shared memory</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;The name of shared memory cannot be empty&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">formats</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">formats</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">formats</span> <span class="o">=</span> <span class="p">[</span><span class="n">formats</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">fmt</span> <span class="ow">in</span> <span class="n">formats</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">fmt</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="s2">&quot;coo&quot;</span><span class="p">,</span>
                <span class="s2">&quot;csr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;csc&quot;</span><span class="p">,</span>
            <span class="p">),</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> is not coo, csr or csc&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fmt</span><span class="p">)</span>
        <span class="n">gidx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">shared_memory</span><span class="p">(</span>
            <span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">,</span> <span class="n">formats</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">gidx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntypes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span>

<div class="viewcode-block" id="DGLGraph.long">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.long.html#dgl.DGLGraph.long">[docs]</a>
    <span class="k">def</span> <span class="nf">long</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cast the graph to one with idtype int64</span>

<span class="sd">        If the graph already has idtype int64, the function directly returns it. Otherwise,</span>
<span class="sd">        it returns a cloned graph of idtype int64 with features copied (shallow copy).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph of idtype int64.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a graph of idtype int32.</span>

<span class="sd">        &gt;&gt;&gt; # (0, 1), (0, 2), (1, 2)</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1]).int(), torch.tensor([1, 2, 2]).int()))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;feat&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.idtype</span>
<span class="sd">        torch.int32</span>

<span class="sd">        Cast the graph to one of idtype int64.</span>

<span class="sd">        &gt;&gt;&gt; # A cloned graph with an idtype of int64</span>
<span class="sd">        &gt;&gt;&gt; g_long = g.long()</span>
<span class="sd">        &gt;&gt;&gt; g_long.idtype</span>
<span class="sd">        torch.int64</span>
<span class="sd">        &gt;&gt;&gt; # The idtype of the original graph does not change.</span>
<span class="sd">        &gt;&gt;&gt; g.idtype</span>
<span class="sd">        torch.int32</span>
<span class="sd">        &gt;&gt;&gt; g_long.edges()</span>
<span class="sd">        (tensor([0, 0, 1]), tensor([1, 2, 2]))</span>
<span class="sd">        &gt;&gt;&gt; g_long.ndata</span>
<span class="sd">        {&#39;feat&#39;: tensor([[1.],</span>
<span class="sd">                         [1.],</span>
<span class="sd">                         [1.]])}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        int</span>
<span class="sd">        idtype</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span></div>


<div class="viewcode-block" id="DGLGraph.int">
<a class="viewcode-back" href="../../generated/dgl.DGLGraph.int.html#dgl.DGLGraph.int">[docs]</a>
    <span class="k">def</span> <span class="nf">int</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cast the graph to one with idtype int32</span>

<span class="sd">        If the graph already has idtype int32, the function directly returns it. Otherwise,</span>
<span class="sd">        it returns a cloned graph of idtype int32 with features copied (shallow copy).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        DGLGraph</span>
<span class="sd">            The graph of idtype int32.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        The following example uses PyTorch backend.</span>

<span class="sd">        &gt;&gt;&gt; import dgl</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>

<span class="sd">        Create a graph of idtype int64.</span>

<span class="sd">        &gt;&gt;&gt; # (0, 1), (0, 2), (1, 2)</span>
<span class="sd">        &gt;&gt;&gt; g = dgl.graph((torch.tensor([0, 0, 1]), torch.tensor([1, 2, 2])))</span>
<span class="sd">        &gt;&gt;&gt; g.ndata[&#39;feat&#39;] = torch.ones(3, 1)</span>
<span class="sd">        &gt;&gt;&gt; g.idtype</span>
<span class="sd">        torch.int64</span>

<span class="sd">        Cast the graph to one of idtype int32.</span>

<span class="sd">        &gt;&gt;&gt; # A cloned graph with an idtype of int32</span>
<span class="sd">        &gt;&gt;&gt; g_int = g.int()</span>
<span class="sd">        &gt;&gt;&gt; g_int.idtype</span>
<span class="sd">        torch.int32</span>
<span class="sd">        &gt;&gt;&gt; # The idtype of the original graph does not change.</span>
<span class="sd">        &gt;&gt;&gt; g.idtype</span>
<span class="sd">        torch.int64</span>
<span class="sd">        &gt;&gt;&gt; g_int.edges()</span>
<span class="sd">        (tensor([0, 0, 1], dtype=torch.int32), tensor([1, 2, 2], dtype=torch.int32))</span>
<span class="sd">        &gt;&gt;&gt; g_int.ndata</span>
<span class="sd">        {&#39;feat&#39;: tensor([[1.],</span>
<span class="sd">                         [1.],</span>
<span class="sd">                         [1.]])}</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        long</span>
<span class="sd">        idtype</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span></div>
</div>



<span class="c1">############################################################</span>
<span class="c1"># Internal APIs</span>
<span class="c1">############################################################</span>


<span class="k">def</span> <span class="nf">make_canonical_etypes</span><span class="p">(</span><span class="n">etypes</span><span class="p">,</span> <span class="n">ntypes</span><span class="p">,</span> <span class="n">metagraph</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Internal function to convert etype name to (srctype, etype, dsttype)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    etypes : list of str</span>
<span class="sd">        Edge type list</span>
<span class="sd">    ntypes : list of str</span>
<span class="sd">        Node type list</span>
<span class="sd">    metagraph : GraphIndex</span>
<span class="sd">        Meta graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of tuples (srctype, etype, dsttype)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># sanity check</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">metagraph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Length of edge type list must match the number of &quot;</span>
            <span class="s2">&quot;edges in the metagraph. </span><span class="si">{}</span><span class="s2"> vs </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">),</span> <span class="n">metagraph</span><span class="o">.</span><span class="n">num_edges</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">metagraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
            <span class="s2">&quot;Length of nodes type list must match the number of &quot;</span>
            <span class="s2">&quot;nodes in the metagraph. </span><span class="si">{}</span><span class="s2"> vs </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">),</span> <span class="n">metagraph</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">ntypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ntypes</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span> <span class="o">=</span> <span class="n">metagraph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="s2">&quot;eid&quot;</span><span class="p">)</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="n">ntypes</span><span class="p">[</span><span class="n">sid</span><span class="p">],</span> <span class="n">etypes</span><span class="p">[</span><span class="n">eid</span><span class="p">],</span> <span class="n">ntypes</span><span class="p">[</span><span class="n">did</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">sid</span><span class="p">,</span> <span class="n">did</span><span class="p">,</span> <span class="n">eid</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">eid</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">rst</span>


<span class="k">def</span> <span class="nf">find_src_dst_ntypes</span><span class="p">(</span><span class="n">ntypes</span><span class="p">,</span> <span class="n">metagraph</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Internal function to split ntypes into SRC and DST categories.</span>

<span class="sd">    If the metagraph is not a uni-bipartite graph (so that the SRC and DST categories</span>
<span class="sd">    are not well-defined), return None.</span>

<span class="sd">    For node types that are isolated (i.e, no relation is associated with it), they</span>
<span class="sd">    are assigned to the SRC category.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    ntypes : list of str</span>
<span class="sd">        Node type list</span>
<span class="sd">    metagraph : GraphIndex</span>
<span class="sd">        Meta graph.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    (dict[int, str], dict[int, str]) or None</span>
<span class="sd">        Node types belonging to SRC and DST categories. Types are stored in</span>
<span class="sd">        a dictionary from type name to type id. Return None if the graph is</span>
<span class="sd">        not uni-bipartite.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">_CAPI_DGLFindSrcDstNtypes</span><span class="p">(</span><span class="n">metagraph</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ret</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">ret</span>
        <span class="n">srctypes</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntypes</span><span class="p">[</span><span class="n">tid</span><span class="p">]:</span> <span class="n">tid</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">src</span><span class="p">}</span>
        <span class="n">dsttypes</span> <span class="o">=</span> <span class="p">{</span><span class="n">ntypes</span><span class="p">[</span><span class="n">tid</span><span class="p">]:</span> <span class="n">tid</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">dst</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">srctypes</span><span class="p">,</span> <span class="n">dsttypes</span>


<span class="k">def</span> <span class="nf">pad_tuple</span><span class="p">(</span><span class="n">tup</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">pad_val</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pad the given tuple to the given length.</span>

<span class="sd">    If the input is not a tuple, convert it to a tuple of length one.</span>
<span class="sd">    Return None if pad fails.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tup</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">tup</span> <span class="o">=</span> <span class="p">(</span><span class="n">tup</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tup</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">length</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">tup</span><span class="p">)</span> <span class="o">==</span> <span class="n">length</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tup</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tup</span> <span class="o">+</span> <span class="p">(</span><span class="n">pad_val</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tup</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reduce_dict_data</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">reducer</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Merge tensor dictionaries into one. Resolve conflict fields using reducer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    frames : list[dict[str, Tensor]]</span>
<span class="sd">        Input tensor dictionaries</span>
<span class="sd">    reducer : str or callable function</span>
<span class="sd">        One of &quot;sum&quot;, &quot;max&quot;, &quot;min&quot;, &quot;mean&quot;, &quot;stack&quot; or a callable function.</span>
<span class="sd">        If a callable function is provided, the input arguments must be a single list</span>
<span class="sd">        of tensors containing aggregation results from each edge type, and the</span>
<span class="sd">        output of function must be a single tensor.</span>
<span class="sd">    order : list[Int], optional</span>
<span class="sd">        Merge order hint. Useful for &quot;stack&quot; reducer.</span>
<span class="sd">        If provided, each integer indicates the relative order</span>
<span class="sd">        of the ``frames`` list. Frames are sorted according to this list</span>
<span class="sd">        in ascending order. Tie is not handled so make sure the order values</span>
<span class="sd">        are distinct.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict[str, Tensor]</span>
<span class="sd">        Merged frame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">reducer</span> <span class="o">!=</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
        <span class="c1"># Directly return the only one input. Stack reducer requires</span>
        <span class="c1"># modifying tensor shape.</span>
        <span class="k">return</span> <span class="n">frames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">reducer</span><span class="p">):</span>
        <span class="n">merger</span> <span class="o">=</span> <span class="n">reducer</span>
    <span class="k">elif</span> <span class="n">reducer</span> <span class="o">==</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>
        <span class="c1"># Stack order does not matter. However, it must be consistent!</span>
        <span class="k">if</span> <span class="n">order</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span>
            <span class="n">sorted_with_key</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">order</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">frames</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">sorted_with_key</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">merger</span><span class="p">(</span><span class="n">flist</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">flist</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">redfn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">reducer</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">redfn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid cross type reducer. Must be one of &quot;</span>
                <span class="s1">&#39;&quot;sum&quot;, &quot;max&quot;, &quot;min&quot;, &quot;mean&quot; or &quot;stack&quot;.&#39;</span>
            <span class="p">)</span>

        <span class="k">def</span> <span class="nf">merger</span><span class="p">(</span><span class="n">flist</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">redfn</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">flist</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">flist</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">flist</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">frm</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">:</span>
        <span class="n">keys</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">frm</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
        <span class="n">flist</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">frm</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">frm</span><span class="p">:</span>
                <span class="n">flist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frm</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="n">ret</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">merger</span><span class="p">(</span><span class="n">flist</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span>


<span class="k">def</span> <span class="nf">combine_frames</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">col_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Merge the frames into one frame, taking the common columns.</span>

<span class="sd">    Return None if there is no common columns.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    frames : List[Frame]</span>
<span class="sd">        List of frames</span>
<span class="sd">    ids : List[int]</span>
<span class="sd">        List of frame IDs</span>
<span class="sd">    col_names : List[str], optional</span>
<span class="sd">        Column names to consider. If not given, it considers all columns.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Frame</span>
<span class="sd">        The resulting frame</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># find common columns and check if their schemes match</span>
    <span class="n">schemes</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">frame_id</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">:</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">frames</span><span class="p">[</span><span class="n">frame_id</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">frame</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">schemes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schemes</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">schemes</span>
            <span class="k">if</span> <span class="n">col_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">schemes</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">frame</span><span class="o">.</span><span class="n">schemes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">col_names</span><span class="p">}</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">scheme</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">schemes</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">frame</span><span class="o">.</span><span class="n">schemes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">frame</span><span class="o">.</span><span class="n">schemes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">!=</span> <span class="n">scheme</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">DGLError</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot concatenate column </span><span class="si">%s</span><span class="s2"> with shape </span><span class="si">%s</span><span class="s2"> and shape </span><span class="si">%s</span><span class="s2">&quot;</span>
                        <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">frame</span><span class="o">.</span><span class="n">schemes</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">scheme</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">schemes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">schemes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># concatenate the columns</span>
    <span class="n">to_cat</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">key</span><span class="p">:</span> <span class="p">[</span><span class="n">frames</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids</span> <span class="k">if</span> <span class="n">frames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_rows</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">F</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">to_cat</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">schemes</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">Frame</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">combine_names</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Combine the selected names into one new name.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    names : list of str</span>
<span class="sd">        String names</span>
<span class="sd">    ids : numpy.ndarray, optional</span>
<span class="sd">        Selected index</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;+&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">selected</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">])</span>
        <span class="k">return</span> <span class="s2">&quot;+&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DGLBlock</span><span class="p">(</span><span class="n">DGLGraph</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass that signifies the graph is a block created from</span>
<span class="sd">    :func:`dgl.to_block`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># (BarclayII) I&#39;m making a subclass because I don&#39;t want to make another version of</span>
    <span class="c1"># serialization that contains the is_block flag.</span>
    <span class="n">is_block</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">srctypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dsttypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">etypes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">):</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="s2">&quot;Block(num_src_nodes=</span><span class="si">{srcnode}</span><span class="s2">, num_dst_nodes=</span><span class="si">{dstnode}</span><span class="s2">, num_edges=</span><span class="si">{edge}</span><span class="s2">)&quot;</span>
            <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">srcnode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_src_nodes</span><span class="p">(),</span>
                <span class="n">dstnode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_dst_nodes</span><span class="p">(),</span>
                <span class="n">edge</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Block(num_src_nodes=</span><span class="si">{srcnode}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      num_dst_nodes=</span><span class="si">{dstnode}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      num_edges=</span><span class="si">{edge}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;      metagraph=</span><span class="si">{meta}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
            <span class="n">nsrcnode_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">ntype</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_src_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">srctypes</span>
            <span class="p">}</span>
            <span class="n">ndstnode_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">ntype</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_dst_nodes</span><span class="p">(</span><span class="n">ntype</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">ntype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dsttypes</span>
            <span class="p">}</span>
            <span class="n">nedge_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">etype</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_edges</span><span class="p">(</span><span class="n">etype</span><span class="p">)</span> <span class="k">for</span> <span class="n">etype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">canonical_etypes</span>
            <span class="p">}</span>
            <span class="n">meta</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metagraph</span><span class="p">()</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">keys</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">srcnode</span><span class="o">=</span><span class="n">nsrcnode_dict</span><span class="p">,</span>
                <span class="n">dstnode</span><span class="o">=</span><span class="n">ndstnode_dict</span><span class="p">,</span>
                <span class="n">edge</span><span class="o">=</span><span class="n">nedge_dict</span><span class="p">,</span>
                <span class="n">meta</span><span class="o">=</span><span class="n">meta</span><span class="p">,</span>
            <span class="p">)</span>


<span class="k">def</span> <span class="nf">_create_compute_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">eid</span><span class="p">,</span> <span class="n">recv_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a computation graph from the given edges.</span>

<span class="sd">    The compute graph is a uni-directional bipartite graph with only</span>
<span class="sd">    one edge type. Similar to subgraph extraction, it stores the original node IDs</span>
<span class="sd">    in the srcdata[NID] and dstdata[NID] and extracts features accordingly.</span>
<span class="sd">    Edges are not relabeled.</span>

<span class="sd">    This function is typically used during message passing to generate</span>
<span class="sd">    a graph that contains only the active set of edges.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    graph : DGLGraph</span>
<span class="sd">        The input graph.</span>
<span class="sd">    u : Tensor</span>
<span class="sd">        Src nodes.</span>
<span class="sd">    v : Tensor</span>
<span class="sd">        Dst nodes.</span>
<span class="sd">    eid : Tensor</span>
<span class="sd">        Edge IDs.</span>
<span class="sd">    recv_nodes : Tensor</span>
<span class="sd">        Nodes that receive messages. If None, it is equal to unique(v).</span>
<span class="sd">        Otherwise, it must be a superset of v and can contain nodes</span>
<span class="sd">        that have no incoming edges.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    DGLGraph</span>
<span class="sd">        A computation graph.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># The computation graph has no edge and will not trigger message</span>
        <span class="c1"># passing. However, because of the apply node phase, we still construct</span>
        <span class="c1"># an empty graph to continue.</span>
        <span class="n">unique_src</span> <span class="o">=</span> <span class="n">new_u</span> <span class="o">=</span> <span class="n">new_v</span> <span class="o">=</span> <span class="n">u</span>
        <span class="k">assert</span> <span class="n">recv_nodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">unique_dst</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">relabel</span><span class="p">(</span><span class="n">recv_nodes</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># relabel u and v to starting from 0</span>
        <span class="n">unique_src</span><span class="p">,</span> <span class="n">src_map</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">relabel</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">recv_nodes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">unique_dst</span><span class="p">,</span> <span class="n">dst_map</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">relabel</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">unique_dst</span><span class="p">,</span> <span class="n">dst_map</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">relabel</span><span class="p">(</span><span class="n">recv_nodes</span><span class="p">)</span>
        <span class="n">new_u</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">src_map</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
        <span class="n">new_v</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">gather_row</span><span class="p">(</span><span class="n">dst_map</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="n">srctype</span><span class="p">,</span> <span class="n">etype</span><span class="p">,</span> <span class="n">dsttype</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">canonical_etypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># create graph</span>
    <span class="n">hgidx</span> <span class="o">=</span> <span class="n">heterograph_index</span><span class="o">.</span><span class="n">create_unitgraph_from_coo</span><span class="p">(</span>
        <span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_src</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_dst</span><span class="p">),</span> <span class="n">new_u</span><span class="p">,</span> <span class="n">new_v</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;coo&quot;</span><span class="p">,</span> <span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="s2">&quot;csc&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="c1"># create frame</span>
    <span class="n">srcframe</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">graph</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">srctype</span><span class="p">)]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span>
        <span class="n">unique_src</span>
    <span class="p">)</span>
    <span class="n">srcframe</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">unique_src</span>
    <span class="n">dstframe</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_node_frames</span><span class="p">[</span><span class="n">graph</span><span class="o">.</span><span class="n">get_ntype_id</span><span class="p">(</span><span class="n">dsttype</span><span class="p">)]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span>
        <span class="n">unique_dst</span>
    <span class="p">)</span>
    <span class="n">dstframe</span><span class="p">[</span><span class="n">NID</span><span class="p">]</span> <span class="o">=</span> <span class="n">unique_dst</span>
    <span class="n">eframe</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">_edge_frames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">subframe</span><span class="p">(</span><span class="n">eid</span><span class="p">)</span>
    <span class="n">eframe</span><span class="p">[</span><span class="n">EID</span><span class="p">]</span> <span class="o">=</span> <span class="n">eid</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">DGLGraph</span><span class="p">(</span>
            <span class="n">hgidx</span><span class="p">,</span>
            <span class="p">([</span><span class="n">srctype</span><span class="p">],</span> <span class="p">[</span><span class="n">dsttype</span><span class="p">]),</span>
            <span class="p">[</span><span class="n">etype</span><span class="p">],</span>
            <span class="n">node_frames</span><span class="o">=</span><span class="p">[</span><span class="n">srcframe</span><span class="p">,</span> <span class="n">dstframe</span><span class="p">],</span>
            <span class="n">edge_frames</span><span class="o">=</span><span class="p">[</span><span class="n">eframe</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="n">unique_src</span><span class="p">,</span>
        <span class="n">unique_dst</span><span class="p">,</span>
        <span class="n">eid</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">_init_api</span><span class="p">(</span><span class="s2">&quot;dgl.heterograph&quot;</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>