<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quickstart &mdash; DGL 2.4 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=0bf289b5" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=9caaf7ed"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=ccdb6887"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Building a Graph Convolutional Network Using Sparse Matrices" href="gcn.html" />
    <link rel="prev" title="Tutorials: dgl.sparse" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            DGL
          </a>
              <div class="version">
                2.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Install and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/blitz/index.html">A Blitz Introduction to DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Materials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../stochastic_training/index.html">🆕 Stochastic Training of GNNs with GraphBolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_cn/index.html">用户指南【包含过时信息】</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide_ko/index.html">사용자 가이드[시대에 뒤쳐진]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../graphtransformer/index.html">🆕 Tutorial: Graph Transformer</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials: dgl.sparse</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="gcn.html">Building a Graph Convolutional Network Using Sparse Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph_diffusion.html">Graph Diffusion in Graph Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="hgnn.html">Hypergraph Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="graph_transformer.html">Graph Transformer in a Nutshell</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/cpu/index.html">Training on CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/multi/index.html">Training on Multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/dist/index.html">Distributed training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/models/index.html">Paper Study with DGL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.html">dgl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.data.html">dgl.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.dataloading.html">dgl.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.DGLGraph.html">dgl.DGLGraph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.distributed.html">dgl.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.function.html">dgl.function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.geometry.html">dgl.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.graphbolt.html">🆕 dgl.graphbolt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn-pytorch.html">dgl.nn (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/nn.functional.html">dgl.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.ops.html">dgl.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.optim.html">dgl.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sampling.html">dgl.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.sparse_v0.html">dgl.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/dgl.multiprocessing.html">dgl.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/transforms.html">dgl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/udf.html">User-defined Functions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contribute.html">Contribute to DGL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer/ffi.html">DGL Foreign Function Interface (FFI)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../performance.html">Performance Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../env_var.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DGL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials: dgl.sparse</a></li>
      <li class="breadcrumb-item active">Quickstart</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/notebooks/sparse/quickstart.nblink.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Quickstart">
<h1>Quickstart<a class="headerlink" href="#Quickstart" title="Link to this heading"></a></h1>
<p>The tutorial provides a quick walkthrough of the classes and operators provided by the <code class="docutils literal notranslate"><span class="pre">dgl.sparse</span></code> package.</p>
<p><a class="reference external" href="https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb"><img alt="GitHub" src="https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&amp;logoColor=ffffff" /></a></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install the required packages.</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="c1"># Uncomment following commands to download Pytorch and DGL</span>
<span class="c1"># !pip install torch==2.0.0+cpu torchvision==0.15.1+cpu torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cpu &gt; /dev/null</span>
<span class="c1"># !pip install  dgl==1.1.0 -f https://data.dgl.ai/wheels/repo.html &gt; /dev/null</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TORCH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;DGLBACKEND&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pytorch&quot;</span>


<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dgl.sparse</span> <span class="k">as</span> <span class="nn">dglsp</span>
    <span class="n">installed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">installed</span> <span class="o">=</span> <span class="kc">False</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DGL installed!&quot;</span> <span class="k">if</span> <span class="n">installed</span> <span class="k">else</span> <span class="s2">&quot;DGL not found!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DGL installed!
</pre></div></div>
</div>
<section id="Sparse-Matrix">
<h2>Sparse Matrix<a class="headerlink" href="#Sparse-Matrix" title="Link to this heading"></a></h2>
<p>The core abstraction of DGL’s sparse package is the <code class="docutils literal notranslate"><span class="pre">SparseMatrix</span></code> class. Compared with other sparse matrix libraries (such as <code class="docutils literal notranslate"><span class="pre">scipy.sparse</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.sparse</span></code>), DGL’s <code class="docutils literal notranslate"><span class="pre">SparseMatrix</span></code> is specialized for the deep learning workloads on structure data (e.g., Graph Neural Networks), with the following features:</p>
<ul class="simple">
<li><p><strong>Auto sparse format.</strong> Don’t bother choosing between different sparse formats. There is only one <code class="docutils literal notranslate"><span class="pre">SparseMatrix</span></code> and it will select the best format for the operation to be performed.</p></li>
<li><p><strong>Non-zero elements can be scalar or vector.</strong> Easy for modeling relations (e.g., edges) by vector representation.</p></li>
<li><p><strong>Fully PyTorch compatible.</strong> The package is built upon PyTorch and is natively compatible with other tools in the PyTorch ecosystem.</p></li>
</ul>
<section id="Creating-a-DGL-Sparse-Matrix">
<h3>Creating a DGL Sparse Matrix<a class="headerlink" href="#Creating-a-DGL-Sparse-Matrix" title="Link to this heading"></a></h3>
<p>The simplest way to create a sparse matrix is using the <code class="docutils literal notranslate"><span class="pre">spmatrix</span></code> API by providing the indices of the non-zero elements. The indices are stored in a tensor of shape <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">nnz)</span></code>, where the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th non-zero element is stored at position <code class="docutils literal notranslate"><span class="pre">(indices[0][i],</span> <span class="pre">indices[1][i])</span></code>. The code below creates a 3x3 sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">dgl.sparse</span> <span class="k">as</span> <span class="nn">dglsp</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>  <span class="c1"># 1.0 is default value for nnz elements.</span>

<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SparseMatrix(indices=tensor([[1, 1, 2],
                             [0, 2, 0]]),
             values=tensor([1., 1., 1.]),
             shape=(3, 3), nnz=3)

In dense format:
tensor([[0., 0., 0.],
        [1., 0., 1.],
        [1., 0., 0.]])
</pre></div></div>
</div>
<p>If not specified, the shape is inferred automatically from the indices but you can specify it explicitly too.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="n">A1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Implicit Shape: </span><span class="si">{</span><span class="n">A1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="n">A2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Explicit Shape: </span><span class="si">{</span><span class="n">A2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Implicit Shape: (2, 3)
tensor([[1., 0., 1.],
        [1., 0., 0.]])

Explicit Shape: (3, 3)
tensor([[1., 0., 1.],
        [1., 0., 0.],
        [0., 0., 0.]])
</pre></div></div>
</div>
<p>Both scalar values and vector values can be set for nnz elements in Sparse Matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="c1"># The length of the value should match the nnz elements represented by the</span>
<span class="c1"># sparse matrix format.</span>
<span class="n">scalar_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">vector_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----Scalar Values-----&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">scalar_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----Vector Values-----&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">vector_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-----Scalar Values-----
SparseMatrix(indices=tensor([[1, 1, 2],
                             [0, 2, 0]]),
             values=tensor([1., 2., 3.]),
             shape=(3, 3), nnz=3)

In dense format:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])

-----Vector Values-----
SparseMatrix(indices=tensor([[1, 1, 2],
                             [0, 2, 0]]),
             values=tensor([[1., 1.],
                            [2., 2.],
                            [3., 3.]]),
             shape=(3, 3), nnz=3, val_size=(2,))

In dense format:
tensor([[[0., 0.],
         [0., 0.],
         [0., 0.]],

        [[1., 1.],
         [0., 0.],
         [2., 2.]],

        [[3., 3.],
         [0., 0.],
         [0., 0.]]])
</pre></div></div>
</div>
<p><em>Duplicated indices</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Whether A contains duplicate indices: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">has_duplicate</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Whether B contains duplicate indices: </span><span class="si">{</span><span class="n">B</span><span class="o">.</span><span class="n">has_duplicate</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SparseMatrix(indices=tensor([[0, 0, 0, 1],
                             [0, 2, 2, 0]]),
             values=tensor([1., 2., 3., 4.]),
             shape=(2, 3), nnz=4)
Whether A contains duplicate indices: True

SparseMatrix(indices=tensor([[0, 0, 1],
                             [0, 2, 0]]),
             values=tensor([1., 5., 4.]),
             shape=(2, 3), nnz=3)
Whether B contains duplicate indices: False
</pre></div></div>
</div>
<p><strong>val_like</strong></p>
<p>You can create a new sparse matrix by retaining the non-zero indices of a given sparse matrix but with different non-zero values.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

<span class="n">new_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">val_like</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">new_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SparseMatrix(indices=tensor([[1, 1, 2],
                             [0, 2, 0]]),
             values=tensor([4., 5., 6.]),
             shape=(3, 3), nnz=3)
</pre></div></div>
</div>
<p><strong>Create a sparse matrix from various sparse formats</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">from_coo()</span></code>: Create a sparse matrix from <a class="reference external" href="https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)">COO</a> format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from_csr()</span></code>: Create a sparse matrix from <a class="reference external" href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)">CSR</a> format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from_csc()</span></code>: Create a sparse matrix from <a class="reference external" href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_column_(CSC_or_CCS)">CSC</a> format.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">row</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">col</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----Create from COO format-----&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">from_coo</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="n">indptr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----Create from CSR format-----&quot;</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">from_csr</span><span class="p">(</span><span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----Create from CSC format-----&quot;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">from_csc</span><span class="p">(</span><span class="n">indptr</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-----Create from COO format-----
SparseMatrix(indices=tensor([[0, 1, 2, 2, 2],
                             [1, 2, 0, 1, 2]]),
             values=tensor([1., 1., 1., 1., 1.]),
             shape=(3, 3), nnz=5)

In dense format:
tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 1., 1.]])

-----Create from CSR format-----
SparseMatrix(indices=tensor([[0, 1, 2, 2, 2],
                             [1, 2, 0, 1, 2]]),
             values=tensor([1., 1., 1., 1., 1.]),
             shape=(3, 3), nnz=5)

In dense format:
tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 1., 1.]])

-----Create from CSC format-----
SparseMatrix(indices=tensor([[1, 2, 0, 1, 2],
                             [0, 1, 2, 2, 2]]),
             values=tensor([1., 1., 1., 1., 1.]),
             shape=(3, 3), nnz=5)

In dense format:
tensor([[0., 0., 1.],
        [1., 0., 1.],
        [0., 1., 1.]])
</pre></div></div>
</div>
</section>
<section id="Attributes-and-methods-of-a-DGL-Sparse-Matrix">
<h3>Attributes and methods of a DGL Sparse Matrix<a class="headerlink" href="#Attributes-and-methods-of-a-DGL-Sparse-Matrix" title="Link to this heading"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of sparse matrix: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The number of nonzero elements of sparse matrix: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">nnz</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Datatype of sparse matrix: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Device sparse matrix is stored on: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get the values of the nonzero elements: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get the row indices of the nonzero elements: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">row</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get the column indices of the nonzero elements: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">col</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get the coordinate (COO) representation: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">coo</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get the compressed sparse row (CSR) representation: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">csr</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get the compressed sparse column (CSC) representation: </span><span class="si">{</span><span class="n">A</span><span class="o">.</span><span class="n">csc</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of sparse matrix: (3, 3)
The number of nonzero elements of sparse matrix: 4
Datatype of sparse matrix: torch.float32
Device sparse matrix is stored on: cpu
Get the values of the nonzero elements: tensor([1., 2., 3., 4.])
Get the row indices of the nonzero elements: tensor([0, 1, 1, 2])
Get the column indices of the nonzero elements: tensor([1, 0, 2, 0])
Get the coordinate (COO) representation: (tensor([0, 1, 1, 2]), tensor([1, 0, 2, 0]))
Get the compressed sparse row (CSR) representation: (tensor([0, 1, 3, 4]), tensor([1, 0, 2, 0]), tensor([0, 1, 2, 3]))
Get the compressed sparse column (CSC) representation: (tensor([0, 2, 3, 4]), tensor([1, 2, 0, 1]), tensor([1, 3, 0, 2]))
</pre></div></div>
</div>
<p><strong>dtype and/or device conversion</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

<span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Device sparse matrix is stored on: </span><span class="si">{</span><span class="n">B</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Datatype of sparse matrix: </span><span class="si">{</span><span class="n">B</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Device sparse matrix is stored on: cpu
Datatype of sparse matrix: torch.int32
</pre></div></div>
</div>
<p>Similar to pytorch, we also provide various fine-grained APIs (<a class="reference external" href="https://docs.dgl.ai/en/latest/api/python/dgl.sparse_v0.html">Doc</a>) for dtype and/or device conversion.</p>
</section>
</section>
<section id="Diagonal-Matrix">
<h2>Diagonal Matrix<a class="headerlink" href="#Diagonal-Matrix" title="Link to this heading"></a></h2>
<p>Diagonal Matrix is a special type of Sparse Matrix, in which the entries outside the main diagonal are all zero.</p>
<section id="Initializing-a-DGL-Diagonal-Sparse-Matrix">
<h3>Initializing a DGL Diagonal Sparse Matrix<a class="headerlink" href="#Initializing-a-DGL-Diagonal-Sparse-Matrix" title="Link to this heading"></a></h3>
<p>A DGL Diagonal Sparse Matrix can be initiate by <code class="docutils literal notranslate"><span class="pre">dglsp.diag()</span></code>.</p>
<p>Identity Matrix is a special type of Diagonal Sparse Matrix, in which all the value on the diagonal are 1.0. Use <code class="docutils literal notranslate"><span class="pre">dglsp.identity()</span></code> to initiate a Diagonal Sparse Matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>

<span class="n">I</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">I</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SparseMatrix(indices=tensor([[0, 1, 2, 3],
                             [0, 1, 2, 3]]),
             values=tensor([1., 2., 3., 4.]),
             shape=(4, 4), nnz=4)
SparseMatrix(indices=tensor([[0, 1, 2],
                             [0, 1, 2]]),
             values=tensor([1., 1., 1.]),
             shape=(3, 3), nnz=3)
</pre></div></div>
</div>
</section>
</section>
<section id="Operations-on-Sparse-Matrix">
<h2>Operations on Sparse Matrix<a class="headerlink" href="#Operations-on-Sparse-Matrix" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Elementwise operations</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">+</span> <span class="pre">B</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">-</span> <span class="pre">B</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">*</span> <span class="pre">B</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">/</span> <span class="pre">B</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">**</span> <span class="pre">scalar</span></code></p></li>
</ul>
</li>
<li><p>Broadcast operations</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sp_&lt;op&gt;_v()</span></code></p></li>
</ul>
</li>
<li><p>Reduce operations</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">reduce()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sum()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">smax()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">smin()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">smean()</span></code></p></li>
</ul>
</li>
<li><p>Matrix transformations</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">SparseMatrix.transpose()</span></code> or <code class="docutils literal notranslate"><span class="pre">SparseMatrix.T</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SparseMatrix.neg()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SparseMatrix.inv()</span></code></p></li>
</ul>
</li>
<li><p>Matrix multiplication</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">matmul()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sddmm()</span></code></p></li>
</ul>
</li>
</ul>
<p><em>We are using dense format to print sparse matrix in this tutorial since it is more intuitive to read.</em></p>
<section id="Elementwise-operations">
<h3><em>Elementwise operations</em><a class="headerlink" href="#Elementwise-operations" title="Link to this heading"></a></h3>
<p><strong>add(A, B), equivalent to A + B</strong></p>
<p>Element-wise addition on two sparse matrices, returning a sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.</span><span class="p">])</span>
<span class="n">D2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 + A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">+</span> <span class="n">A2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 + D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">+</span> <span class="n">D1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 + D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">+</span> <span class="n">D2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A1:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
A2:
tensor([[4., 0., 0.],
        [0., 0., 5.],
        [0., 6., 0.]])
D1:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
D2:
tensor([[-4.,  0.,  0.],
        [ 0., -5.,  0.],
        [ 0.,  0., -6.]])
A1 + A2:
tensor([[4., 0., 0.],
        [1., 0., 7.],
        [3., 6., 0.]])
A1 + D1:
tensor([[-1.,  0.,  0.],
        [ 1., -2.,  2.],
        [ 3.,  0., -3.]])
D1 + D2:
tensor([[-5.,  0.,  0.],
        [ 0., -7.,  0.],
        [ 0.,  0., -9.]])
</pre></div></div>
</div>
<p><strong>sub(A, B), equivalent to A - B</strong></p>
<p>Element-wise substraction on two sparse matrices, returning a sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.</span><span class="p">])</span>
<span class="n">D2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 - A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">-</span> <span class="n">A2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 - D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">-</span> <span class="n">D1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 - A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">-</span> <span class="n">A1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 - D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">-</span> <span class="n">D2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A1:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
A2:
tensor([[4., 0., 0.],
        [0., 0., 5.],
        [0., 6., 0.]])
D1:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
D2:
tensor([[-4.,  0.,  0.],
        [ 0., -5.,  0.],
        [ 0.,  0., -6.]])
A1 - A2:
tensor([[-4.,  0.,  0.],
        [ 1.,  0., -3.],
        [ 3., -6.,  0.]])
A1 - D1:
tensor([[1., 0., 0.],
        [1., 2., 2.],
        [3., 0., 3.]])
D1 - A1:
tensor([[-1.,  0.,  0.],
        [-1., -2., -2.],
        [-3.,  0., -3.]])
D1 - D2:
tensor([[3., 0., 0.],
        [0., 3., 0.],
        [0., 0., 3.]])
</pre></div></div>
</div>
<p><strong>mul(A, B), equivalent to A * B</strong></p>
<p>Element-wise multiplication on two sparse matrices or on a sparse matrix and a scalar, returning a sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 * 3:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;3 * A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="n">A1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 * A2&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">*</span> <span class="n">A2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 * A2&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">*</span> <span class="n">A2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.</span><span class="p">])</span>
<span class="n">D2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 * -2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">*</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-2 * D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">D1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 * D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">*</span> <span class="n">D2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A1:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
A2:
tensor([[1., 0., 0.],
        [0., 0., 2.],
        [3., 4., 0.]])
A1 * 3:
tensor([[0., 0., 0.],
        [3., 0., 6.],
        [9., 0., 0.]])
3 * A1:
tensor([[0., 0., 0.],
        [3., 0., 6.],
        [9., 0., 0.]])
A1 * A2
tensor([[0., 0., 0.],
        [0., 0., 4.],
        [9., 0., 0.]])
D1:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
D1 * A2
tensor([[-1.,  0.,  0.],
        [ 0.,  0.,  0.],
        [ 0.,  0.,  0.]])
D2:
tensor([[-4.,  0.,  0.],
        [ 0., -5.,  0.],
        [ 0.,  0., -6.]])
D1 * -2:
tensor([[2., 0., 0.],
        [0., 4., 0.],
        [0., 0., 6.]])
-2 * D1:
tensor([[2., 0., 0.],
        [0., 4., 0.],
        [0., 0., 6.]])
D1 * D2:
tensor([[ 4.,  0.,  0.],
        [ 0., 10.,  0.],
        [ 0.,  0., 18.]])
</pre></div></div>
</div>
<p><strong>div(A, B), equivalent to A / B</strong></p>
<p>Element-wise multiplication on two sparse matrices or on a sparse matrix and a scalar, returning a sparse matrix. If both <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are sparse matrices, both of them must have the same sparsity. And the returned matrix has the same order of non-zero entries as <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">])</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 / 2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 / A2&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">/</span> <span class="n">A2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.</span><span class="p">])</span>
<span class="n">D2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 / D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">/</span> <span class="n">D2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 / 2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A1:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
A1 / 2:
tensor([[0.0000, 0.0000, 0.0000],
        [0.5000, 0.0000, 1.0000],
        [1.5000, 0.0000, 0.0000]])
A1 / A2
tensor([[0., 0., 0.],
        [1., 0., 1.],
        [1., 0., 0.]])
D1:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
D2:
tensor([[-4.,  0.,  0.],
        [ 0., -5.,  0.],
        [ 0.,  0., -6.]])
D1 / D2:
tensor([[0.2500, 0.0000, 0.0000],
        [0.0000, 0.4000, 0.0000],
        [0.0000, 0.0000, 0.5000]])
D1 / 2:
tensor([[-0.5000,  0.0000,  0.0000],
        [ 0.0000, -1.0000,  0.0000],
        [ 0.0000,  0.0000, -1.5000]])
</pre></div></div>
</div>
<p><strong>power(A, B), equivalent to A ** B</strong></p>
<p>Element-wise power of a sparse matrix and a scalar, returning a sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A ** 3:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 ** 2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
A ** 3:
tensor([[ 0.,  0.,  0.],
        [ 1.,  0.,  8.],
        [27.,  0.,  0.]])
D:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
D1 ** 2:
tensor([[1., 0., 0.],
        [0., 4., 0.],
        [0., 0., 9.]])
</pre></div></div>
</div>
</section>
<section id="Broadcast-operations">
<h3><em>Broadcast operations</em><a class="headerlink" href="#Broadcast-operations" title="Link to this heading"></a></h3>
<p>**sp_&lt;op&gt;_v(A, v)**</p>
<p>Broadcast operations on a sparse matrix and a vector, returning a sparse matrix. <code class="docutils literal notranslate"><span class="pre">v</span></code> is broadcasted to the shape of <code class="docutils literal notranslate"><span class="pre">A</span></code> and then the operator is applied on the non-zero values of <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">&lt;op&gt;</span></code> can be add, sub, mul, and div.</p>
<p>There are two cases regarding the shape of <code class="docutils literal notranslate"><span class="pre">v</span></code>:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">v</span></code> is a vector of shape <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">A.shape[1])</span></code> or <code class="docutils literal notranslate"><span class="pre">(A.shape[1])</span></code>. In this case, <code class="docutils literal notranslate"><span class="pre">v</span></code> is broadcasted on the row dimension of <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v</span></code> is a vector of shape <code class="docutils literal notranslate"><span class="pre">(A.shape[0],</span> <span class="pre">1)</span></code>. In this case, <code class="docutils literal notranslate"><span class="pre">v</span></code> is broadcasted on the column dimension of <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;v1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sp_add_v(A, v1)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dglsp</span><span class="o">.</span><span class="n">sp_add_v</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">v2</span> <span class="o">=</span> <span class="n">v1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;v2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sp_add_v(A, v2)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dglsp</span><span class="o">.</span><span class="n">sp_add_v</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">v3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;v3:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sp_add_v(A, v3)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dglsp</span><span class="o">.</span><span class="n">sp_add_v</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">v3</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A:
tensor([[ 0,  0,  0, 20],
        [10,  0,  0,  0],
        [ 0,  0, 30,  0]])
v1:
tensor([1, 2, 3, 4])
sp_add_v(A, v1)
tensor([[ 0,  0,  0, 24],
        [11,  0,  0,  0],
        [ 0,  0, 33,  0]])
v2:
tensor([[1, 2, 3, 4]])
sp_add_v(A, v2)
tensor([[ 0,  0,  0, 24],
        [11,  0,  0,  0],
        [ 0,  0, 33,  0]])
v3:
tensor([[1],
        [2],
        [3]])
sp_add_v(A, v3)
tensor([[ 0,  0,  0, 21],
        [12,  0,  0,  0],
        [ 0,  0, 33,  0]])
</pre></div></div>
</div>
</section>
<section id="Reduce-operations">
<h3><em>Reduce operations</em><a class="headerlink" href="#Reduce-operations" title="Link to this heading"></a></h3>
<p>All DGL sparse reduce operations only consider non-zero elements. To distinguish them from dense PyTorch reduce operations that consider zero elements, we use name <code class="docutils literal notranslate"><span class="pre">smax</span></code>, <code class="docutils literal notranslate"><span class="pre">smin</span></code> and <code class="docutils literal notranslate"><span class="pre">smean</span></code> (<code class="docutils literal notranslate"><span class="pre">s</span></code> stands for sparse).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="c1"># O1, O2 will have the same value.</span>
<span class="n">O1</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">O2</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reduce with reducer:sum along dim = 0:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">O1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="c1"># O3, O4 will have the same value.</span>
<span class="n">O3</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;smax&#39;</span><span class="p">)</span>
<span class="n">O4</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">smax</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reduce with reducer:max along dim = 0:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">O3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="c1"># O5, O6 will have the same value.</span>
<span class="n">O5</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;smin&#39;</span><span class="p">)</span>
<span class="n">O6</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">smin</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reduce with reducer:min along dim = 0:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">O5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="c1"># O7, O8 will have the same value.</span>
<span class="n">O7</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;smean&#39;</span><span class="p">)</span>
<span class="n">O8</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">smean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reduce with reducer:smean along dim = 0:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">O7</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[0., 2., 4.],
        [1., 0., 0.],
        [0., 3., 0.]])

Reduce with reducer:sum along dim = 0:
tensor([6., 1., 3.])

Reduce with reducer:max along dim = 0:
tensor([4., 1., 3.])

Reduce with reducer:min along dim = 0:
tensor([2., 1., 3.])

Reduce with reducer:smean along dim = 0:
tensor([3., 1., 3.])

</pre></div></div>
</div>
</section>
<section id="Matrix-transformations">
<h3><em>Matrix transformations</em><a class="headerlink" href="#Matrix-transformations" title="Link to this heading"></a></h3>
<p><em>Sparse Matrix</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Get transpose of sparse matrix.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="c1"># Alias</span>
<span class="c1"># A.transpose()</span>
<span class="c1"># A.t()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Get a sparse matrix with the negation of the original nonzero values.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[0., 1., 0.],
        [2., 0., 3.],
        [4., 0., 0.]])

Get transpose of sparse matrix.
tensor([[0., 2., 4.],
        [1., 0., 0.],
        [0., 3., 0.]])

Get a sparse matrix with the negation of the original nonzero values.
tensor([[ 0., -1.,  0.],
        [-2.,  0., -3.],
        [-4.,  0.,  0.]])

</pre></div></div>
</div>
</section>
<section id="Matrix-multiplication">
<h3><em>Matrix multiplication</em><a class="headerlink" href="#Matrix-multiplication" title="Link to this heading"></a></h3>
<p><strong>matmul(A, B), equivalent to A &#64; B</strong></p>
<p>Matrix multiplication on sparse matrices and/or dense matrix. There are two cases as follows.</p>
<p><strong>SparseMatrix &#64; SparseMatrix -&gt; SparseMatrix:</strong></p>
<p>For a <span class="math notranslate nohighlight">\(L \times M\)</span> sparse matrix A and a <span class="math notranslate nohighlight">\(M \times N\)</span> sparse matrix B, the shape of <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">B</span></code> will be <span class="math notranslate nohighlight">\(L \times N\)</span> sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D1</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.</span><span class="p">])</span>
<span class="n">D2</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 @ A2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">@</span> <span class="n">A2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A1 @ D1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">A1</span> <span class="o">@</span> <span class="n">D1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 @ A1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">@</span> <span class="n">A1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D1 @ D2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">D1</span> <span class="o">@</span> <span class="n">D2</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A1:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
A2:
tensor([[4., 0., 0.],
        [0., 0., 5.],
        [0., 6., 0.]])
D1:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
D2:
tensor([[-4.,  0.,  0.],
        [ 0., -5.,  0.],
        [ 0.,  0., -6.]])
A1 @ A2:
tensor([[ 0.,  0.,  0.],
        [ 4., 12.,  0.],
        [12.,  0.,  0.]])
A1 @ D1:
tensor([[ 0.,  0.,  0.],
        [-1.,  0., -6.],
        [-3.,  0.,  0.]])
D1 @ A1:
tensor([[ 0.,  0.,  0.],
        [-2.,  0., -4.],
        [-9.,  0.,  0.]])
D1 @ D2:
tensor([[ 4.,  0.,  0.],
        [ 0., 10.,  0.],
        [ 0.,  0., 18.]])
</pre></div></div>
</div>
<p><strong>SparseMatrix &#64; Tensor -&gt; Tensor:</strong></p>
<p>For a <span class="math notranslate nohighlight">\(L \times M\)</span> sparse matrix A and a <span class="math notranslate nohighlight">\(M \times N\)</span> dense matrix B, the shape of <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">B</span></code> will be <span class="math notranslate nohighlight">\(L \times N\)</span> dense matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.</span><span class="p">])</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">11.</span><span class="p">,</span> <span class="mf">22.</span><span class="p">],</span> <span class="p">[</span><span class="mf">33.</span><span class="p">,</span> <span class="mf">44.</span><span class="p">],</span> <span class="p">[</span><span class="mf">55.</span><span class="p">,</span> <span class="mf">66.</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A @ X:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D @ X:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A:
tensor([[0., 0., 0.],
        [1., 0., 2.],
        [3., 0., 0.]])
D:
tensor([[-1.,  0.,  0.],
        [ 0., -2.,  0.],
        [ 0.,  0., -3.]])
X:
tensor([[11., 22.],
        [33., 44.],
        [55., 66.]])
A @ X:
tensor([[  0.,   0.],
        [121., 154.],
        [ 33.,  66.]])
D @ X:
tensor([[ -11.,  -22.],
        [ -66.,  -88.],
        [-165., -198.]])
</pre></div></div>
</div>
<p>This operator also supports batched sparse-dense matrix multiplication. The sparse matrix A should have shape <span class="math notranslate nohighlight">\(L \times M\)</span>, where the non-zero values are vectors of length <span class="math notranslate nohighlight">\(K\)</span>. The dense matrix B should have shape <span class="math notranslate nohighlight">\(M \times N \times K\)</span>. The output is a dense matrix of shape <span class="math notranslate nohighlight">\(L \times N \times K\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]],</span>
                  <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]],</span>
                  <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A @ X:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A:
tensor([[[0., 0.],
         [0., 0.],
         [0., 0.]],

        [[1., 1.],
         [0., 0.],
         [2., 2.]],

        [[3., 3.],
         [0., 0.],
         [0., 0.]]])
X:
tensor([[[1., 1.],
         [1., 2.]],

        [[1., 3.],
         [1., 4.]],

        [[1., 5.],
         [1., 6.]]])
A @ X:
tensor([[[ 0.,  0.],
         [ 0.,  0.]],

        [[ 3., 11.],
         [ 3., 14.]],

        [[ 3.,  3.],
         [ 3.,  6.]]])
</pre></div></div>
</div>
<p><strong>Sampled-Dense-Dense Matrix Multiplication (SDDMM)</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">sddmm</span></code> matrix-multiplies two dense matrices X1 and X2, then elementwise-multiplies the result with sparse matrix A at the nonzero locations. This is designed for sparse matrix with scalar values.</p>
<div class="math notranslate nohighlight">
\[out = (X_1 &#64; X_2) * A\]</div>
<p>For a <span class="math notranslate nohighlight">\(L \times N\)</span> sparse matrix A, a <span class="math notranslate nohighlight">\(L \times M\)</span> dense matrix X1 and a <span class="math notranslate nohighlight">\(M \times N\)</span> dense matrix X2, <code class="docutils literal notranslate"><span class="pre">sddmm(A,</span> <span class="pre">X1,</span> <span class="pre">X2)</span></code> will be a <span class="math notranslate nohighlight">\(L \times N\)</span> sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>

<span class="n">O</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">sddmm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dglsp.sddmm(A, X1, X2):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">O</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A:
tensor([[0., 0., 0., 0.],
        [0., 0., 1., 2.],
        [0., 0., 0., 3.]])
X1:
tensor([[ 0.1243, -0.1927, -0.0130, -0.8050, -0.3171],
        [-0.4640, -0.2396,  1.6771, -0.7616, -0.3175],
        [-0.5457, -0.5886, -0.6801,  0.9870, -0.3302]])
X2:
tensor([[-1.0775,  0.8597,  0.5328, -0.2897],
        [-0.9933,  0.1147, -1.5623,  0.8077],
        [ 1.0438,  0.5805, -0.6827, -2.5676],
        [ 1.9219,  0.7320, -0.2477, -1.2312],
        [ 1.8221, -0.2008,  0.1179, -0.8589]])
dglsp.sddmm(A, X1, X2):
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000, -0.8666, -6.3095],
        [ 0.0000,  0.0000,  0.0000,  1.4920]])
</pre></div></div>
</div>
<p>This operator also supports batched sampled-dense-dense matrix multiplication. For a <span class="math notranslate nohighlight">\(L \times N\)</span> sparse matrix A with non-zero vector values of length <span class="math notranslate nohighlight">\(𝐾\)</span>, a <span class="math notranslate nohighlight">\(L \times M \times K\)</span> dense matrix X1 and a <span class="math notranslate nohighlight">\(M \times N \times K\)</span> dense matrix X2, <code class="docutils literal notranslate"><span class="pre">sddmm(A,</span> <span class="pre">X1,</span> <span class="pre">X2)</span></code> will be a <span class="math notranslate nohighlight">\(L \times N \times K\)</span> sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X1:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X2:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>

<span class="n">O</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">sddmm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dglsp.sddmm(A, X1, X2):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">O</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A:
tensor([[[0., 0.],
         [0., 0.],
         [0., 0.],
         [0., 0.]],

        [[0., 0.],
         [0., 0.],
         [1., 1.],
         [2., 2.]],

        [[0., 0.],
         [0., 0.],
         [0., 0.],
         [3., 3.]]])
X1:
tensor([[[ 0.6481, -1.0157],
         [ 0.3048,  0.0373],
         [ 0.5914,  1.0993],
         [-1.1350,  0.3918],
         [ 1.1703,  0.0892]],

        [[ 1.1587,  0.6698],
         [ 0.1449,  0.2524],
         [ 0.9417,  0.2380],
         [ 2.7911, -0.1064],
         [-0.8196,  0.4363]],

        [[ 1.5475,  1.4784],
         [ 0.3072,  2.5861],
         [-0.7243, -0.2665],
         [ 0.2701, -0.4411],
         [ 0.1382,  0.4228]]])
X2:
tensor([[[ 1.7541, -0.2148],
         [-2.1926,  1.4757],
         [-0.1390,  0.6236],
         [ 0.9889, -0.1963]],

        [[-0.2306, -0.8966],
         [ 0.4754, -1.4410],
         [-0.0810,  0.5001],
         [ 0.3620, -1.0956]],

        [[ 0.3982, -0.4546],
         [ 2.1000, -0.0722],
         [ 0.8060, -1.3085],
         [ 0.5977, -0.2148]],

        [[ 1.6976, -0.6395],
         [ 0.1182, -0.9638],
         [ 0.5466, -1.6042],
         [-0.0671,  0.0892]],

        [[ 0.8389,  1.5538],
         [-0.1479, -1.7469],
         [ 0.7406, -0.4911],
         [-0.0054,  2.2109]]])
dglsp.sddmm(A, X1, X2):
tensor([[[ 0.0000,  0.0000],
         [ 0.0000,  0.0000],
         [ 0.0000,  0.0000],
         [ 0.0000,  0.0000]],

        [[ 0.0000,  0.0000],
         [ 0.0000,  0.0000],
         [ 1.5047,  0.1890],
         [ 3.1566,  0.9919]],

        [[ 0.0000,  0.0000],
         [ 0.0000,  0.0000],
         [ 0.0000,  0.0000],
         [ 3.5692, -6.5127]]])
</pre></div></div>
</div>
</section>
</section>
<section id="Non-linear-activation-functions">
<h2>Non-linear activation functions<a class="headerlink" href="#Non-linear-activation-functions" title="Link to this heading"></a></h2>
<section id="Element-wise-functions">
<h3>Element-wise functions<a class="headerlink" href="#Element-wise-functions" title="Link to this heading"></a></h3>
<p>Most activation functions are element-wise and can be further grouped into two categories:</p>
<p><strong>Sparse-preserving functions</strong> such as <code class="docutils literal notranslate"><span class="pre">sin()</span></code>, <code class="docutils literal notranslate"><span class="pre">tanh()</span></code>, <code class="docutils literal notranslate"><span class="pre">sigmoid()</span></code>, <code class="docutils literal notranslate"><span class="pre">relu()</span></code>, etc. You can directly apply them on the <code class="docutils literal notranslate"><span class="pre">val</span></code> tensor of the sparse matrix and then recreate a new matrix of the same sparsity using <code class="docutils literal notranslate"><span class="pre">val_like</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apply tanh.&quot;</span><span class="p">)</span>
<span class="n">A_new</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">val_like</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">val</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A_new</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[ 0.0000,  0.4265,  0.0000],
        [-1.8705,  0.0000,  0.2432],
        [ 0.2092,  0.0000,  0.0000]])
Apply tanh.
tensor([[ 0.0000,  0.4024,  0.0000],
        [-0.9536,  0.0000,  0.2386],
        [ 0.2062,  0.0000,  0.0000]])
</pre></div></div>
</div>
<p><strong>Non-sparse-preserving functions</strong> such as <code class="docutils literal notranslate"><span class="pre">exp()</span></code>, <code class="docutils literal notranslate"><span class="pre">cos()</span></code>, etc. You can first convert the sparse matrix to dense before applying the functions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apply exp.&quot;</span><span class="p">)</span>
<span class="n">A_new</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A_new</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[ 0.0000,  2.1944,  0.0000],
        [-0.4551,  0.0000, -0.2537],
        [-0.3482,  0.0000,  0.0000]])
Apply exp.
tensor([[1.0000, 8.9742, 1.0000],
        [0.6344, 1.0000, 0.7759],
        [0.7060, 1.0000, 1.0000]])
</pre></div></div>
</div>
</section>
<section id="Softmax">
<h3>Softmax<a class="headerlink" href="#Softmax" title="Link to this heading"></a></h3>
<p>Apply row-wise softmax to the nonzero entries of the sparse matrix.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">softmax</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;In dense format:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">softmax</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SparseMatrix(indices=tensor([[0, 1, 1, 2],
                             [1, 0, 2, 0]]),
             values=tensor([1.0000, 0.2689, 0.7311, 1.0000]),
             shape=(3, 3), nnz=4)
In dense format:
tensor([[0.0000, 1.0000, 0.0000],
        [0.2689, 0.0000, 0.7311],
        [1.0000, 0.0000, 0.0000]])


</pre></div></div>
</div>
</section>
</section>
<section id="Exercise-#1">
<h2>Exercise #1<a class="headerlink" href="#Exercise-#1" title="Link to this heading"></a></h2>
<p><em>Let’s test what you’ve learned. Feel free to</em> <a class="reference external" href="https://colab.research.google.com/github/dmlc/dgl/blob/master/notebooks/sparse/quickstart.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a><em>.</em></p>
<p>Given a sparse symmetrical adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>, calculate its symmetrically normalized adjacency matrix:</p>
<div class="math notranslate nohighlight">
\[norm = \bar{D}^{-\frac{1}{2}}\bar{A}\bar{D}^{-\frac{1}{2}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\bar{A} = A + I\)</span>, <span class="math notranslate nohighlight">\(I\)</span> is the identity matrix, and <span class="math notranslate nohighlight">\(\bar{D}\)</span> is the diagonal node degree matrix of <span class="math notranslate nohighlight">\(\bar{A}\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">asym_A</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">spmatrix</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1"># Step 1: create symmetrical adjacency matrix A from asym_A.</span>
<span class="c1"># A =</span>

<span class="c1"># Step 2: calculate A_hat from A.</span>
<span class="c1"># A_hat =</span>

<span class="c1"># Step 3: diagonal node degree matrix of A_hat</span>
<span class="c1"># D_hat =</span>

<span class="c1"># Step 4: calculate the norm from D_hat and A_hat.</span>
<span class="c1"># norm =</span>
</pre></div>
</div>
</div>
</section>
<section id="Exercise-#2">
<h2>Exercise #2<a class="headerlink" href="#Exercise-#2" title="Link to this heading"></a></h2>
<p>Let’s implement a simplified version of the Graph Attention Network (GAT) layer.</p>
<p>A GAT layer has two inputs: the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> and the node input features <span class="math notranslate nohighlight">\(X\)</span>. The idea of GAT layer is to update each node’s representation with a weighted average of the node’s own representation and its neighbors’ representations. In particular, when computing the output for node <span class="math notranslate nohighlight">\(i\)</span>, the GAT layer does the following: 1. Compute the scores <span class="math notranslate nohighlight">\(S_{ij}\)</span> representing the attention logit from neighbor <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>. <span class="math notranslate nohighlight">\(S_{ij}\)</span> is a function of
<span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>’s input features <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(X_j\)</span>:</p>
<div class="math notranslate nohighlight">
\[S_{ij} = LeakyReLU(X_i^\top v_1 + X_j^\top v_2)\]</div>
<p>, where <span class="math notranslate nohighlight">\(v_1\)</span> and <span class="math notranslate nohighlight">\(v_2\)</span> are trainable vectors. 2. Compute a softmax attention <span class="math notranslate nohighlight">\(R_{ij} = \exp S_{ij} / \left( \sum_{j' \in \mathcal{N}_i} s_{ij'} \right)\)</span>, where <span class="math notranslate nohighlight">\(\mathcal{N}_j\)</span> means the neighbors of <span class="math notranslate nohighlight">\(j\)</span>. This means that <span class="math notranslate nohighlight">\(R\)</span> is a row-wise softmax attention of <span class="math notranslate nohighlight">\(S\)</span>. 3. Compute the weighted average <span class="math notranslate nohighlight">\(H_i = \sum_{j' : j' \in \mathcal{N}_i} R_{j'} X_{j'} W\)</span>, where <span class="math notranslate nohighlight">\(W\)</span> is a trainable matrix.</p>
<p>The following code defined all the parameters you need but only completes step 1. Could you implement step 2 and step 3?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">SimplifiedGAT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># A: A sparse matrix with size (N, N).  A[i, j] represent the edge from j to i.</span>
        <span class="c1"># X: A dense matrix with size (N, D)</span>
        <span class="c1"># Step 1: compute S[i, j]</span>
        <span class="n">Xv1</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">v1</span>
        <span class="n">Xv2</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">v2</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">Xv1</span><span class="p">[</span><span class="n">A</span><span class="o">.</span><span class="n">col</span><span class="p">]</span> <span class="o">+</span> <span class="n">Xv2</span><span class="p">[</span><span class="n">A</span><span class="o">.</span><span class="n">row</span><span class="p">])</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">dglsp</span><span class="o">.</span><span class="n">val_like</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

        <span class="c1"># Step 2: compute R[i, j] which is the row-wise attention of $S$.</span>
        <span class="c1"># EXERCISE: replace the statement below.</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">S</span>

        <span class="c1"># Step 3: compute H.</span>
        <span class="c1"># EXERCISE: replace the statement below.</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">return</span> <span class="n">H</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test:</span>
<span class="c1"># Let&#39;s use the symmetric A created above.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">module</span> <span class="o">=</span> <span class="n">SimplifiedGAT</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Tutorials: dgl.sparse" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="gcn.html" class="btn btn-neutral float-right" title="Building a Graph Convolutional Network Using Sparse Matrices" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, DGL Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>