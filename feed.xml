<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="https://www.dgl.ai/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.dgl.ai/" rel="alternate" type="text/html" /><updated>2020-04-02T09:10:30+00:00</updated><id>https://www.dgl.ai/feed.xml</id><title type="html">Deep Graph Library</title><subtitle>Easy Deep Learning on Graphs</subtitle><entry><title type="html">What is new in DGL v0.4.3 release?</title><link href="https://www.dgl.ai/release/2020/04/01/release.html" rel="alternate" type="text/html" title="What is new in DGL v0.4.3 release?" /><published>2020-04-01T00:00:00+00:00</published><updated>2020-04-01T00:00:00+00:00</updated><id>https://www.dgl.ai/release/2020/04/01/release</id><content type="html" xml:base="https://www.dgl.ai/release/2020/04/01/release.html">&lt;p&gt;The DGL v0.4.3 release brings many new features for an enhanced usability and
system efficiency. The article takes a peek at some of the major highlights.&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-support&quot;&gt;TensorFlow support&lt;/h2&gt;

&lt;p&gt;DGL finally comes to the TensorFlow community starting from this release.
Switching to TensorFlow is easy. If you are a first-time user, please install
DGL and &lt;code class=&quot;highlighter-rouge&quot;&gt;import dgl&lt;/code&gt;, and then follow the instructions to set the default
backend. You can always switch back by changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;config.json&lt;/code&gt; file, which is
under &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.dgl&lt;/code&gt; folder. DGL keeps a coherent user experience regardless of which
backend is currently in use. The following code demonstrates the basic steps to
apply a graph convolution layer.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dglnn&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Random features for 10 nodes; each is of length 5.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Random graph; 10 nodes and 20 edges.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Pre-defined graph convolution module.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dglnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GraphConv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Apply the graph convolution layer.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We have implemented and released 15 common GNN modules in TensorFlow (more are
coming), all of which can be invoked in one line of codes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GraphConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/abs/1609.02907&quot;&gt;Graph Convolutional Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GATConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;Graph Attention Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SAGEConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1706.02216.pdf&quot;&gt;Inductive Representation Learning on Large Graphs&lt;/a&gt; paper (a.k.a. GraphSAGE).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GINConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1810.00826.pdf&quot;&gt;How Powerful are Graph Neural Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RelGraphConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/abs/1703.06103&quot;&gt;Modeling Relational Data with Graph Convolutional Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SGConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1902.07153.pdf&quot;&gt;Simplifying Graph Convolutional Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APPNPConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1810.05997.pdf&quot;&gt;Predict then Propagate: Graph Neural Networks meet Personalized PageRank&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;An &lt;code class=&quot;highlighter-rouge&quot;&gt;edge_softmax&lt;/code&gt; function for computing softmax over the neighboring edges of each vertex.&lt;/li&gt;
  &lt;li&gt;Various pooling layers: &lt;code class=&quot;highlighter-rouge&quot;&gt;SumPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;AvgPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SortPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;WeightAndSum&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;GlobalAttentionPooling&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;HeteroGraphConv&lt;/code&gt; module for applying GNN modules to heterogeneous graphs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our preliminary benchmark shows strong performance improvement against other
TF-based tools for GNNs in terms of both training speed (measured by epoch
running time in seconds) and memory consumption.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dateset&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;DGL&lt;/th&gt;
      &lt;th&gt;GraphNet&lt;/th&gt;
      &lt;th&gt;tf_geometric&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Core&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.0148&lt;/td&gt;
      &lt;td&gt;0.0152&lt;/td&gt;
      &lt;td&gt;0.0192&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Reddit&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.1095&lt;/td&gt;
      &lt;td&gt;OOM&lt;/td&gt;
      &lt;td&gt;OOM&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PubMed&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.0156&lt;/td&gt;
      &lt;td&gt;0.0553&lt;/td&gt;
      &lt;td&gt;0.0185&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PPI&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.09&lt;/td&gt;
      &lt;td&gt;0.16&lt;/td&gt;
      &lt;td&gt;0.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cora&lt;/td&gt;
      &lt;td&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.0442&lt;/td&gt;
      &lt;td&gt;n/a&lt;/td&gt;
      &lt;td&gt;0.058&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PPI&lt;/td&gt;
      &lt;td&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.398&lt;/td&gt;
      &lt;td&gt;n/a&lt;/td&gt;
      &lt;td&gt;0.752&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To get started, install &lt;a href=&quot;https://www.dgl.ai/pages/start.html&quot;&gt;DGL&lt;/a&gt; and check out the examples &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/tensorflow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;dgl-ke-a-light-speed-package-for-learning-knowledge-graph-embeddings&quot;&gt;DGL-KE: A light-speed package for learning knowledge graph embeddings&lt;/h2&gt;
&lt;p&gt;Previously incubated under the DGL main repository, DGL-KE now officially
announces its 0.1 release as a standalone package. The key highlights are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Effortlessly generate knowledge graph embedding with one line of code.&lt;/li&gt;
  &lt;li&gt;Support for giant graphs with millions of nodes and edges.&lt;/li&gt;
  &lt;li&gt;Distributed training with highly-optimized graph partitioning, negative
sampling and communication, which can be deployed on both multi-GPU machines
and multi-machine clusters.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DGL-KE can be installed with pip:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install dglke
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The following command trains embeddings of the full FreeBase graph (over 86M nodes
and 338M edges) with 8 GPUs.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dglke_train --model TransE_l2 --dataset Freebase --batch_size 1000 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --neg_sample_size 200 --hidden_dim 400 --gamma 10 --lr 0.1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --regularization_coef 1e-9 -adv --gpu 0 1 2 3 4 5 6 7 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --max_step 320000 --log_interval 10000 --async_update &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --rel_part --force_sync_interval 10000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;DGL-KE is designed for learning at scale and speed. Our benchmark on the full
FreeBase graph shows that DGL-KE can train
embeddings under 100 minutes on an 8-GPU machine and under 30 minutes on a 4-machine
cluster (48 cores/machine). These results represent a 2×∼5× speedup over the
best competing approaches.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;center&gt;DGL-KE v.s. PyTorch-BigGraph on FreeBase&lt;/center&gt;&lt;/th&gt;
      &lt;th&gt;&lt;center&gt;DGL-KE v.s. GraphVite on FB15k&lt;/center&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;https://github.com/awslabs/dgl-ke/raw/master/img/vs-gv-fb15k.png&quot; alt=&quot;&quot; width=&quot;600x&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;https://github.com/awslabs/dgl-ke/raw/master/img/vs-pbg-fb.png&quot; alt=&quot;&quot; width=&quot;600x&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Check out our new GitHub repository, examples and documentations under
&lt;a href=&quot;https://github.com/awslabs/dgl-ke&quot;&gt;https://github.com/awslabs/dgl-ke&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;dgl-lifesci-bringing-graph-neural-networks-to-chemistry-and-biology&quot;&gt;DGL-LifeSci: Bringing Graph Neural Networks to Chemistry and Biology&lt;/h2&gt;

&lt;p&gt;Previously incubated as a model zoo for chemistry, DGL-LifeSci is now spun off
as a standalone package. The key highlights are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training scripts and pre-trained models for various applications — molecular
property prediction, generative models, and reaction prediction.&lt;/li&gt;
  &lt;li&gt;Up to 5.5x model training speedup compared to previous implementations.&lt;/li&gt;
  &lt;li&gt;Well defined pipelines for data processing, model construction and
evaluation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DGL-LifeSci can be installed with pip or conda.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install dgllife
conda install -c dglteam dgllife
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;A summary of speedup in seconds per epoch of training:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Original Implementations&lt;/th&gt;
      &lt;th&gt;DGL-LifeSci Implementations&lt;/th&gt;
      &lt;th&gt;Speedup&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GCN on Tox21&lt;/td&gt;
      &lt;td&gt;5.5 (DeepChem)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5.5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AttentiveFP on Aromaticity&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.2&lt;/td&gt;
      &lt;td&gt;5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;JTNN on ZINC&lt;/td&gt;
      &lt;td&gt;1826&lt;/td&gt;
      &lt;td&gt;743&lt;/td&gt;
      &lt;td&gt;2.5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;WLN for reaction center prediction&lt;/td&gt;
      &lt;td&gt;11657&lt;/td&gt;
      &lt;td&gt;5095&lt;/td&gt;
      &lt;td&gt;2.3x&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To get started, check out the examples and documentations under
&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/apps/life_sci&quot;&gt;https://github.com/dmlc/dgl/tree/master/apps/life_sci&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;experimenting-new-apis-for-sampling&quot;&gt;Experimenting new APIs for sampling&lt;/h2&gt;

&lt;p&gt;Sampling is crucial to training GNNs on giant graphs. In this release, we
re-design the APIs for sampling, aiming for a more intuitive programming
experience and a better performance at the same time. The new APIs have several
advantages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Support a wide range of sampling-based GNN models, including PinSAGE,
GraphSAGE, Graph Convolutional Matrix Completion (GCMC), and etc.&lt;/li&gt;
  &lt;li&gt;Support customization in Python.&lt;/li&gt;
  &lt;li&gt;Support heterogeneous graphs.&lt;/li&gt;
  &lt;li&gt;Leverage all pre-defined NN modules with no code change.&lt;/li&gt;
  &lt;li&gt;Utilize both multi-processing and multi-threading for maximum speed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The code below defines a basic neighbor sampler:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeighborSampler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# The full graph structure&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# fan-out of each layer&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_blocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# `seeds` are the set of nodes to build one sample from.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# For each seed node, sample ``fanout`` neighbors.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;frontier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sampling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# Then we compact the frontier into a bipartite graph for message passing.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frontier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# Obtain the seed nodes for next layer.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Although these APIs are still experimental, you can find their usages in many
examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Train the GraphSAGE model by neighbor sampling and scale it to multiple GPUs
(&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/graphsage&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Train the Relational GCN model on heterogeneous graphs by sampling for both
node classification and link prediction (&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn-hetero&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Train the PinSAGE model by random walk sampling for item recommendation (&lt;a href=&quot;https://github.com/dmlc/dgl/pull/1334&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Train the GCMC model by sampling for MovieLens rating prediction (&lt;a href=&quot;https://github.com/dmlc/dgl/pull/1296&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Implement the variance reduction technique for neighbor sampling (&lt;a href=&quot;https://github.com/dmlc/dgl/pull/1355&quot;&gt;link&lt;/a&gt;) proposed by &lt;a href=&quot;https://arxiv.org/abs/1710.10568&quot;&gt;Chen et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will continue polishing these APIs, and the corresponding documentations and
tutorials are coming.&lt;/p&gt;

&lt;h2 id=&quot;other-improvements&quot;&gt;Other Improvements&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;All GNN modules under &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn&lt;/code&gt; now support both homogeneous graph and bipartite graph.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLHeteroGraph&lt;/code&gt; now has a faster pickling/unpickling implementation.&lt;/li&gt;
  &lt;li&gt;Add new APIs for saving and loading &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLHeteroGraph&lt;/code&gt; from checkpoints.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BatchedDGLGraph&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLSubGraph&lt;/code&gt; classes have been merged to &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Constructing &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; no longer requires a &lt;code class=&quot;highlighter-rouge&quot;&gt;multigraph&lt;/code&gt; flag.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More details can be found in the &lt;a href=&quot;https://github.com/dmlc/dgl/releases/tag/0.4.3&quot;&gt;full release note&lt;/a&gt;.&lt;/p&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">The DGL v0.4.3 release brings many new features for an enhanced usability and system efficiency. The article takes a peek at some of the major highlights.</summary></entry><entry><title type="html">DGL v0.4 Release (heterogeneous graph update)</title><link href="https://www.dgl.ai/release/2019/10/08/release.html" rel="alternate" type="text/html" title="DGL v0.4 Release (heterogeneous graph update)" /><published>2019-10-08T00:00:00+00:00</published><updated>2019-10-08T00:00:00+00:00</updated><id>https://www.dgl.ai/release/2019/10/08/release</id><content type="html" xml:base="https://www.dgl.ai/release/2019/10/08/release.html">&lt;p&gt;We are thrilled to announce the 0.4 release!  This includes:&lt;/p&gt;

&lt;h1 id=&quot;heterogeneous-graph-support&quot;&gt;Heterogeneous Graph Support&lt;/h1&gt;

&lt;h2 id=&quot;what-is-a-heterogeneous-graph&quot;&gt;What is a heterogeneous graph?&lt;/h2&gt;

&lt;p&gt;A heterogeneous graph is a graph whose nodes and edges are typed:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/2978100/66382127-3196d400-e9ed-11e9-94f8-ee89ba530a13.png&quot; alt=&quot;&quot; width=&quot;350x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;models-that-work-on-heterogeneous-graphs&quot;&gt;Models that work on heterogeneous graphs?&lt;/h2&gt;

&lt;p&gt;Models using Heterogeneous Graph API:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.02263&quot;&gt;GCMC&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/mxnet/gcmc&quot;&gt;Code in MXNet&lt;/a&gt;]&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;Dataset&lt;/th&gt;
          &lt;th&gt;RMSE (DGL)&lt;/th&gt;
          &lt;th&gt;RMSE (Official)&lt;/th&gt;
          &lt;th&gt;Speed (DGL)&lt;/th&gt;
          &lt;th&gt;Speed (Official)&lt;/th&gt;
          &lt;th&gt;Speed Comparison&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;MovieLens-100K&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.9077&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.910&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.0246s/epoch&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.1008s/epoch&lt;/td&gt;
          &lt;td&gt;5x&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;MovieLens-1M&lt;/td&gt;
          &lt;td&gt;0.8377&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.832&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.0695s/epoch&lt;/td&gt;
          &lt;td&gt;1.538s/epoch&lt;/td&gt;
          &lt;td&gt;22x&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;MovieLens-10M (full-graph training)&lt;/td&gt;
          &lt;td&gt;0.7875&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.777&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.6480s/epoch&lt;/td&gt;
          &lt;td&gt;OOM&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.06103&quot;&gt;R-GCN&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn-hetero&quot;&gt;Code in PyTorch&lt;/a&gt;]
    &lt;ul&gt;
      &lt;li&gt;We provide an R-GCN model for heterograph input. The new code can train the model for the AM dataset (&amp;gt;5M edges) using one GPU, while the original implementation can only run on CPU and consume 32GB memory.&lt;/li&gt;
      &lt;li&gt;The original implementation takes 51.88s to train one epoch on CPU. The new R-GCN based on heterograph takes only 0.1781s for one epoch on V100 GPU (&lt;strong&gt;291x faster !!&lt;/strong&gt;).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1903.07293&quot;&gt;Heterogeneous Attention Networks&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/han&quot;&gt;Code in PyTorch&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3098036&quot;&gt;Metapath2vec&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/metapath2vec&quot;&gt;Code in PyTorch&lt;/a&gt;]
    &lt;ul&gt;
      &lt;li&gt;The metapath sampler is twice as fast as the original implementation.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-could-i-play-with-a-heterogeneous-graph&quot;&gt;How could I play with a heterogeneous graph?&lt;/h2&gt;

&lt;p&gt;Here is an example for creating and manipulating a heterogeneous graph:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.function&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heterograph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'plays'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'attracts'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'developer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'develops'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Here the user nodes have a single feature named x, and game nodes have a single feature named y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Edge features are similar&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'plays'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# One can also perform message passing.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# The following code performs a full message passing on the &quot;plays&quot; edges.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Moreover, one can also perform message passing on multiple types at the same time, aggregating the results&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multi_update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'attracts'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sum'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Checkout our heterograph tutorial: &lt;a href=&quot;https://docs.dgl.ai/tutorials/hetero/1_basics.html&quot;&gt;Working with Heterogeneous Graphs in DGL&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Checkout the full &lt;a href=&quot;https://docs.dgl.ai/api/python/heterograph.html&quot;&gt;API reference&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;knowledge-graph-models&quot;&gt;Knowledge Graph Models&lt;/h1&gt;

&lt;p&gt;We also released DGL-KE, a subpackage of DGL that trains embeddings on knowledge graphs. This package is adapted from the &lt;a href=&quot;https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding&quot;&gt;KnowledgeGraphEmbedding&lt;/a&gt; package. We made it fast and scalable while still maintaining the flexibility of the original package. Using a single NVIDIA V100 GPU, DGL-KE can train TransE on FB15k in &lt;strong&gt;6.85 mins&lt;/strong&gt;, substantially outperforming existing tools such as GraphVite.  For graphs with hundreds of millions of edges (such as the full Freebase graph), it takes a couple of hours on &lt;strong&gt;one&lt;/strong&gt; EC2 x1.32xlarge machine.&lt;/p&gt;

&lt;p&gt;Currently, the following models are supported:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TransE&lt;/li&gt;
  &lt;li&gt;DistMult&lt;/li&gt;
  &lt;li&gt;ComplEx&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And the following training schemas are supported:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU training&lt;/li&gt;
  &lt;li&gt;GPU training&lt;/li&gt;
  &lt;li&gt;Joint CPU &amp;amp; GPU training&lt;/li&gt;
  &lt;li&gt;Multiprocessing training on CPUs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Training results on FB15k using one NVIDIA V100 GPU&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Training Speed:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Models&lt;/th&gt;
      &lt;th&gt;TransE&lt;/th&gt;
      &lt;th&gt;DistMult&lt;/th&gt;
      &lt;th&gt;ComplEx&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;MAX_STEPS&lt;/td&gt;
      &lt;td&gt;20000&lt;/td&gt;
      &lt;td&gt;100000&lt;/td&gt;
      &lt;td&gt;100000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;TIME&lt;/td&gt;
      &lt;td&gt;411s&lt;/td&gt;
      &lt;td&gt;690s&lt;/td&gt;
      &lt;td&gt;806s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Training accuracy:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Models&lt;/th&gt;
      &lt;th&gt;MR&lt;/th&gt;
      &lt;th&gt;MRR&lt;/th&gt;
      &lt;th&gt;HITS@1&lt;/th&gt;
      &lt;th&gt;HITS@3&lt;/th&gt;
      &lt;th&gt;HITS@10&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;TransE&lt;/td&gt;
      &lt;td&gt;69.12&lt;/td&gt;
      &lt;td&gt;0.656&lt;/td&gt;
      &lt;td&gt;0.567&lt;/td&gt;
      &lt;td&gt;0.718&lt;/td&gt;
      &lt;td&gt;0.802&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DistMult&lt;/td&gt;
      &lt;td&gt;43.35&lt;/td&gt;
      &lt;td&gt;0.783&lt;/td&gt;
      &lt;td&gt;0.713&lt;/td&gt;
      &lt;td&gt;0.837&lt;/td&gt;
      &lt;td&gt;0.897&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ComplEx&lt;/td&gt;
      &lt;td&gt;51.99&lt;/td&gt;
      &lt;td&gt;0.785&lt;/td&gt;
      &lt;td&gt;0.720&lt;/td&gt;
      &lt;td&gt;0.832&lt;/td&gt;
      &lt;td&gt;0.889&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In comparison, GraphVite uses 4 GPUs and takes 14 minutes. Thus, DGL-KE trains TransE on FB15k 2x times faster than GraphVite while using much fewer resources.&lt;/p&gt;

&lt;p&gt;For more information, please refer to &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/apps/kg&quot;&gt;this directory&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous&quot;&gt;Miscellaneous&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;New builtin message function: dot product (&lt;code class=&quot;highlighter-rouge&quot;&gt;u_dot_v&lt;/code&gt; etc. #831 @classicsong )&lt;/li&gt;
  &lt;li&gt;More efficient data format and serialization (#728 @VoVAllen )&lt;/li&gt;
  &lt;li&gt;ClusterGCN (#877 , @Zardinality )&lt;/li&gt;
  &lt;li&gt;CoraFull, Amazon, KarateClub, Coauthor datasets (#855 @VoVAllen )&lt;/li&gt;
  &lt;li&gt;More performance improvements&lt;/li&gt;
  &lt;li&gt;More bugfixes&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">We are thrilled to announce the 0.4 release! This includes:</summary></entry><entry><title type="html">DGL v0.3.1 Release</title><link href="https://www.dgl.ai/release/2019/08/28/release.html" rel="alternate" type="text/html" title="DGL v0.3.1 Release" /><published>2019-08-28T00:00:00+00:00</published><updated>2019-08-28T00:00:00+00:00</updated><id>https://www.dgl.ai/release/2019/08/28/release</id><content type="html" xml:base="https://www.dgl.ai/release/2019/08/28/release.html">&lt;p&gt;We have received many requests from our community for more GNN layers, models and examples. This is the time to respond. In this minor release, we enriched DGL with a ton of common GNN modules. We have also verified their correctness on some popular datasets so feel free to try them out. Another direction we are working on is to build more domain friendly packages based on DGL. As a first step, we released several pretrained GNN models for molecular property prediction and molecule generation (currently grouped under &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.model_zoo&lt;/code&gt; namespace). We will continue explore this idea and release more domain specific models and packages.&lt;/p&gt;

&lt;h1 id=&quot;new-apis&quot;&gt;New APIs&lt;/h1&gt;

&lt;h2 id=&quot;new-nn-modules&quot;&gt;New NN Modules&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GATConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;“Graph Attention Network”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RelGraphConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/abs/1703.06103&quot;&gt;“Modeling Relational Data with Graph Convolutional Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TAGConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1710.10370.pdf&quot;&gt;“Topology Adaptive Graph Convolutional Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;EdgeConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1801.07829&quot;&gt;“Dynamic Graph CNN for Learning on Point Clouds”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SAGEConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1706.02216.pdf&quot;&gt;“Inductive Representation Learning on Large Graphs”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GatedGraphConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1511.05493.pdf&quot;&gt;“Gated Graph Sequence Neural Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GMMConv&lt;/code&gt; from &lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2017/papers/Monti_Geometric_Deep_Learning_CVPR_2017_paper.pdf&quot;&gt;“Geometric Deep Learning on Graphs and Manifolds using Mixture Model CNNs”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GINConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1810.00826.pdf&quot;&gt;“How Powerful are Graph Neural Networks?”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ChebConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1606.09375.pdf&quot;&gt;“Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SGConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1902.07153.pdf&quot;&gt;“Simplifying Graph Convolutional Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NNConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1704.01212.pdf&quot;&gt;“Neural Message Passing for Quantum Chemistry”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APPNPConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1810.05997.pdf&quot;&gt;“Predict then Propagate: Graph Neural Networks meet Personalized PageRank”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AGNNConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/abs/1803.03735&quot;&gt;“Attention-based Graph Neural Network for Semi-Supervised Learning
”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DenseGraphConv&lt;/code&gt; (Dense implementation of &lt;code class=&quot;highlighter-rouge&quot;&gt;GraphConv&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DenseSAGEConv&lt;/code&gt; (Dense implementation of &lt;code class=&quot;highlighter-rouge&quot;&gt;SAGEConv&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DenseChebConv&lt;/code&gt; (Dense implementation of &lt;code class=&quot;highlighter-rouge&quot;&gt;ChebConv&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;new-global-pooling-module&quot;&gt;New global pooling module&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Sum/Avg/MaxPooling&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SortPooling&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GlobalAttentionPooling&lt;/code&gt; from GGNN model&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Set2Set&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1511.06391.pdf&quot;&gt;“Order Matters: Sequence to sequence for sets”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SetTransformerEncoder&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SetTransformerDecoder&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1810.00825.pdf&quot;&gt;“Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks”&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please refer to the &lt;a href=&quot;https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.glob&quot;&gt;API document&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h2 id=&quot;new-graph-transformation-routines&quot;&gt;New graph transformation routines&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.khop_adj&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.khop_graph&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.laplacian_lambda_max&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.knn_graph&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.segmented_knn_graph&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please refer to the &lt;a href=&quot;https://docs.dgl.ai/api/python/transform.html&quot;&gt;API document&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h1 id=&quot;model-zoo-for-chemistry-and-molecule-applications&quot;&gt;Model zoo for chemistry and molecule applications&lt;/h1&gt;
&lt;p&gt;To make it easy for domain scientists, we are now releasing a model zoo for chemistry, with training scripts and pre-trained models, and focuses on two particular tasks: property prediction and targeted molecular generation/optimization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Credit&lt;/strong&gt;: Shout out to @geekinglcq from Tencent Quantum Lab for contributing three models (MGCN, SchNet and MPNN). We also thank WuXi AppTec CADD team for their critical feedback on usability.&lt;/p&gt;

&lt;h2 id=&quot;property-prediction&quot;&gt;Property prediction&lt;/h2&gt;
&lt;p&gt;In practice, the determination of molecular properties is mostly achieved via wet lab experiments. We can cast the problem as a regression or classification problem.&lt;/p&gt;

&lt;p&gt;Featurization is the beginning of prediction. Traditionally, chemists develop pre-defined rules to convert molecular graphs into binary strings where each bit indicates the presence or absence of a particular substructure.&lt;/p&gt;

&lt;p&gt;Graph neural networks enable a data-driven representation of molecules out of the atoms, bonds and molecular graph topology, which may be viewed as a learned fingerprint. The message passing mechanism allows the model to learn the interactions between atoms in a molecule.&lt;/p&gt;

&lt;p&gt;The following code script is self-explanatory.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.data.chem&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tox21&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tox21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GCN_Tox21'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Pretrained model loaded&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;smiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                   &lt;span class=&quot;c&quot;&gt;# CCOc1ccc2nc(S(N)(=O)=O)sc2c1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Mask non-existing labels&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# tensor([[-0.7956,  0.4054,  0.4288, -0.5565, -0.0911,  &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 0.9981, -0.1663,  0.2311, -0.2376,  0.9196]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Supported Models&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Graph Convolution&lt;/li&gt;
  &lt;li&gt;Graph Attention Networks&lt;/li&gt;
  &lt;li&gt;SchNet&lt;/li&gt;
  &lt;li&gt;Multilevel Graph Convolutional neural Network&lt;/li&gt;
  &lt;li&gt;Message Passing Neural Networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generative-models&quot;&gt;Generative Models&lt;/h2&gt;

&lt;p&gt;Targeted molecular generation refers to finding new molecules with desired properties. This gives rise to the need for generative models for two purposes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Distribution Learning&lt;/strong&gt;: Given a collection of molecules, we want to model their distribution and generate new molecules consistent with the distribution.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Goal-directed Optimization&lt;/strong&gt;: Find molecules with desired properties.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this model zoo, we provide only graph-based generative models. There are other generative models working with alternative representations like SMILES.&lt;/p&gt;

&lt;p&gt;Example with Pre-trained Models&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# We recommend running the code below with Jupyter notebooks&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;IPython.display&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVG&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rdkit&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Chem&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rdkit.Chem&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Draw&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'DGMG_ZINC_canonical'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mols&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;SMILES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdkit_mol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MolFromSmiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SMILES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Generating 4 molecules takes less than a second.&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;SVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Draw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MolsToGridImage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;molsPerRow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subImgSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;180&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;useSVG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/model_zoo/drug_discovery/dgmg_model_zoo_example2.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Supported Models&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Learning Deep Generative Models of Graphs&lt;/li&gt;
  &lt;li&gt;Junction Tree Variational Autoencoder for Molecular Graph Generation&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;api-break&quot;&gt;API break&lt;/h1&gt;
&lt;p&gt;We refactor the &lt;code class=&quot;highlighter-rouge&quot;&gt;nn&lt;/code&gt; package to make all APIs more consistent. Thus, there are following changes to the API that breaks the previous behavior:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Change the argument order of &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.pytorch.GraphConv&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.mxnet.GraphConv&lt;/code&gt;. The argument order is now first &lt;code class=&quot;highlighter-rouge&quot;&gt;graph&lt;/code&gt; and then &lt;code class=&quot;highlighter-rouge&quot;&gt;feat&lt;/code&gt;, which follows the convention of all the other new modules.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;new-model-example&quot;&gt;New model example&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.08028.pdf&quot;&gt;Recurrent Relational Networks&lt;/a&gt; in PyTorch (credit: @HuXiangkun )&lt;/p&gt;

&lt;p&gt;There are also many bug fixes and minor changes. We will list them in the next 0.4 major release.&lt;/p&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">We have received many requests from our community for more GNN layers, models and examples. This is the time to respond. In this minor release, we enriched DGL with a ton of common GNN modules. We have also verified their correctness on some popular datasets so feel free to try them out. Another direction we are working on is to build more domain friendly packages based on DGL. As a first step, we released several pretrained GNN models for molecular property prediction and molecule generation (currently grouped under dgl.model_zoo namespace). We will continue explore this idea and release more domain specific models and packages.</summary></entry><entry><title type="html">Large-Scale Training of Graph Neural Networks</title><link href="https://www.dgl.ai/blog/2019/06/13/giant.html" rel="alternate" type="text/html" title="Large-Scale Training of Graph Neural Networks" /><published>2019-06-13T00:00:00+00:00</published><updated>2019-06-13T00:00:00+00:00</updated><id>https://www.dgl.ai/blog/2019/06/13/giant</id><content type="html" xml:base="https://www.dgl.ai/blog/2019/06/13/giant.html">&lt;p&gt;Many graph applications deal with &lt;em&gt;giant&lt;/em&gt; scale. Social networks, recommendation and knowledge graphs have nodes and edges in the order of hundreds of millions or even billions of nodes. For example, a recent snapshot of the friendship network of Facebook contains 800 million nodes and over 100 billion links.&lt;/p&gt;

&lt;h2 id=&quot;sampling-methods-in-dgl&quot;&gt;Sampling methods in DGL&lt;/h2&gt;
&lt;p&gt;Giant graphs are a classic challenge, and is even more so in graph neural networks (GNN). In a GNN model, computing the embedding of a node depends on the embeddings of its neighbors. Such dependency leads to exponential growth of the number of nodes involved with number of GNN layers.&lt;/p&gt;

&lt;p&gt;A typical technique is sampling, and there are many variants, some of them are applicable to GNN and DGL supports a few of them. The basic idea is to prune the node dependency to reduce the computation while still estimating the embeddings of GNN accurately. We leave the exact formulation of these techniques at the end of the tutorial (and users are encouraged to read them!), and describe the gists of them breifly here:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.02216&quot;&gt;neighbor sampling&lt;/a&gt;. This is the most basic: simply pick a small number of random neighbors.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1809.05343&quot;&gt;layer-wise sampling&lt;/a&gt;. The problem with simple neighbor sampling is that number of nodes needed will continue to grow exponentially with deeper layers. The idea here is to consider a layer as a whole and constrain the amount of samples per layer.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.01973&quot;&gt;random-walk sampling&lt;/a&gt;. As the name suggests, samples are picked up by performing random walks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sampling estimators can suffer from high variance. Obviously, including more neighbors will reduce the variance but this defeats the purpose of sampling. One interesting soution is &lt;a href=&quot;https://arxiv.org/abs/1710.10568&quot;&gt;control-variate sampling&lt;/a&gt;, a standard variance reduction technique used in Monte Carlo methods.&lt;/p&gt;

&lt;p&gt;The basic idea is simple: given a random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and we wish to estimate its expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [X] = \theta&lt;/script&gt;, the control variate method finds another random variable &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; which is highly correlated with &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and whose expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [Y]&lt;/script&gt; can be easily computed. Control variate needs to keep extra state, but otherwise is effective in reducing sample size. In fact, one neighbor is enough, for the Reddit dataset!
&lt;!--
We experiment neighbor sampling and control variate sampling to train GCN and GraphSage on Reddit to evaluate the effectiveness of these two sampling methods. The result is shown in the figure below. For GCN, control variate sampling is much more effective than neighbor sampling. Sampling only one neighbor is sufficient to train GCN on the Reddit dataset. Similarly, when training GraphSage, we only need to sample one neighbor to get its accuracy over 96%.
--&gt;
&lt;img src=&quot;https://i.imgur.com/DTPQu5V.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;system-support-for-giant-graphs&quot;&gt;System support for giant graphs&lt;/h2&gt;
&lt;p&gt;Sampling provides the nice possiblity of dealing with giant graphs with a data-parallel perspective. DGL adds two components, see figure below:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sampler&lt;/strong&gt;: a sampler constructs small subgraphs (&lt;code class=&quot;highlighter-rouge&quot;&gt;NodeFlow&lt;/code&gt;) from a given (giant) graph; tutorials of &lt;code class=&quot;highlighter-rouge&quot;&gt;NodeFlow&lt;/code&gt; can be found &lt;a href=&quot;https://doc.dgl.ai/tutorials/models/5_giant_graph/1_sampling_mx.html#sphx-glr-tutorials-models-5-giant-graph-1-sampling-mx-py&quot;&gt;here&lt;/a&gt;. Multiple samplers can be launched locally, or remotely, and on many machines.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Graph store&lt;/strong&gt;: this prepares the I/O substrate to scale out with a large number of trainers. The graph store contains graph embeddings as well as its structure. For now, the implementation is based on shared-memory, supporting multi-processing training on multi-GPU and/or non-uniform memory access (NUMA) machines.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The shared-memory graph store has a similar interface to &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; for programming. DGL will also support a distributed graph store that can store graph embeddings across machines in the future release.&lt;/p&gt;

&lt;!--
The figure below shows the interaction of the trainer with the samplers and the graph store. The trainer takes subgraphs (`NodeFlow`) from the sampler and fetches graph embeddings from the graph store before training. The trainer can push new graph embeddings to the graph store or invoke some computation on the graph store.
--&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/OmLVXfo.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, let’s demonstrate how good these supports are.&lt;/p&gt;

&lt;h3 id=&quot;multi-processing-training-and-optimizations-on-a-numa-machine&quot;&gt;Multi-processing training and optimizations on a NUMA machine&lt;/h3&gt;
&lt;p&gt;The speedup is almost linear, and on Reddit dataset takes about only 20 seconds to converge to the accuracy of 96% with 20 iterations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/eaiEcEi.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;X1.32xlarge instance has 4 processors, each of which has 16 physical CPU cores.&lt;/li&gt;
  &lt;li&gt;We need to be aware of NUMA architecture, otherwise there’s hardly any speedup with more CPU processors. Please see &lt;a href=&quot;https://doc.dgl.ai/tutorials/models/5_giant_graph/2_giant.html#sphx-glr-tutorials-models-5-giant-graph-2-giant-py&quot;&gt;our tutorial&lt;/a&gt; for more details.&lt;/li&gt;
&lt;/ul&gt;

&lt;!--
To demonstrate the effectiveness of multi-processing training with this architecture on a NUMA machine and on a multi-GPU machine, we train GraphSage on the Reddit dataset with control-variate sampling. To optimize the training in a NUMA machine, we need to bind trainers' processes to specific NUMA nodes. Please see [our tutorial](https://doc.dgl.ai/tutorials/models/5_giant_graph/2_giant.html#sphx-glr-tutorials-models-5-giant-graph-2-giant-py) for more details how to bind processes on a NUMA node.
The figure below shows that NUMA-aware multi-processing training can accelerate training almost by a factor of 4 on an X1.32xlarge instance where there are 4 processors, each of which has 16 physical CPU cores. We can see that NUMA-unaware training cannot take advantage of computation power of the machine. It is even slightly slower than just using one of the processors in the machine. NUMA-aware training, on the other hand, takes about only 20 seconds to converge to the accuracy of 96% with 20 iterations.
--&gt;

&lt;h3 id=&quot;distributed-sampler&quot;&gt;Distributed Sampler&lt;/h3&gt;

&lt;p&gt;We can move samplers around. For GCN variants where computation aren’t that intense, running samplers on small (and cheaper) machines and training on NUMA is both faster and more cost-effective (additional 20%-40% speedups).&lt;/p&gt;

&lt;!--
are ran on different machines, we can 
We also notice that the sampling in many tasks takes a significant amount of time for the training process on a giant graph. So DGL supports distributed samplers for speeding up the sampling process on giant graphs. DGL allows users to launch multiple samplers on different machines concurrently, and each sampler can send its sampled subgraph (`NodeFlow`) to trainer machines continuously. 
The figure below shows the overall performance improvement of training GCN and GraphSage on the Reddit dataset after deploying NUMA optimizations and distributed sampling. Our NUMA optimization speeds up the training by a factor of 3. The distributed sampling achieves additional 20%-40% speed improvement for different tasks.
--&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/e0MXa5N.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;scale-to-giant-graphs&quot;&gt;Scale to giant graphs&lt;/h3&gt;
&lt;!--Finally, we would like to demonstrate the scalability of DGL on giant graphs. 
--&gt;
&lt;p&gt;We create three large power-law graphs with &lt;a href=&quot;http://www.cs.cmu.edu/~christos/PUBLICATIONS/siam04.pdf&quot;&gt;RMAT&lt;/a&gt;. Each node is associated with 100 features and we compute node embeddings with 64 dimensions. Below shows the training speed and memory consumption of GCN with neighbor sampling.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;#Nodes&lt;/th&gt;
      &lt;th&gt;#Edges&lt;/th&gt;
      &lt;th&gt;Time per epoch (s)&lt;/th&gt;
      &lt;th&gt;Memory (GB)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;5M&lt;/td&gt;
      &lt;td&gt;250M&lt;/td&gt;
      &lt;td&gt;4.7&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50M&lt;/td&gt;
      &lt;td&gt;2.5B&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;500M&lt;/td&gt;
      &lt;td&gt;25B&lt;/td&gt;
      &lt;td&gt;505&lt;/td&gt;
      &lt;td&gt;740&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that DGL can scale to graphs with 500M nodes and 25B edges on an X1.32xlarge instance.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;We are looking forward to your feedbacks and would love to hear your use cases and models for giant graphs! All of these new features shown in this blog will be in our upcoming v0.3 release. Please try them out and give us feedbacks.&lt;/p&gt;

&lt;p&gt;We are continuing working on our infrastructure for training graph neural networks on giant graphs, which includes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In the infrastructure, we will add a distributed graph store to support fully distributed training for graph neural networks.&lt;/li&gt;
  &lt;li&gt;We will experiment various strategies to accelerate distributed training. For example, we will experiment fast and scalable graph partitioning algorithms to reduce network communication.&lt;/li&gt;
  &lt;li&gt;We will also add more demonstrations of other sampling strategies. For example, we will scale PinSage with our random walk sampler.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sampling-techniques-in-gnn&quot;&gt;Sampling techniques in GNN&lt;/h2&gt;

&lt;p&gt;Let’s use graph convolution network as an example to show these sampling techniques. Given a graph &lt;script type=&quot;math/tex&quot;&gt;G=(V, E)&lt;/script&gt;, represented as an adjacency matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt;, with node features &lt;script type=&quot;math/tex&quot;&gt;H^{(0)} = X \in \mathbb{R}^{|V| \times m}&lt;/script&gt;, graph convolution networks (GCNs) compute the hidden features &lt;script type=&quot;math/tex&quot;&gt;H^{(l+1)}&lt;/script&gt; of the &lt;script type=&quot;math/tex&quot;&gt;(l+1)&lt;/script&gt;-th layer by computing for each &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;h_v^{(l+1)} = \sigma ( z_v^{(l)} W^{(l)}) \qquad z_v^{(l)} = \sum_{u \in \mathcal{N}(v)} \tilde{A}_{uv} h_u^{(l)}&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(v)&lt;/script&gt; denotes the neighborhood of &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}&lt;/script&gt; is a normalized version of &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; such as &lt;script type=&quot;math/tex&quot;&gt;D^{-1} A&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\sigma(\cdot)&lt;/script&gt; is the activation function, &lt;script type=&quot;math/tex&quot;&gt;W^{(l)}&lt;/script&gt; is a trainable parameter of the &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;-th layer. For a &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-layer GCN model, the computation of &lt;script type=&quot;math/tex&quot;&gt;H^{(L)}&lt;/script&gt; requires the propagation from all of its &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-hop neighbors. This is too expensive in mini-batch training because the receptive field of a node grows exponentially with respective to the number of layers &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Neighbor Sampling&lt;/strong&gt;
Instead of using all the &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-hop neighbors of a node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;, neighbor sampling randomly samples a few neighbors &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathcal{N}}^{(l)}(v)&lt;/script&gt; to estimate the aggregation &lt;script type=&quot;math/tex&quot;&gt;z_v^{(l)}&lt;/script&gt; of its total neighbors &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(v)&lt;/script&gt; in &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;-th GCN layer by an unbiased estimator &lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{z}_v^{(l)} = \frac{\vert \mathcal{N}(v) \vert }{\vert \hat{\mathcal{N}}^{(l)}(v) \vert} \sum_{u \in \hat{\mathcal{N}}^{(l)}(v)} \tilde{A}_{uv} \hat{h}_u^{(l)} \\
\hat{h}_v^{(l+1)} = \sigma ( \hat{z}_v^{(l)} W^{(l)} )&lt;/script&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;D^{(l)}&lt;/script&gt; be the number of neighbors to be sampled for each node at the &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;-th layer, then the receptive field size of each node can be controlled under &lt;script type=&quot;math/tex&quot;&gt;\prod_{i=0}^{L-1} D^{(l)}&lt;/script&gt; by neighbor sampling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Layer-Wise Sampling&lt;/strong&gt;
In node-wise sampling, each parent node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; independently samples a few neighbors &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathcal{N}}(v)&lt;/script&gt;, which are not visible to other parent nodes &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; except &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;. The receptive field size still grows exponentially if &lt;script type=&quot;math/tex&quot;&gt;\vert \hat{\mathcal{N}}(v) \vert &gt; 1&lt;/script&gt;. In layer-wise sampling, the sampling procedure is performed only once in each layer, where each node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; gets sampled into &lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}^{(l)}&lt;/script&gt; with probability &lt;script type=&quot;math/tex&quot;&gt;p^{(l)}(v)&lt;/script&gt;,
&lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)} = \sum_{u \in \mathcal{S}^{(l)}} \frac{1}{p^{(l)}(u)} \tilde{A}_{uv} \hat{h}_u^{(l)}&lt;/script&gt;
The receptive field size can be controlled directly by &lt;script type=&quot;math/tex&quot;&gt;\vert \mathcal{S}^{(0)} \vert&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Random Walk Sampling&lt;/strong&gt;
Given a source node &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; and a decay factor &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;, a random walk from &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; is a trace beginning from &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt;, at each step either proceeds to a neighbor uniformly at random, or stop with probability &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;. The personalized PageRank (PPR) score &lt;script type=&quot;math/tex&quot;&gt;\pi(s, t)&lt;/script&gt; is the probability that a random walk from &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; terminates at &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;In PinSage, each node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; selects top-&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; important nodes with highest PPR scores with respective to &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; as its neighbors &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathcal{N}}(v)&lt;/script&gt;, and the hidden feature of each neighbor &lt;script type=&quot;math/tex&quot;&gt;u \in \hat{\mathcal{N}}(v)&lt;/script&gt; is weighted by &lt;script type=&quot;math/tex&quot;&gt;\pi(v, u)&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{z}^{(l)}_v = \frac{\sum_{u \in \hat{\mathcal{N}}(v)} \pi(v, u) \tilde{A}_{uv} \hat{h}_u^{(l)}}{\sum_{u \in \hat{\mathcal{N}}(v)} \pi(v, u)}&lt;/script&gt;

&lt;p&gt;Compared to GCNs which uses all the &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-hop neighbors, PinSage selects &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; topology-based important neighbors which have the largest influence.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Control Variate&lt;/strong&gt;
Although unbiased, sampling estimators such as &lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)}&lt;/script&gt; in neighbor sampling suffers from high variance, so it still requires a relatively large number of neighbors, e.g. &lt;script type=&quot;math/tex&quot;&gt;D^{(0)}=25&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;D^{(1)}=10&lt;/script&gt; in the GraphSage paper. With control variate, a standard variance reduction technique used in Monte Carlo methods, 2 neighbors for a node are sufficient in the experiments.&lt;/p&gt;

&lt;p&gt;Given a random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and we wish to estimate its expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [X] = \theta&lt;/script&gt;, the control variate method finds another random variable &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; which is highly correlated with &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and whose expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [Y]&lt;/script&gt; can be easily computed. The control variate estimator is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z = X - Y + \mathbb{E} [Y]&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{VAR} [Z] = \mathbb{VAR} [X] + \mathbb{VAR} [Y] - 2 \cdot \mathbb{COV} [X, Y]&lt;/script&gt;
If &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\mathbb{VAR} [Y] - 2\mathbb{COV} [X, Y] &lt; 0 %]]&gt;&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\mathbb{VAR} [Z] &lt; \mathbb{VAR} [X] %]]&gt;&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;For GCN, by using history &lt;script type=&quot;math/tex&quot;&gt;\bar{H}^{(l)}&lt;/script&gt; of the nodes which are not sampled, the modified estimator &lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)}&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{z}_v^{(l)} = \frac{\vert \mathcal{N}(v) \vert }{\vert \hat{\mathcal{N}}^{(l)}(v) \vert} \sum_{u \in \hat{\mathcal{N}}^{(l)}(v)} \tilde{A}_{uv} ( \hat{h}_u^{(l)} - \bar{h}_u^{(l)} ) + \sum_{u \in \mathcal{N}(v)} \tilde{A}_{uv} \bar{h}_u^{(l)}&lt;/script&gt;</content><author><name>Da Zheng</name></author><category term="blog" /><category term="blog" /><summary type="html">Many graph applications deal with giant scale. Social networks, recommendation and knowledge graphs have nodes and edges in the order of hundreds of millions or even billions of nodes. For example, a recent snapshot of the friendship network of Facebook contains 800 million nodes and over 100 billion links.</summary></entry><entry><title type="html">DGL v0.3 Release</title><link href="https://www.dgl.ai/release/2019/06/12/release.html" rel="alternate" type="text/html" title="DGL v0.3 Release" /><published>2019-06-12T00:00:00+00:00</published><updated>2019-06-12T00:00:00+00:00</updated><id>https://www.dgl.ai/release/2019/06/12/release</id><content type="html" xml:base="https://www.dgl.ai/release/2019/06/12/release.html">&lt;p&gt;V0.3 release includes many crucial updates:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fused message passing kernels that greatly boost the training speed of GNNs on large graphs.
Please refer to our &lt;a href=&quot;https://www.dgl.ai/blog/2019/05/04/kernel.html&quot;&gt;blogpost&lt;/a&gt; for more details.&lt;/li&gt;
  &lt;li&gt;Add components to enable distributed training of GNNs on giant graphs with graph sampling.
Please see our &lt;a href=&quot;https://www.dgl.ai/blog/2019/06/13/giant.html&quot;&gt;blogpost&lt;/a&gt; for more details.&lt;/li&gt;
  &lt;li&gt;New models and NN modules.&lt;/li&gt;
  &lt;li&gt;Many other bugfixes and other enhancement.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a result, please be aware of the following changes:&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;/h2&gt;

&lt;p&gt;Previous installation methods with pip and conda, i.e.:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install dgl
conda install -c dglteam dgl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;now &lt;strong&gt;only install CPU builds&lt;/strong&gt; (works for Linux/MacOS/Windows).&lt;/p&gt;

&lt;h3 id=&quot;installing-cuda-builds-with-pip&quot;&gt;Installing CUDA builds with pip&lt;/h3&gt;
&lt;p&gt;Pip users could install the DGL CUDA builds with the following:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install &amp;lt;package-url&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;package-url&amp;gt;&lt;/code&gt; is one of the following:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;CUDA 9.0&lt;/th&gt;
      &lt;th&gt;CUDA 10.0&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Linux + Py35&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda9.0/dgl-0.3-cp35-cp35m-manylinux1_x86_64.whl&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp35-cp35m-manylinux1_x86_64.whl&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Linux + Py36&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda9.0/dgl-0.3-cp36-cp36m-manylinux1_x86_64.whl&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp36-cp36m-manylinux1_x86_64.whl&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Linux + Py37&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda9.0/dgl-0.3-cp37-cp37m-manylinux1_x86_64.whl&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp37-cp37m-manylinux1_x86_64.whl&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Win + Py35&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda9.0/dgl-0.3-cp35-cp35m-win_amd64.whl&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp35-cp35m-win_amd64.whl&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Win + Py36&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda9.0/dgl-0.3-cp36-cp36m-win_amd64.whl&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp36-cp36m-win_amd64.whl&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Win + Py37&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda9.0/dgl-0.3-cp37-cp37m-win_amd64.whl&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp37-cp37m-win_amd64.whl&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MacOS&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;installing-cuda-builds-with-conda&quot;&gt;Installing CUDA builds with conda&lt;/h3&gt;
&lt;p&gt;Conda users could install the CUDA builds with&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda install -c dglteam dgl-cuda9.0   # For CUDA 9.0
conda install -c dglteam dgl-cuda10.0  # For CUDA 10.0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;DGL currently support CUDA 9.0 (dgl-cuda9.0) and 10.0 (dgl-cuda10.0). To find your CUDA version, use &lt;code class=&quot;highlighter-rouge&quot;&gt;nvcc --version&lt;/code&gt;. To install from source, checkout our &lt;a href=&quot;https://docs.dgl.ai/install/index.html#install-from-source&quot;&gt;installation guide&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;new-built-in-message-and-reduce-functions&quot;&gt;New built-in message and reduce functions&lt;/h2&gt;

&lt;p&gt;We have expanded the list of built-in message and reduce functions to cover more use cases. Previously, DGL only has &lt;code class=&quot;highlighter-rouge&quot;&gt;copy_src&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;copy_edge&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;src_mul_edge&lt;/code&gt;. With the v0.3 release, we support more combinations. Here is a demonstration of some of the new builtin functions.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.function&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;th&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# create a DGLGraph&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_of_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# each node has feature size 10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_of_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# each edge has feature size 1&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# collect features from source nodes and aggregate them in destination nodes&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h_sum'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# multiply source node features with edge weights and aggregate them in destination nodes&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u_mul_e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h_max'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# compute edge embedding by multiplying source and destination node embeddings&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u_mul_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w_new'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As you can see, the syntax is quite straight-forward. &lt;code class=&quot;highlighter-rouge&quot;&gt;u_mul_e&lt;/code&gt; means multiplying the source node data with the edge data; &lt;code class=&quot;highlighter-rouge&quot;&gt;u_mul_v&lt;/code&gt; means multiplying the source node data with the destination node data, and so on and so forth. Each builtin combination will be mapped to a CPU/CUDA kernel and broadcasting and gradient computation are also supported. Checkout our &lt;a href=&quot;https://docs.dgl.ai/features/builtin.html&quot;&gt;document&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h2 id=&quot;training-giant-graphs&quot;&gt;Training giant graphs&lt;/h2&gt;

&lt;p&gt;We added new components shared-memory DGLGraph and distributed samplers to support distributed and multi-processing training of graph neural networks.&lt;/p&gt;

&lt;p&gt;Two new tutorials are now live:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Train GNNs by neighbor sampling and its variants (&lt;a href=&quot;https://docs.dgl.ai/tutorials/models/5_giant_graph/1_sampling_mx.html&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Scale the sampler-trainer architecture to giant graphs using distributed graph store (&lt;a href=&quot;https://docs.dgl.ai/tutorials/models/5_giant_graph/2_giant.html&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We also provide scripts on how to setup such distributed setting (&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/mxnet/sampling/dis_sampling&quot;&gt;link&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;enhancement-and-bugfix&quot;&gt;Enhancement and bugfix&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;NN modules
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.[mxnet|pytorch].edge_softmax&lt;/code&gt; now directly returns the normalized scores on edges.&lt;/li&gt;
      &lt;li&gt;Fix a memory leak bug when graph is passed as the input.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Graph
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; now supports direct conversion from scipy csr matrix rather than conversion to coo matrix first.&lt;/li&gt;
      &lt;li&gt;Readonly graph can now be batched via &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.batch&lt;/code&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; now supports node/edge removal via &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.remove_nodes&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.remove_edges&lt;/code&gt; (&lt;a href=&quot;https://docs.dgl.ai/api/python/graph.html#removing-nodes-and-edges&quot;&gt;doc&lt;/a&gt;).&lt;/li&gt;
      &lt;li&gt;A new API &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.to(device)&lt;/code&gt; that can move all node/edge data to the given device.&lt;/li&gt;
      &lt;li&gt;A new API &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.to_simple&lt;/code&gt; that can convert a graph to a simple graph with no multi-edges.&lt;/li&gt;
      &lt;li&gt;A new API &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.to_bidirected&lt;/code&gt; that can convert a graph to a bidirectional graph.&lt;/li&gt;
      &lt;li&gt;A new API &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.contrib.sampling.random_walk&lt;/code&gt; that can generate random walks from a graph.&lt;/li&gt;
      &lt;li&gt;Allow &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; to be constructed from another &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;New model examples
    &lt;ul&gt;
      &lt;li&gt;APPNP&lt;/li&gt;
      &lt;li&gt;GIN&lt;/li&gt;
      &lt;li&gt;PinSage (slow version)&lt;/li&gt;
      &lt;li&gt;DGI&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bugfix
    &lt;ul&gt;
      &lt;li&gt;Fix a bug where numpy integer is passed in as the argument.&lt;/li&gt;
      &lt;li&gt;Fix a bug when constructing from a networkx graph that has no edge.&lt;/li&gt;
      &lt;li&gt;Fix a bug in nodeflow where id is not correctly converted sometimes.&lt;/li&gt;
      &lt;li&gt;Fix a bug in MiniGC dataset where the number of nodes is not consistent.&lt;/li&gt;
      &lt;li&gt;Fix a bug in RGCN example when bfs_level=0.&lt;/li&gt;
      &lt;li&gt;Fix a bug where DLContext is not correctly exposed in CFFI.&lt;/li&gt;
      &lt;li&gt;Fix a crash during Cython build.&lt;/li&gt;
      &lt;li&gt;Fix a bug in &lt;code class=&quot;highlighter-rouge&quot;&gt;send&lt;/code&gt; when the given message function is a builtin.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">V0.3 release includes many crucial updates: Fused message passing kernels that greatly boost the training speed of GNNs on large graphs. Please refer to our blogpost for more details. Add components to enable distributed training of GNNs on giant graphs with graph sampling. Please see our blogpost for more details. New models and NN modules. Many other bugfixes and other enhancement.</summary></entry><entry><title type="html">When Kernel Fusion meets Graph Neural Networks</title><link href="https://www.dgl.ai/blog/2019/05/04/kernel.html" rel="alternate" type="text/html" title="When Kernel Fusion meets Graph Neural Networks" /><published>2019-05-04T00:00:00+00:00</published><updated>2019-05-04T00:00:00+00:00</updated><id>https://www.dgl.ai/blog/2019/05/04/kernel</id><content type="html" xml:base="https://www.dgl.ai/blog/2019/05/04/kernel.html">&lt;p&gt;In DGL’s first release last December, we focused on usability by introducing a
set of carefully designed, easy-to-use APIs that support a variety of model
implementations of Graph Neural Networks. We decided to keep DGL
framework-agnostic to engage with users from different platforms (PyTorch,
MXNet…). As a result, in our earlier releases, we largely leveraged the
available functionalities provided by these frameworks, and based on many
valuable feedback from our users, we are well-aware of the room of improvement
particularly on some new models defined on the sparse and irregular graphs.&lt;/p&gt;

&lt;p&gt;With DGL’s APIs from the first relase being well-received and gradually stable,
we have been working on boosting its performance in a high gear. Our next major
release (&lt;strong&gt;v0.3&lt;/strong&gt;) will focus on much faster training speed, lower memory
consumption, and scalability.&lt;/p&gt;

&lt;p&gt;The performance gains of the upcoming DGL v0.3 are substantial. Compared to the
current version, DGL v0.3 achieves up to &lt;strong&gt;19X&lt;/strong&gt; the training throughput and
can train &lt;strong&gt;8X&lt;/strong&gt; larger graphs on a single GPU.  DGL’s training speed is now
competitive with alternative frameworks such as Pytorch Geometric, however with
much better scalability. DGL allows training on considerably larger
graphs—&lt;strong&gt;500M&lt;/strong&gt; nodes and &lt;strong&gt;25B&lt;/strong&gt; edges. For a more concrete performance
evaluation and comparison, check out our &lt;a href=&quot;https://rlgm.github.io/papers/49.pdf&quot;&gt;workshop
paper&lt;/a&gt; for more details.&lt;/p&gt;

&lt;p&gt;In the rest of this post, we’ll get technical and describe fused message
passing, the key technique enabling these performance improvements.  We will
address the following questions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Why cannot basic message passing scale to large graphs?&lt;/li&gt;
  &lt;li&gt;How does fused message passing help?&lt;/li&gt;
  &lt;li&gt;How to enable fused message passing in DGL?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-cant-basic-message-passing-scale-to-large-graphs&quot;&gt;Why can’t basic message passing scale to large graphs?&lt;/h2&gt;
&lt;p&gt;Most GNN models perform message-passing style computation over a graph. Such a
computation constitutes two main user-defined functions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Message function&lt;/strong&gt; specifies to send a message along an edge from a node to
its neighbor. This is &lt;strong&gt;edge-wise computation&lt;/strong&gt; since it is performed for all
(or a subset of) edges.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reduce function&lt;/strong&gt; specifies to aggregate the incoming messages of a node
and updates the node feature. This is &lt;strong&gt;node-wide computation&lt;/strong&gt; since it is
performed for all (or a subset of) nodes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following figure gives an illustration. The user-defined message function
is denoted as &lt;script type=&quot;math/tex&quot;&gt;\phi^e&lt;/script&gt;, which is used to generate a message (yellow boxes) on
each edge.  To create a message &lt;script type=&quot;math/tex&quot;&gt;m_{i,j}&lt;/script&gt; for edge &lt;script type=&quot;math/tex&quot;&gt;i\rightarrow j&lt;/script&gt;, the
message function takes into account the edge feature &lt;script type=&quot;math/tex&quot;&gt;e_{i,j}&lt;/script&gt; as well as the
two endpoints’ node features, &lt;script type=&quot;math/tex&quot;&gt;h_i&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;h_j&lt;/script&gt;. At each node, incoming messages are
aggregated using the user-defined reduce function &lt;script type=&quot;math/tex&quot;&gt;\sum&lt;/script&gt; and another
user-defined function &lt;script type=&quot;math/tex&quot;&gt;\phi^v&lt;/script&gt; is used to update the node feature. In DGL, one
can easily implement such message passing by calling &lt;code class=&quot;highlighter-rouge&quot;&gt;send&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;recv&lt;/code&gt; APIs
(see &lt;a href=&quot;https://docs.dgl.ai/tutorials/basics/3_pagerank.html&quot;&gt;our tutorial on message passing for more
details&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/wTda40k.jpg&quot; alt=&quot;&quot; width=&quot;450x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The basic strategy for implementing message-passing is straighforward. First,
we &lt;code class=&quot;highlighter-rouge&quot;&gt;send&lt;/code&gt; messages by invoking &lt;strong&gt;edge-wise&lt;/strong&gt; message functions.  Then, we
&lt;code class=&quot;highlighter-rouge&quot;&gt;recv&lt;/code&gt; messages by applying &lt;strong&gt;node-wise&lt;/strong&gt; computation to aggregate messages
according to their destination nodes (and updating node features). In DGL
example below, we implement &lt;a href=&quot;https://docs.dgl.ai/tutorials/models/1_gnn/1_gcn.html&quot;&gt;Graph Convolution Network
(GCN)&lt;/a&gt; by specifying its
message and reduce functions in lambdas, and DGL uses basic message passing
underneath.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# A GCN example with user-defined message function.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Using user-defined message function causes DGL to use &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# the basic message passing strategy.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]},&lt;/span&gt; 
             &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mailbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The problem with basic message passing is that messages are explicitly
materialized and stored, resulting in memory explosion as the graph becomes
larger. As a concrete example, consider the reddit graph dataset introduced in
the &lt;a href=&quot;https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf&quot;&gt;GraphSAGE
paper&lt;/a&gt;.
It has 232K nodes and 114M edges. If we are to train a GCN model whose message
function copies the source node feature, this will cause a whopping &lt;strong&gt;~500
times&lt;/strong&gt; memory consumption of the storage for the node features! It gets even
worse since the frequent memory access can bottleneck the computation, leading
to under-utilization of GPU device.&lt;/p&gt;

&lt;h1 id=&quot;fused-message-passing--no-explicit-messages&quot;&gt;Fused message passing == NO explicit messages&lt;/h1&gt;

&lt;p&gt;To avoid the overhead of materializing messages, we implement fused message
passing, i.e. combining the &lt;code class=&quot;highlighter-rouge&quot;&gt;send&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;recv&lt;/code&gt; into one operation
&lt;code class=&quot;highlighter-rouge&quot;&gt;send_and_recv&lt;/code&gt; (shown in following figure). Under the hood, the fused
&lt;code class=&quot;highlighter-rouge&quot;&gt;send_and_recv&lt;/code&gt; operation is implemented using a CUDA kernel in which each
thread loads the source node feature into the per-thread local memory, computes
a message, and directly aggregates it into the buffer for a given destination
node and immediately discards the message afterwards.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/0oMUTrZ.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To enable fused message passing, there are two challenges to be solved:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;How to fuse the user-defined functions &lt;script type=&quot;math/tex&quot;&gt;\phi^e&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;?&lt;/em&gt; In DGL, we
provide a set of pre-defined functions, called DGL built-ins, and let users
choose from them. This restricts the message and reduce functions to be used
for fused message passing, but we provide a variety of common functions so most
GNN models can be implemented. UDFs are still allowed, in which case DGL will
use basic message passing instead.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;How to backprop the gradient without explicit messages?&lt;/em&gt;  The trick is to
recompute the message during backward propagation, similar to the technique
used in &lt;a href=&quot;https://arxiv.org/abs/1604.06174&quot;&gt;training very deep NN models&lt;/a&gt;. In
practice, many &lt;script type=&quot;math/tex&quot;&gt;\phi^e&lt;/script&gt; do not require explicit messages to compute the
gradient (such as copying the node features as messages), and our
implementation leverages this optimization.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, we can re-write our earlier GCN implementation to use the built-in
&lt;code class=&quot;highlighter-rouge&quot;&gt;copy_src&lt;/code&gt; message function and &lt;code class=&quot;highlighter-rouge&quot;&gt;sum&lt;/code&gt; reduce function, as shown below.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.function&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fn&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# some graph&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# copy src feature 'h' as the message and sum it as new 'h'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.dgl.ai/tutorials/models/1_gnn/9_gat.html&quot;&gt;A Graph Attention Network
(GAT)&lt;/a&gt; can also be
implemented using the built-in &lt;code class=&quot;highlighter-rouge&quot;&gt;src_mul_edge&lt;/code&gt; message function and &lt;code class=&quot;highlighter-rouge&quot;&gt;sum&lt;/code&gt; reduce
function.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# the src features 'h' are weighted by the attention score 'e'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# on the edges and are summed as the new feature 'h'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src_mul_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;DGL v0.3 includes built-in functions that support the following combinations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The message function &lt;script type=&quot;math/tex&quot;&gt;\phi^e&lt;/script&gt; can be any one of add/sub/mul/div between two
given features among src, edge, dst.&lt;/li&gt;
  &lt;li&gt;Broadcasting is supported on the feature dimensions. For example, a
multi-head attention module where the node feature is of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;(NUM_HEADS,
NUM_FEATS)&lt;/code&gt; and the attention score is of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;(NUM_HEADS, 1)&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The reduce function &lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt; can be any one of sum/max/min/prod.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The rule of thumb is to &lt;strong&gt;use built-in functions as much as possible&lt;/strong&gt; so that
DGL can use fused message passing for better performance. We notice that this
might introduce some programming burden but the payoff is definitely worthy
(see next section for the evaluation results).&lt;/p&gt;

&lt;h1 id=&quot;convince-me-with-numbers&quot;&gt;Convince me with numbers&lt;/h1&gt;
&lt;p&gt;We compare with our v0.2 release to see how much we have improved the system.
In addition, we compare against PyG (Pytorch Geometric v1.2.0). PyG implements
basic message passing by first &lt;code class=&quot;highlighter-rouge&quot;&gt;gather&lt;/code&gt; node features as edge messages and then
&lt;code class=&quot;highlighter-rouge&quot;&gt;scatter&lt;/code&gt; them for message aggregation, which generates explicit messages.&lt;/p&gt;

&lt;p&gt;We benchmark both GCN and GAT models on several popular datasets following
their original settings. The testbed is one AWS p3.2xlarge instance with NVIDIA
V100 GPU (16GB memory).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dataset&lt;/th&gt;
      &lt;th&gt;#V&lt;/th&gt;
      &lt;th&gt;#E&lt;/th&gt;
      &lt;th&gt;Models&lt;/th&gt;
      &lt;th&gt;DGL(v0.2) Times(s)&lt;/th&gt;
      &lt;th&gt;PyG Time(s)&lt;/th&gt;
      &lt;th&gt;DGL(v0.3) Time(s)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Cora&lt;/td&gt;
      &lt;td&gt;3K&lt;/td&gt;
      &lt;td&gt;11K&lt;/td&gt;
      &lt;td&gt;GCN&lt;br /&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.685&lt;br /&gt;9.727&lt;/td&gt;
      &lt;td&gt;0.482&lt;br /&gt;1.248&lt;/td&gt;
      &lt;td&gt;0.619&lt;br /&gt;1.389&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Citeseer&lt;/td&gt;
      &lt;td&gt;3K&lt;/td&gt;
      &lt;td&gt;9K&lt;/td&gt;
      &lt;td&gt;GCN&lt;br /&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.670&lt;br /&gt;9.018&lt;/td&gt;
      &lt;td&gt;0.490&lt;br /&gt;1.254&lt;/td&gt;
      &lt;td&gt;0.631&lt;br /&gt;1.363&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pubmed&lt;/td&gt;
      &lt;td&gt;20K&lt;/td&gt;
      &lt;td&gt;889K&lt;/td&gt;
      &lt;td&gt;GCN&lt;br /&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.694&lt;br /&gt;26.186&lt;/td&gt;
      &lt;td&gt;0.485&lt;br /&gt;1.509&lt;/td&gt;
      &lt;td&gt;0.603&lt;br /&gt;1.381&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Reddit&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;232K&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;114M&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;GCN&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;OOM&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;OOM&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;25.30&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The up-coming release has huge performance boost especially on the GAT model
(&lt;strong&gt;19x&lt;/strong&gt;) faster thanks to the kernel fusion. Compared with PyG, for small
graphs (i.e, Cora, Citeseer and Pubmed), the computation and memory consumption
stay the same, relatively invariant to the graph sizes. In this regime, the
graph computation does not bottleneck the training and DGL has some slight,
constant overhead compared with PyG. However, when evaluating on a much larger
graph extracted from Reddit, PyG runs out of memory while DGL fits the graph
quite easily.&lt;/p&gt;

&lt;p&gt;We further perform some ablation studies using synthetic graphs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/8K3n5PU.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We first vary the number of nodes in the graph with fixed graph density
(0.0008), and test the training speed of GCN and GAT. DGL can train GCN on the
graph with up to 500K nodes, twice larger than PyG. PyG is also 3.4x slower
than DGL on the largest graph it can fits.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/VvI7xoc.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We then fix the number of nodes in the graph (32K), but vary the density of the
graph. The result clearly shows the advantage of fused message passing. For
both GCN and GAT, DGL can train on graphs with up to 8 times more edges and is
7.5x faster than PyG on the largest graph it can fits.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/awXc1mP.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We also vary the hidden layer size and compare the performance on a
median-sized graph (32K nodes with density 0.0008). For GCN, although PyG can
fit the largest hidden size we tested, it is 4x slower than DGL. For GAT, PyG
cannot train with hidden size of more than 32.&lt;/p&gt;

&lt;p&gt;Finally, we push the limit to see how large is the graph can be trained on one
machine with large CPU memory (AWS x1.32xlarge instance with 2TB memory).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;#Nodes&lt;/th&gt;
      &lt;th&gt;#Edges&lt;/th&gt;
      &lt;th&gt;Times(s)&lt;/th&gt;
      &lt;th&gt;Memory(GB)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;5M&lt;/td&gt;
      &lt;td&gt;250M&lt;/td&gt;
      &lt;td&gt;4.7&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50M&lt;/td&gt;
      &lt;td&gt;2.5B&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;500M&lt;/td&gt;
      &lt;td&gt;25B&lt;/td&gt;
      &lt;td&gt;505&lt;/td&gt;
      &lt;td&gt;740&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The result shows that DGL can train a GCN model on graphs with up to 500M nodes and 25B edges.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;The DGL team is very passionate about the bag of features to deliver on our
future agenda. As a matter of fact, many of these have been in our mind since
the intiation of the project. For example, the built-in functions have been our
priority the whole time but they only shine with the help of kernel fusion. To
shed some light on the directions we are working on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A detailed demo and tutorial on how to reproduce the large graph experiement in this post on a large CPU machine.&lt;/li&gt;
  &lt;li&gt;Support for heterogenous graph.&lt;/li&gt;
  &lt;li&gt;Accelerate graph traversal and querying using GPU.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DGL always stays close with our users and we greatly value your feedback! To
try out this new feature, simple as this: clone DGL’s repository, switch to
&lt;code class=&quot;highlighter-rouge&quot;&gt;kernel&lt;/code&gt; branch and build the library from source.&lt;/p&gt;

&lt;p&gt;Please stay tuned for our next major release! More good stuff coming soon.&lt;/p&gt;</content><author><name>Minjie Wang</name></author><category term="blog" /><category term="blog" /><summary type="html">In DGL’s first release last December, we focused on usability by introducing a set of carefully designed, easy-to-use APIs that support a variety of model implementations of Graph Neural Networks. We decided to keep DGL framework-agnostic to engage with users from different platforms (PyTorch, MXNet…). As a result, in our earlier releases, we largely leveraged the available functionalities provided by these frameworks, and based on many valuable feedback from our users, we are well-aware of the room of improvement particularly on some new models defined on the sparse and irregular graphs.</summary></entry><entry><title type="html">Understand Graph Attention Network</title><link href="https://www.dgl.ai/blog/2019/02/17/gat.html" rel="alternate" type="text/html" title="Understand Graph Attention Network" /><published>2019-02-17T00:00:00+00:00</published><updated>2019-02-17T00:00:00+00:00</updated><id>https://www.dgl.ai/blog/2019/02/17/gat</id><content type="html" xml:base="https://www.dgl.ai/blog/2019/02/17/gat.html">&lt;p&gt;From &lt;a href=&quot;https://arxiv.org/abs/1609.02907&quot;&gt;Graph Convolutional Network (GCN)&lt;/a&gt;, we
learned that combining local graph structure and node-level features yields
good performance on node classification task. However, the way GCN aggregates
is structure-dependent, which may hurt its generalizability.&lt;/p&gt;

&lt;p&gt;One workaround is to simply average over all neighbor node features as in
&lt;a href=&quot;https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf&quot;&gt;GraphSAGE&lt;/a&gt;.
&lt;a href=&quot;https://arxiv.org/abs/1710.10903&quot;&gt;Graph Attention Network&lt;/a&gt; proposes an
alternative way by weighting neighbor features with feature dependent and
structure free normalization, in the style of attention.&lt;/p&gt;

&lt;p&gt;The goal of this tutorial:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Explain what is Graph Attention Network.&lt;/li&gt;
  &lt;li&gt;Demonstrate how it can be implemented in DGL.&lt;/li&gt;
  &lt;li&gt;Understand the attentions learnt.&lt;/li&gt;
  &lt;li&gt;Introduce to inductive learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introducing-attention-to-gcn&quot;&gt;Introducing Attention to GCN&lt;/h2&gt;

&lt;p&gt;The key difference between GAT and GCN is how the information from the one-hop
neighborhood is aggregated.&lt;/p&gt;

&lt;p&gt;For GCN, a graph convolution operation produces the normalized sum of the node
features of neighbors:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_i^{(l+1)}=\sigma\left(\sum_{j\in \mathcal{N}(i)} {\frac{1}{c_{ij}} W^{(l)}h^{(l)}_j}\right),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(i)&lt;/script&gt; is the set of its one-hop neighbors (to include &lt;script type=&quot;math/tex&quot;&gt;v_i&lt;/script&gt; in
the set, simply add a self-loop to each node),
&lt;script type=&quot;math/tex&quot;&gt;c_{ij}=\sqrt{|\mathcal{N}(i)|}\sqrt{|\mathcal{N}(j)|}&lt;/script&gt; is a normalization
constant based on graph structure, &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; is an activation function (GCN uses
&lt;script type=&quot;math/tex&quot;&gt;\text{ReLU}&lt;/script&gt;), and &lt;script type=&quot;math/tex&quot;&gt;W^{(l)}&lt;/script&gt; is a shared weight matrix for node-wise feature
transformation. Another model proposed in
&lt;a href=&quot;https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf&quot;&gt;GraphSAGE&lt;/a&gt;
employs the same update rule except that they set &lt;script type=&quot;math/tex&quot;&gt;c_{ij}=|\mathcal{N}(i)|&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;GAT introduces the attention mechanism as a substitute for the statically
normalized convolution operation. Below are the equations to compute the node
embedding &lt;script type=&quot;math/tex&quot;&gt;h_i^{(l+1)}&lt;/script&gt; of layer &lt;script type=&quot;math/tex&quot;&gt;l+1&lt;/script&gt; from the embeddings of layer &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/gat.png&quot; alt=&quot;&quot; width=&quot;450x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
z_i^{(l)}&amp;=W^{(l)}h_i^{(l)},&amp;(1)\\
e_{ij}^{(l)}&amp;=\text{LeakyReLU}(\vec a^{(l)^T}(z_i^{(l)}\|z_j^{(l)})),&amp;(2)\\
\alpha_{ij}^{(l)}&amp;=\frac{\exp(e_{ij}^{(l)})}{\sum_{k\in \mathcal{N}(i)}^{}\exp(e_{ik}^{(l)})},&amp;(3)\\
h_i^{(l+1)}&amp;=\sigma\left(\sum_{j\in \mathcal{N}(i)} {\alpha^{(l)}_{ij} z^{(l)}_j }\right),&amp;(4)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Explanations:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Equation (1) is a linear transformation of the lower layer embedding
&lt;script type=&quot;math/tex&quot;&gt;h_i^{(l)}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;W^{(l)}&lt;/script&gt; is its learnable weight matrix.&lt;/li&gt;
  &lt;li&gt;Equation (2) computes a pair-wise &lt;em&gt;unnormalized&lt;/em&gt; attention score between two
neighbors. Here, it first concatenates the &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; embeddings of the two nodes,
where &lt;script type=&quot;math/tex&quot;&gt;\|&lt;/script&gt; denotes concatenation, then takes a dot product of it and a
learnable weight vector &lt;script type=&quot;math/tex&quot;&gt;\vec a^{(l)}&lt;/script&gt;, and applies a LeakyReLU in the end.
This form of attention is usually called &lt;em&gt;additive attention&lt;/em&gt;, contrast with
the dot-product attention in the Transformer model.&lt;/li&gt;
  &lt;li&gt;Equation (3) applies a softmax to normalize the attention scores on each
node’s in-coming edges.&lt;/li&gt;
  &lt;li&gt;Equation (4) is similar to GCN. The embeddings from neighbors are aggregated
together, scaled by the attention scores.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are other details from the paper, such as dropout and skip connections.
For the purpose of simplicity, we omit them in this tutorial and leave the link
to the full example at the end for interested readers.&lt;/p&gt;

&lt;p&gt;In its essence, GAT is just a different aggregation function with attention
over features of neighbors, instead of a simple mean aggregation.&lt;/p&gt;

&lt;h2 id=&quot;gat-in-dgl&quot;&gt;GAT in DGL&lt;/h2&gt;
&lt;p&gt;Let’s first have an overall impression about how a &lt;code class=&quot;highlighter-rouge&quot;&gt;GATLayer&lt;/code&gt; module is
implemented in DGL. Don’t worry, we will break down the four equations above
one-by-one.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (1)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (2)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;edge_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# edge UDF for equation (2)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaky_relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;message_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# message UDF for equation (3) &amp;amp; (4)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reduce_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# reduce UDF for equation (3) &amp;amp; (4)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (3)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mailbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (4)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mailbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (1)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (2)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (3) &amp;amp; (4)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;message_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;equation-1&quot;&gt;Equation (1)&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
z_i^{(l)}&amp;=W^{(l)}h_i^{(l)},&amp;(1)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;The first one is simple. Linear transformation is very common and can be easily
implemented in Pytorch using &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn.Linear&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;equation-2&quot;&gt;Equation (2)&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
e_{ij}^{(l)}&amp;=\text{LeakyReLU}(\vec a^{(l)^T}(z_i^{(l)}\|z_j^{(l)})),&amp;(2)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;The unnormalized attention score &lt;script type=&quot;math/tex&quot;&gt;e_{ij}&lt;/script&gt; is calculated using the embeddings of
adjacent nodes &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;. This suggests that the attention scores can be
viewed as edge data which can be calculated by the &lt;code class=&quot;highlighter-rouge&quot;&gt;apply_edges&lt;/code&gt; API. The
argument to the &lt;code class=&quot;highlighter-rouge&quot;&gt;apply_edges&lt;/code&gt; is an &lt;strong&gt;Edge UDF&lt;/strong&gt;, which is defined as below:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;edge_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# edge UDF for equation (2)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaky_relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Here, the dot product with the learnable weight vector &lt;script type=&quot;math/tex&quot;&gt;\vec a^{(l)}&lt;/script&gt; is
implemented again using pytorch’s linear transformation &lt;code class=&quot;highlighter-rouge&quot;&gt;attn_fc&lt;/code&gt;. Note that
&lt;code class=&quot;highlighter-rouge&quot;&gt;apply_edges&lt;/code&gt; will &lt;strong&gt;batch&lt;/strong&gt; all the edge data in one tensor, so the &lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt;,
&lt;code class=&quot;highlighter-rouge&quot;&gt;attn_fc&lt;/code&gt; here are applied on all the edges in parallel.&lt;/p&gt;

&lt;h3 id=&quot;equation-3--4&quot;&gt;Equation (3) &amp;amp; (4)&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\alpha_{ij}^{(l)}&amp;=\frac{\exp(e_{ij}^{(l)})}{\sum_{k\in \mathcal{N}(i)}^{}\exp(e_{ik}^{(l)})},&amp;(3)\\
h_i^{(l+1)}&amp;=\sigma\left(\sum_{j\in \mathcal{N}(i)} {\alpha^{(l)}_{ij} z^{(l)}_j }\right),&amp;(4)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Similar to GCN, &lt;code class=&quot;highlighter-rouge&quot;&gt;update_all&lt;/code&gt; API is used to trigger message passing on all the
nodes. The message function sends out two tensors: the transformed &lt;code class=&quot;highlighter-rouge&quot;&gt;z&lt;/code&gt;
embedding of the source node and the unnormalized attention score &lt;code class=&quot;highlighter-rouge&quot;&gt;e&lt;/code&gt; on each
edge. The reduce function then performs two tasks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Normalize the attention scores using softmax (equation (3)).&lt;/li&gt;
  &lt;li&gt;Aggregate neighbor embeddings weighted by the attention scores (equation(4)).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Both tasks first fetch data from the mailbox and then manipulate it on the
second dimension (&lt;code class=&quot;highlighter-rouge&quot;&gt;dim=1&lt;/code&gt;), on which the messages are batched.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reduce_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# reduce UDF for equation (3) &amp;amp; (4)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (3)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mailbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# equation (4)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mailbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;multi-head-attention&quot;&gt;Multi-head Attention&lt;/h3&gt;

&lt;p&gt;Analogous to multiple channels in ConvNet, GAT introduces &lt;strong&gt;multi-head
attention&lt;/strong&gt; to enrich the model capacity and to stabilize the learning process.
Each attention head has its own parameters and their outputs can be merged in
two ways:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{concatenation}: h^{(l+1)}_{i} =\|_{k=1}^{K}\sigma\left(\sum_{j\in \mathcal{N}(i)}\alpha_{ij}^{k}W^{k}h^{(l)}_{j}\right)&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{average}: h_{i}^{(l+1)}=\sigma\left(\frac{1}{K}\sum_{k=1}^{K}\sum_{j\in\mathcal{N}(i)}\alpha_{ij}^{k}W^{k}h^{(l)}_{j}\right)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; is the number of heads. The authors suggest using concatenation for
intermediary layers and average for the final layer.&lt;/p&gt;

&lt;p&gt;We can use the above defined single-head &lt;code class=&quot;highlighter-rouge&quot;&gt;GATLayer&lt;/code&gt; as the building block for
the &lt;code class=&quot;highlighter-rouge&quot;&gt;MultiHeadGATLayer&lt;/code&gt; below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadGATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cat'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MultiHeadGATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ModuleList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;head_outs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_head&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'cat'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# concat on the output feature dimension (dim=1)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head_outs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# merge using average&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head_outs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;put-everything-together&quot;&gt;Put everything together&lt;/h3&gt;

&lt;p&gt;Now, we can define a two-layer GAT model:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiHeadGATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Be aware that the input dimension is hidden_dim*num_heads since&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   multiple head outputs are concatenated together. Also, only&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;#   one attention head in the output layer.&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultiHeadGATLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We then load the cora dataset using DGL’s built-in data module.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DGLGraph&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;citation_graph&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;citegrh&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_cora_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;citegrh&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_cora&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ByteTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DGLGraph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The training loop is exactly the same as in the GCN tutorial.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_cora_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# create the model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
          &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
          &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
          &lt;span class=&quot;n&quot;&gt;out_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
          &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# create optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# main loop&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;t0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
    &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nll_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dur&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;visualizing-and-understanding-attention-learnt&quot;&gt;Visualizing and Understanding Attention Learnt&lt;/h2&gt;

&lt;h3 id=&quot;cora&quot;&gt;Cora&lt;/h3&gt;

&lt;p&gt;The following table summarizes the model performances on Cora reported in &lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;the
GAT paper&lt;/a&gt; and obtained with dgl
implementations.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Accuracy&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GCN (paper)&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;81.4\pm 0.5&lt;/script&gt;%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GCN (dgl)&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;82.05\pm 0.33&lt;/script&gt;%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GAT (paper)&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;83.0\pm 0.7&lt;/script&gt;%&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GAT (dgl)&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;83.69\pm 0.529&lt;/script&gt;%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;What kind of attention distribution has our model learnt?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Because the attention weight &lt;script type=&quot;math/tex&quot;&gt;a_{ij}&lt;/script&gt; is associated with edges, we can
visualize it by coloring edges. Below we pick a subgraph of Cora and plot the
attention weights of the last &lt;code class=&quot;highlighter-rouge&quot;&gt;GATLayer&lt;/code&gt;. The nodes are colored according to
their labels, whereas the edges are colored according to the magnitude of the
attention weights, which can be referred with the colorbar on the right.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/cora-attention.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can that the model seems to learn different attention weights. To
understand the distribution more thoroughly, we measure the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Entropy_(information_theory)&quot;&gt;entropy&lt;/a&gt; of the
attention distribution. For any node &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;,
&lt;script type=&quot;math/tex&quot;&gt;\{\alpha_{ij}\}_{j\in\mathcal{N}(i)}&lt;/script&gt; forms a discrete probability
distribution over all its neighbors with the entropy given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(\{\alpha_{ij}\}_{j\in\mathcal{N}(i)})=-\sum_{j\in\mathcal{N}(i)} \alpha_{ij}\log\alpha_{ij}&lt;/script&gt;

&lt;p&gt;Intuitively, a low entropy means a high degree of concentration, and vice
versa; an entropy of 0 means all attention is on one source node. The uniform
distribution has the highest entropy of &lt;script type=&quot;math/tex&quot;&gt;\log(\mathcal{N}(i))&lt;/script&gt;. Ideally, we
want to see the model learns a distribution of lower entropy (i.e, one or two
neighbors are much more important than the others).&lt;/p&gt;

&lt;p&gt;Note that since nodes can have different degrees, the maximum entropy will also
be different. Therefore, we plot the aggregated histogram of entropy values of
all nodes in the entire graph. Below are the attention histogram of learned by
each attention head.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/cora-attention-hist.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a reference, here is the histogram if all the nodes have uniform attention weight distribution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/cora-attention-uniform-hist.png&quot; alt=&quot;&quot; width=&quot;400x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One can see that &lt;strong&gt;the attention values learned is quite similar to uniform
distribution&lt;/strong&gt; (i.e, all neighbors are equally important). This partially
explains why the performance of GAT is close to that of GCN on Cora (according
to &lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;author’s reported result&lt;/a&gt;, the
accuracy difference averaged over &lt;script type=&quot;math/tex&quot;&gt;100&lt;/script&gt; runs is less than &lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;%); attention does
not matter since it does not differentiate much any ways.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Does that mean the attention mechanism is not useful?&lt;/em&gt; No! A different dataset
exhibits an entirely different pattern, as we show next.&lt;/p&gt;

&lt;h3 id=&quot;protein-protein-interaction-ppi-networks&quot;&gt;Protein-Protein Interaction (PPI) networks&lt;/h3&gt;

&lt;p&gt;The PPI dataset used here consists of &lt;script type=&quot;math/tex&quot;&gt;24&lt;/script&gt; graphs corresponding to different
human tissues. Nodes can have up to &lt;script type=&quot;math/tex&quot;&gt;121&lt;/script&gt; kinds of labels, so the label of node
is represented as a binary tensor of size &lt;script type=&quot;math/tex&quot;&gt;121&lt;/script&gt;. The task is to predict node
label.&lt;/p&gt;

&lt;p&gt;We use &lt;script type=&quot;math/tex&quot;&gt;20&lt;/script&gt; graphs for training, &lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt; for validation and &lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt; for test. The
average number of nodes per graph is &lt;script type=&quot;math/tex&quot;&gt;2372&lt;/script&gt;. Each node has &lt;script type=&quot;math/tex&quot;&gt;50&lt;/script&gt; features that
are composed of positional gene sets, motif gene sets and immunological
signatures. Critically, test graphs remain completely unobserved during
training, a setting called “inductive learning”.&lt;/p&gt;

&lt;p&gt;We compare the performance of GAT and GCN for &lt;script type=&quot;math/tex&quot;&gt;10&lt;/script&gt; random runs on this task and
use hyperparameter search on the validation set to find the best model.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;F1 Score(micro)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GAT&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;0.975 \pm 0.006&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;0.509 \pm 0.025&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Paper&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;0.973 \pm 0.002&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The table above is the result of this experiment, where we use micro &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F1
score&lt;/a&gt; to evaluate the model
performance.&lt;/p&gt;

&lt;p&gt;During training, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;BCEWithLogitsLoss&lt;/code&gt; as the loss function. The learning
curves of GAT and GCN are presented below; what is evident is the dramatic
performance adavantage of GAT over GCN.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/ppi-curve.png&quot; alt=&quot;ppi-curve&quot; width=&quot;500x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As before, we can have a statistical understanding of the attentions learnt by
showing the histogram plot for the node-wise attention entropy. Below are the
attention histogram learnt by different attention layers.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Attention learnt in layer 1:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/ppi-first-layer-hist.png&quot; alt=&quot;&quot; width=&quot;600px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Attention learnt in layer 2:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/ppi-second-layer-hist.png&quot; alt=&quot;&quot; width=&quot;600px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Attention learnt in final layer:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/ppi-final-layer-hist.png&quot; alt=&quot;&quot; width=&quot;600px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Again, comparing with uniform distribution:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/gat/ppi-uniform-hist.png&quot; alt=&quot;&quot; width=&quot;300px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Clearly, &lt;strong&gt;GAT does learn sharp attention weights&lt;/strong&gt;! There is a clear pattern
over the layers as well: &lt;strong&gt;the attention gets more sharper with higher layer&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Unlike the Cora dataset where GAT’s gain is lukewarm at best, for PPI there is
a significant performance gap between GAT and other GNN variants compared in
&lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;the GAT paper&lt;/a&gt; (at least &lt;script type=&quot;math/tex&quot;&gt;20&lt;/script&gt;%), and the
attention distributions between the two clearly differ. While this deserves
further research, one immediate conclusion is that GAT’s advantage lies perhaps
more in its ability to handle a graph with more complex neighborhood structure.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h2&gt;

&lt;p&gt;So far, we demonstrated how to use DGL to implement GAT. There are some missing
details such as dropout, skip connections and hyper-parameter tuning, which are
common practices and do not involve DGL-related concepts. We refer interested
readers to the full example.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;See the optimized full example
&lt;a href=&quot;https://github.com/dmlc/dgl/blob/master/examples/pytorch/gat/gat.py&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Stay tune for our next tutorial about how to speedup GAT models by
parallelizing multiple attention heads and SPMV optimization.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Hao Zhang</name></author><category term="blog" /><category term="blog" /><summary type="html">From Graph Convolutional Network (GCN), we learned that combining local graph structure and node-level features yields good performance on node classification task. However, the way GCN aggregates is structure-dependent, which may hurt its generalizability.</summary></entry><entry><title type="html">Batched Graph Classification with DGL</title><link href="https://www.dgl.ai/blog/2019/01/25/batch.html" rel="alternate" type="text/html" title="Batched Graph Classification with DGL" /><published>2019-01-25T00:00:00+00:00</published><updated>2019-01-25T00:00:00+00:00</updated><id>https://www.dgl.ai/blog/2019/01/25/batch</id><content type="html" xml:base="https://www.dgl.ai/blog/2019/01/25/batch.html">&lt;p&gt;Graph classification is an important problem
with applications across many fields – bioinformatics, chemoinformatics, social
network analysis, urban computing and cyber-security. Applying graph neural
networks to this problem has been a popular approach recently (&lt;a href=&quot;https://arxiv.org/abs/1806.08804&quot;&gt;Ying et al.,
2018&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1811.01287&quot;&gt;Cangea et al.,
2018&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1811.09595&quot;&gt;Knyazev et al.,
2018&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1901.01343&quot;&gt;Bianchi et al.,
2019&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1901.01484&quot;&gt;Liao et al.,
2019&lt;/a&gt;, &lt;a href=&quot;https://openreview.net/pdf?id=HJePRoAct7&quot;&gt;Gao et al.,
2019&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;This tutorial is a demonstration for&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;batching multiple graphs of variable size and shape with DGL&lt;/li&gt;
  &lt;li&gt;training a graph neural network for a simple graph classification task&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;simple-graph-classification-task&quot;&gt;Simple Graph Classification Task&lt;/h2&gt;
&lt;p&gt;In this tutorial, we will learn how to perform &lt;em&gt;batched&lt;/em&gt; graph classification
with DGL via a toy example of classifying 8 types of regular graphs as below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/dataset_overview.png&quot; alt=&quot;task&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We implement this &lt;a href=&quot;https://docs.dgl.ai/api/python/data.html&quot;&gt;Mini Graph Classification
Dataset&lt;/a&gt; in DGL. The dataset has 8
different types of graphs and each class has the same number of graph samples.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MiniGCDataset&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;networkx&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nx&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# a dataset with 80 samples, each graph is&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#  of size [10, 20]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MiniGCDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_networkx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Class:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2019-01-25-batch/001.png&quot; alt=&quot;sample&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;form-a-graph-mini-batch&quot;&gt;Form a graph mini-batch&lt;/h2&gt;

&lt;p&gt;To train neural networks more efficiently, a common practice is to &lt;strong&gt;batch&lt;/strong&gt;
multiple samples together to form a mini-batch. Batching fixed-shaped tensor
inputs is quite easy (for example, batching two images of size 28x28 gives a
tensor of shape 2x28x28). By contrast, batching graph inputs has two
challenges:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Graphs are sparse.&lt;/li&gt;
  &lt;li&gt;Graphs can have various length (e.g. number of nodes and eges).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To address this, DGL provides a &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.batch&lt;/code&gt; API. It leverages the trick that a
batch of graphs can be viewed as a large graph that have many disjoint
connected components. Below is a visualization that gives the general idea:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/batch.png&quot; alt=&quot;batch&quot; height=&quot;600px&quot; width=&quot;600px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For example, we can define the following &lt;code class=&quot;highlighter-rouge&quot;&gt;collate&lt;/code&gt; function to form a
mini-batch from a given list of graph and label pairs (as provided by the
&lt;code class=&quot;highlighter-rouge&quot;&gt;MiniGCDataset&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;collate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# The input `samples` is a list of pairs&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#  (graph, label).&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;graphs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batched_graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batched_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The return type of &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.batch&lt;/code&gt; is still a graph (similar to the fact that a
batch of tensors is still a tensor). This means that any code that works for
one graph immediately works for a batch of graphs. More importantly, since DGL
processes messages on all nodes and edges in parallel, this greatly improves
efficiency.&lt;/p&gt;

&lt;h2 id=&quot;graph-classifier&quot;&gt;Graph Classifier&lt;/h2&gt;

&lt;p&gt;The graph classification can be proceeded as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/graph_classifier.png&quot; alt=&quot;model&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From a batch of graphs, we first perform message passing/graph convolution for
nodes to “communicate” with others. After message passing, we compute a tensor
for graph representation from node (and edge) attributes. This step may be
called “readout/aggregation” interchangeably. Finally, the graph
representations are fed into a classifier to predict the graph labels.&lt;/p&gt;

&lt;h2 id=&quot;graph-convolution&quot;&gt;Graph Convolution&lt;/h2&gt;

&lt;p&gt;Our graph convolution operation is basically the same as that for GCN (checkout our
earlier &lt;a href=&quot;https://docs.dgl.ai/tutorials/models/1_gnn/1_gcn.html&quot;&gt;tutorial on GCN&lt;/a&gt;). The
only difference is that we replace &lt;script type=&quot;math/tex&quot;&gt;h_{v}^{(l+1)} =
\text{ReLU}\left(b^{(l)}+\sum_{u\in\mathcal{N}(v)}h_{u}^{(l)}W^{(l)}\right)&lt;/script&gt; by
&lt;script type=&quot;math/tex&quot;&gt;h_{v}^{(l+1)} =
\text{ReLU}\left(b^{(l)}+\frac{1}{|\mathcal{N}(v)|}\sum_{u\in\mathcal{N}(v)}h_{u}^{(l)}W^{(l)}\right)&lt;/script&gt;.
The replacement of summation by average is to balance nodes with different
degrees, which gives a better performance for this experiment.&lt;/p&gt;

&lt;p&gt;Note that the self edges added in the dataset initialization allows us to
include the original node feature &lt;script type=&quot;math/tex&quot;&gt;h_{v}^{(l)}&lt;/script&gt; when taking the average.
Below is the code snipplet to implement this GCN in DGL.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.function&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Sends a message of node feature h.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Take an average over all neighbor node features hu and use it to
    overwrite the original node feature.&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mailbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NodeApplyModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Update the node feature hv with ReLU(Whv+b).&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NodeApplyModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GCN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GCN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_mod&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NodeApplyModule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Initialize the node features with h. &lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feature&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;readout-and-classification&quot;&gt;Readout and Classification&lt;/h2&gt;

&lt;p&gt;For this demonstration, we consider initial node features to be their degrees.
After two rounds of graph convolution, we perform a graph readout by averaging
over all node features for each graph in the batch:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_g=\frac{1}{|\mathcal{V}|}\sum_{v\in\mathcal{V}}h_{v}&lt;/script&gt;

&lt;p&gt;In DGL, &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.mean_nodes(g)&lt;/code&gt; handles this task for a batch of graphs with
variable size. We then feed our graph representations into a classifier with
one linear layer followed by &lt;script type=&quot;math/tex&quot;&gt;\text{sigmoid}&lt;/script&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GCN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GCN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classify&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# For undirected graphs, in_degree is the same as&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# out_degree.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_degrees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;setup-and-training&quot;&gt;Setup and Training&lt;/h2&gt;

&lt;p&gt;We create a synthetic dataset of 1000 graphs with 10 - 20 nodes.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MiniGCDataset&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Create training and testing set.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MiniGCDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MiniGCDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Use pytorch's DataLoader and the collate function&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# defined before.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Create model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;epoch_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epoch {}, loss {:.4f}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_losses&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The learning curve of a run is presented below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2019-01-25-batch/002.png&quot; alt=&quot;curve&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On our test set with the trained classifier, the accuracy of sampled
predictions varies across random runs between 78% ~ 85%. The argmax
accuracy is typically higher and can reach up to 91%.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Convert a list of tuples to two lists&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_bg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;probs_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_bg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sampled_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multinomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probs_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;argmax_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probs_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Accuracy of sampled predictions on the test set: {:.4f}&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sampled_Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Accuracy of argmax predictions on the test set: {:4f}&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argmax_Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Below is an animation where we plot graphs with the probability a trained model
assigns its ground truth label to it:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/test_eval4.gif&quot; alt=&quot;anim&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To understand how the node/graph features change over layers with a trained
model, we use &lt;a href=&quot;https://lvdmaaten.github.io/tsne/&quot;&gt;t-SNE&lt;/a&gt; for dimensionality
reduction and visualization.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/tsne_node2.png&quot; alt=&quot;&quot; height=&quot;600px&quot; width=&quot;800px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/tsne_graph2.png&quot; alt=&quot;&quot; height=&quot;600px&quot; width=&quot;800px&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The two small figures on the top separately visualize node features after ,
graph convolution layer #1 and #2, and the figure on the bottom visualizes the
pre-softmax logits for graphs. As you can see, the node embeddings of different
types of graphs are more separable in the higher layer and the lower layer. Finally,
the embeddings of different types of graphs are well-separated.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h2&gt;

&lt;p&gt;Download the full tutorial code and jupyter notebook &lt;a href=&quot;https://docs.dgl.ai/tutorials/basics/4_batch.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Graph classification with graph neural networks is still a very young field
waiting for folks to bring more exciting discoveries! It is not easy as it
requires mapping different graphs to different embeddings while preserving
their structural similarity in the embedding space. To learn more about it,
&lt;a href=&quot;https://arxiv.org/abs/1810.00826&quot;&gt;“How Powerful Are Graph Neural
Networks?”&lt;/a&gt; in ICLR 2019 might be a good
starting point.&lt;/p&gt;

&lt;p&gt;With regards to more examples on batched graph processing, see:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;our tutorials on &lt;a href=&quot;https://docs.dgl.ai/tutorials/models/2_small_graph/3_tree-lstm.html&quot;&gt;Tree LSTM&lt;/a&gt;
and &lt;a href=&quot;https://docs.dgl.ai/tutorials/models/3_generative_model/5_dgmg.html&quot;&gt;Deep Generative Models of Graphs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;an example implementation of &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/jtnn&quot;&gt;Junction Tree
VAE&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Mufei Li</name></author><category term="blog" /><category term="blog" /><summary type="html">Graph classification is an important problem with applications across many fields – bioinformatics, chemoinformatics, social network analysis, urban computing and cyber-security. Applying graph neural networks to this problem has been a popular approach recently (Ying et al., 2018, Cangea et al., 2018, Knyazev et al., 2018, Bianchi et al., 2019, Liao et al., 2019, Gao et al., 2019).</summary></entry></feed>