<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="https://www.dgl.ai/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.dgl.ai/" rel="alternate" type="text/html" /><updated>2021-07-07T16:39:43+08:00</updated><id>https://www.dgl.ai/feed.xml</id><title type="html">Deep Graph Library</title><subtitle>Easy Deep Learning on Graphs</subtitle><entry><title type="html">v0.6 Release Highlight</title><link href="https://www.dgl.ai/release/2021/02/25/release.html" rel="alternate" type="text/html" title="v0.6 Release Highlight" /><published>2021-02-25T00:00:00+08:00</published><updated>2021-02-25T00:00:00+08:00</updated><id>https://www.dgl.ai/release/2021/02/25/release</id><content type="html" xml:base="https://www.dgl.ai/release/2021/02/25/release.html">&lt;p&gt;The recent DGL 0.6 release is a major update on many aspects of the project
including documentation, APIs, system speed, and scalability. This article
highlights some of the new features and enhancements.&lt;/p&gt;

&lt;h2 id=&quot;a-blitz-introduction-to-dgl-in-120-minutes&quot;&gt;A Blitz Introduction to DGL in 120 minutes&lt;/h2&gt;

&lt;p&gt;The brand new set of tutorials come from our past hands-on tutorials in several
major academic conferences (e.g., KDD’19, KDD’20, WWW’20). They start from an
end-to-end example of using GNNs for node classification, and gradually unveil
the core components in DGL such as DGLGraph, GNN modules, and graph datasets.
The tutorials are now available on &lt;a href=&quot;https://docs.dgl.ai/tutorials/blitz/index.html&quot;&gt;docs.dgl.ai&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2021-02-25-release/blitz-intro.png&quot; alt=&quot;blitz&quot; width=&quot;800x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-gentle-tutorial-on-mini-batch-training-of-gnns&quot;&gt;A Gentle Tutorial on Mini-batch Training of GNNs&lt;/h2&gt;

&lt;p&gt;The scale of real world data can be massive, which demands training GNNs
stochastically by mini-batches. However, unlike images or text corpus where
data samples are independent, stochastic training of GNNs is more complex
because one must handle the dependencies among samples. We observed that
stochastic training is one of the most-asked topics on our discuss forum. In
0.6, we summarize the answers to those common questions in a set of
&lt;a href=&quot;https://docs.dgl.ai/tutorials/large/index.html&quot;&gt;tutorials&lt;/a&gt; on stochastic
training of GNNs, including the insight into neighbor sampling algorithms,
training loops and code snippets in DGL to realize them.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://data.dgl.ai/tutorial/img/sampling.gif&quot; alt=&quot;sampling&quot; width=&quot;800x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;more-examples&quot;&gt;More Examples&lt;/h2&gt;

&lt;p&gt;The release includes &lt;strong&gt;13 new examples&lt;/strong&gt;, brings &lt;strong&gt;a total of 72 models&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/mixhop&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/mixhop&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Self-Attention Graph Pooling: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/sagpool]&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/sagpool&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/GNN-FiLM&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/GNN-FiLM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;TensorFlow implementation of Simplifying Graph Convolutional Networks: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/tensorflow/sgc&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/tensorflow/sgc&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Graph Representation Learning via Hard and Channel-Wise Attention Networks: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/hardgat&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/hardgat&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Graph Random Neural Network for Semi-Supervised Learning on Graphs: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/grand&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/grand&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Hierarchical Graph Pooling with Structure Learning: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/hgp_sl&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/hgp_sl&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Towards Deeper Graph Neural Networks: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/dagnn&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/dagnn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation/PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space (part segmentation): &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/pointcloud/pointnet&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/pointcloud/pointnet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Graph Cross Networks with Vertex Infomax Pooling: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/gxn&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/gxn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Neural Graph Collaborative Filtering: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/NGCF&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/NGCF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Link Prediction Based on Graph Neural Networks: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/seal&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/seal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Graph Neural Networks with Convolutional ARMA Filters: &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/arma&quot;&gt;https://github.com/dmlc/dgl/tree/master/examples/pytorch/arma&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples&quot;&gt;official example folder&lt;/a&gt; now indexes the examples by their notable tags such as their targeted tasks and so on.&lt;/p&gt;

&lt;h2 id=&quot;usability-enhancements&quot;&gt;Usability Enhancements&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Two new APIs &lt;a href=&quot;https://docs.dgl.ai/generated/dgl.DGLGraph.set_batch_num_nodes.html#dgl.DGLGraph.set_batch_num_nodes&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.set_batch_num_nodes&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://docs.dgl.ai/generated/dgl.DGLGraph.set_batch_num_edges.html#dgl.DGLGraph.set_batch_num_edges&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.set_batch_num_edges&lt;/code&gt;&lt;/a&gt; for setting batch information manually, which are useful for transforming a batched graph into another or constructing a new batched graph manually.&lt;/li&gt;
  &lt;li&gt;A new API &lt;a href=&quot;https://docs.dgl.ai/api/python/dgl.dataloading.html#dgl.dataloading.pytorch.GraphDataLoader&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GraphDataLoader&lt;/code&gt;&lt;/a&gt;, a data loader wrapper for graph classification tasks.&lt;/li&gt;
  &lt;li&gt;A new dataset class &lt;a href=&quot;https://docs.dgl.ai/api/python/dgl.data.html#qm9-dataset&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;QM9Dataset&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;A new namespace &lt;a href=&quot;https://docs.dgl.ai/api/python/nn.functional.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.functional&lt;/code&gt;&lt;/a&gt; for hosting NN related utility functions.&lt;/li&gt;
  &lt;li&gt;DGL now supports training with half precision and is compatible with PyTorch’s automatic mixed precision package. See the &lt;a href=&quot;https://docs.dgl.ai/guide/mixed_precision.html&quot;&gt;user guide chapter&lt;/a&gt; for how to use it.&lt;/li&gt;
  &lt;li&gt;(Experimental) Users can now use DistGraph with heterogeneous graph data. This also applies to &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.sample_neighbors&lt;/code&gt; on DistGraph. In addition, DGL supports distributed graph partitioning on a cluster of machines. See the &lt;a href=&quot;https://docs.dgl.ai/guide/distributed.html&quot;&gt;user guide chapter&lt;/a&gt; for more details.&lt;/li&gt;
  &lt;li&gt;(Experimental) Several new APIs for training sparse embeddings:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://docs.dgl.ai/api/python/nn.pytorch.html#nodeembedding-module&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.NodeEmbedding&lt;/code&gt;&lt;/a&gt; is a dedicated class for storing trainable node embeddings that can scale to graphs with millions of nodes.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://docs.dgl.ai/api/python/dgl.optim.html#dgl.optim.pytorch.SparseAdagrad&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.optim.SparseAdagrad&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://docs.dgl.ai/api/python/dgl.optim.html#dgl.optim.pytorch.SparseAdam&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.optim.SparseAdam&lt;/code&gt;&lt;/a&gt; are two optimizers for the NodeEmbedding class.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;system-efficiency-improvements&quot;&gt;System Efficiency Improvements&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;With PyTorch backend, DGL will use PyTorch’s native memory management to cache repeated memory allocation and deallocation.&lt;/li&gt;
  &lt;li&gt;A new implementation for &lt;code class=&quot;highlighter-rouge&quot;&gt;nn.RelGraphConv&lt;/code&gt; when &lt;code class=&quot;highlighter-rouge&quot;&gt;low_mem=True&lt;/code&gt; (PyTorch backend). A benchmark on V100 GPU shows it gives a &lt;strong&gt;4.8x&lt;/strong&gt; boost in training speed on AIFB dataset.&lt;/li&gt;
  &lt;li&gt;Faster CPU kernels using AVX512 instructions.&lt;/li&gt;
  &lt;li&gt;Faster GPU kernels on CUDA 11.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;further-readings&quot;&gt;Further Readings&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Full release note: &lt;a href=&quot;https://github.com/dmlc/dgl/releases/tag/v0.6.0&quot;&gt;https://github.com/dmlc/dgl/releases/tag/v0.6.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">The recent DGL 0.6 release is a major update on many aspects of the project including documentation, APIs, system speed, and scalability. This article highlights some of the new features and enhancements.</summary></entry><entry><title type="html">DGL Empowers Service for Predictions on Connected Datasets with Graph Neural Networks</title><link href="https://www.dgl.ai/news/2020/12/15/neptuneml.html" rel="alternate" type="text/html" title="DGL Empowers Service for Predictions on Connected Datasets with Graph Neural Networks" /><published>2020-12-15T00:00:00+08:00</published><updated>2020-12-15T00:00:00+08:00</updated><id>https://www.dgl.ai/news/2020/12/15/neptuneml</id><content type="html" xml:base="https://www.dgl.ai/news/2020/12/15/neptuneml.html">&lt;p&gt;AWS just announced the availability of &lt;a href=&quot;http://aws.amazon.com/neptune/machine-learning/&quot;&gt;Neptune ML&lt;/a&gt;.
Amazon Neptune is a fast,
reliable, fully managed graph database service that makes it easy to build and
run applications that work with highly connected datasets. Neptune ML is a new
capability that uses graph neural networks (GNNs), a machine learning (ML)
technique purpose-built for graphs, for making easy, fast, and accurate
predictions on graphs. The accuracy of most predictions for graphs increases to
50% with Neptune ML when compared to non-graph methods. Neptune ML uses the
Deep Graph Library (DGL), an open-source library to which AWS contributes that
makes it easy to develop and apply GNN models on graph data. Now, developers
can create, train, and apply ML on Neptune data in hours instead of weeks
without the need to learn new tools and ML technologies.&lt;/p&gt;

&lt;p&gt;We would love to see more commercial vendors build innovation on top of DGL in
the future. For more information about Neptune ML, please visit the &lt;a href=&quot;https://aws.amazon.com/blogs/database/announcing-amazon-neptune-ml-easy-fast-and-accurate-predictions-on-graphs/&quot;&gt;AWS blog&lt;/a&gt;
and &lt;a href=&quot;https://aws.amazon.com/neptune/machine-learning/&quot;&gt;product page&lt;/a&gt;. Watch the
&lt;a href=&quot;https://reinvent.awsevents.com/keynotes/&quot;&gt;re:Invent 2020 Machine Learning Keynote&lt;/a&gt;
by Swami Sivasubramanian for the full announcement.&lt;/p&gt;</content><author><name>DGLTeam</name></author><category term="news" /><category term="news" /><summary type="html">AWS just announced the availability of Neptune ML. Amazon Neptune is a fast, reliable, fully managed graph database service that makes it easy to build and run applications that work with highly connected datasets. Neptune ML is a new capability that uses graph neural networks (GNNs), a machine learning (ML) technique purpose-built for graphs, for making easy, fast, and accurate predictions on graphs. The accuracy of most predictions for graphs increases to 50% with Neptune ML when compared to non-graph methods. Neptune ML uses the Deep Graph Library (DGL), an open-source library to which AWS contributes that makes it easy to develop and apply GNN models on graph data. Now, developers can create, train, and apply ML on Neptune data in hours instead of weeks without the need to learn new tools and ML technologies.</summary></entry><entry><title type="html">v0.5.3 Patch Update</title><link href="https://www.dgl.ai/release/2020/12/04/release.html" rel="alternate" type="text/html" title="v0.5.3 Patch Update" /><published>2020-12-04T00:00:00+08:00</published><updated>2020-12-04T00:00:00+08:00</updated><id>https://www.dgl.ai/release/2020/12/04/release</id><content type="html" xml:base="https://www.dgl.ai/release/2020/12/04/release.html">&lt;p&gt;This is a patch release mainly for supporting CUDA 11.0.  Now DGL supports CUDA 11.0 and PyTorch 1.7 on Linux/Windows/Mac.&lt;/p&gt;

&lt;p&gt;Other fixes include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Performance fix of graph batching. Affect the &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.batch&lt;/code&gt; API.&lt;/li&gt;
  &lt;li&gt;Speedup on graph readout. Affect &lt;a href=&quot;https://docs.dgl.ai/api/python/dgl.html#batching-and-reading-out-ops&quot;&gt;all APIs&lt;/a&gt; under &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.readout&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Speedup in CPU SpMM with sum reducer.&lt;/li&gt;
  &lt;li&gt;Performance optimization that removes redundant copies between CPU and GPU.&lt;/li&gt;
  &lt;li&gt;Fix &lt;code class=&quot;highlighter-rouge&quot;&gt;segment_reduce()&lt;/code&gt; ignoring tailing 0 segments.&lt;/li&gt;
  &lt;li&gt;Fix a crash bug due to unfound attribute.&lt;/li&gt;
  &lt;li&gt;Performance optimization in COO-CSR conversion.&lt;/li&gt;
  &lt;li&gt;Parallelization in heterogeneous graph format conversion.&lt;/li&gt;
  &lt;li&gt;Fix a bug to enable distributed training of RGCN with CPU.&lt;/li&gt;
  &lt;li&gt;Numerous documentation fixes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;New examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sparse embedding for GATNE-T for large graphs.&lt;/li&gt;
  &lt;li&gt;LINE.&lt;/li&gt;
  &lt;li&gt;SIGN for OGB.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Chinese user guide has been released for chapter 1 to 4. Further chapters will be released soon.&lt;/p&gt;

&lt;p&gt;Full release note: &lt;a href=&quot;https://github.com/dmlc/dgl/releases/tag/0.5.3&quot;&gt;https://github.com/dmlc/dgl/releases/tag/0.5.3&lt;/a&gt;&lt;/p&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">This is a patch release mainly for supporting CUDA 11.0. Now DGL supports CUDA 11.0 and PyTorch 1.7 on Linux/Windows/Mac.</summary></entry><entry><title type="html">What is new in DGL v0.5 release?</title><link href="https://www.dgl.ai/release/2020/08/26/release.html" rel="alternate" type="text/html" title="What is new in DGL v0.5 release?" /><published>2020-08-26T00:00:00+08:00</published><updated>2020-08-26T00:00:00+08:00</updated><id>https://www.dgl.ai/release/2020/08/26/release</id><content type="html" xml:base="https://www.dgl.ai/release/2020/08/26/release.html">&lt;p&gt;The recent DGL 0.5 release is a major update on many aspects of the project
including documentation, APIs, system speed and scalability. This article
highlights some of the new features and enhancements.&lt;/p&gt;

&lt;h2 id=&quot;more-docs-fewer-codes&quot;&gt;More docs, fewer codes&lt;/h2&gt;

&lt;p&gt;DGL has been through several releases with numerous new APIs and
features. While the development pace is rapid, DGL’s documentation has
been lagging behind. We have been aware of this issue and finally got a hand on
it in this release. There are two major changes. A new
&lt;a href=&quot;https://docs.dgl.ai/en/0.5.x/guide/index.html&quot;&gt;user guide&lt;/a&gt; with dedicated chapters for the
core concepts of DGL and how they connect with the pipeline of training/testing
GNNs. There are currently seven chapters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Graph&lt;/em&gt;: The chapter explains the basics about the graph data structure, the
usage of the core &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; class, heterogeneous graph and so on.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Message Passing&lt;/em&gt;: The chapter starts from the mathematical definition of the
message passing neural networks and then explains how to express them in DGL.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Building GNN Modules&lt;/em&gt;: The chapter walk-throughs the steps to define GNN
layers/modules in DGL for both homogeneous and heterogeneous graphs.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Graph Data Pipeline&lt;/em&gt;: The chapter explains how the datasets are organized in
DGL and how to create with your own one.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Training Graph Neural Networks&lt;/em&gt;: The chapter provides guidance on training
GNNs in DGL for node, edge and graph prediction tasks.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Stochastic Training on Large Graphs&lt;/em&gt;: The chapter introduces
mini-batch training in the GNN domain and the designated DGL APIs.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Distributed Training&lt;/em&gt;: The chapter explains DGL’s components for training
graphs scaling beyond one machine.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Besides the user guide, we have re-worked the API document extensively and
organized them by their namespaces. We also took this chance to prune the set
of API, deprecate rare and redundant APIs and consolidate functionalities into
fewer. For example, the creation of a graph in DGL now only involves &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.graph&lt;/code&gt;
and &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.heterograph&lt;/code&gt; for homogeneous and heterogeneous graphs, respectively.
Another noticeable simplification is that &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; is now the only class for
storing graph and feature. It can represent a homogeneous or heterogeneous
graph, a subgraph or a batched graph.&lt;/p&gt;

&lt;h2 id=&quot;more-flexibility-on-dglgraph&quot;&gt;More flexibility on &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The 0.5 release enables more flexibility on the core graph structure. First, DGL
now supports creating graphs stored in int32; it not only cuts the memory
consumption by half compared with int64, but also enables many fast operators
only available for int32 provided by cuSPARSE. Second, previous DGL only
provides APIs to control the host device of node/edge features,  while in the new
version, it allows changing the host device of the graph structure too (via
&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.to&lt;/code&gt;). DGL has implemented many structure-related operators such as
getting degrees, extracting subgraphs on CUDA. Third, to store giant graphs even
more compactly, DGL adds the &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph.formats&lt;/code&gt; API to control the internal
sparse formats of graphs. This could reduce the memory
consumption by half or more especially for storing the graph for sampling
in mini-batch training. You can find the explanations of all these new features in
the dedicated &lt;a href=&quot;https://docs.dgl.ai/guide/graph.html&quot;&gt;user guide chapter&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;faster-and-deterministic-kernels&quot;&gt;Faster and deterministic kernels&lt;/h2&gt;

&lt;p&gt;Alongside the usability improvement, the DGL team always keeps system
performance at heart. We have conducted an extensive code refactoring during
this release to reduce the Python stack overhead and enhance the code
readability. In addition, we upgrade the core CPU/GPU kernels for message
passing computation. Specifically, we found that the message passing in GNNs
can be reduced to two general computational patterns: g-SpMM and g-SDDMM. The
two patterns have a number of choices of parallelization and DGL carefully
chooses the suitable ones based on the sparse format and operator type.
Moreover, DGL by default chooses deterministic implementations for a better
reproducibility. Read the updated &lt;a href=&quot;https://arxiv.org/abs/1909.01315&quot;&gt;white paper&lt;/a&gt;
for more details about the new kernel design.&lt;/p&gt;

&lt;h2 id=&quot;scaling-beyond-one-machine&quot;&gt;Scaling beyond one machine&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Can DGL scale to giant graphs that cannot be fit in one machine?&lt;/em&gt; This question
has been on our watch from the genesis of the DGL project. Despite several
attempts from the previous releases, 0.5 is the very first release that
thoroughly defines the user-facing APIs and components for distributed
training. The goal is to create a coherent user experience of mini-batch
training from on a single machine to multiple machines, ideally with few or no
code changes. Specifically, this release includes the following new components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To split a graph for distributed computation, DGL integrates a light-weight
version of the highly-optimized METIS &lt;em&gt;*graph partition&lt;/em&gt; toolkit.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DistGraphServer&lt;/strong&gt; stores the partitioned graph structure and node/edge
features on each machine. These servers work together to serve the graph data
to training processes. One can deploy multiple servers on one machine to boost
the service throughput.&lt;/li&gt;
  &lt;li&gt;New &lt;strong&gt;distributed sampler&lt;/strong&gt; that interacts with remote servers and supports
sampling from partitioned graph.&lt;/li&gt;
  &lt;li&gt;For training processes, DGL provides the &lt;strong&gt;DistGraph&lt;/strong&gt;, &lt;strong&gt;DistTensor&lt;/strong&gt; and
&lt;strong&gt;DistEmbedding&lt;/strong&gt; abstractions for accessing graph structures, node/edge
features and embeddings stored remotely. There is also a convenient
&lt;strong&gt;DistDataLoader&lt;/strong&gt; to get mini-batches from the distributed sampler.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DGL has performed several optimizations within the entire stack. For example,
when the sampler and target server are located in the same machine, they can
communicate with each other through the local shared-memory, instead of using
IPC or TCP/IP communication. More optimizations are coming in the future
releases. To get started, check out the &lt;a href=&quot;https://docs.dgl.ai/guide/distributed.html&quot;&gt;user guide chapter&lt;/a&gt; for distributed
training and examples for training &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/graphsage/experimental&quot;&gt;GraphSAGE&lt;/a&gt;
and &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn/experimental&quot;&gt;RGCN&lt;/a&gt;
on the ogbn-paper100M dataset.&lt;/p&gt;

&lt;h2 id=&quot;further-readings&quot;&gt;Further readings&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Our updated white paper available at: &lt;a href=&quot;https://arxiv.org/abs/1909.01315&quot;&gt;https://arxiv.org/abs/1909.01315&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Release note: &lt;a href=&quot;https://github.com/dmlc/dgl/releases/tag/0.5.0&quot;&gt;https://github.com/dmlc/dgl/releases/tag/0.5.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">The recent DGL 0.5 release is a major update on many aspects of the project including documentation, APIs, system speed and scalability. This article highlights some of the new features and enhancements.</summary></entry><entry><title type="html">Fighting COVID-19 with Deep Graph</title><link href="https://www.dgl.ai/news/2020/06/09/covid.html" rel="alternate" type="text/html" title="Fighting COVID-19 with Deep Graph" /><published>2020-06-09T00:00:00+08:00</published><updated>2020-06-09T00:00:00+08:00</updated><id>https://www.dgl.ai/news/2020/06/09/covid</id><content type="html" xml:base="https://www.dgl.ai/news/2020/06/09/covid.html">&lt;p&gt;Since December 2019, the rapid spread of COVID-19 corona-viruses worldwide has
caused more than 7 million infections and more than 400,000 deaths. The rapid
spread of COVID-19 demonstrates the dire need for quick and effective drug
discovery. Drug repurposing is a drug discovery paradigm that uses existing
drugs for new therapeutic indications. It has the advantages of significantly
reducing time and cost relative to de novo drug discovery. Drug repurposing
with knowledge graphs presents a promising strategy for COVID-19 treatment.&lt;/p&gt;

&lt;p&gt;A team of AWS scientists from Amazon Shanghai AI Lab and AWS Deep Engine
Science team working along with academic collaborators from the University of
Minnesota, The Ohio State University, and Hunan University have created the
&lt;strong&gt;Drug Repurposing Knowledge Graph (DRKG)&lt;/strong&gt; and a set of machine learning tools
that can be used to prioritize drugs for repurposing studies. DRKG and the ML
tools are open sourced in github to help researchers conduct drug relocation
research on COVID-19 and other diseases (such as Alzheimer’s disease).&lt;/p&gt;

&lt;p&gt;DRKG is a comprehensive biological knowledge graph that relates human genes,
compounds, biological processes, drug side effects, diseases and symptoms. DRKG
includes, curates, and normalizes information from six publicly available
databases and data that were collected from recent publications related to
Covid-19. It has 97,238 entities belonging to 13 types of entities, and
5,874,261 triplets belonging to 107 types of relations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2020-06-09-drkg/drkg.png&quot; alt=&quot;drkg&quot; width=&quot;800x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
&lt;center&gt;
&lt;i&gt;The high-level structure of DRKG. Numerals indicate the number of different
types of relationships between classes of entities; terms between parentheses
are examples of those relationships.&lt;/i&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;p&gt;The machine learning tools use DGL-KE to learn low dimension embedding
representations of entities and relations in DRKG. The resulting embeddings are
used to predict how likely a drug can treat a disease or how likely a drug can
bind to a protein associated with the disease. &lt;a href=&quot;https://github.com/awslabs/dgl-ke&quot;&gt;DGL-KE&lt;/a&gt; is a high performance,
easy-to-use, and scalable package for learning large-scale knowledge graph
embeddings developed by Amazon Shanghai AI Lab. The package is implemented on
the top of Deep Graph Library (DGL) and developers can run DGL-KE on CPU
machine, GPU machine, as well as clusters with a set of popular models,
including TransE, DistMult, ComplEx, RotatE and etc. It can train a knowledge
graph consisting of over &lt;em&gt;86M&lt;/em&gt; nodes and &lt;em&gt;338M&lt;/em&gt; edges in 100 minutes on an EC2
instance with 8 GPUs and 30 minutes on an EC2 cluster with 4 machines.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2020-06-09-drkg/dgl-ke.png&quot; alt=&quot;dglke&quot; width=&quot;400x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DRKG github repository provides examples on using DGL-KE to &lt;a href=&quot;https://github.com/gnn4dr/DRKG/blob/master/embedding_analysis/Train_embeddings.ipynb&quot;&gt;learn low
dimension embedding representations of entities and relations in
DRKG&lt;/a&gt;
and using pre-trained knowledge graph embedding of DRKG to do &lt;a href=&quot;https://github.com/gnn4dr/DRKG/blob/master/drug_repurpose/COVID-19_drug_repurposing.ipynb&quot;&gt;drug
repurposing&lt;/a&gt;.
Preliminary experimental results show that using certain machine learning tools
for COVID-19 drug discovery can identify a variety of drugs currently in
clinical trials with high ranking scores.&lt;/p&gt;

&lt;h2 id=&quot;use-dgl-ke-to-learn-low-dimension-embedding-representations-of-entities-and-relations-in-drkg&quot;&gt;Use DGL-KE to Learn Low Dimension Embedding Representations of Entities and Relations in DRKG&lt;/h2&gt;

&lt;p&gt;DRKG uses DGL-KE to learn knowledge graph embedding&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Step 1:&lt;/em&gt; Downloading DRKG from &lt;a href=&quot;https://dgl-data.s3-us-west-2.amazonaws.com/dataset/DRKG/drkg.tar.gz&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Step 2:&lt;/em&gt; Load DRKG as follows.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'../utils'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download_and_extract&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;download_and_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;drkg_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'../data/drkg/drkg.tsv'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 3:&lt;/em&gt; DRKG data package has a drkg.tsv file containing all triplets in the
knowledge graph. Before training, We randomly divide the data set into training
set, validation set and test set according to the ratio of 0.9:0.05:0.05.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drkg_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_triples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_triples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;valid_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;valid_cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;train/drkg_train.tsv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writelines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
      
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;train/drkg_valid.tsv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writelines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;train/drkg_test.tsv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writelines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 4:&lt;/em&gt; Then we directly invoke the command line toolkit provided by DGL-KE
to learn low dimension embedding representations of entities and relations in
DRKG. Here we choose the &lt;code class=&quot;highlighter-rouge&quot;&gt;TransE_l2&lt;/code&gt; model and use an AWS p3.16xlarge instance to
train the model with multi-GPU in parallel. To use other KGE model or AWS
instances please refer to DGL-KE’s &lt;a href=&quot;https://aws-dglke.readthedocs.io/en/latest/index.html&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;DGLBACKEND&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;pytorch dglke_train --dataset DRKG --data_path ./train &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --data_files drkg_train.tsv drkg_valid.tsv drkg_test.tsv &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --format &lt;span class=&quot;s1&quot;&gt;'raw_udd_hrt'&lt;/span&gt; --model_name TransE_l2 --batch_size 2048 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --neg_sample_size 256 --hidden_dim 400 --gamma 12.0 --lr 0.1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --max_step 100000 --log_interval 1000 --batch_size_eval 16 -adv &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --regularization_coef 1.00E-07 --test --num_thread 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --gpu 0 1 2 3 4 5 6 7 --num_proc 8 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
                               --neg_sample_size_eval 10000 --async_update
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 5:&lt;/em&gt; After training, two files are generated: 1)
&lt;code class=&quot;highlighter-rouge&quot;&gt;DRKG_TransE_l2_entity.npy&lt;/code&gt;, containing the low dimension embedding
representations of entities in DRKG and 2) &lt;code class=&quot;highlighter-rouge&quot;&gt;DRKG_TransE_l2_relation.npy&lt;/code&gt;,
containing the low dimension embeddings representations of relations in DRKG.
These embeddings can be used in drug repurposing tasks.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;node_emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./ckpts/TransE_l2_DRKG_0/DRKG_TransE_l2_entity.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;relation_emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'./ckpts/TransE_l2_DRKG_0/DRKG_TransE_l2_relation.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The complete example code can be found &lt;a href=&quot;https://github.com/gnn4dr/DRKG/blob/master/embedding_analysis/Train_embeddings.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Use Pre-trained Knowledge Graph Embedding for Repurposing Drugs for COVID-19
— A collaboration work from Amazon AWS AI, Hunan University, Cleveland Clinic
Lerner Center for Genomic Medicine, and University of Minnesota (Repurpose Open
Data to Discover Therapeutics for COVID-19 using Deep Learning) proposed a new
drug repurposing methodology for COVID-19 using the combination of knowledge
graph embedding and gene-set enrichment analysis method. DRKG borrows the
similar idea and provides pre-trained knowledge graph embedding of DRKG for
drug repurposing for COVID-19.&lt;/p&gt;

&lt;p&gt;First of all, we define the task of finding drugs for COVID-19 using DRKG
knowledge graph as a task of predicting the possible connections between
candidate drug entities and the COVID-19 related disease entities under the
relation of &lt;code class=&quot;highlighter-rouge&quot;&gt;'Hetionet::CtD::Compound:Disease'&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;'GNBR::T::Compound:Disease'&lt;/code&gt;,
i.e. the treatment relationship. We select FDA approved drugs with molecular
weight larger than 250 from DRKG as drug candidates and use 34 COVID-19 virus
related entities in DRKG as target entities. Then we predict the connection
scores of all possible triplets (Drug, Treatment, Virus) under the &lt;code class=&quot;highlighter-rouge&quot;&gt;TransE_L2&lt;/code&gt;
algorithm and sort the scores. Finally, we choose the top100 highest confident
connections and take the corresponding drugs as repurposed drugs. The detailed
steps are as following:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Step 1:&lt;/em&gt; Setting target virus entities, drug entities and treatment relations.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# COVID-19 related virus entities&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;COV_disease_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Disease::SARS-CoV2 E'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Disease::SARS-CoV2 M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# treatment relations&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;treatment&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Hetionet::CtD::Compound:Disease'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GNBR::T::Compound:Disease'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# candidate drugs（provided in infer_drug.tsv along with the whole DRKG dataset)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;drug_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./infer_drug.tsv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newline&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'utf-8'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csvfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DictReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csvfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delimiter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fieldnames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drug'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ids'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_val&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;drug_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'drug'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 2:&lt;/em&gt; Get the pretrained DRKG knowledge graph embedding.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Reading pretrained embeddings&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entity_emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'../data/drkg/embed/DRKG_TransE_l2_entity.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rel_emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'../data/drkg/embed/DRKG_TransE_l2_relation.npy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;drug_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drug_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;disease_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disease_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;treatment_rid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;treatment_rid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;drug_emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entity_emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drug_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;treatment_embs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rel_emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rid&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;treatment_rid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 3:&lt;/em&gt; Predict the connection scores of all possible triplets (Drug, Treatment, Virus) under the &lt;code class=&quot;highlighter-rouge&quot;&gt;TransE_L2&lt;/code&gt; algorithm，the formula is as following:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{d} = \gamma - ||\mathbf{h} + \mathbf{r} - \mathbf{t}||_2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{score} = \log\left(\frac{1}{1+e^{-\mathbf{d}}}\right)&lt;/script&gt;

&lt;p&gt;, where &lt;script type=&quot;math/tex&quot;&gt;\mathbf{h}&lt;/script&gt; is for head (i.e., drugs), &lt;script type=&quot;math/tex&quot;&gt;\mathbf{r}&lt;/script&gt; for relation, &lt;script type=&quot;math/tex&quot;&gt;\mathbf{t}&lt;/script&gt; for tail
(i.e., virus) and &lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt; is the constant value used in training.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;12.0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transE_l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;scores_per_disease&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# predict the connection scores of (Drug, Treatment, Virus) triplets &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# for each treatment type and combine them together.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rid&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;treatment_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;treatment_emb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;treatment_embs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disease_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disease_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;disease_emb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entity_emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disease_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logsigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transE_l2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drug_emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;treatment_emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disease_emb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;scores_per_disease&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;dids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drug_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores_per_disease&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 4:&lt;/em&gt; Sort the scores.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 5:&lt;/em&gt; Get the top-100 repurposed drugs.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unique_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;topk_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# top-100 drug Ids&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;proposed_dids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# top-100 drug scores&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;proposed_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Step 6:&lt;/em&gt; Six drugs in clinical trials appears in the top100 repurposed drugs. Their ranking and score is as following:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[0]    Ribavirin          -0.21416784822940826
[4]    Dexamethasone      -0.9984006881713867
[8]    Colchicine         -1.080674648284912
[16]   Methylprednisolone -1.1618402004241943
[49]   Oseltamivir        -1.3885014057159424
[87]   Deferoxamine       -1.513066053390503
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The complete example code can be found &lt;a href=&quot;https://github.com/gnn4dr/DRKG/blob/master/drug_repurpose/COVID-19_drug_repurposing.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;further-read&quot;&gt;Further read&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Check out the &lt;a href=&quot;https://github.com/gnn4dr/DRKG&quot;&gt;DRKG repository&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Check out the &lt;a href=&quot;https://www.amazon.science/blog/amazon-web-services-open-sources-biological-knowledge-graph-to-fight-covid-19&quot;&gt;announcement&lt;/a&gt; on Amazon Science.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/147329945&quot;&gt;Blog in chinese&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DGLTeam</name></author><category term="news" /><category term="news" /><summary type="html">Since December 2019, the rapid spread of COVID-19 corona-viruses worldwide has caused more than 7 million infections and more than 400,000 deaths. The rapid spread of COVID-19 demonstrates the dire need for quick and effective drug discovery. Drug repurposing is a drug discovery paradigm that uses existing drugs for new therapeutic indications. It has the advantages of significantly reducing time and cost relative to de novo drug discovery. Drug repurposing with knowledge graphs presents a promising strategy for COVID-19 treatment.</summary></entry><entry><title type="html">Learning Graph Neural Networks with DGL – The WebConf 2020 Tutorial</title><link href="https://www.dgl.ai/news/2020/05/24/webconf.html" rel="alternate" type="text/html" title="Learning Graph Neural Networks with DGL -- The WebConf 2020 Tutorial" /><published>2020-05-24T00:00:00+08:00</published><updated>2020-05-24T00:00:00+08:00</updated><id>https://www.dgl.ai/news/2020/05/24/webconf</id><content type="html" xml:base="https://www.dgl.ai/news/2020/05/24/webconf.html">&lt;p&gt;In the last few years, graph neural networks (GNNs) have emerged as a promising
new supervised learning framework capable of bringing the power of deep
representation learning to graph and relational data.&lt;/p&gt;

&lt;p&gt;During &lt;a href=&quot;https://www.amazon.science/conferences-and-events/the-web-conference-2020&quot;&gt;The Web Conference&lt;/a&gt; in April, AWS deep learning scientists and engineers
George Karypis, Zheng Zhang, Minjie Wang, Da Zheng, and Quan Gan presented a
&lt;a href=&quot;https://github.com/dglai/WWW20-Hands-on-Tutorial&quot;&gt;tutorial&lt;/a&gt; on GNNs.&lt;/p&gt;

&lt;p&gt;The tutorial offers an overview of how learning GNNs can be used to solve
problems such as detecting fraud and abuse (e.g., malicious accounts,
fraudulent financial transactions, fake reviews), supporting customer
recommendations (e.g., suggesting relevant products, jobs, articles, etc.), and
delivering marketing campaigns (e.g., targeting who should get a discount,
identifying influencers).&lt;/p&gt;

&lt;p&gt;Watch the video presentation to learn more about putting GNNs to use in
learning applications, and get an introduction and training on the AWS Deep
Graph Library, a new software framework that simplifies the development of
efficient GNN-based training and inference programs.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/bD6S3xUXNds&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Tutorial sections:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Overview of graph neural networks&lt;/li&gt;
  &lt;li&gt;Overview of Deep Graph Library (DGL)&lt;/li&gt;
  &lt;li&gt;GNN models for basic graph tasks&lt;/li&gt;
  &lt;li&gt;GNN training on large graphs&lt;/li&gt;
  &lt;li&gt;GNN models for real-world applications&lt;/li&gt;
&lt;/ol&gt;</content><author><name>DGLTeam</name></author><category term="news" /><category term="news" /><summary type="html">In the last few years, graph neural networks (GNNs) have emerged as a promising new supervised learning framework capable of bringing the power of deep representation learning to graph and relational data.</summary></entry><entry><title type="html">What is new in DGL v0.4.3 release?</title><link href="https://www.dgl.ai/release/2020/04/01/release.html" rel="alternate" type="text/html" title="What is new in DGL v0.4.3 release?" /><published>2020-04-01T00:00:00+08:00</published><updated>2020-04-01T00:00:00+08:00</updated><id>https://www.dgl.ai/release/2020/04/01/release</id><content type="html" xml:base="https://www.dgl.ai/release/2020/04/01/release.html">&lt;p&gt;The DGL v0.4.3 release brings many new features for an enhanced usability and
system efficiency. The article takes a peek at some of the major highlights.&lt;/p&gt;

&lt;h2 id=&quot;tensorflow-support&quot;&gt;TensorFlow support&lt;/h2&gt;

&lt;p&gt;DGL finally comes to the TensorFlow community starting from this release.
Switching to TensorFlow is easy. If you are a first-time user, please install
DGL and &lt;code class=&quot;highlighter-rouge&quot;&gt;import dgl&lt;/code&gt;, and then follow the instructions to set the default
backend. You can always switch back by changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;config.json&lt;/code&gt; file, which is
under &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.dgl&lt;/code&gt; folder. DGL keeps a coherent user experience regardless of which
backend is currently in use. The following code demonstrates the basic steps to
apply a graph convolution layer.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dglnn&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Random features for 10 nodes; each is of length 5.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Random graph; 10 nodes and 20 edges.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Pre-defined graph convolution module.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dglnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GraphConv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Apply the graph convolution layer.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We have implemented and released 15 common GNN modules in TensorFlow (more are
coming), all of which can be invoked in one line of codes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GraphConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/abs/1609.02907&quot;&gt;Graph Convolutional Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GATConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;Graph Attention Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SAGEConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1706.02216.pdf&quot;&gt;Inductive Representation Learning on Large Graphs&lt;/a&gt; paper (a.k.a. GraphSAGE).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GINConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1810.00826.pdf&quot;&gt;How Powerful are Graph Neural Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RelGraphConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/abs/1703.06103&quot;&gt;Modeling Relational Data with Graph Convolutional Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SGConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1902.07153.pdf&quot;&gt;Simplifying Graph Convolutional Networks&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APPNPConv&lt;/code&gt; from the &lt;a href=&quot;https://arxiv.org/pdf/1810.05997.pdf&quot;&gt;Predict then Propagate: Graph Neural Networks meet Personalized PageRank&lt;/a&gt; paper.&lt;/li&gt;
  &lt;li&gt;An &lt;code class=&quot;highlighter-rouge&quot;&gt;edge_softmax&lt;/code&gt; function for computing softmax over the neighboring edges of each vertex.&lt;/li&gt;
  &lt;li&gt;Various pooling layers: &lt;code class=&quot;highlighter-rouge&quot;&gt;SumPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;AvgPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;MaxPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SortPooling&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;WeightAndSum&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;GlobalAttentionPooling&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;HeteroGraphConv&lt;/code&gt; module for applying GNN modules to heterogeneous graphs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our preliminary benchmark shows strong performance improvement against other
TF-based tools for GNNs in terms of both training speed (measured by epoch
running time in seconds) and memory consumption.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dateset&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;DGL&lt;/th&gt;
      &lt;th&gt;GraphNet&lt;/th&gt;
      &lt;th&gt;tf_geometric&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Core&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.0148&lt;/td&gt;
      &lt;td&gt;0.0152&lt;/td&gt;
      &lt;td&gt;0.0192&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Reddit&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.1095&lt;/td&gt;
      &lt;td&gt;OOM&lt;/td&gt;
      &lt;td&gt;OOM&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PubMed&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.0156&lt;/td&gt;
      &lt;td&gt;0.0553&lt;/td&gt;
      &lt;td&gt;0.0185&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PPI&lt;/td&gt;
      &lt;td&gt;GCN&lt;/td&gt;
      &lt;td&gt;0.09&lt;/td&gt;
      &lt;td&gt;0.16&lt;/td&gt;
      &lt;td&gt;0.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cora&lt;/td&gt;
      &lt;td&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.0442&lt;/td&gt;
      &lt;td&gt;n/a&lt;/td&gt;
      &lt;td&gt;0.058&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PPI&lt;/td&gt;
      &lt;td&gt;GAT&lt;/td&gt;
      &lt;td&gt;0.398&lt;/td&gt;
      &lt;td&gt;n/a&lt;/td&gt;
      &lt;td&gt;0.752&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To get started, install &lt;a href=&quot;https://www.dgl.ai/pages/start.html&quot;&gt;DGL&lt;/a&gt; and check out the examples &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/tensorflow&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;dgl-ke-a-light-speed-package-for-learning-knowledge-graph-embeddings&quot;&gt;DGL-KE: A light-speed package for learning knowledge graph embeddings&lt;/h2&gt;
&lt;p&gt;Previously incubated under the DGL main repository, DGL-KE now officially
announces its 0.1 release as a standalone package. The key highlights are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Effortlessly generate knowledge graph embedding with one line of code.&lt;/li&gt;
  &lt;li&gt;Support for giant graphs with millions of nodes and edges.&lt;/li&gt;
  &lt;li&gt;Distributed training with highly-optimized graph partitioning, negative
sampling and communication, which can be deployed on both multi-GPU machines
and multi-machine clusters.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DGL-KE can be installed with pip:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install dglke
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The following command trains embeddings of the full FreeBase graph (over 86M nodes
and 338M edges) with 8 GPUs.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dglke_train --model TransE_l2 --dataset Freebase --batch_size 1000 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --neg_sample_size 200 --hidden_dim 400 --gamma 10 --lr 0.1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --regularization_coef 1e-9 -adv --gpu 0 1 2 3 4 5 6 7 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --max_step 320000 --log_interval 10000 --async_update &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
            --rel_part --force_sync_interval 10000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;DGL-KE is designed for learning at scale and speed. Our benchmark on the full
FreeBase graph shows that DGL-KE can train
embeddings under 100 minutes on an 8-GPU machine and under 30 minutes on a 4-machine
cluster (48 cores/machine). These results represent a 2×∼5× speedup over the
best competing approaches.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;center&gt;DGL-KE v.s. PyTorch-BigGraph on FreeBase&lt;/center&gt;&lt;/th&gt;
      &lt;th&gt;&lt;center&gt;DGL-KE v.s. GraphVite on FB15k&lt;/center&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;https://github.com/awslabs/dgl-ke/raw/master/img/vs-pbg-fb.png&quot; alt=&quot;&quot; width=&quot;600x&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;https://github.com/awslabs/dgl-ke/raw/master/img/vs-gv-fb15k.png&quot; alt=&quot;&quot; width=&quot;600x&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Check out our new GitHub repository, examples and documentations under
&lt;a href=&quot;https://github.com/awslabs/dgl-ke&quot;&gt;https://github.com/awslabs/dgl-ke&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;dgl-lifesci-bringing-graph-neural-networks-to-chemistry-and-biology&quot;&gt;DGL-LifeSci: Bringing Graph Neural Networks to Chemistry and Biology&lt;/h2&gt;

&lt;p&gt;Previously incubated as a model zoo for chemistry, DGL-LifeSci is now spun off
as a standalone package. The key highlights are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training scripts and pre-trained models for various applications — molecular
property prediction, generative models, and reaction prediction.&lt;/li&gt;
  &lt;li&gt;Up to 5.5x model training speedup compared to previous implementations.&lt;/li&gt;
  &lt;li&gt;Well defined pipelines for data processing, model construction and
evaluation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DGL-LifeSci can be installed with pip or conda.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install dgllife
conda install -c dglteam dgllife
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;A summary of speedup in seconds per epoch of training:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Original Implementations&lt;/th&gt;
      &lt;th&gt;DGL-LifeSci Implementations&lt;/th&gt;
      &lt;th&gt;Speedup&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GCN on Tox21&lt;/td&gt;
      &lt;td&gt;5.5 (DeepChem)&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;5.5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;AttentiveFP on Aromaticity&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;1.2&lt;/td&gt;
      &lt;td&gt;5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;JTNN on ZINC&lt;/td&gt;
      &lt;td&gt;1826&lt;/td&gt;
      &lt;td&gt;743&lt;/td&gt;
      &lt;td&gt;2.5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;WLN for reaction center prediction&lt;/td&gt;
      &lt;td&gt;11657&lt;/td&gt;
      &lt;td&gt;5095&lt;/td&gt;
      &lt;td&gt;2.3x&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To get started, check out the examples and documentations under
&lt;a href=&quot;https://github.com/awslabs/dgl-lifesci&quot;&gt;https://github.com/awslabs/dgl-lifesci&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;experimenting-new-apis-for-sampling&quot;&gt;Experimenting new APIs for sampling&lt;/h2&gt;

&lt;p&gt;Sampling is crucial to training GNNs on giant graphs. In this release, we
re-design the APIs for sampling, aiming for a more intuitive programming
experience and a better performance at the same time. The new APIs have several
advantages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Support a wide range of sampling-based GNN models, including PinSAGE,
GraphSAGE, Graph Convolutional Matrix Completion (GCMC), and etc.&lt;/li&gt;
  &lt;li&gt;Support customization in Python.&lt;/li&gt;
  &lt;li&gt;Support heterogeneous graphs.&lt;/li&gt;
  &lt;li&gt;Leverage all pre-defined NN modules with no code change.&lt;/li&gt;
  &lt;li&gt;Utilize both multi-processing and multi-threading for maximum speed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The code below defines a basic neighbor sampler:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeighborSampler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# The full graph structure&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# fan-out of each layer&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_blocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# `seeds` are the set of nodes to build one sample from.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fanouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# For each seed node, sample ``fanout`` neighbors.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;frontier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sampling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_neighbors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fanout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# Then we compact the frontier into a bipartite graph for message passing.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frontier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# Obtain the seed nodes for next layer.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;seeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Although these APIs are still experimental, you can find their usages in many
examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Train the GraphSAGE model by neighbor sampling and scale it to multiple GPUs
(&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/graphsage&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Train the Relational GCN model on heterogeneous graphs by sampling for both
node classification and link prediction (&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn-hetero&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Train the PinSAGE model by random walk sampling for item recommendation (&lt;a href=&quot;https://github.com/dmlc/dgl/pull/1334&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Train the GCMC model by sampling for MovieLens rating prediction (&lt;a href=&quot;https://github.com/dmlc/dgl/pull/1296&quot;&gt;link&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Implement the variance reduction technique for neighbor sampling (&lt;a href=&quot;https://github.com/dmlc/dgl/pull/1355&quot;&gt;link&lt;/a&gt;) proposed by &lt;a href=&quot;https://arxiv.org/abs/1710.10568&quot;&gt;Chen et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will continue polishing these APIs, and the corresponding documentations and
tutorials are coming.&lt;/p&gt;

&lt;h2 id=&quot;other-improvements&quot;&gt;Other Improvements&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;All GNN modules under &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn&lt;/code&gt; now support both homogeneous graph and bipartite graph.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DGLHeteroGraph&lt;/code&gt; now has a faster pickling/unpickling implementation.&lt;/li&gt;
  &lt;li&gt;Add new APIs for saving and loading &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLHeteroGraph&lt;/code&gt; from checkpoints.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BatchedDGLGraph&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLSubGraph&lt;/code&gt; classes have been merged to &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Constructing &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; no longer requires a &lt;code class=&quot;highlighter-rouge&quot;&gt;multigraph&lt;/code&gt; flag.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More details can be found in the &lt;a href=&quot;https://github.com/dmlc/dgl/releases/tag/0.4.3&quot;&gt;full release note&lt;/a&gt;.&lt;/p&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">The DGL v0.4.3 release brings many new features for an enhanced usability and system efficiency. The article takes a peek at some of the major highlights.</summary></entry><entry><title type="html">DGL v0.4 Release (heterogeneous graph update)</title><link href="https://www.dgl.ai/release/2019/10/08/release.html" rel="alternate" type="text/html" title="DGL v0.4 Release (heterogeneous graph update)" /><published>2019-10-08T00:00:00+08:00</published><updated>2019-10-08T00:00:00+08:00</updated><id>https://www.dgl.ai/release/2019/10/08/release</id><content type="html" xml:base="https://www.dgl.ai/release/2019/10/08/release.html">&lt;p&gt;We are thrilled to announce the 0.4 release!  This includes:&lt;/p&gt;

&lt;h1 id=&quot;heterogeneous-graph-support&quot;&gt;Heterogeneous Graph Support&lt;/h1&gt;

&lt;h2 id=&quot;what-is-a-heterogeneous-graph&quot;&gt;What is a heterogeneous graph?&lt;/h2&gt;

&lt;p&gt;A heterogeneous graph is a graph whose nodes and edges are typed:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/2978100/66382127-3196d400-e9ed-11e9-94f8-ee89ba530a13.png&quot; alt=&quot;&quot; width=&quot;350x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;models-that-work-on-heterogeneous-graphs&quot;&gt;Models that work on heterogeneous graphs?&lt;/h2&gt;

&lt;p&gt;Models using Heterogeneous Graph API:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.02263&quot;&gt;GCMC&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/mxnet/gcmc&quot;&gt;Code in MXNet&lt;/a&gt;]&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;Dataset&lt;/th&gt;
          &lt;th&gt;RMSE (DGL)&lt;/th&gt;
          &lt;th&gt;RMSE (Official)&lt;/th&gt;
          &lt;th&gt;Speed (DGL)&lt;/th&gt;
          &lt;th&gt;Speed (Official)&lt;/th&gt;
          &lt;th&gt;Speed Comparison&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;MovieLens-100K&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.9077&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.910&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.0246s/epoch&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.1008s/epoch&lt;/td&gt;
          &lt;td&gt;5x&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;MovieLens-1M&lt;/td&gt;
          &lt;td&gt;0.8377&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.832&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.0695s/epoch&lt;/td&gt;
          &lt;td&gt;1.538s/epoch&lt;/td&gt;
          &lt;td&gt;22x&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;MovieLens-10M (full-graph training)&lt;/td&gt;
          &lt;td&gt;0.7875&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;0.777&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;0.6480s/epoch&lt;/td&gt;
          &lt;td&gt;OOM&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.06103&quot;&gt;R-GCN&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn-hetero&quot;&gt;Code in PyTorch&lt;/a&gt;]
    &lt;ul&gt;
      &lt;li&gt;We provide an R-GCN model for heterograph input. The new code can train the model for the AM dataset (&amp;gt;5M edges) using one GPU, while the original implementation can only run on CPU and consume 32GB memory.&lt;/li&gt;
      &lt;li&gt;The original implementation takes 51.88s to train one epoch on CPU. The new R-GCN based on heterograph takes only 0.1781s for one epoch on V100 GPU (&lt;strong&gt;291x faster !!&lt;/strong&gt;).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1903.07293&quot;&gt;Heterogeneous Attention Networks&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/han&quot;&gt;Code in PyTorch&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3098036&quot;&gt;Metapath2vec&lt;/a&gt; [&lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/examples/pytorch/metapath2vec&quot;&gt;Code in PyTorch&lt;/a&gt;]
    &lt;ul&gt;
      &lt;li&gt;The metapath sampler is twice as fast as the original implementation.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-could-i-play-with-a-heterogeneous-graph&quot;&gt;How could I play with a heterogeneous graph?&lt;/h2&gt;

&lt;p&gt;Here is an example for creating and manipulating a heterogeneous graph:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.function&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dgl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heterograph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'plays'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'attracts'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'developer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'develops'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Here the user nodes have a single feature named x, and game nodes have a single feature named y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Edge features are similar&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'plays'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# One can also perform message passing.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# The following code performs a full message passing on the &quot;plays&quot; edges.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'game'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allclose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Moreover, one can also perform message passing on multiple types at the same time, aggregating the results&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multi_update_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'follows'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'attracts'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'sum'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Checkout our heterograph tutorial: &lt;a href=&quot;https://docs.dgl.ai/tutorials/hetero/1_basics.html&quot;&gt;Working with Heterogeneous Graphs in DGL&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Checkout the full &lt;a href=&quot;https://docs.dgl.ai/api/python/heterograph.html&quot;&gt;API reference&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;knowledge-graph-models&quot;&gt;Knowledge Graph Models&lt;/h1&gt;

&lt;p&gt;We also released DGL-KE, a subpackage of DGL that trains embeddings on knowledge graphs. This package is adapted from the &lt;a href=&quot;https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding&quot;&gt;KnowledgeGraphEmbedding&lt;/a&gt; package. We made it fast and scalable while still maintaining the flexibility of the original package. Using a single NVIDIA V100 GPU, DGL-KE can train TransE on FB15k in &lt;strong&gt;6.85 mins&lt;/strong&gt;, substantially outperforming existing tools such as GraphVite.  For graphs with hundreds of millions of edges (such as the full Freebase graph), it takes a couple of hours on &lt;strong&gt;one&lt;/strong&gt; EC2 x1.32xlarge machine.&lt;/p&gt;

&lt;p&gt;Currently, the following models are supported:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TransE&lt;/li&gt;
  &lt;li&gt;DistMult&lt;/li&gt;
  &lt;li&gt;ComplEx&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And the following training schemas are supported:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU training&lt;/li&gt;
  &lt;li&gt;GPU training&lt;/li&gt;
  &lt;li&gt;Joint CPU &amp;amp; GPU training&lt;/li&gt;
  &lt;li&gt;Multiprocessing training on CPUs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Training results on FB15k using one NVIDIA V100 GPU&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Training Speed:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Models&lt;/th&gt;
      &lt;th&gt;TransE&lt;/th&gt;
      &lt;th&gt;DistMult&lt;/th&gt;
      &lt;th&gt;ComplEx&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;MAX_STEPS&lt;/td&gt;
      &lt;td&gt;20000&lt;/td&gt;
      &lt;td&gt;100000&lt;/td&gt;
      &lt;td&gt;100000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;TIME&lt;/td&gt;
      &lt;td&gt;411s&lt;/td&gt;
      &lt;td&gt;690s&lt;/td&gt;
      &lt;td&gt;806s&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Training accuracy:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Models&lt;/th&gt;
      &lt;th&gt;MR&lt;/th&gt;
      &lt;th&gt;MRR&lt;/th&gt;
      &lt;th&gt;HITS@1&lt;/th&gt;
      &lt;th&gt;HITS@3&lt;/th&gt;
      &lt;th&gt;HITS@10&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;TransE&lt;/td&gt;
      &lt;td&gt;69.12&lt;/td&gt;
      &lt;td&gt;0.656&lt;/td&gt;
      &lt;td&gt;0.567&lt;/td&gt;
      &lt;td&gt;0.718&lt;/td&gt;
      &lt;td&gt;0.802&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DistMult&lt;/td&gt;
      &lt;td&gt;43.35&lt;/td&gt;
      &lt;td&gt;0.783&lt;/td&gt;
      &lt;td&gt;0.713&lt;/td&gt;
      &lt;td&gt;0.837&lt;/td&gt;
      &lt;td&gt;0.897&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ComplEx&lt;/td&gt;
      &lt;td&gt;51.99&lt;/td&gt;
      &lt;td&gt;0.785&lt;/td&gt;
      &lt;td&gt;0.720&lt;/td&gt;
      &lt;td&gt;0.832&lt;/td&gt;
      &lt;td&gt;0.889&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In comparison, GraphVite uses 4 GPUs and takes 14 minutes. Thus, DGL-KE trains TransE on FB15k 2x times faster than GraphVite while using much fewer resources.&lt;/p&gt;

&lt;p&gt;For more information, please refer to &lt;a href=&quot;https://github.com/dmlc/dgl/tree/master/apps/kg&quot;&gt;this directory&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;miscellaneous&quot;&gt;Miscellaneous&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;New builtin message function: dot product (&lt;code class=&quot;highlighter-rouge&quot;&gt;u_dot_v&lt;/code&gt; etc. #831 @classicsong )&lt;/li&gt;
  &lt;li&gt;More efficient data format and serialization (#728 @VoVAllen )&lt;/li&gt;
  &lt;li&gt;ClusterGCN (#877 , @Zardinality )&lt;/li&gt;
  &lt;li&gt;CoraFull, Amazon, KarateClub, Coauthor datasets (#855 @VoVAllen )&lt;/li&gt;
  &lt;li&gt;More performance improvements&lt;/li&gt;
  &lt;li&gt;More bugfixes&lt;/li&gt;
&lt;/ul&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">We are thrilled to announce the 0.4 release! This includes:</summary></entry><entry><title type="html">DGL v0.3.1 Release</title><link href="https://www.dgl.ai/release/2019/08/28/release.html" rel="alternate" type="text/html" title="DGL v0.3.1 Release" /><published>2019-08-28T00:00:00+08:00</published><updated>2019-08-28T00:00:00+08:00</updated><id>https://www.dgl.ai/release/2019/08/28/release</id><content type="html" xml:base="https://www.dgl.ai/release/2019/08/28/release.html">&lt;p&gt;We have received many requests from our community for more GNN layers, models and examples. This is the time to respond. In this minor release, we enriched DGL with a ton of common GNN modules. We have also verified their correctness on some popular datasets so feel free to try them out. Another direction we are working on is to build more domain friendly packages based on DGL. As a first step, we released several pretrained GNN models for molecular property prediction and molecule generation (currently grouped under &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.model_zoo&lt;/code&gt; namespace). We will continue explore this idea and release more domain specific models and packages.&lt;/p&gt;

&lt;h1 id=&quot;new-apis&quot;&gt;New APIs&lt;/h1&gt;

&lt;h2 id=&quot;new-nn-modules&quot;&gt;New NN Modules&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GATConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1710.10903.pdf&quot;&gt;“Graph Attention Network”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RelGraphConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/abs/1703.06103&quot;&gt;“Modeling Relational Data with Graph Convolutional Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TAGConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1710.10370.pdf&quot;&gt;“Topology Adaptive Graph Convolutional Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;EdgeConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1801.07829&quot;&gt;“Dynamic Graph CNN for Learning on Point Clouds”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SAGEConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1706.02216.pdf&quot;&gt;“Inductive Representation Learning on Large Graphs”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GatedGraphConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1511.05493.pdf&quot;&gt;“Gated Graph Sequence Neural Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GMMConv&lt;/code&gt; from &lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2017/papers/Monti_Geometric_Deep_Learning_CVPR_2017_paper.pdf&quot;&gt;“Geometric Deep Learning on Graphs and Manifolds using Mixture Model CNNs”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GINConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1810.00826.pdf&quot;&gt;“How Powerful are Graph Neural Networks?”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ChebConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1606.09375.pdf&quot;&gt;“Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SGConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1902.07153.pdf&quot;&gt;“Simplifying Graph Convolutional Networks”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;NNConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1704.01212.pdf&quot;&gt;“Neural Message Passing for Quantum Chemistry”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APPNPConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1810.05997.pdf&quot;&gt;“Predict then Propagate: Graph Neural Networks meet Personalized PageRank”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AGNNConv&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/abs/1803.03735&quot;&gt;“Attention-based Graph Neural Network for Semi-Supervised Learning
”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DenseGraphConv&lt;/code&gt; (Dense implementation of &lt;code class=&quot;highlighter-rouge&quot;&gt;GraphConv&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DenseSAGEConv&lt;/code&gt; (Dense implementation of &lt;code class=&quot;highlighter-rouge&quot;&gt;SAGEConv&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DenseChebConv&lt;/code&gt; (Dense implementation of &lt;code class=&quot;highlighter-rouge&quot;&gt;ChebConv&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;new-global-pooling-module&quot;&gt;New global pooling module&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Sum/Avg/MaxPooling&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SortPooling&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GlobalAttentionPooling&lt;/code&gt; from GGNN model&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Set2Set&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1511.06391.pdf&quot;&gt;“Order Matters: Sequence to sequence for sets”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SetTransformerEncoder&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SetTransformerDecoder&lt;/code&gt; from &lt;a href=&quot;https://arxiv.org/pdf/1810.00825.pdf&quot;&gt;“Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks”&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please refer to the &lt;a href=&quot;https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.glob&quot;&gt;API document&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h2 id=&quot;new-graph-transformation-routines&quot;&gt;New graph transformation routines&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.khop_adj&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.khop_graph&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.laplacian_lambda_max&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.knn_graph&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.transform.segmented_knn_graph&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please refer to the &lt;a href=&quot;https://docs.dgl.ai/api/python/transform.html&quot;&gt;API document&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h1 id=&quot;model-zoo-for-chemistry-and-molecule-applications&quot;&gt;Model zoo for chemistry and molecule applications&lt;/h1&gt;
&lt;p&gt;To make it easy for domain scientists, we are now releasing a model zoo for chemistry, with training scripts and pre-trained models, and focuses on two particular tasks: property prediction and targeted molecular generation/optimization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Credit&lt;/strong&gt;: Shout out to @geekinglcq from Tencent Quantum Lab for contributing three models (MGCN, SchNet and MPNN). We also thank WuXi AppTec CADD team for their critical feedback on usability.&lt;/p&gt;

&lt;h2 id=&quot;property-prediction&quot;&gt;Property prediction&lt;/h2&gt;
&lt;p&gt;In practice, the determination of molecular properties is mostly achieved via wet lab experiments. We can cast the problem as a regression or classification problem.&lt;/p&gt;

&lt;p&gt;Featurization is the beginning of prediction. Traditionally, chemists develop pre-defined rules to convert molecular graphs into binary strings where each bit indicates the presence or absence of a particular substructure.&lt;/p&gt;

&lt;p&gt;Graph neural networks enable a data-driven representation of molecules out of the atoms, bonds and molecular graph topology, which may be viewed as a learned fingerprint. The message passing mechanism allows the model to learn the interactions between atoms in a molecule.&lt;/p&gt;

&lt;p&gt;The following code script is self-explanatory.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl.data.chem&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tox21&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tox21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GCN_Tox21'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Pretrained model loaded&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;smiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                   &lt;span class=&quot;c&quot;&gt;# CCOc1ccc2nc(S(N)(=O)=O)sc2c1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Mask non-existing labels&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# tensor([[-0.7956,  0.4054,  0.4288, -0.5565, -0.0911,  &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 0.9981, -0.1663,  0.2311, -0.2376,  0.9196]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Supported Models&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Graph Convolution&lt;/li&gt;
  &lt;li&gt;Graph Attention Networks&lt;/li&gt;
  &lt;li&gt;SchNet&lt;/li&gt;
  &lt;li&gt;Multilevel Graph Convolutional neural Network&lt;/li&gt;
  &lt;li&gt;Message Passing Neural Networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generative-models&quot;&gt;Generative Models&lt;/h2&gt;

&lt;p&gt;Targeted molecular generation refers to finding new molecules with desired properties. This gives rise to the need for generative models for two purposes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Distribution Learning&lt;/strong&gt;: Given a collection of molecules, we want to model their distribution and generate new molecules consistent with the distribution.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Goal-directed Optimization&lt;/strong&gt;: Find molecules with desired properties.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this model zoo, we provide only graph-based generative models. There are other generative models working with alternative representations like SMILES.&lt;/p&gt;

&lt;p&gt;Example with Pre-trained Models&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# We recommend running the code below with Jupyter notebooks&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;IPython.display&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVG&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rdkit&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Chem&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rdkit.Chem&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Draw&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dgl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'DGMG_ZINC_canonical'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mols&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;SMILES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdkit_mol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MolFromSmiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SMILES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Generating 4 molecules takes less than a second.&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;SVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Draw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MolsToGridImage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;molsPerRow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subImgSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;180&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;useSVG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://data.dgl.ai/model_zoo/drug_discovery/dgmg_model_zoo_example2.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Supported Models&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Learning Deep Generative Models of Graphs&lt;/li&gt;
  &lt;li&gt;Junction Tree Variational Autoencoder for Molecular Graph Generation&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;api-break&quot;&gt;API break&lt;/h1&gt;
&lt;p&gt;We refactor the &lt;code class=&quot;highlighter-rouge&quot;&gt;nn&lt;/code&gt; package to make all APIs more consistent. Thus, there are following changes to the API that breaks the previous behavior:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Change the argument order of &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.pytorch.GraphConv&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;dgl.nn.mxnet.GraphConv&lt;/code&gt;. The argument order is now first &lt;code class=&quot;highlighter-rouge&quot;&gt;graph&lt;/code&gt; and then &lt;code class=&quot;highlighter-rouge&quot;&gt;feat&lt;/code&gt;, which follows the convention of all the other new modules.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;new-model-example&quot;&gt;New model example&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.08028.pdf&quot;&gt;Recurrent Relational Networks&lt;/a&gt; in PyTorch (credit: @HuXiangkun )&lt;/p&gt;

&lt;p&gt;There are also many bug fixes and minor changes. We will list them in the next 0.4 major release.&lt;/p&gt;</content><author><name>DGLTeam</name></author><category term="release" /><category term="release" /><summary type="html">We have received many requests from our community for more GNN layers, models and examples. This is the time to respond. In this minor release, we enriched DGL with a ton of common GNN modules. We have also verified their correctness on some popular datasets so feel free to try them out. Another direction we are working on is to build more domain friendly packages based on DGL. As a first step, we released several pretrained GNN models for molecular property prediction and molecule generation (currently grouped under dgl.model_zoo namespace). We will continue explore this idea and release more domain specific models and packages.</summary></entry><entry><title type="html">Large-Scale Training of Graph Neural Networks</title><link href="https://www.dgl.ai/blog/2019/06/13/giant.html" rel="alternate" type="text/html" title="Large-Scale Training of Graph Neural Networks" /><published>2019-06-13T00:00:00+08:00</published><updated>2019-06-13T00:00:00+08:00</updated><id>https://www.dgl.ai/blog/2019/06/13/giant</id><content type="html" xml:base="https://www.dgl.ai/blog/2019/06/13/giant.html">&lt;p&gt;Many graph applications deal with &lt;em&gt;giant&lt;/em&gt; scale. Social networks, recommendation and knowledge graphs have nodes and edges in the order of hundreds of millions or even billions of nodes. For example, a recent snapshot of the friendship network of Facebook contains 800 million nodes and over 100 billion links.&lt;/p&gt;

&lt;h2 id=&quot;sampling-methods-in-dgl&quot;&gt;Sampling methods in DGL&lt;/h2&gt;
&lt;p&gt;Giant graphs are a classic challenge, and is even more so in graph neural networks (GNN). In a GNN model, computing the embedding of a node depends on the embeddings of its neighbors. Such dependency leads to exponential growth of the number of nodes involved with number of GNN layers.&lt;/p&gt;

&lt;p&gt;A typical technique is sampling, and there are many variants, some of them are applicable to GNN and DGL supports a few of them. The basic idea is to prune the node dependency to reduce the computation while still estimating the embeddings of GNN accurately. We leave the exact formulation of these techniques at the end of the tutorial (and users are encouraged to read them!), and describe the gists of them breifly here:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.02216&quot;&gt;neighbor sampling&lt;/a&gt;. This is the most basic: simply pick a small number of random neighbors.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1809.05343&quot;&gt;layer-wise sampling&lt;/a&gt;. The problem with simple neighbor sampling is that number of nodes needed will continue to grow exponentially with deeper layers. The idea here is to consider a layer as a whole and constrain the amount of samples per layer.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.01973&quot;&gt;random-walk sampling&lt;/a&gt;. As the name suggests, samples are picked up by performing random walks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sampling estimators can suffer from high variance. Obviously, including more neighbors will reduce the variance but this defeats the purpose of sampling. One interesting soution is &lt;a href=&quot;https://arxiv.org/abs/1710.10568&quot;&gt;control-variate sampling&lt;/a&gt;, a standard variance reduction technique used in Monte Carlo methods.&lt;/p&gt;

&lt;p&gt;The basic idea is simple: given a random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and we wish to estimate its expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [X] = \theta&lt;/script&gt;, the control variate method finds another random variable &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; which is highly correlated with &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and whose expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [Y]&lt;/script&gt; can be easily computed. Control variate needs to keep extra state, but otherwise is effective in reducing sample size. In fact, one neighbor is enough, for the Reddit dataset!
&lt;!--
We experiment neighbor sampling and control variate sampling to train GCN and GraphSage on Reddit to evaluate the effectiveness of these two sampling methods. The result is shown in the figure below. For GCN, control variate sampling is much more effective than neighbor sampling. Sampling only one neighbor is sufficient to train GCN on the Reddit dataset. Similarly, when training GraphSage, we only need to sample one neighbor to get its accuracy over 96%.
--&gt;
&lt;img src=&quot;https://i.imgur.com/DTPQu5V.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;system-support-for-giant-graphs&quot;&gt;System support for giant graphs&lt;/h2&gt;
&lt;p&gt;Sampling provides the nice possiblity of dealing with giant graphs with a data-parallel perspective. DGL adds two components, see figure below:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sampler&lt;/strong&gt;: a sampler constructs small subgraphs (&lt;code class=&quot;highlighter-rouge&quot;&gt;NodeFlow&lt;/code&gt;) from a given (giant) graph; tutorials of &lt;code class=&quot;highlighter-rouge&quot;&gt;NodeFlow&lt;/code&gt; can be found &lt;a href=&quot;https://doc.dgl.ai/tutorials/models/5_giant_graph/1_sampling_mx.html#sphx-glr-tutorials-models-5-giant-graph-1-sampling-mx-py&quot;&gt;here&lt;/a&gt;. Multiple samplers can be launched locally, or remotely, and on many machines.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Graph store&lt;/strong&gt;: this prepares the I/O substrate to scale out with a large number of trainers. The graph store contains graph embeddings as well as its structure. For now, the implementation is based on shared-memory, supporting multi-processing training on multi-GPU and/or non-uniform memory access (NUMA) machines.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The shared-memory graph store has a similar interface to &lt;code class=&quot;highlighter-rouge&quot;&gt;DGLGraph&lt;/code&gt; for programming. DGL will also support a distributed graph store that can store graph embeddings across machines in the future release.&lt;/p&gt;

&lt;!--
The figure below shows the interaction of the trainer with the samplers and the graph store. The trainer takes subgraphs (`NodeFlow`) from the sampler and fetches graph embeddings from the graph store before training. The trainer can push new graph embeddings to the graph store or invoke some computation on the graph store.
--&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/OmLVXfo.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, let’s demonstrate how good these supports are.&lt;/p&gt;

&lt;h3 id=&quot;multi-processing-training-and-optimizations-on-a-numa-machine&quot;&gt;Multi-processing training and optimizations on a NUMA machine&lt;/h3&gt;
&lt;p&gt;The speedup is almost linear, and on Reddit dataset takes about only 20 seconds to converge to the accuracy of 96% with 20 iterations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/eaiEcEi.png&quot; alt=&quot;&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;X1.32xlarge instance has 4 processors, each of which has 16 physical CPU cores.&lt;/li&gt;
  &lt;li&gt;We need to be aware of NUMA architecture, otherwise there’s hardly any speedup with more CPU processors. Please see &lt;a href=&quot;https://doc.dgl.ai/tutorials/models/5_giant_graph/2_giant.html#sphx-glr-tutorials-models-5-giant-graph-2-giant-py&quot;&gt;our tutorial&lt;/a&gt; for more details.&lt;/li&gt;
&lt;/ul&gt;

&lt;!--
To demonstrate the effectiveness of multi-processing training with this architecture on a NUMA machine and on a multi-GPU machine, we train GraphSage on the Reddit dataset with control-variate sampling. To optimize the training in a NUMA machine, we need to bind trainers' processes to specific NUMA nodes. Please see [our tutorial](https://doc.dgl.ai/tutorials/models/5_giant_graph/2_giant.html#sphx-glr-tutorials-models-5-giant-graph-2-giant-py) for more details how to bind processes on a NUMA node.
The figure below shows that NUMA-aware multi-processing training can accelerate training almost by a factor of 4 on an X1.32xlarge instance where there are 4 processors, each of which has 16 physical CPU cores. We can see that NUMA-unaware training cannot take advantage of computation power of the machine. It is even slightly slower than just using one of the processors in the machine. NUMA-aware training, on the other hand, takes about only 20 seconds to converge to the accuracy of 96% with 20 iterations.
--&gt;

&lt;h3 id=&quot;distributed-sampler&quot;&gt;Distributed Sampler&lt;/h3&gt;

&lt;p&gt;We can move samplers around. For GCN variants where computation aren’t that intense, running samplers on small (and cheaper) machines and training on NUMA is both faster and more cost-effective (additional 20%-40% speedups).&lt;/p&gt;

&lt;!--
are ran on different machines, we can 
We also notice that the sampling in many tasks takes a significant amount of time for the training process on a giant graph. So DGL supports distributed samplers for speeding up the sampling process on giant graphs. DGL allows users to launch multiple samplers on different machines concurrently, and each sampler can send its sampled subgraph (`NodeFlow`) to trainer machines continuously. 
The figure below shows the overall performance improvement of training GCN and GraphSage on the Reddit dataset after deploying NUMA optimizations and distributed sampling. Our NUMA optimization speeds up the training by a factor of 3. The distributed sampling achieves additional 20%-40% speed improvement for different tasks.
--&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/e0MXa5N.png&quot; alt=&quot;&quot; width=&quot;700x&quot; class=&quot;aligncenter&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;scale-to-giant-graphs&quot;&gt;Scale to giant graphs&lt;/h3&gt;
&lt;!--Finally, we would like to demonstrate the scalability of DGL on giant graphs. 
--&gt;
&lt;p&gt;We create three large power-law graphs with &lt;a href=&quot;http://www.cs.cmu.edu/~christos/PUBLICATIONS/siam04.pdf&quot;&gt;RMAT&lt;/a&gt;. Each node is associated with 100 features and we compute node embeddings with 64 dimensions. Below shows the training speed and memory consumption of GCN with neighbor sampling.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;#Nodes&lt;/th&gt;
      &lt;th&gt;#Edges&lt;/th&gt;
      &lt;th&gt;Time per epoch (s)&lt;/th&gt;
      &lt;th&gt;Memory (GB)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;5M&lt;/td&gt;
      &lt;td&gt;250M&lt;/td&gt;
      &lt;td&gt;4.7&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;50M&lt;/td&gt;
      &lt;td&gt;2.5B&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;500M&lt;/td&gt;
      &lt;td&gt;25B&lt;/td&gt;
      &lt;td&gt;505&lt;/td&gt;
      &lt;td&gt;740&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that DGL can scale to graphs with 500M nodes and 25B edges on an X1.32xlarge instance.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;We are looking forward to your feedbacks and would love to hear your use cases and models for giant graphs! All of these new features shown in this blog will be in our upcoming v0.3 release. Please try them out and give us feedbacks.&lt;/p&gt;

&lt;p&gt;We are continuing working on our infrastructure for training graph neural networks on giant graphs, which includes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In the infrastructure, we will add a distributed graph store to support fully distributed training for graph neural networks.&lt;/li&gt;
  &lt;li&gt;We will experiment various strategies to accelerate distributed training. For example, we will experiment fast and scalable graph partitioning algorithms to reduce network communication.&lt;/li&gt;
  &lt;li&gt;We will also add more demonstrations of other sampling strategies. For example, we will scale PinSage with our random walk sampler.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sampling-techniques-in-gnn&quot;&gt;Sampling techniques in GNN&lt;/h2&gt;

&lt;p&gt;Let’s use graph convolution network as an example to show these sampling techniques. Given a graph &lt;script type=&quot;math/tex&quot;&gt;G=(V, E)&lt;/script&gt;, represented as an adjacency matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt;, with node features &lt;script type=&quot;math/tex&quot;&gt;H^{(0)} = X \in \mathbb{R}^{|V| \times m}&lt;/script&gt;, graph convolution networks (GCNs) compute the hidden features &lt;script type=&quot;math/tex&quot;&gt;H^{(l+1)}&lt;/script&gt; of the &lt;script type=&quot;math/tex&quot;&gt;(l+1)&lt;/script&gt;-th layer by computing for each &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;h_v^{(l+1)} = \sigma ( z_v^{(l)} W^{(l)}) \qquad z_v^{(l)} = \sum_{u \in \mathcal{N}(v)} \tilde{A}_{uv} h_u^{(l)}&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(v)&lt;/script&gt; denotes the neighborhood of &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}&lt;/script&gt; is a normalized version of &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; such as &lt;script type=&quot;math/tex&quot;&gt;D^{-1} A&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\sigma(\cdot)&lt;/script&gt; is the activation function, &lt;script type=&quot;math/tex&quot;&gt;W^{(l)}&lt;/script&gt; is a trainable parameter of the &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;-th layer. For a &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-layer GCN model, the computation of &lt;script type=&quot;math/tex&quot;&gt;H^{(L)}&lt;/script&gt; requires the propagation from all of its &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-hop neighbors. This is too expensive in mini-batch training because the receptive field of a node grows exponentially with respective to the number of layers &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Neighbor Sampling&lt;/strong&gt;
Instead of using all the &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-hop neighbors of a node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;, neighbor sampling randomly samples a few neighbors &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathcal{N}}^{(l)}(v)&lt;/script&gt; to estimate the aggregation &lt;script type=&quot;math/tex&quot;&gt;z_v^{(l)}&lt;/script&gt; of its total neighbors &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(v)&lt;/script&gt; in &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;-th GCN layer by an unbiased estimator &lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{z}_v^{(l)} = \frac{\vert \mathcal{N}(v) \vert }{\vert \hat{\mathcal{N}}^{(l)}(v) \vert} \sum_{u \in \hat{\mathcal{N}}^{(l)}(v)} \tilde{A}_{uv} \hat{h}_u^{(l)} \\
\hat{h}_v^{(l+1)} = \sigma ( \hat{z}_v^{(l)} W^{(l)} )&lt;/script&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;D^{(l)}&lt;/script&gt; be the number of neighbors to be sampled for each node at the &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;-th layer, then the receptive field size of each node can be controlled under &lt;script type=&quot;math/tex&quot;&gt;\prod_{i=0}^{L-1} D^{(l)}&lt;/script&gt; by neighbor sampling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Layer-Wise Sampling&lt;/strong&gt;
In node-wise sampling, each parent node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; independently samples a few neighbors &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathcal{N}}(v)&lt;/script&gt;, which are not visible to other parent nodes &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; except &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;. The receptive field size still grows exponentially if &lt;script type=&quot;math/tex&quot;&gt;\vert \hat{\mathcal{N}}(v) \vert &gt; 1&lt;/script&gt;. In layer-wise sampling, the sampling procedure is performed only once in each layer, where each node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; gets sampled into &lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}^{(l)}&lt;/script&gt; with probability &lt;script type=&quot;math/tex&quot;&gt;p^{(l)}(v)&lt;/script&gt;,
&lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)} = \sum_{u \in \mathcal{S}^{(l)}} \frac{1}{p^{(l)}(u)} \tilde{A}_{uv} \hat{h}_u^{(l)}&lt;/script&gt;
The receptive field size can be controlled directly by &lt;script type=&quot;math/tex&quot;&gt;\vert \mathcal{S}^{(0)} \vert&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Random Walk Sampling&lt;/strong&gt;
Given a source node &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; and a decay factor &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;, a random walk from &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; is a trace beginning from &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt;, at each step either proceeds to a neighbor uniformly at random, or stop with probability &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;. The personalized PageRank (PPR) score &lt;script type=&quot;math/tex&quot;&gt;\pi(s, t)&lt;/script&gt; is the probability that a random walk from &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt; terminates at &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;In PinSage, each node &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; selects top-&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; important nodes with highest PPR scores with respective to &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; as its neighbors &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathcal{N}}(v)&lt;/script&gt;, and the hidden feature of each neighbor &lt;script type=&quot;math/tex&quot;&gt;u \in \hat{\mathcal{N}}(v)&lt;/script&gt; is weighted by &lt;script type=&quot;math/tex&quot;&gt;\pi(v, u)&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{z}^{(l)}_v = \frac{\sum_{u \in \hat{\mathcal{N}}(v)} \pi(v, u) \tilde{A}_{uv} \hat{h}_u^{(l)}}{\sum_{u \in \hat{\mathcal{N}}(v)} \pi(v, u)}&lt;/script&gt;

&lt;p&gt;Compared to GCNs which uses all the &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-hop neighbors, PinSage selects &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; topology-based important neighbors which have the largest influence.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Control Variate&lt;/strong&gt;
Although unbiased, sampling estimators such as &lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)}&lt;/script&gt; in neighbor sampling suffers from high variance, so it still requires a relatively large number of neighbors, e.g. &lt;script type=&quot;math/tex&quot;&gt;D^{(0)}=25&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;D^{(1)}=10&lt;/script&gt; in the GraphSage paper. With control variate, a standard variance reduction technique used in Monte Carlo methods, 2 neighbors for a node are sufficient in the experiments.&lt;/p&gt;

&lt;p&gt;Given a random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and we wish to estimate its expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [X] = \theta&lt;/script&gt;, the control variate method finds another random variable &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; which is highly correlated with &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and whose expectation &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E} [Y]&lt;/script&gt; can be easily computed. The control variate estimator is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z = X - Y + \mathbb{E} [Y]&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{VAR} [Z] = \mathbb{VAR} [X] + \mathbb{VAR} [Y] - 2 \cdot \mathbb{COV} [X, Y]&lt;/script&gt;
If &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\mathbb{VAR} [Y] - 2\mathbb{COV} [X, Y] &lt; 0 %]]&gt;&lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\mathbb{VAR} [Z] &lt; \mathbb{VAR} [X] %]]&gt;&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;For GCN, by using history &lt;script type=&quot;math/tex&quot;&gt;\bar{H}^{(l)}&lt;/script&gt; of the nodes which are not sampled, the modified estimator &lt;script type=&quot;math/tex&quot;&gt;\hat{z}_v^{(l)}&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{z}_v^{(l)} = \frac{\vert \mathcal{N}(v) \vert }{\vert \hat{\mathcal{N}}^{(l)}(v) \vert} \sum_{u \in \hat{\mathcal{N}}^{(l)}(v)} \tilde{A}_{uv} ( \hat{h}_u^{(l)} - \bar{h}_u^{(l)} ) + \sum_{u \in \mathcal{N}(v)} \tilde{A}_{uv} \bar{h}_u^{(l)}&lt;/script&gt;</content><author><name>Da Zheng</name></author><category term="blog" /><category term="blog" /><summary type="html">Many graph applications deal with giant scale. Social networks, recommendation and knowledge graphs have nodes and edges in the order of hundreds of millions or even billions of nodes. For example, a recent snapshot of the friendship network of Facebook contains 800 million nodes and over 100 billion links.</summary></entry></feed>